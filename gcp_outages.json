[
  {
    "begin": "2021-02-19T13:47:53Z",
    "created": "2021-02-19T13:50:30Z",
    "end": null,
    "external_desc": "We are experiencing an intermittent issue with Google Kubernetes Engine creation",
    "modified": "2021-02-19T18:27:06Z",
    "most-recent-update": {
      "created": "2021-02-19T18:27:06Z",
      "modified": "2021-02-19T18:27:06Z",
      "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine creation.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2021-02-19 11:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: intermittent issue with GKE cluster creation\n\nWorkaround: Retry the creation process",
      "when": "2021-02-19T18:27:06Z"
    },
    "number": 21004,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-19T18:27:06Z",
        "modified": "2021-02-19T18:27:06Z",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine creation.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2021-02-19 11:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: intermittent issue with GKE cluster creation\n\nWorkaround: Retry the creation process",
        "when": "2021-02-19T18:27:06Z"
      },
      {
        "created": "2021-02-19T17:29:51Z",
        "modified": "2021-02-19T17:29:51Z",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine creation.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2021-02-19 10:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: intermittent issue with GKE cluster creation\n\nWorkaround: Retry the creation process",
        "when": "2021-02-19T17:29:51Z"
      },
      {
        "created": "2021-02-19T16:05:41Z",
        "modified": "2021-02-19T16:05:41Z",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine creation.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2021-02-19 09:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: intermittent issue with GKE cluster creation\n\nWorkaround: Retry the creation process",
        "when": "2021-02-19T16:05:41Z"
      },
      {
        "created": "2021-02-19T13:50:31Z",
        "modified": "2021-02-19T13:50:31Z",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine creation.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2021-02-19 08:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: intermittent issue with GKE cluster creation\n\nWorkaround: Retry the creation process",
        "when": "2021-02-19T13:50:31Z"
      }
    ],
    "uri": "/incident/container-engine/21004"
  },
  {
    "begin": "2021-02-18T22:31:23Z",
    "created": "2021-02-18T22:46:21Z",
    "end": "2021-02-19T00:11:05Z",
    "external_desc": "Google App Engine Flex deployments are seeing increased errors in us-central1, us-east1 and us-east4, us-west3, europe-west6",
    "modified": "2021-02-19T00:11:06Z",
    "most-recent-update": {
      "created": "2021-02-19T00:11:05Z",
      "modified": "2021-02-19T00:11:05Z",
      "text": "The issue with Google App Engine Flex deployments seeing increased errors in us-central1, us-east1 and us-east4, us-west3, europe-west6 has been resolved for all affected users as of Thursday, 2021-02-18 15:00 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-02-19T00:11:05Z"
    },
    "number": 21004,
    "public": true,
    "service_key": "appengine",
    "service_name": "Google App Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-19T00:11:05Z",
        "modified": "2021-02-19T00:11:05Z",
        "text": "The issue with Google App Engine Flex deployments seeing increased errors in us-central1, us-east1 and us-east4, us-west3, europe-west6 has been resolved for all affected users as of Thursday, 2021-02-18 15:00 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-02-19T00:11:05Z"
      },
      {
        "created": "2021-02-18T23:48:23Z",
        "modified": "2021-02-18T23:48:23Z",
        "text": "Description: We believe the issue with Google App Engine deployments in us-central1, us-east1 and us-east4, us-west3, europe-west6 is partially resolved and error rates are improving.\n\nWe do not have an ETA for full resolution at this point, but are monitoring for full recovery.\n\nWe will provide an update by Thursday, 2021-02-18 16:30 US/Pacific with current details.\n\nDiagnosis: Customers impacted by this issue may see an increase in errors when deploying new versions of App Engine Flex applications.\n\nWorkaround: None at this time.",
        "when": "2021-02-18T23:48:23Z"
      },
      {
        "created": "2021-02-18T23:12:01Z",
        "modified": "2021-02-18T23:12:01Z",
        "text": "Description: We've received a report of an issue with Google App Engine Flex deployments in us-central1, us-east1 and us-east4, us-west3, europe-west6 as of Thursday, 2021-02-18 12:54 US/Pacific.  Mitigation appears to be effective and error rates are decreasing. We are working to speed up a full recovery and continuing to monitor the situation.\n\nExisting deployments are not impacted.\n\nWe will provide more information by Thursday, 2021-02-18 15:45 US/Pacific.\n\nLocations:\n\n* us-east1\n* europe-west6\n* us-east4\n* us-central1\n* us-west3\n\nDiagnosis: Customers impacted by this issue may see an increase in errors when deploying new versions of App Engine Flex applications.\n\nWorkaround: None at this time.",
        "when": "2021-02-18T23:12:01Z"
      },
      {
        "created": "2021-02-18T22:46:21Z",
        "modified": "2021-02-18T22:46:21Z",
        "text": "Description: We've received a report of an issue with Google App Engine Flex deployments in us-central1, us-east1 and us-east4, us-west3, europe-west6 as of Thursday, 2021-02-18 12:54 US/Pacific. A mitigation is being deployed and we are monitoring the situation. Existing deployments are not impacted.\n\nWe will provide more information by Thursday, 2021-02-18 15:30 US/Pacific.\n\nLocations:\n\n* us-east1\n* europe-west6\n* us-east4\n* us-central1\n* us-west3\n\nDiagnosis: Customers impacted by this issue may see an increase in errors when deploying new versions of App Engine Flex applications.\n\nWorkaround: None at this time.",
        "when": "2021-02-18T22:46:21Z"
      }
    ],
    "uri": "/incident/appengine/21004"
  },
  {
    "begin": "2021-02-18T21:43:44Z",
    "created": "2021-02-18T22:42:00Z",
    "end": "2021-02-18T23:43:06Z",
    "external_desc": "Cloud Function deployments are seeing increased errors in us-central1, us-east1 and us-east4",
    "modified": "2021-02-18T23:43:07Z",
    "most-recent-update": {
      "created": "2021-02-18T23:43:07Z",
      "modified": "2021-02-18T23:43:07Z",
      "text": "The issue with Google Cloud Functions deployments experiencing increased errors in us-central1, us-east1 and us-east4 has been resolved for all affected users as of Thursday, 2021-02-18 15:42 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-02-18T23:43:06Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "cloud-functions",
    "service_name": "Google Cloud Functions",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-18T23:43:07Z",
        "modified": "2021-02-18T23:43:07Z",
        "text": "The issue with Google Cloud Functions deployments experiencing increased errors in us-central1, us-east1 and us-east4 has been resolved for all affected users as of Thursday, 2021-02-18 15:42 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-02-18T23:43:06Z"
      },
      {
        "created": "2021-02-18T23:11:33Z",
        "modified": "2021-02-18T23:11:33Z",
        "text": "Description: We've received a report of an issue with Google Cloud Functions deployments in us-central1, us-east1, and us-east4 as of Thursday, 2021-02-18 12:54 US/Pacific. Mitigation appears to be effective and error rates are decreasing. We are working to speed up a full recovery and continuing to monitor the situation.\n\nWe will provide more information by Thursday, 2021-02-18 15:45 US/Pacific.\n\nLocations:\n\n* us-central1\n* us-east1\n* us-east4\n\nDiagnosis: Customers impacted by this issue may see increased errors deploying new versions of cloud functions in the impacted regions.\n\nWorkaround: None at this time.",
        "when": "2021-02-18T23:11:33Z"
      },
      {
        "created": "2021-02-18T22:42:01Z",
        "modified": "2021-02-18T22:42:01Z",
        "text": "Description: We've received a report of an issue with Google Cloud Functions deployments in us-central1, us-east1, and us-east4 as of Thursday, 2021-02-18 12:54 US/Pacific. A mitigation is being deployed and we are monitoring the situation. Existing deployments are not impacted.\n\nWe will provide more information by Thursday, 2021-02-18 15:30 US/Pacific.\n\nLocations:\n\n* us-central1\n* us-east1\n* us-east4\n\nDiagnosis: Customers impacted by this issue may see increased errors deploying new versions of cloud functions in the impacted regions.\n\nWorkaround: None at this time.",
        "when": "2021-02-18T22:42:01Z"
      }
    ],
    "uri": "/incident/cloud-functions/21001"
  },
  {
    "begin": "2021-02-18T21:18:09Z",
    "created": "2021-02-18T22:17:54Z",
    "end": "2021-02-19T00:59:43Z",
    "external_desc": "The issue with Google Compute Engine VM instance creation and deletion is partially resolved as of 15:14 US/Pacific.",
    "modified": "2021-02-19T00:59:44Z",
    "most-recent-update": {
      "created": "2021-02-19T00:59:44Z",
      "modified": "2021-02-19T00:59:44Z",
      "text": "The issue with Google Compute Engine VM creation and deletion has been resolved for all affected projects as of Thursday, 2021-02-18 16:56 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-02-19T00:59:43Z"
    },
    "number": 21002,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-19T00:59:44Z",
        "modified": "2021-02-19T00:59:44Z",
        "text": "The issue with Google Compute Engine VM creation and deletion has been resolved for all affected projects as of Thursday, 2021-02-18 16:56 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-02-19T00:59:43Z"
      },
      {
        "created": "2021-02-19T00:45:17Z",
        "modified": "2021-02-19T00:45:17Z",
        "text": "Description: The issue with Google Compute Engine VM instance creation and deletion is partially resolved. New VM instance creation and deletion requests as of 15:14 US/Pacific should succeed. \n\nWe are working through a backlog of creation and deletion requests that should complete in the next few hours and users may continue to see issues while we process this backlog.\n\nWe will provide an update by Thursday, 2021-02-18 18:00 US/Pacific with current details.\n\nDiagnosis: Users impacted by this may have been unable to create new instances in us-central1, any products that rely on creating GCE instances in us-central1 as part of a workflow may also have seen an increase in errors. Delete operations may also have experienced latency.\n\nWorkaround: Retrying operations may succeed.",
        "when": "2021-02-19T00:45:17Z"
      },
      {
        "created": "2021-02-18T23:54:35Z",
        "modified": "2021-02-18T23:54:35Z",
        "text": "Description: We believe the issue with Google Compute Engine VM instance creation and deletion is partially resolved. New VM instance creation requests as of 15:14 US/Pacific should succeed. We are working through a backlog of creation requests that should complete in the next few hours.\n\nCurrent list of known impacted products in us-central1:\nCompute Engine  \nKubernetes Engine  \nCloud AI  \nCloud SQL  \nCloud Dataproc  \n\nWe will provide an update by Thursday, 2021-02-18 16:30 US/Pacific with current details.\n\nDiagnosis: Users impacted by this may have been unable to create new instances in us-central1, any products that rely on creating GCE instances in us-central1 as part of a workflow may also have seen an increase in errors. Delete operations may also have experienced latency.\n\nWorkaround: Retrying operations may succeed.",
        "when": "2021-02-18T23:54:35Z"
      },
      {
        "created": "2021-02-18T23:11:33Z",
        "modified": "2021-02-18T23:11:33Z",
        "text": "Description: We are beginning to see recovery from applying the mitigation. We are continuing to monitor and exploring methods of increasing the rate of recovery.\n\nCurrent list of known impacted products in us-central1:\nCompute Engine  \nKubernetes Engine  \nApp Engine Flex  \nCloud Functions  \nCloud AI  \nCloud SQL  \nCloud Memorystore  \nCloud Filestore  \nCloud Dataproc  \nCloud Dataflow  \n\nWe will provide an update by Thursday, 2021-02-18 15:45 US/Pacific with current details.\n\nDiagnosis: Users may be unable to create new instances in us-central1, any products that rely on creating GCE instances in us-central1 as part of a workflow may also see an increase in errors. Delete operations may also experience latency.\n\nWorkaround: None at this time.",
        "when": "2021-02-18T23:11:33Z"
      },
      {
        "created": "2021-02-18T22:51:52Z",
        "modified": "2021-02-18T22:51:52Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine VM Instance creation in us-central1 beginning at Thursday, 2021-02-18 12:13 US/Pacific. We have begun rolling out a mitigation for the issue and are continuing to monitor.\n\nCurrent list of known impacted products:\nCompute Engine  \nKubernetes Engine  \nApp Engine Flex  \nCloud Functions  \nCloud AI  \n\nWe will provide an update by Thursday, 2021-02-18 15:15 US/Pacific with current details.\n\nDiagnosis: Users may be unable to create new VMs in us-central1, any products that rely on creating GCE instances in us-central1 as part of a workflow may also see an increase in errors. \n\nWorkaround: None at this time.",
        "when": "2021-02-18T22:51:52Z"
      },
      {
        "created": "2021-02-18T22:17:56Z",
        "modified": "2021-02-18T22:17:56Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine VM Instance creation in us-central1 beginning at Thursday, 2021-02-18 12:13 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2021-02-18 14:45 US/Pacific with current details.\n\nDiagnosis: Users may be unable to create new VMs in us-central1, any products that rely on GCE will be impacted by this.\n\nWorkaround: None at this time.",
        "when": "2021-02-18T22:17:56Z"
      }
    ],
    "uri": "/incident/compute/21002"
  },
  {
    "begin": "2021-02-18T20:13:00Z",
    "created": "2021-02-18T23:21:40Z",
    "end": "2021-02-19T00:47:04Z",
    "external_desc": "We are experiencing an issue with Cloud Dataproc in us-central1 starting at 12:13 US/Pacific.",
    "modified": "2021-02-19T00:47:05Z",
    "most-recent-update": {
      "created": "2021-02-19T00:47:05Z",
      "modified": "2021-02-19T00:47:05Z",
      "text": "Our engineers have determined this issue was mitigated at 16:14 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
      "when": "2021-02-19T00:47:04Z"
    },
    "number": 21003,
    "public": true,
    "service_key": "cloud-dataproc",
    "service_name": "Google Cloud Dataproc",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-19T00:47:05Z",
        "modified": "2021-02-19T00:47:05Z",
        "text": "Our engineers have determined this issue was mitigated at 16:14 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
        "when": "2021-02-19T00:47:04Z"
      },
      {
        "created": "2021-02-18T23:21:40Z",
        "modified": "2021-02-18T23:21:40Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "when": "2021-02-18T23:21:40Z"
      }
    ],
    "uri": "/incident/cloud-dataproc/21003"
  },
  {
    "begin": "2021-02-18T20:13:00Z",
    "created": "2021-02-18T23:20:01Z",
    "end": "2021-02-18T23:58:49Z",
    "external_desc": "We are experiencing an issue with Cloud Filestore in us-central1 starting at 12:13 US/Pacific.",
    "modified": "2021-02-18T23:58:49Z",
    "most-recent-update": {
      "created": "2021-02-18T23:58:49Z",
      "modified": "2021-02-18T23:58:49Z",
      "text": "Our engineers have determined this issue was mitigated at 15:28 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
      "when": "2021-02-18T23:58:49Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "cloud-filestore",
    "service_name": "Cloud Filestore",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-18T23:58:49Z",
        "modified": "2021-02-18T23:58:49Z",
        "text": "Our engineers have determined this issue was mitigated at 15:28 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
        "when": "2021-02-18T23:58:49Z"
      },
      {
        "created": "2021-02-18T23:20:01Z",
        "modified": "2021-02-18T23:20:01Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "when": "2021-02-18T23:20:01Z"
      }
    ],
    "uri": "/incident/cloud-filestore/21001"
  },
  {
    "begin": "2021-02-18T20:13:00Z",
    "created": "2021-02-18T23:17:02Z",
    "end": "2021-02-18T23:59:42Z",
    "external_desc": "We are experiencing an issue with Cloud Memorystore in us-central1 starting at 12:13 US/Pacific.",
    "modified": "2021-02-18T23:59:43Z",
    "most-recent-update": {
      "created": "2021-02-18T23:59:43Z",
      "modified": "2021-02-18T23:59:43Z",
      "text": "Our engineers have determined this issue was mitigated at 15:28 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
      "when": "2021-02-18T23:59:42Z"
    },
    "number": 21003,
    "public": true,
    "service_key": "cloud-memorystore",
    "service_name": "Cloud Memorystore",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-18T23:59:43Z",
        "modified": "2021-02-18T23:59:43Z",
        "text": "Our engineers have determined this issue was mitigated at 15:28 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
        "when": "2021-02-18T23:59:42Z"
      },
      {
        "created": "2021-02-18T23:17:02Z",
        "modified": "2021-02-18T23:17:02Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "when": "2021-02-18T23:17:02Z"
      }
    ],
    "uri": "/incident/cloud-memorystore/21003"
  },
  {
    "begin": "2021-02-18T20:13:00Z",
    "created": "2021-02-18T23:05:15Z",
    "end": "2021-02-19T00:48:39Z",
    "external_desc": "We are experiencing an issue with Cloud AI in us-central1 starting at 12:13 US/Pacific.",
    "modified": "2021-02-19T01:32:47Z",
    "most-recent-update": {
      "created": "2021-02-18T23:05:15Z",
      "modified": "2021-02-18T23:05:15Z",
      "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
      "when": "2021-02-18T23:05:15Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "cloud-ml",
    "service_name": "Cloud Machine Learning",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-18T23:05:15Z",
        "modified": "2021-02-18T23:05:15Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "when": "2021-02-18T23:05:15Z"
      }
    ],
    "uri": "/incident/cloud-ml/21001"
  },
  {
    "begin": "2021-02-18T20:13:00Z",
    "created": "2021-02-18T23:06:39Z",
    "end": "2021-02-19T00:13:25Z",
    "external_desc": "We are experiencing an issue with Cloud SQL instances in us-central1 starting at 12:13 US/Pacific.",
    "modified": "2021-02-19T00:13:26Z",
    "most-recent-update": {
      "created": "2021-02-19T00:13:25Z",
      "modified": "2021-02-19T00:13:25Z",
      "text": "Our engineers have determined this issue was mitigated at 15:46 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
      "when": "2021-02-19T00:13:25Z"
    },
    "number": 21004,
    "public": true,
    "service_key": "cloud-sql",
    "service_name": "Google Cloud SQL",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-19T00:13:25Z",
        "modified": "2021-02-19T00:13:25Z",
        "text": "Our engineers have determined this issue was mitigated at 15:46 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
        "when": "2021-02-19T00:13:25Z"
      },
      {
        "created": "2021-02-18T23:06:39Z",
        "modified": "2021-02-18T23:06:39Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "when": "2021-02-18T23:06:39Z"
      }
    ],
    "uri": "/incident/cloud-sql/21004"
  },
  {
    "begin": "2021-02-18T20:13:00Z",
    "created": "2021-02-18T22:44:37Z",
    "end": "2021-02-19T00:15:35Z",
    "external_desc": "We are experiencing an issue with Google Kubernetes Engine in us-central1 starting at 12:13 US/Pacific.",
    "modified": "2021-02-19T00:15:35Z",
    "most-recent-update": {
      "created": "2021-02-19T00:15:35Z",
      "modified": "2021-02-19T00:15:35Z",
      "text": "Our engineers have determined this issue was mitigated at 16:05 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
      "when": "2021-02-19T00:15:35Z"
    },
    "number": 21003,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-19T00:15:35Z",
        "modified": "2021-02-19T00:15:35Z",
        "text": "Our engineers have determined this issue was mitigated at 16:05 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
        "when": "2021-02-19T00:15:35Z"
      },
      {
        "created": "2021-02-18T22:44:37Z",
        "modified": "2021-02-18T22:44:37Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "when": "2021-02-18T22:44:37Z"
      }
    ],
    "uri": "/incident/container-engine/21003"
  },
  {
    "begin": "2021-02-12T22:51:10Z",
    "created": "2021-02-13T00:10:58Z",
    "end": "2021-02-13T02:55:46Z",
    "external_desc": "The issue with network configuration propagating for Cloud Networking VPN, Network Load Balancer VIPs, and VM Instances in multiple regions is resolved.",
    "modified": "2021-02-19T17:05:12Z",
    "most-recent-update": {
      "created": "2021-02-19T17:03:00Z",
      "modified": "2021-02-19T17:05:12Z",
      "text": "# ISSUE SUMMARY\r\n\r\nOn Friday, 12 February 2021, Google Cloud Networking experienced elevated packet loss for newly created, updated, deleted or migrated virtual machines (VMs) and network endpoints for a duration of 4 hours, 4 minutes. Network programming for VMs and network endpoints was also affected for the duration. To our customers whose businesses were impacted during this service disruption, we sincerely apologize – this is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability.\r\n\r\n# ROOT CAUSE\r\n\r\nGoogle Cloud's networking control plane has global components that are responsible for fanning-out network configurations that can affect an entire Virtual Private Cloud (VPC) network to downstream (regional/zonal) networking controllers. Work has been ongoing to better isolate global networking control plane components to limit scope of impact for issues that affect these global components. Cloud Networking also relies on a suite of automation tools to manage and enforce the quota of resources allocated to VPC networks. Some quotas are enforced with logic that will automatically remove resources when the quota is decreased, and reprocess previous resource operations when quota is increased.\r\n\r\nThe circumstances that led to this was a latent issue in the control plane quota enforcement logic. During routine handling of peering quota change requests, previous operations that were rejected due to a lack of available quota were being re-evaluated and re-processed by the networking control plane. While doing this re-evaluation, the networking control plane encountered the latent issue and could not process other incoming network programming operations, triggering timeouts for those requests. As VPC resources are multi-regional in nature, this also meant that newly created, updated, deleted or migrated VM resources in regions that required programming on the network control plane were not able to establish connectivity, resulting in elevated packet loss.\r\n\r\n# REMEDIATION AND PREVENTION\r\n\r\nOnce the nature and scope of the issue became clear, Google engineers paused VM migrations globally to prevent existing instances from being impacted. Networking quota changes were also paused to prevent a recurrence until a fix had been rolled out. The issue trigger was isolated to update operations, not initial load operations, so a rolling restart of the networking control plane was triggered to mitigate the issue. Teams worked through the weekend to ensure that recurrence was not possible by rolling out a fix globally.\r\n\r\nIn addition to fixing the underlying cause, we will be implementing changes to prevent and reduce the impact of this type of failure in several ways:\r\n\r\n1\\. Add health checks and automated restarts when the networking control plane responsible for peering operations becomes unresponsive\r\n\r\n2\\. Continue work to regionalize network control plane components to reduce scope of impact for future issues of this type\r\n\r\n3\\. Automatically pause VM migrations when high numbers of VMs are exhibiting networking issues\r\n\r\n4\\. Improve monitoring of network control plane operations to decrease time to mitigation for issues of this type\r\n\r\n5\\. Improve networking data plane resilience when the networking control plane is unresponsive\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\n\r\nOn Friday 12 February, 2021 from 14:51 to 18:55 US/Pacific, Cloud Networking control plane operations experienced increased error rates, and experienced elevated packet loss for both inter- and intra-region traffic.\r\n\r\n#### Cloud Networking\r\n\r\nElevated control plane operation error rates of up to 15% in most regions except for us-central1.  Region us-central1 experienced elevated control plane error rates of up to 50% between 15:00 and 16:15, dropping to values similar to other regions by 16:45. VM to VM traffic experienced up to 2.5% packet loss for intra-region traffic, and up to 3.5% loss for inter-region traffic.\r\n\r\n#### Cloud VPN\r\n\r\n1.4% of Cloud VPN tunnels in us-central1 lost connectivity from 15:12 to 17:00.\r\n\r\n#### Cloud Interconnect\r\nChanges to Cloud Interconnect resources experienced delayed propagation or failures during the incident.\r\n\r\n#### Compute Engine (GCE)\r\n\r\nNewly created, updated, deleted or migrated VMs failed to have networking set up during the incident. Existing instances that were not migrated or updated during the incident were not impacted.\r\n\r\n#### Kubernetes Engine (GKE)\r\n\r\nApproximately 1000 clusters were affected by the inability to provision new clusters or nodes. Node availability was impacted due to the impact to Cloud Networking and GCE instances for the duration of the incident.\r\n\r\n#### Cloud Dataproc\r\n\r\nCluster creation and update operations that created new nodes experienced failures during the incident due to the impact to GCE VM networking.\r\n\r\n#### Cloud Shell\r\n\r\nCloud Shell users assigned to us-central1 were unable to connect to Cloud Shell. Existing sessions were unaffected.\r\n\r\n#### Cloud SQL\r\n\r\n6.3% of instance creation operations failed globally between 14:55 and 17:52. Maintenance operations failed or timed out during the incident, but did not impact data plane availability on existing instances. Replica creation during the incident resulted in instances in a failed state, and were automatically recovered within 24 hours.\r\n\r\n#### Cloud Memorystore\r\n\r\nUp to 100% of instance creations failed between 15:15 and 18:20. Instances that were being live-migrated came up on new hosts without networking and faced connectivity issues until they recovered automatically.\r\n\r\n#### Cloud Data Fusion\r\n\r\nCloud Data Fusion instance creations failed during the incident due to failure to create GKE and Cloud SQL instances.\r\n\r\n#### Filestore\r\n\r\nA small number of Filestore instances were live-migrated during the incident. These newly migrated instances lost networking after the live migration before recovering on their own.\r\n\r\n#### Cloud Load Balancing\r\n\r\nCreate and update requests for global L7 external load balancers experienced up to 98% error rate between 15:17 and 18:15, and error rates up to 50% between 18:15 and 18:33. Create and update requests for regional L7 internal load balancers experienced up to 10% error rates, with us-central1 experiencing up to 70% error rates between 15:10 and 17:02.\r\n\r\n#### App Engine Flex\r\n\r\nUp to 80% of new deployments to App Engine Flex failed during the incident.",
      "when": "2021-02-19T17:02:59Z"
    },
    "number": 21002,
    "public": true,
    "service_key": "cloud-networking",
    "service_name": "Google Cloud Networking",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-19T17:03:00Z",
        "modified": "2021-02-19T17:05:12Z",
        "text": "# ISSUE SUMMARY\r\n\r\nOn Friday, 12 February 2021, Google Cloud Networking experienced elevated packet loss for newly created, updated, deleted or migrated virtual machines (VMs) and network endpoints for a duration of 4 hours, 4 minutes. Network programming for VMs and network endpoints was also affected for the duration. To our customers whose businesses were impacted during this service disruption, we sincerely apologize – this is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability.\r\n\r\n# ROOT CAUSE\r\n\r\nGoogle Cloud's networking control plane has global components that are responsible for fanning-out network configurations that can affect an entire Virtual Private Cloud (VPC) network to downstream (regional/zonal) networking controllers. Work has been ongoing to better isolate global networking control plane components to limit scope of impact for issues that affect these global components. Cloud Networking also relies on a suite of automation tools to manage and enforce the quota of resources allocated to VPC networks. Some quotas are enforced with logic that will automatically remove resources when the quota is decreased, and reprocess previous resource operations when quota is increased.\r\n\r\nThe circumstances that led to this was a latent issue in the control plane quota enforcement logic. During routine handling of peering quota change requests, previous operations that were rejected due to a lack of available quota were being re-evaluated and re-processed by the networking control plane. While doing this re-evaluation, the networking control plane encountered the latent issue and could not process other incoming network programming operations, triggering timeouts for those requests. As VPC resources are multi-regional in nature, this also meant that newly created, updated, deleted or migrated VM resources in regions that required programming on the network control plane were not able to establish connectivity, resulting in elevated packet loss.\r\n\r\n# REMEDIATION AND PREVENTION\r\n\r\nOnce the nature and scope of the issue became clear, Google engineers paused VM migrations globally to prevent existing instances from being impacted. Networking quota changes were also paused to prevent a recurrence until a fix had been rolled out. The issue trigger was isolated to update operations, not initial load operations, so a rolling restart of the networking control plane was triggered to mitigate the issue. Teams worked through the weekend to ensure that recurrence was not possible by rolling out a fix globally.\r\n\r\nIn addition to fixing the underlying cause, we will be implementing changes to prevent and reduce the impact of this type of failure in several ways:\r\n\r\n1\\. Add health checks and automated restarts when the networking control plane responsible for peering operations becomes unresponsive\r\n\r\n2\\. Continue work to regionalize network control plane components to reduce scope of impact for future issues of this type\r\n\r\n3\\. Automatically pause VM migrations when high numbers of VMs are exhibiting networking issues\r\n\r\n4\\. Improve monitoring of network control plane operations to decrease time to mitigation for issues of this type\r\n\r\n5\\. Improve networking data plane resilience when the networking control plane is unresponsive\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\n\r\nOn Friday 12 February, 2021 from 14:51 to 18:55 US/Pacific, Cloud Networking control plane operations experienced increased error rates, and experienced elevated packet loss for both inter- and intra-region traffic.\r\n\r\n#### Cloud Networking\r\n\r\nElevated control plane operation error rates of up to 15% in most regions except for us-central1.  Region us-central1 experienced elevated control plane error rates of up to 50% between 15:00 and 16:15, dropping to values similar to other regions by 16:45. VM to VM traffic experienced up to 2.5% packet loss for intra-region traffic, and up to 3.5% loss for inter-region traffic.\r\n\r\n#### Cloud VPN\r\n\r\n1.4% of Cloud VPN tunnels in us-central1 lost connectivity from 15:12 to 17:00.\r\n\r\n#### Cloud Interconnect\r\nChanges to Cloud Interconnect resources experienced delayed propagation or failures during the incident.\r\n\r\n#### Compute Engine (GCE)\r\n\r\nNewly created, updated, deleted or migrated VMs failed to have networking set up during the incident. Existing instances that were not migrated or updated during the incident were not impacted.\r\n\r\n#### Kubernetes Engine (GKE)\r\n\r\nApproximately 1000 clusters were affected by the inability to provision new clusters or nodes. Node availability was impacted due to the impact to Cloud Networking and GCE instances for the duration of the incident.\r\n\r\n#### Cloud Dataproc\r\n\r\nCluster creation and update operations that created new nodes experienced failures during the incident due to the impact to GCE VM networking.\r\n\r\n#### Cloud Shell\r\n\r\nCloud Shell users assigned to us-central1 were unable to connect to Cloud Shell. Existing sessions were unaffected.\r\n\r\n#### Cloud SQL\r\n\r\n6.3% of instance creation operations failed globally between 14:55 and 17:52. Maintenance operations failed or timed out during the incident, but did not impact data plane availability on existing instances. Replica creation during the incident resulted in instances in a failed state, and were automatically recovered within 24 hours.\r\n\r\n#### Cloud Memorystore\r\n\r\nUp to 100% of instance creations failed between 15:15 and 18:20. Instances that were being live-migrated came up on new hosts without networking and faced connectivity issues until they recovered automatically.\r\n\r\n#### Cloud Data Fusion\r\n\r\nCloud Data Fusion instance creations failed during the incident due to failure to create GKE and Cloud SQL instances.\r\n\r\n#### Filestore\r\n\r\nA small number of Filestore instances were live-migrated during the incident. These newly migrated instances lost networking after the live migration before recovering on their own.\r\n\r\n#### Cloud Load Balancing\r\n\r\nCreate and update requests for global L7 external load balancers experienced up to 98% error rate between 15:17 and 18:15, and error rates up to 50% between 18:15 and 18:33. Create and update requests for regional L7 internal load balancers experienced up to 10% error rates, with us-central1 experiencing up to 70% error rates between 15:10 and 17:02.\r\n\r\n#### App Engine Flex\r\n\r\nUp to 80% of new deployments to App Engine Flex failed during the incident.",
        "when": "2021-02-19T17:02:59Z"
      },
      {
        "created": "2021-02-13T03:55:46Z",
        "modified": "2021-02-13T03:55:46Z",
        "text": "The issue with network configuration propagating for Cloud Networking VPN, Network Load Balancer VIPs, and VM Instances in multiple regions has been resolved for all affected projects as of Friday, 2021-02-12 18:55 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-02-13T03:55:46Z"
      },
      {
        "created": "2021-02-13T03:10:34Z",
        "modified": "2021-02-13T03:10:34Z",
        "text": "Description: The mitigation has rolled out to all regions. We will continue to monitor the situation to ensure the issue does not recur before declaring full resolution.\n\nAll affected products should be recovered.\n\nWe will provide an update by Friday, 2021-02-12 20:00 US/Pacific\n\n\nDiagnosis: None at this time.\n\nWorkaround: Customers should now be able to continue using products as normal.",
        "when": "2021-02-13T03:10:34Z"
      },
      {
        "created": "2021-02-13T02:26:41Z",
        "modified": "2021-02-13T02:26:41Z",
        "text": "Description: Mitigation work is progressing as expected and we are continuing to see recovery. Mitigation is continuing to roll out in other regions. Mitigation is still expected to complete by 19:00 US/Pacific.\n\nNetwork connectivity within us-central1 should be fully recovered, however, some connectivity issues to other regions may persist while the mitigation completes roll out.\n\nCurrent known impacted products:  \nCompute Engine\nCloud SQL\nDataproc  \nMemorystore  \nApp Engine Flex\nCloud Composer\nKubernetes Engine\nCloud Data Fusion\n\nWe will provide an update by Friday, 2021-02-12 19:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Customers using Cloud VPN, creating new Network Load Balancer VIPs, and new VM Instances may not be able to achieve external connectivity. Existing configurations should be unaffected. Instances that have live-migrated within the impact period may experience connectivity loss. Cloud VPN tunnels may have been impacted between 14:50 and 15:31\n\nThis issue would impact services that rely on instances to function, dataproc cluster creation, new dataflow jobs, and App Engine Flex deployments may also be impacted.\n\n\nWorkaround: No workaround at this time. However, to reduce the likelihood of impact customers should pause autoscalers and other systems which may cause changes such as upgrades or deployments.",
        "when": "2021-02-13T02:26:41Z"
      },
      {
        "created": "2021-02-13T01:50:09Z",
        "modified": "2021-02-13T02:29:39Z",
        "text": "Description: Mitigation work is still underway by our engineering team and we are continuing to see recovery. We believe that mitigation has fully completed rolling out in the us-central1 region, and we are monitoring for recovery. Mitigation is continuing to roll out in other regions. We estimate mitigation to be fully complete by 19:00 US/Pacific.\r\n\r\nNetwork connectivity within us-central1 should be fully recovered, however, some connectivity issues to other regions may persist while the mitigation completes roll out.\r\n\r\nCurrent known impacted products:\r\n\r\nCompute Engine\r\n\r\nCloud SQL\r\n\r\nDataproc \r\n\r\nMemorystore\r\n\r\nApp Engine Flex\r\n\r\nCloud Composer\r\n\r\nKubernetes Engine\r\n\r\nCloud Data Fusion\r\n\r\nWe will provide an update by Friday, 2021-02-12 18:15 US/Pacific with current details.\r\n\r\nWe apologize to all who are affected by the disruption.\r\n\r\n\r\nDiagnosis: Customers using Cloud VPN, creating new Network Load Balancer VIPs, and new VM Instances with external IPs may not be able to achieve external connectivity. Existing configurations should be unaffected. Instances that have live-migrated within the impact period may experience connectivity loss. Cloud VPN tunnels may have been impacted between 14:50 and 15:31\r\n\r\nThis issue would impact services that rely on instances to function, dataproc cluster creation, new dataflow jobs, and App Engine Flex deployments may also be impacted.\r\n\r\nWorkaround: No workaround at this time. However, to reduce the likelihood of impact customers should pause autoscalers and other systems which may cause changes such as upgrades or deployments.",
        "when": "2021-02-13T01:50:09Z"
      },
      {
        "created": "2021-02-13T01:06:04Z",
        "modified": "2021-02-13T02:30:39Z",
        "text": "Description: Mitigation work is currently underway by our engineering team and we are starting to see recovery.\r\n\r\nWe do not have an ETA for mitigation at this point.\r\n\r\nCurrent known impacted products:\r\n\r\nCompute Engine\r\n\r\nCloud SQL\r\n\r\nDataproc\r\n\r\nMemorystore\r\n\r\nApp Engine Flex\r\n\r\nCloud Composer\r\n\r\nKubernetes Engine\r\n\r\nWe will provide more information by Friday, 2021-02-12 17:45 US/Pacific.\r\n\r\nDiagnosis: Customers using Cloud VPN, creating new Network Load Balancer VIPs, and new VM Instances with external IPs may not be able to achieve external connectivity. Existing configurations should be unaffected. \r\n\r\nThis issue would impact services that rely on instances to function, dataproc cluster creation, new dataflow jobs, and App Engine Flex deployments may also be impacted.\r\n\r\nWorkaround: No workaround at this time. However, to reduce the likelihood of impact customers should pause autoscalers and other systems which may cause changes such as upgrades or deployments.",
        "when": "2021-02-13T01:06:04Z"
      },
      {
        "created": "2021-02-13T00:45:03Z",
        "modified": "2021-02-13T02:31:01Z",
        "text": "Description: We are experiencing an issue with network configuration propagation for Cloud Networking VPN, Network Load Balancer VIPs, and VM Instance Public IPs in us-central1 with some impact in: us-east1, europe-west4, europe-west1, asia-east1, asia-northeast1, beginning at Friday, 2021-02-12 14:50 US/Pacific.\r\n\r\nConnectivity for existing configurations should not be impacted.\r\n\r\nCurrent known impacted products:\r\n\r\nCompute Engine\r\n\r\nCloud SQL\r\n\r\nDataproc\r\n\r\nMemorystore\r\n\r\nApp Engine Flex\r\n\r\nCloud Composer\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Friday, 2021-02-12 17:15 US/Pacific with current details.\r\n\r\nWe apologize to all who are affected by the disruption.\r\n\r\n\r\nDiagnosis: Customers using Cloud VPN, creating new Network Load Balancer VIPs, and new VM Instances with external IPs may not be able to achieve external connectivity. Existing configurations should be unaffected. \r\n\r\nThis issue would impact services that rely on instances to function, dataproc cluster creation, new dataflow jobs, and App Engine Flex deployments may also be impacted.\r\n\r\nWorkaround: No workaround at this time. However, to reduce the likelihood of impact customers should pause autoscalers and other systems which may cause changes such as upgrades or deployments.",
        "when": "2021-02-13T00:45:03Z"
      },
      {
        "created": "2021-02-13T00:10:59Z",
        "modified": "2021-02-13T00:10:59Z",
        "text": "Description: We are experiencing an issue with Cloud Networking VPN, Network Load Balancer VIPs, and VM Instance Public IPs in us-east1, us-central1, europe-west4, europe-west1, asia-east1, asia-northeast1, beginning at Friday, 2021-02-12 14:50 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2021-02-12 17:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Customers using Cloud VPN, creating new Network Load Balancer VIPs, and new VM Instances with external IPs may not be able to achieve external connectivity. Existing configurations should be unaffected. \n\nWorkaround: None at this time.",
        "when": "2021-02-13T00:10:59Z"
      }
    ],
    "uri": "/incident/cloud-networking/21002"
  },
  {
    "begin": "2021-02-12T22:50:18Z",
    "created": "2021-02-13T00:24:19Z",
    "end": "2021-02-13T03:16:01Z",
    "external_desc": "We are experiencing an issue with Google Cloud infrastructure components, beginning at Friday, 2021-02-12 14:50 US/Pacific.",
    "modified": "2021-02-13T03:16:01Z",
    "most-recent-update": {
      "created": "2021-02-13T03:16:01Z",
      "modified": "2021-02-13T03:16:01Z",
      "text": "For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
      "when": "2021-02-13T03:16:01Z"
    },
    "number": 21003,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-13T03:16:01Z",
        "modified": "2021-02-13T03:16:01Z",
        "text": "For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "when": "2021-02-13T03:16:01Z"
      },
      {
        "created": "2021-02-13T00:24:19Z",
        "modified": "2021-02-13T00:24:19Z",
        "text": "Description: We are experiencing an issue with Google Cloud infrastructure components, beginning at Friday, 2021-02-12 14:50 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2021-02-12 17:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2021-02-13T00:24:19Z"
      }
    ],
    "uri": "/incident/zall/21003"
  },
  {
    "begin": "2021-02-12T22:50:00Z",
    "created": "2021-02-13T00:56:34Z",
    "end": "2021-02-13T02:55:00Z",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident.  For regular status updates, please visit https://status.cloud.goog",
    "modified": "2021-02-13T03:28:03Z",
    "most-recent-update": {
      "created": "2021-02-13T03:28:03Z",
      "modified": "2021-02-13T03:28:03Z",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "when": "2021-02-13T02:55:00Z"
    },
    "number": 21003,
    "public": true,
    "service_key": "appengine",
    "service_name": "Google App Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-13T03:28:03Z",
        "modified": "2021-02-13T03:28:03Z",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "when": "2021-02-13T02:55:00Z"
      },
      {
        "created": "2021-02-13T00:56:34Z",
        "modified": "2021-02-13T00:56:34Z",
        "text": "Our engineers have determined this issue to be linked to a single Google incident.  For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002.  No further\r\n updates will be made through this incident.",
        "when": "2021-02-13T00:56:34Z"
      }
    ],
    "uri": "/incident/appengine/21003"
  },
  {
    "begin": "2021-02-12T22:50:00Z",
    "created": "2021-02-13T01:43:04Z",
    "end": "2021-02-13T02:55:00Z",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident.  For regular status updates, please visit https://status.cloud.goog",
    "modified": "2021-02-13T03:28:07Z",
    "most-recent-update": {
      "created": "2021-02-13T03:28:07Z",
      "modified": "2021-02-13T03:28:07Z",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "when": "2021-02-13T02:55:00Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "cloud-data-fusion",
    "service_name": "Cloud Data Fusion",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-13T03:28:07Z",
        "modified": "2021-02-13T03:28:07Z",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "when": "2021-02-13T02:55:00Z"
      },
      {
        "created": "2021-02-13T01:43:04Z",
        "modified": "2021-02-13T01:43:04Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "when": "2021-02-13T01:43:04Z"
      }
    ],
    "uri": "/incident/cloud-data-fusion/21001"
  },
  {
    "begin": "2021-02-12T22:50:00Z",
    "created": "2021-02-13T01:11:09Z",
    "end": "2021-02-13T02:55:00Z",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident.  For regular status updates, please visit https://status.cloud.goog",
    "modified": "2021-02-13T03:27:32Z",
    "most-recent-update": {
      "created": "2021-02-13T03:27:32Z",
      "modified": "2021-02-13T03:27:32Z",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "when": "2021-02-13T02:55:00Z"
    },
    "number": 21002,
    "public": true,
    "service_key": "cloud-dataproc",
    "service_name": "Google Cloud Dataproc",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-13T03:27:32Z",
        "modified": "2021-02-13T03:27:32Z",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "when": "2021-02-13T02:55:00Z"
      },
      {
        "created": "2021-02-13T01:11:09Z",
        "modified": "2021-02-13T01:11:09Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "when": "2021-02-13T01:11:09Z"
      }
    ],
    "uri": "/incident/cloud-dataproc/21002"
  },
  {
    "begin": "2021-02-12T22:50:00Z",
    "created": "2021-02-13T00:55:29Z",
    "end": "2021-02-13T02:55:00Z",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident.  For regular status updates, please visit https://status.cloud.goog",
    "modified": "2021-02-13T03:28:02Z",
    "most-recent-update": {
      "created": "2021-02-13T03:28:01Z",
      "modified": "2021-02-13T03:28:01Z",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "when": "2021-02-13T02:55:00Z"
    },
    "number": 21002,
    "public": true,
    "service_key": "cloud-memorystore",
    "service_name": "Cloud Memorystore",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-13T03:28:01Z",
        "modified": "2021-02-13T03:28:01Z",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "when": "2021-02-13T02:55:00Z"
      },
      {
        "created": "2021-02-13T00:55:29Z",
        "modified": "2021-02-13T00:55:29Z",
        "text": "Our engineers have determined this issue to be linked to a single Google incident.  For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002.  No further\r\n updates will be made through this incident.",
        "when": "2021-02-13T00:55:29Z"
      }
    ],
    "uri": "/incident/cloud-memorystore/21002"
  },
  {
    "begin": "2021-02-12T22:50:00Z",
    "created": "2021-02-13T01:06:56Z",
    "end": "2021-02-13T02:55:00Z",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident.  For regular status updates, please visit https://status.cloud.goog",
    "modified": "2021-02-13T03:28:26Z",
    "most-recent-update": {
      "created": "2021-02-13T03:28:26Z",
      "modified": "2021-02-13T03:28:26Z",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "when": "2021-02-13T02:55:00Z"
    },
    "number": 21003,
    "public": true,
    "service_key": "cloud-sql",
    "service_name": "Google Cloud SQL",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-13T03:28:26Z",
        "modified": "2021-02-13T03:28:26Z",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "when": "2021-02-13T02:55:00Z"
      },
      {
        "created": "2021-02-13T01:06:56Z",
        "modified": "2021-02-13T01:06:56Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "when": "2021-02-13T01:06:56Z"
      }
    ],
    "uri": "/incident/cloud-sql/21003"
  },
  {
    "begin": "2021-02-12T22:50:00Z",
    "created": "2021-02-13T01:14:15Z",
    "end": "2021-02-13T02:55:00Z",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident.  For regular status updates, please visit https://status.cloud.goog",
    "modified": "2021-02-13T03:28:20Z",
    "most-recent-update": {
      "created": "2021-02-13T03:28:20Z",
      "modified": "2021-02-13T03:28:20Z",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "when": "2021-02-13T02:55:00Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "composer",
    "service_name": "Google Cloud Composer",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-13T03:28:20Z",
        "modified": "2021-02-13T03:28:20Z",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "when": "2021-02-13T02:55:00Z"
      },
      {
        "created": "2021-02-13T01:14:15Z",
        "modified": "2021-02-13T01:14:15Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "when": "2021-02-13T01:14:15Z"
      }
    ],
    "uri": "/incident/composer/21001"
  },
  {
    "begin": "2021-02-12T22:50:00Z",
    "created": "2021-02-13T01:16:51Z",
    "end": "2021-02-13T02:55:00Z",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident.  For regular status updates, please visit https://status.cloud.goog",
    "modified": "2021-02-13T03:28:12Z",
    "most-recent-update": {
      "created": "2021-02-13T03:28:11Z",
      "modified": "2021-02-13T03:28:11Z",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "when": "2021-02-13T02:55:00Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-13T03:28:11Z",
        "modified": "2021-02-13T03:28:11Z",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "when": "2021-02-13T02:55:00Z"
      },
      {
        "created": "2021-02-13T01:16:51Z",
        "modified": "2021-02-13T01:16:51Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "when": "2021-02-13T01:16:51Z"
      }
    ],
    "uri": "/incident/compute/21001"
  },
  {
    "begin": "2021-02-12T22:50:00Z",
    "created": "2021-02-13T01:15:31Z",
    "end": "2021-02-13T02:55:00Z",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident.  For regular status updates, please visit https://status.cloud.goog",
    "modified": "2021-02-13T03:28:07Z",
    "most-recent-update": {
      "created": "2021-02-13T03:28:07Z",
      "modified": "2021-02-13T03:28:07Z",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "when": "2021-02-13T02:55:00Z"
    },
    "number": 21002,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-13T03:28:07Z",
        "modified": "2021-02-13T03:28:07Z",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "when": "2021-02-13T02:55:00Z"
      },
      {
        "created": "2021-02-13T01:15:32Z",
        "modified": "2021-02-13T01:15:32Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "when": "2021-02-13T01:15:32Z"
      }
    ],
    "uri": "/incident/container-engine/21002"
  },
  {
    "begin": "2021-02-11T19:50:44Z",
    "created": "2021-02-11T19:50:45Z",
    "end": "2021-02-11T20:05:20Z",
    "external_desc": "Cloud Datastore experiencing increased error rates and latencies for operations for data in the US multi-region",
    "modified": "2021-02-11T20:05:20Z",
    "most-recent-update": {
      "created": "2021-02-11T20:05:20Z",
      "modified": "2021-02-11T20:05:20Z",
      "text": "The issue with Cloud Datastore has been resolved for all affected users as of Thursday, 2021-02-11 12:05 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-02-11T20:05:20Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "cloud-datastore",
    "service_name": "Google Cloud Datastore",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-11T20:05:20Z",
        "modified": "2021-02-11T20:05:20Z",
        "text": "The issue with Cloud Datastore has been resolved for all affected users as of Thursday, 2021-02-11 12:05 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-02-11T20:05:20Z"
      },
      {
        "created": "2021-02-11T19:57:03Z",
        "modified": "2021-02-11T19:57:03Z",
        "text": "Description: Mitigation work is currently underway by our engineering team and we are noticing error rates and latencies return to normal levels.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Thursday, 2021-02-11 12:30 US/Pacific.\n\nDiagnosis: Elevated latencies and error rates for requests for data in the US multi-region.\n\nWorkaround: Retry requests/queries.",
        "when": "2021-02-11T19:57:03Z"
      },
      {
        "created": "2021-02-11T19:50:46Z",
        "modified": "2021-02-11T19:50:46Z",
        "text": "Description: We are experiencing an issue with Cloud Datastore where requests affecting data in the US multi-region are experiencing elevated latencies and error rates beginning at Thursday, 2021-02-11 11:09:33  US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nIf you are affected by this issue, please retry requests.\n\nWe will provide an update by Thursday, 2021-02-11 12:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Elevated latencies and error rates for requests for data in the US multi-region.\n\nWorkaround: Retry requests/queries.",
        "when": "2021-02-11T19:50:46Z"
      }
    ],
    "uri": "/incident/cloud-datastore/21001"
  },
  {
    "begin": "2021-02-11T19:30:47Z",
    "created": "2021-02-11T19:43:18Z",
    "end": "2021-02-11T20:04:40Z",
    "external_desc": "Cloud Firestore experiencing increased error rates and latencies for operations for data in the US multi-region",
    "modified": "2021-02-11T20:04:40Z",
    "most-recent-update": {
      "created": "2021-02-11T20:04:40Z",
      "modified": "2021-02-11T20:04:40Z",
      "text": "The issue with Cloud Firestore has been resolved for all affected users as of Thursday, 2021-02-11 12:04 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-02-11T20:04:40Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "cloud-firestore",
    "service_name": "Cloud Firestore",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-11T20:04:40Z",
        "modified": "2021-02-11T20:04:40Z",
        "text": "The issue with Cloud Firestore has been resolved for all affected users as of Thursday, 2021-02-11 12:04 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-02-11T20:04:40Z"
      },
      {
        "created": "2021-02-11T19:56:10Z",
        "modified": "2021-02-11T19:56:10Z",
        "text": "Description: Mitigation work is currently underway by our engineering team and we are noticing error rates and latencies return to normal levels.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Thursday, 2021-02-11 12:30 US/Pacific.\n\nDiagnosis: Elevated latencies and error rates for operations on data in the US multi-region. These include, queries, commits, listen API requests, and reads.\n\nWorkaround: Retry requests/queries.",
        "when": "2021-02-11T19:56:10Z"
      },
      {
        "created": "2021-02-11T19:47:41Z",
        "modified": "2021-02-11T19:47:41Z",
        "text": "Description: We are experiencing an issue with Cloud Firestore where operations (commits, listen API, reads, query) in the US multi-region are experiencing elevated latencies and error rates beginning at Thursday, 2021-02-11 11:09:33  US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nIf you are affected by this issue, please retry requests.\n\nWe will provide an update by Thursday, 2021-02-11 12:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Elevated latencies and error rates for operations on data in the US multi-region. These include, queries, commits, listen API requests, and reads.\n\nWorkaround: Retry requests/queries.",
        "when": "2021-02-11T19:47:41Z"
      },
      {
        "created": "2021-02-11T19:43:18Z",
        "modified": "2021-02-11T19:43:18Z",
        "text": "Description: We are experiencing an issue with Cloud Firestore where operations (commits, listen API, reads, query) in the US multi-region are experiencing elevated latencies and error rates beginning at Thursday, 2021-02-11 11:09:33  US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nIf you are affected by this issue, please retry requests.\n\nWe will provide an update by Thursday, 2021-02-11 12:18 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Elevated latencies and error rates for operations on data in the US multi-region. These include, queries, commits, listen API requests, and reads.\n\nWorkaround: Retry requests/queries.",
        "when": "2021-02-11T19:43:18Z"
      }
    ],
    "uri": "/incident/cloud-firestore/21001"
  },
  {
    "begin": "2021-02-11T19:15:44Z",
    "created": "2021-02-11T19:27:53Z",
    "end": "2021-02-11T20:11:18Z",
    "external_desc": "Google BigQuery experiencing increased error rates and latencies for queries for data in the US multi-region",
    "modified": "2021-02-11T20:11:19Z",
    "most-recent-update": {
      "created": "2021-02-11T20:11:18Z",
      "modified": "2021-02-11T20:11:18Z",
      "text": "The issue with Google BigQuery has been resolved for all affected users as of Thursday, 2021-02-11 12:05 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-02-11T20:11:18Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "bigquery",
    "service_name": "Google BigQuery",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-11T20:11:18Z",
        "modified": "2021-02-11T20:11:18Z",
        "text": "The issue with Google BigQuery has been resolved for all affected users as of Thursday, 2021-02-11 12:05 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-02-11T20:11:18Z"
      },
      {
        "created": "2021-02-11T19:54:40Z",
        "modified": "2021-02-11T19:54:40Z",
        "text": "Description: Mitigation work is currently underway by our engineering team and we are noticing error rates and latencies return to normal levels.\n\nWe expect mitigation to be complete by Thursday, 2021-02-11 13:00 US/Pacific.\n\nWe will provide more information by Thursday, 2021-02-11 12:30 US/Pacific.\n\nDiagnosis: Elevated latencies and error rates for queries for data in the US multi-region.\n\nWorkaround: Retry requests/queries.",
        "when": "2021-02-11T19:54:40Z"
      },
      {
        "created": "2021-02-11T19:46:52Z",
        "modified": "2021-02-11T19:46:52Z",
        "text": "Description: We are experiencing an issue with Google BigQuery where queries for data in the US multi-region are experiencing elevated latencies and error rates beginning at Thursday, 2021-02-11 11:09:33  US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nIf you are affected by this issue, please retry requests.\n\nWe will provide an update by Thursday, 2021-02-11 12:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Elevated latencies and error rates for queries for data in the US multi-region.\n\nWorkaround: Retry requests/queries.",
        "when": "2021-02-11T19:46:52Z"
      },
      {
        "created": "2021-02-11T19:27:53Z",
        "modified": "2021-02-11T19:27:53Z",
        "text": "Description: We are experiencing an issue with Google BigQuery where queries for data in the US multi-region are experiencing elevated latencies and error rates beginning at Thursday, 2021-02-11 11:09:33  US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nIf you are affected by this issue, please retry requests.\n\nWe will provide an update by Thursday, 2021-02-11 12:18 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Elevated latencies and error rates for queries for data in the US multi-region.\n\nWorkaround: Retry requests/queries.",
        "when": "2021-02-11T19:27:53Z"
      }
    ],
    "uri": "/incident/bigquery/21001"
  },
  {
    "begin": "2021-02-11T18:58:00Z",
    "created": "2021-02-11T22:07:35Z",
    "end": "2021-02-11T19:35:04Z",
    "external_desc": "Cloud BigTable is experiencing increased error rates and latencies for operations on data in us-central1-c.",
    "modified": "2021-02-11T22:11:02Z",
    "most-recent-update": {
      "created": "2021-02-11T22:09:04Z",
      "modified": "2021-02-11T22:09:04Z",
      "text": "The issue with Cloud Bigtable has been resolved for all affected projects as of Thursday, 2021-02-11 11:35 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-02-11T22:09:04Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "cloud-bigtable",
    "service_name": "Google Cloud Bigtable",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-11T22:09:04Z",
        "modified": "2021-02-11T22:09:04Z",
        "text": "The issue with Cloud Bigtable has been resolved for all affected projects as of Thursday, 2021-02-11 11:35 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-02-11T22:09:04Z"
      },
      {
        "created": "2021-02-11T22:07:35Z",
        "modified": "2021-02-11T22:07:35Z",
        "text": "Cloud BigTable is experiencing increased error rates and latencies for operations on data in us-central1-c starting at Thursday, 2021-02-11 11:58 US/Pacific.\r\n\r\nThe issue with Cloud Bigtable has been resolved for all affected projects as of Thursday, 2021-02-11 11:35 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-02-11T22:07:35Z"
      }
    ],
    "uri": "/incident/cloud-bigtable/21001"
  },
  {
    "begin": "2021-02-06T06:57:02Z",
    "created": "2021-02-06T07:24:24Z",
    "end": "2021-02-06T08:32:03Z",
    "external_desc": "Google App Engine services in multiple regions may experience errors ",
    "modified": "2021-02-06T08:32:03Z",
    "most-recent-update": {
      "created": "2021-02-06T08:32:03Z",
      "modified": "2021-02-06T08:32:03Z",
      "text": "The issue with Google App Engine has been resolved for all affected projects as of Saturday, 2021-02-06 00:25 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-02-06T08:32:03Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "appengine",
    "service_name": "Google App Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-06T08:32:03Z",
        "modified": "2021-02-06T08:32:03Z",
        "text": "The issue with Google App Engine has been resolved for all affected projects as of Saturday, 2021-02-06 00:25 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-02-06T08:32:03Z"
      },
      {
        "created": "2021-02-06T07:55:37Z",
        "modified": "2021-02-06T07:55:37Z",
        "text": "Description: We believe the issue with Google App Engine is partially resolved.\n\nWe do not have an ETA for full resolution at this point.\n\nWe will provide an update by Saturday, 2021-02-06 01:20 US/Pacific with current details.\n\nDiagnosis: Increased errors and elevated latency.\n\nWorkaround: None at this time.",
        "when": "2021-02-06T07:55:37Z"
      },
      {
        "created": "2021-02-06T07:27:43Z",
        "modified": "2021-02-06T07:27:43Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\n\nThe mitigation is expected to complete by Saturday, 2021-02-06 00:00 US/Pacific.\n\nWe will provide more information by Saturday, 2021-02-06 00:21 US/Pacific.\n\nDiagnosis: Increased errors and elevated latency.\n\nWorkaround: None at this time.",
        "when": "2021-02-06T07:27:43Z"
      },
      {
        "created": "2021-02-06T07:24:25Z",
        "modified": "2021-02-06T07:24:25Z",
        "text": "Description: We are experiencing an issue with Google App Engine, beginning at Friday, 2021-02-05 22:15 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2021-02-05 23:53 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Increased errors and elevated latency.\n\nWorkaround: None at this time.",
        "when": "2021-02-06T07:24:25Z"
      }
    ],
    "uri": "/incident/appengine/21001"
  },
  {
    "begin": "2021-02-02T01:17:39Z",
    "created": "2021-02-02T01:48:13Z",
    "end": "2021-02-02T02:20:10Z",
    "external_desc": "GKE cluster operations may fail in various regions.",
    "modified": "2021-02-02T02:20:10Z",
    "most-recent-update": {
      "created": "2021-02-02T02:20:10Z",
      "modified": "2021-02-02T02:20:10Z",
      "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Monday, 2021-02-01 18:19 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-02-02T02:20:10Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-02-02T02:20:10Z",
        "modified": "2021-02-02T02:20:10Z",
        "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Monday, 2021-02-01 18:19 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-02-02T02:20:10Z"
      },
      {
        "created": "2021-02-02T01:48:13Z",
        "modified": "2021-02-02T01:48:13Z",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Monday, 2021-02-01 18:32 US/Pacific with current details.\n\nLocations:\n* asia-east2\n* asia-northeast2\n* asia-northeast3\n* asia-southeast2\n* europe-north1\n* us-central1\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Clusters and node-pool creation operation may ended up with an error.\n\nWorkaround: None at this time.",
        "when": "2021-02-02T01:48:13Z"
      }
    ],
    "uri": "/incident/container-engine/21001"
  },
  {
    "begin": "2021-01-29T17:39:24Z",
    "created": "2021-01-29T20:52:13Z",
    "end": "2021-01-30T03:45:31Z",
    "external_desc": "The issue with Cloud SQL API instance mutations and SQL Proxy operations in us-central1 has partially recovered",
    "modified": "2021-01-30T03:45:32Z",
    "most-recent-update": {
      "created": "2021-01-30T03:45:32Z",
      "modified": "2021-01-30T03:45:32Z",
      "text": "The issue with Cloud SQL API instance mutations and SQL Proxy operations has been resolved for all affected users as of Friday, 2021-01-29 18:45 US/Pacific.\n\nAll operations including instance restart and delete are healthy.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-01-30T03:45:31Z"
    },
    "number": 21002,
    "public": true,
    "service_key": "cloud-sql",
    "service_name": "Google Cloud SQL",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-01-30T03:45:32Z",
        "modified": "2021-01-30T03:45:32Z",
        "text": "The issue with Cloud SQL API instance mutations and SQL Proxy operations has been resolved for all affected users as of Friday, 2021-01-29 18:45 US/Pacific.\n\nAll operations including instance restart and delete are healthy.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-01-30T03:45:31Z"
      },
      {
        "created": "2021-01-30T02:59:39Z",
        "modified": "2021-01-30T02:59:39Z",
        "text": "Description: The issue with Cloud SQL API instance mutations and SQL Proxy operations in us-central1 has partially recovered. We believe impact began at 08:50 US/Pacific with the error rate increasing starting at 09:25 US/Pacific. Partial recovery occurred at 14:54 US/Pacific\n\nOur engineering team has rolled out a mitigation and partially resolved the issue. We believe most of the service has recovered. At this time we believe only instances.delete and instances.restart continue to be impacted. Some operations such as instances.patch which require an instance.restart may also be impacted. The product team has identified the root cause of the issue and has begun implementing a fix.\n\nThe product team has started rolling out the potential fix. We are monitoring the effects of this rollout to determine if the fix has solved the issue.\n\nWe will provide an update by Friday, 2021-01-29 20:00 US/Pacific with current details.\n\n\n\nDiagnosis: Customers impacted by this issue may see increased latency or errors when performing Instance mutation requests, such as create, delete and update. Connection to Cloud SQL instances may be disrupted if a new ephemeral cert is required by the Cloud SQL Proxy. Errors returned may be 502 or 503.\n\nWorkaround: None at this time. We believe other regions are not impacted at this time.",
        "when": "2021-01-30T02:59:39Z"
      },
      {
        "created": "2021-01-30T00:28:50Z",
        "modified": "2021-01-30T00:28:50Z",
        "text": "Description: The issue with Cloud SQL API instance mutations and SQL Proxy operations in us-central1 has partially recovered. We believe impact began at 08:50 US/Pacific with the error rate increasing starting at 09:25 US/Pacific. Partial recovery occurred at 14:54 US/Pacific\n\nOur engineering team has rolled out a mitigation and partially resolved the issue. We believe most of the service has recovered. At this time we believe only instances.delete and instances.restart continue to be impacted. Some operations such as instances.patch which require an instance.restart may also be impacted. The product team has identified the root cause of the issue and has begun implementing a fix. We expect that the Cloud SQL API will remain in the current partially resolved state for several hours until the fix is fully verified and rolled out.\n\nWe will provide an update by Friday, 2021-01-29 19:00 US/Pacific with current details.\n\n\n\nDiagnosis: Customers impacted by this issue may see increased latency or errors when performing Instance mutation requests, such as create, delete and update. Connection to Cloud SQL instances may be disrupted if a new ephemeral cert is required by the Cloud SQL Proxy. Errors returned may be 502 or 503.\n\nWorkaround: None at this time. We believe other regions are not impacted at this time.",
        "when": "2021-01-30T00:28:50Z"
      },
      {
        "created": "2021-01-29T23:31:04Z",
        "modified": "2021-01-29T23:31:04Z",
        "text": "Description: The issue with Cloud SQL API instance mutations and SQL Proxy operations in us-central1 has partially recovered. We believe impact began at 08:50 US/Pacific with the error rate increasing starting at 09:25 US/Pacific. Partial recovery occurred at 14:54 US/Pacific\n\nOur engineering team has rolled out a mitigation and partially resolved the issue. We believe most of the service has recovered. At this time we believe only instances.delete and instances.restart continue to be impacted. Some operations such as instances.patch which require an instance.restart may also be impacted. We are working on further mitigation to bring the service back to a nominal operating state.\n\nWe will provide an update by Friday, 2021-01-29 16:30 US/Pacific with current details.\n\n\nDiagnosis: Customers impacted by this issue may see increased latency or errors when performing Instance mutation requests, such as create, delete and update. Connection to Cloud SQL instances may be disrupted if a new ephemeral cert is required by the Cloud SQL Proxy. Errors returned may be 502 or 503.\n\nWorkaround: None at this time. We believe other regions are not impacted at this time.",
        "when": "2021-01-29T23:31:04Z"
      },
      {
        "created": "2021-01-29T22:38:04Z",
        "modified": "2021-01-29T22:38:04Z",
        "text": "Description: We are experiencing an issue with Cloud SQL API instance mutations and SQL Proxy operations in us-central1. We believe impact began at 08:50 US/Pacific with the error rate increasing starting at 09:25 US/Pacific.\n\nOur engineering team continues to investigate the issue. Instance mutation operations (such as instances.create or instances.delete) as well as requests for certificates (sslCerts.createEphemeral) when using Cloud SQL Proxy are impacted. Existing connections to Cloud SQL instances should be unaffected. New connections without Cloud SQL Proxy are also unaffected.\n\nThe product team has identified a potential mitigation and is working to implement it. We believe the change will be finished rolling out by 15:00 US/Pacific, we will be continuously monitoring the service to evaluate the effectiveness of the mitigation. \n\nWe will provide an update by Friday, 2021-01-29 15:30 US/Pacific with current details.\n\n\nDiagnosis: Customers impacted by this issue may see increased latency or errors when performing Instance mutation requests, such as create, delete and update. Connection to Cloud SQL instances may be disrupted if a new ephemeral cert is required by the Cloud SQL Proxy. Errors returned may be 502 or 503.\n\n\nWorkaround: None at this time. We believe other regions are not impacted at this time.",
        "when": "2021-01-29T22:38:04Z"
      },
      {
        "created": "2021-01-29T21:59:53Z",
        "modified": "2021-01-29T21:59:53Z",
        "text": "Description: We are experiencing an issue with Cloud SQL API instance mutations in us-central1. We believe impact began at 08:50 US/Pacific with the error rate increasing starting at 09:25 US/Pacific.\n\nOur engineering team continues to investigate the issue. Instance mutation operations (such as instances.create or instances.delete) as well as requests for certificates (sslCerts.createEphemeral) when using Cloud SQL Proxy are impacted. Existing connections to Cloud SQL instances should be unaffected.\n\nThe product team has identified a potential mitigation and is working to implement it. As part of the mitigation, all requests to instances delete and instances restart will receive an error.\n\nWe will provide an update by Friday, 2021-01-29 15:00 US/Pacific with current details.\n\n\nDiagnosis: Customers impacted by this issue may see increased latency or errors when performing Instance mutation requests, such as create, delete and update. Connection to Cloud SQL instances may be disrupted if a new ephemeral cert is required by the Cloud SQL Proxy. Errors returned may be 502 or 503.\n\nWorkaround: None at this time. We believe other regions are not impacted at this time.",
        "when": "2021-01-29T21:59:53Z"
      },
      {
        "created": "2021-01-29T21:41:52Z",
        "modified": "2021-01-29T21:41:52Z",
        "text": "Description: We are experiencing an issue with Cloud SQL.\n\nOur engineering team continues to investigate the issue. New instance creation, other instance operations, and SQL queries to already existing instances may be failing.  We are troubleshooting the error at this time.\n\nWe will provide an update by Friday, 2021-01-29 16:00 US/Pacific with current details.\n\nDiagnosis: Instance creation, operations, and queries in us-central1 region may result in 502 (backend timeout) or 503 (service unavailable) errors.\n\nCustomers may also experience Cloud SQL Proxy connectivity related issues, due in part to this incident.\n\nWorkaround: None at this time.",
        "when": "2021-01-29T21:41:52Z"
      },
      {
        "created": "2021-01-29T20:52:14Z",
        "modified": "2021-01-29T20:52:14Z",
        "text": "Description: We are experiencing an issue with Cloud SQL.\n\nOur engineering team continues to investigate the issue. New instance creation, other instance operations, and SQL queries to already existing instances may be failing.  We are troubleshooting the error at this time.\n\nWe will provide an update by Friday, 2021-01-29 16:00 US/Pacific with current details.\n\nDiagnosis: Instance creation, operations, and queries in us-central1 region may result in 502 (backend timeout) or 503 (service unavailable) errors.\n\nWorkaround: None at this time.",
        "when": "2021-01-29T20:52:14Z"
      },
      {
        "created": "2021-01-29T21:01:31Z",
        "modified": "2021-01-29T21:01:31Z",
        "text": "Description: We are experiencing an issue with Cloud SQL.\r\n\r\nOur engineering team continues to investigate the issue. New instance creation, other instance operations, and SQL queries to already existing instances may be failing.\r\n\r\nWe will provide an update by Friday, 2021-01-29 13:00 US/Pacific with current details.\r\n\r\nDiagnosis: Instance creation, operations, and queries in us-central1 region may result in 502 (backend timeout) or 503 (service unavailable) errors.\r\n\r\nWorkaround: None at this time.",
        "when": "2021-01-29T20:16:00Z"
      }
    ],
    "uri": "/incident/cloud-sql/21002"
  },
  {
    "begin": "2021-01-21T23:55:40Z",
    "created": "2021-01-22T00:26:46Z",
    "end": "2021-01-22T03:17:48Z",
    "external_desc": "We are experiencing an issue with Cloud DNS CNAME chasing in multiple zones.",
    "modified": "2021-01-22T03:17:49Z",
    "most-recent-update": {
      "created": "2021-01-22T03:17:49Z",
      "modified": "2021-01-22T03:17:49Z",
      "text": "The issue with Cloud DNS has been resolved for all affected projects as of Thursday, 2021-01-21 19:17 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-01-22T03:17:48Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "cloud-dns",
    "service_name": "Google Cloud DNS",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-01-22T03:17:49Z",
        "modified": "2021-01-22T03:17:49Z",
        "text": "The issue with Cloud DNS has been resolved for all affected projects as of Thursday, 2021-01-21 19:17 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-01-22T03:17:48Z"
      },
      {
        "created": "2021-01-22T02:48:04Z",
        "modified": "2021-01-22T02:48:04Z",
        "text": "Description: Customers using CNAME chasing may experience an issue with Cloud DNS. Querying for a record defined in one private zone that points to a record in another private zone does not return the final answer. See https://cloud.google.com/dns/docs/cnamechasing for more details about CNAME chasing.\n\nThe following zones are known to be impacted currently: us-east1-d\n\nMitigation work is currently underway by our engineering team. The mitigation is expected to complete by Thursday, 2021-01-21 19:15 US/Pacific.\n\nWe will provide more information by Thursday, 2021-01-21 19:15 US/Pacific.\n\nDiagnosis: CNAME chasing between private zone to private zone is not working.\n\nWorkaround: None at this time.",
        "when": "2021-01-22T02:48:04Z"
      },
      {
        "created": "2021-01-22T02:16:10Z",
        "modified": "2021-01-22T02:16:10Z",
        "text": "Description: Customers using CNAME chasing may experience an issue with Cloud DNS. Querying for a record defined in one private zone that points to a record in another private zone does not return the final answer. See https://cloud.google.com/dns/docs/cnamechasing for more details about CNAME chasing.\n\nThe following zones are known to be impacted currently:\n\neurope-west1-c\nus-east1-d\nus-west1-a\n\nMitigation work is currently underway by our engineering team. The mitigation is expected to complete by Thursday, 2021-01-21 18:45 US/Pacific.\n\nWe will provide more information by Thursday, 2021-01-21 18:45 US/Pacific.\n\nDiagnosis: CNAME chasing between private zone to private zone is not working.\n\nWorkaround: None at this time.",
        "when": "2021-01-22T02:16:10Z"
      },
      {
        "created": "2021-01-22T01:39:18Z",
        "modified": "2021-01-22T01:43:10Z",
        "text": "Description: Customers using CNAME chasing may experience an issue with Cloud DNS. Querying for a record defined in one private zone that points to a record in another private zone does not return the final answer. See https://cloud.google.com/dns/docs/cnamechasing for more details about CNAME chasing.\r\n\r\nThe following zones are known to be impacted currently:\r\n\r\nasia-east1-a\r\naustralia-southeast1-a\r\neurope-west1-c\r\neurope-west2-a\r\nus-east1-d\r\nus-west1-a\r\n\r\nMitigation work is currently underway by our engineering team. The mitigation is expected to complete by Thursday, 2021-01-21 18:30 US/Pacific.\r\n\r\nWe will provide more information by Thursday, 2021-01-21 18:15 US/Pacific.\r\n\r\nDiagnosis: CNAME chasing between private zone to private zone is not working.\r\n\r\nWorkaround: None at this time.",
        "when": "2021-01-22T01:39:18Z"
      },
      {
        "created": "2021-01-22T01:31:59Z",
        "modified": "2021-01-22T02:17:49Z",
        "text": "Description: Customers using CNAME chasing may experience an issue with Cloud DNS. Querying for a record defined in one private zone that points to a record in another private zone does not return the final answer. See https://cloud.google.com/dns/docs/cnamechasing for more details about CNAME chasing.\r\n\r\nMitigation work is currently underway by our engineering team.\r\n\r\nThe following zones are known to be impacted: \r\n\r\nasia-east1-a\r\nasia-east2-c\r\nasia-northeast1-a\r\nasia-northeast2-c\r\nasia-northeast3-c\r\nasia-south1-a\r\nasia-southeast1-a\r\nasia-southeast2-c\r\naustralia-southeast1-a\r\neurope-west1-c\r\neurope-west2-a\r\neurope-west3-a\r\neurope-west6-c\r\nsouthamerica-east1-a\r\nus-central1-d\r\nus-east1-d\r\nus-west1-a\r\nus-west2-c\r\nus-west3-c\r\nus-west4-c\r\n\r\nWe do not have an ETA for mitigation at this point.\r\n\r\nWe will provide more information by Thursday, 2021-01-21 18:00 US/Pacific.\r\n\r\nDiagnosis: CNAME chasing between private zone to private zone is not working.\r\n\r\nWorkaround: None at this time.",
        "when": "2021-01-22T01:31:59Z"
      },
      {
        "created": "2021-01-22T00:26:46Z",
        "modified": "2021-01-22T02:18:23Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\r\n\r\nThe following zones are known to be impacted: \r\n\r\nasia-east1-a  \r\nasia-east2-c  \r\nasia-northeast1-a  \r\nasia-northeast2-c  \r\nasia-northeast3-c  \r\nasia-south1-a  \r\nasia-southeast1-a  \r\nasia-southeast2-c  \r\naustralia-southeast1-a  \r\neurope-west1-c  \r\neurope-west2-a  \r\neurope-west3-a  \r\neurope-west6-c  \r\nsouthamerica-east1-a  \r\nus-central1-d    \r\nus-east1-d  \r\nus-west1-a  \r\nus-west2-c  \r\nus-west3-c  \r\nus-west4-c  \r\n\r\nWe do not have an ETA for mitigation at this point.\r\n\r\nWe will provide more information by Thursday, 2021-01-21 17:30 US/Pacific.\r\n\r\nDiagnosis: CNAME chasing between private zone to private zone is not working.\r\n\r\nWorkaround: None at this time.",
        "when": "2021-01-22T00:26:46Z"
      }
    ],
    "uri": "/incident/cloud-dns/21001"
  },
  {
    "begin": "2021-01-19T19:12:54Z",
    "created": "2021-01-19T20:06:01Z",
    "end": "2021-01-19T21:57:23Z",
    "external_desc": "We are experiencing network latency in us-central1 and us-east1",
    "modified": "2021-01-19T22:12:58Z",
    "most-recent-update": {
      "created": "2021-01-19T21:57:23Z",
      "modified": "2021-01-19T21:57:23Z",
      "text": "The issue with Google Cloud infrastructure components is believed to be currently affecting a very small number of projects and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nNo further updates will be provided here.\n\nWe thank you for your patience while we're working on resolving the issue.",
      "when": "2021-01-19T21:57:23Z"
    },
    "number": 21002,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-01-19T21:57:23Z",
        "modified": "2021-01-19T21:57:23Z",
        "text": "The issue with Google Cloud infrastructure components is believed to be currently affecting a very small number of projects and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nNo further updates will be provided here.\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2021-01-19T21:57:23Z"
      },
      {
        "created": "2021-01-19T21:40:17Z",
        "modified": "2021-01-19T22:12:58Z",
        "text": "Description: We believe the issue with Google Cloud infrastructure components is partially resolved and risk of reoccurrence is low. The last event with this issue happened at 11:39 AM US/Pacific\r\n\r\nWe do not have an ETA for full resolution at this point.\r\n\r\nWe will provide an update by Tuesday, 2021-01-19 15:00 US/Pacific with current details.\r\n\r\nDiagnosis: Cloud Networking traffic going through us-central1 and us-east1 shows increased latency.\r\n\r\nWorkaround: None at this time.",
        "when": "2021-01-19T21:40:17Z"
      },
      {
        "created": "2021-01-19T21:25:19Z",
        "modified": "2021-01-19T22:12:42Z",
        "text": "Description: Our engineering team has determined that further investigation is required to mitigate the issue. The issue remains intermittent.\r\n\r\nWe will provide an update by Tuesday, 2021-01-19 14:00 US/Pacific with current details.\r\n\r\nDiagnosis: Cloud Networking traffic going through us-central1 and us-east1 shows increased latency.\r\n\r\nWorkaround: None at this time.",
        "when": "2021-01-19T21:25:18Z"
      },
      {
        "created": "2021-01-19T20:06:02Z",
        "modified": "2021-01-19T22:12:23Z",
        "text": "Description: We are experiencing an intermittent issue with Google Cloud infrastructure components, the issue manifests itself as periods of increased latency every 30 minutes, beginning at Tuesday, 2021-01-19 07:50:00 US/Pacific.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Tuesday, 2021-01-19 13:30 US/Pacific with current details.\r\n\r\nDiagnosis: Cloud Networking traffic going through us-central1 and us-east1 shows increased latency.\r\n\r\nWorkaround: None at this time.",
        "when": "2021-01-19T20:06:02Z"
      }
    ],
    "uri": "/incident/zall/21002"
  },
  {
    "begin": "2021-01-15T13:29:29Z",
    "created": "2021-01-15T13:34:25Z",
    "end": "2021-01-15T15:05:47Z",
    "external_desc": "We are experiencing an issue with Cloud Interconnect ",
    "modified": "2021-01-15T15:05:48Z",
    "most-recent-update": {
      "created": "2021-01-15T15:05:48Z",
      "modified": "2021-01-15T15:05:48Z",
      "text": "The issue with Cloud Interconnect has been resolved for all affected projects as of Friday, 2021-01-15 06:53 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-01-15T15:05:47Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "cloud-networking",
    "service_name": "Google Cloud Networking",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-01-15T15:05:48Z",
        "modified": "2021-01-15T15:05:48Z",
        "text": "The issue with Cloud Interconnect has been resolved for all affected projects as of Friday, 2021-01-15 06:53 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-01-15T15:05:47Z"
      },
      {
        "created": "2021-01-15T14:14:09Z",
        "modified": "2021-01-15T14:14:09Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Friday, 2021-01-15 07:25 US/Pacific.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2021-01-15T14:14:09Z"
      },
      {
        "created": "2021-01-15T13:34:26Z",
        "modified": "2021-01-15T13:34:26Z",
        "text": "Description: We are experiencing an issue with Cloud Interconnect beginning at Friday, 2021-01-15 04:36:30 PST.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2021-01-15 06:15 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2021-01-15T13:34:26Z"
      }
    ],
    "uri": "/incident/cloud-networking/21001"
  },
  {
    "begin": "2021-01-14T01:05:22Z",
    "created": "2021-01-14T20:15:47Z",
    "end": "2021-01-19T21:03:12Z",
    "external_desc": "We are experiencing an issue with Cloud SDK Versions 321, 322 and 323 Installed on Windows.",
    "modified": "2021-01-19T21:03:13Z",
    "most-recent-update": {
      "created": "2021-01-19T21:03:12Z",
      "modified": "2021-01-19T21:03:12Z",
      "text": "The issue with Cloud Developer Tools has been resolved for all affected users as of Tuesday, 2021-01-19 12:58 US/Pacific.\n\nPlease see workaround for detailed instructions\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-01-19T21:03:12Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "support",
    "service_name": "Google Cloud Support",
    "severity": "medium",
    "updates": [
      {
        "created": "2021-01-19T21:03:12Z",
        "modified": "2021-01-19T21:03:12Z",
        "text": "The issue with Cloud Developer Tools has been resolved for all affected users as of Tuesday, 2021-01-19 12:58 US/Pacific.\n\nPlease see workaround for detailed instructions\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-01-19T21:03:12Z"
      },
      {
        "created": "2021-01-19T21:02:48Z",
        "modified": "2021-01-19T21:02:48Z",
        "text": "Description: Mitigation work has been completed by our engineering team.\n\nFor mitigation steps please see workaround.\n\nWe will provide an update by Tuesday, 2021-01-19 13:10 US/Pacific with current details.\n\nDiagnosis: The command \"gcloud components update\" fails for Cloud SDK versions 321, 322 and 323 installed on Windows.\n\nWorkaround: Please run the following commands in a PowerShell window:\n```\n$gcloudDir = Get-Command gcloud | Select -ExpandProperty \"Source\" | Split-Path | Split-Path\nattrib -r \"$gcloudDir\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\lib\\kuberun\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\lib\\kuberun\\*.*\" /s\nRemove-Item \"$gcloudDir\\..\\google-cloud-sdk.staging\" -Recurse\n\nIf any of the commands fail, proceed with running the remaining commands. After running the PowerShell script, run the following in a regular Command Prompt (not PowerShell):\n```\ngcloud components update\n```\n\nAfter running this command, ensure that your gcloud installation is at version 324.0.0 or higher.",
        "when": "2021-01-19T21:02:48Z"
      },
      {
        "created": "2021-01-19T20:57:49Z",
        "modified": "2021-01-19T20:57:49Z",
        "text": "Description: Mitigation work has been completed by our engineering team.\n\nFor mitigation steps please see workaround.\n\nWe will provide an update by Tuesday, 2021-01-19 13:10 US/Pacific with current details.\n\nDiagnosis: The command \"gcloud components update\" fails for Cloud SDK versions 321, 322 and 323 installed on Windows.\n\nWorkaround: Please run the following commands in a PowerShell window:\n```\n$gcloudDir = Get-Command gcloud | Select -ExpandProperty \"Source\" | Split-Path | Split-Path\nattrib -r \"$gcloudDir\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\lib\\kuberun\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\lib\\kuberun\\*.*\" /s\nRemove-Item \"$gcloudDir\\..\\google-cloud-sdk.staging\" -Recurse\n\nIf any of the commands fail, proceed with running the remaining commands. After running the PowerShell script, run the following in a regular Command Prompt (not PowerShell):\n```\ngcloud components update --version 324.0.0\n```",
        "when": "2021-01-19T20:57:49Z"
      },
      {
        "created": "2021-01-14T20:15:48Z",
        "modified": "2021-01-14T20:15:48Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nThe mitigation is expected to complete by Tuesday, 2021-01-19 12:00 US/Pacific.\n\nPlease see the workaround section below for more details.\n\n\nDiagnosis: The command \"gcloud components update\" fails for Cloud SDK versions 321, 322 and 323 installed on Windows.\n\nWorkaround: Please run the following commands in a PowerShell window:\n\n$gcloudDir = Get-Command gcloud | Select -ExpandProperty \"Source\" | Split-Path | Split-Path\nattrib -r \"$gcloudDir\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\lib\\kuberun\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\lib\\kuberun\\*.*\" /s\nRemove-Item \"$gcloudDir\\..\\google-cloud-sdk.staging\" -Recurse\n\nIf any of the commands fail, proceed with running the remaining commands.\n\nAfter running the PowerShell script, run the following in a regular Command Prompt (not PowerShell):\n\ngcloud components update --version 320.0.0\n\nPlease note, after applying this workaround, do not run 'gcloud components update' as this will re-trigger the issue. Please wait until the fix is released before updating components.",
        "when": "2021-01-14T20:15:48Z"
      }
    ],
    "uri": "/incident/support/21001"
  },
  {
    "begin": "2021-01-08T20:27:14Z",
    "created": "2021-01-08T20:27:16Z",
    "end": "2021-01-08T21:20:56Z",
    "external_desc": "Cloud L7 (HTTP) External LB configuration changes propagating with high latency",
    "modified": "2021-01-08T21:20:56Z",
    "most-recent-update": {
      "created": "2021-01-08T21:20:56Z",
      "modified": "2021-01-08T21:20:56Z",
      "text": "The issue with Cloud L7 (HTTP) External Load Balancer components has been resolved for all affected users as of Friday, 2021-01-08 12:21 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2021-01-08T21:20:56Z"
    },
    "number": 21001,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "high",
    "updates": [
      {
        "created": "2021-01-08T21:20:56Z",
        "modified": "2021-01-08T21:20:56Z",
        "text": "The issue with Cloud L7 (HTTP) External Load Balancer components has been resolved for all affected users as of Friday, 2021-01-08 12:21 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2021-01-08T21:20:56Z"
      },
      {
        "created": "2021-01-08T20:31:46Z",
        "modified": "2021-01-08T20:31:46Z",
        "text": "Description: We are experiencing an intermittent issue with Cloud L7 (HTTP) External Load Balancer components beginning at Friday, 2021-01-08 11:39 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2021-01-08 14:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Cloud L7 (HTTP) External LB updates appear stalled - customers will likely see delays to updating their projects.\n\nWorkaround: None at this time.",
        "when": "2021-01-08T20:31:46Z"
      },
      {
        "created": "2021-01-08T20:27:17Z",
        "modified": "2021-01-08T20:27:17Z",
        "text": "Description: We are experiencing an intermittent issue with Google Cloud configuration infrastructure components beginning at Friday, 2021-01-08 11:39 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2021-01-08 14:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Cloud customer updates appear stalled - customers will likely see delays to updating their projects.\n\nWorkaround: None at this time.",
        "when": "2021-01-08T20:27:17Z"
      }
    ],
    "uri": "/incident/zall/21001"
  },
  {
    "begin": "2020-12-15T10:01:01Z",
    "created": "2020-12-15T10:20:28Z",
    "end": "2020-12-15T12:13:00Z",
    "external_desc": "Cloud Router: metrics missing",
    "modified": "2020-12-15T12:13:01Z",
    "most-recent-update": {
      "created": "2020-12-15T12:13:00Z",
      "modified": "2020-12-15T12:13:00Z",
      "text": "The issue with Cloud Router metrics has been resolved for all affected projects as of Tuesday, 2020-12-15 04:00 US/Pacific and metrics from Cloud Router should now be flowing to Metrics Explorer.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-12-15T12:13:00Z"
    },
    "number": 20011,
    "public": true,
    "service_key": "cloud-networking",
    "service_name": "Google Cloud Networking",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-12-15T12:13:00Z",
        "modified": "2020-12-15T12:13:00Z",
        "text": "The issue with Cloud Router metrics has been resolved for all affected projects as of Tuesday, 2020-12-15 04:00 US/Pacific and metrics from Cloud Router should now be flowing to Metrics Explorer.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-12-15T12:13:00Z"
      },
      {
        "created": "2020-12-15T10:20:29Z",
        "modified": "2020-12-15T10:20:29Z",
        "text": "Description: We are experiencing an issue with Cloud Router monitoring data (metrics) missing beginning at Monday, 2020-12-14 12:00 US/Pacific. Routers themselves are not impacted and should be working with no issues.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Tuesday, 2020-12-15 04:15 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Visible decrease in Cloud Router data in Metrics Explorer.\n\nWorkaround: None at this time.",
        "when": "2020-12-15T10:20:29Z"
      }
    ],
    "uri": "/incident/cloud-networking/20011"
  },
  {
    "begin": "2020-12-14T12:07:00Z",
    "created": "2020-12-14T13:34:13Z",
    "end": "2020-12-14T14:23:42Z",
    "external_desc": "Google Cloud services are experiencing issues and we have an other update at 5:30 PDT",
    "modified": "2020-12-23T00:49:44Z",
    "most-recent-update": {
      "created": "2020-12-23T00:49:44Z",
      "modified": "2020-12-23T00:49:44Z",
      "text": "The following is a correction to the previously posted ISSUE SUMMARY, which after further research we determined needed an amendment. All services that require sign-in via a Google Account were affected with varying impact. Some operations with Cloud service accounts experienced elevated error rates on requests to the following endpoints: www.googleapis.com or oauth2.googleapis.com. Impact varied based on the Cloud Service and service account. Please open a support case if you were impacted and have further questions.",
      "when": "2020-12-23T00:49:44Z"
    },
    "number": 20013,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "high",
    "updates": [
      {
        "created": "2020-12-23T00:49:44Z",
        "modified": "2020-12-23T00:49:44Z",
        "text": "The following is a correction to the previously posted ISSUE SUMMARY, which after further research we determined needed an amendment. All services that require sign-in via a Google Account were affected with varying impact. Some operations with Cloud service accounts experienced elevated error rates on requests to the following endpoints: www.googleapis.com or oauth2.googleapis.com. Impact varied based on the Cloud Service and service account. Please open a support case if you were impacted and have further questions.",
        "when": "2020-12-23T00:49:44Z"
      },
      {
        "created": "2020-12-18T19:37:01Z",
        "modified": "2020-12-18T19:38:53Z",
        "text": "# ISSUE SUMMARY\r\n\r\nOn Monday 14 December, 2020, for a duration of 47 minutes, customer-facing Google services that required Google OAuth access were unavailable. Cloud Service accounts used by GCP workloads were not impacted and continued to function. We apologize to our customers whose services or businesses were impacted during this incident, and we are taking immediate steps to improve the platform’s performance and availability.\r\n\r\n# ROOT CAUSE\r\n\r\nThe Google User ID Service maintains a unique identifier for every account and handles authentication credentials for OAuth tokens and cookies.  It stores account data in a distributed database, which uses Paxos protocols to coordinate updates. For security reasons, this service will reject requests when it detects outdated data.\r\n\r\nGoogle uses an evolving suite of automation tools to manage the quota of various resources allocated for services. As part of an ongoing migration of the User ID Service to a new quota system, a change was made in October to register the User ID Service with the new quota system, but parts of the previous quota system were left in place which incorrectly reported the usage for the User ID Service as 0. An existing grace period on enforcing quota restrictions delayed the impact, which eventually expired, triggering automated quota systems to decrease the quota allowed for the User ID service and triggering this incident. Existing safety checks exist to prevent many unintended quota changes, but at the time they did not cover the scenario of zero reported load for a single service: \r\n\r\n• Quota changes to large number of users, since only a single group was the target of the change,   \r\n\r\n• Lowering quota below usage, since the reported usage was inaccurately being reported as zero,  \r\n\r\n• Excessive quota reduction to storage systems, since no alert fired during the grace period, \r\n\r\n• Low quota, since the difference between usage and quota exceeded the protection limit. \r\n\r\nAs a result, the quota for the account database was reduced, which prevented the Paxos leader from writing. Shortly after, the majority of read operations became outdated which resulted in errors on authentication lookups.\r\n\r\n\r\n# REMEDIATION AND PREVENTION\r\n\r\nThe scope of the problem was immediately clear as the new quotas took effect. This was detected by automated alerts for capacity at 2020-12-14 03:43 US/Pacific, and for errors with the User ID Service starting at 03:46, which paged Google Engineers at 03:48 within one minute of customer impact. At 04:08 the root cause and a potential fix were identified, which led to disabling the quota enforcement in one datacenter at 04:22. This quickly improved the situation, and at 04:27 the same mitigation was applied to all datacenters, which returned error rates to normal levels by 04:33. As outlined below, some user services took longer to fully recover. \r\n\r\nIn addition to fixing the underlying cause, we will be implementing changes to prevent, reduce the impact of, and better communicate about this type of failure in several ways:\r\n\r\n\r\n1\\. Review our quota management automation to prevent fast implementation of global changes\r\n\r\n2\\. Improve monitoring and alerting to catch incorrect configurations sooner\r\n\r\n3\\. Improve reliability of tools and procedures for posting external communications during outages that affect internal tools\r\n\r\n4\\. Evaluate and implement improved write failure resilience into our User ID service database\r\n\r\n5\\. Improve resilience of GCP Services to more strictly limit the impact to the data plane during User ID Service failures\r\n\r\nWe would like to apologize for the scope of impact that this incident had on our customers and their businesses. We take any incident that affects the availability and reliability of our customers extremely seriously, particularly incidents which span multiple regions. We are conducting a thorough investigation of the incident and will be making the changes which result from that investigation our top priority in Google Engineering.\r\n\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\n\r\nOn Monday 14 December, 2020 from 03:46 to 04:33 US/Pacific, credential issuance and account metadata lookups for all Google user accounts failed. As a result, we could not verify that user requests were authenticated and served 5xx errors on virtually all authenticated traffic. The majority of authenticated services experienced similar control plane impact: elevated error rates across all Google Cloud Platform and Google Workspace APIs and Consoles. Products continued to deliver service normally during the incident except where specifically called out below. Most services recovered automatically within a short period of time after the main issue ended at 04:33. Some services had unique or lingering impact, which is detailed below. \r\n\r\n#### Cloud Console\r\n\r\nAny users who hadn't already previously authenticated to Cloud Console were unable to login. Users who had already authenticated may have been able to use Cloud Console but may have seen some features degraded.\r\n\r\n#### Google BigQuery\r\n\r\nDuring the incident, streaming requests returned ~75% errors, while BigQuery jobs returned ~10% errors on average globally. \r\n\r\n#### Google Cloud Storage\r\n\r\nApproximately 15% of requests to Google Cloud Storage (GCS) were impacted during the outage, specifically those using OAuth, HMAC or email authentication. After 2020-12-14 04:31 US/Pacific, the majority of impact was resolved, however, there was lingering impact, for <1% of clients that attempted to finalize resumable uploads that started during the window. These uploads were left in a non-resumable state; the error code GCS returned was retryable, but subsequent retries were unable to make progress, leaving these objects unfinalized.\r\n\r\n#### Google Cloud Networking\r\n\r\nThe networking control plane continued to see elevated error rates on operations until it fully recovered at 2020-12-14 05:21 US/Pacific. Only operations that made modifications to the data plane VPC network were impacted. All existing configurations in the data plane remained operational. \r\n\r\n#### Google Kubernetes Engine \r\n\r\nDuring the incident, ~4% of requests to the GKE control plane API failed, and nearly all Google-managed and customer workloads could not report metrics to Cloud Monitoring. \r\n\r\nWe believe ~5% of requests to Kubernetes control planes failed but do not have accurate measures due to unreported Cloud Monitoring metrics.\r\n\r\nFor up to an hour after the outage, ~1.9% nodes reported conditions such as StartGracePeriod or NetworkUnavailable which may have had an impact on user workloads. \r\n\r\n#### Google Workspace\r\n\r\nAll Google Workspace services rely on Google's account infrastructure for login, authentication, and enforcement of access control on resources (e.g. documents, Calendar events, Gmail messages). As a consequence, all authenticated Google Workspace apps were down for the duration of the incident. After the issue was mitigated at 2020-12-14 04:32 US/Pacific, Google Workspace apps recovered, and most services were fully recovered by 05:00. Some services, including Google Calendar and Google Workspace Admin Console, served errors up to 05:21 due to a traffic spike following initial recovery. Some Gmail users experienced errors for up to an hour after recovery due to caching of errors from identity services.\r\n\r\n#### Cloud Support \r\n\r\nCloud Support's internal tools were impacted, which delayed our ability to share outage communications with customers on the Google Cloud Platform and Google Workspace Status Dashboards. Customers were unable to create or view cases in the Cloud Console. We were able to update customers at 2020-12-14 05:34 US/Pacific after the impact had ended.",
        "when": "2020-12-18T19:37:01Z"
      },
      {
        "created": "2020-12-14T20:17:52Z",
        "modified": "2020-12-14T20:26:36Z",
        "text": "Preliminary Incident Statement while full Incident Report is prepared. \r\n\r\n(All Times US/Pacific)  \r\nIncident Start: 2020-12-14 03:45   \r\nIncident End: 2020-12-14 04:35  \r\nDuration: 50 minutes;   \r\n\r\n### Affected:  \r\n  \r\n- Services: Google Cloud Platform, Google Workspace  \r\n- Features: Account login and authentication to all Cloud services  \r\n- Regions/Zones: Global  \r\n\r\n\r\n  \r\n### Description:   \r\n  \r\nGoogle Cloud Platform and Google Workspace experienced a global outage affecting all services which require Google account authentication for a duration of 50 minutes. The root cause was an issue in our automated quota management system which reduced capacity for Google's central identity management system, causing it to return errors globally. As a result, we couldn’t verify that user requests were authenticated and served errors to our users. \r\n\r\n\r\n  \r\n### Customer Impact:  \r\n  \r\n- GCP services (including Cloud Console, Cloud Storage, BigQuery, Google Kubernetes Engine) requiring authentication would have returned an error for all users.    \r\n- Google Workspace services (including Gmail, Calendar, Meet, Docs and Drive) requiring authentication would have returned an error for all users.    \r\n\r\n\r\n\r\n### Additional Details:    \r\n\r\n- Many of our internal users and tools experienced similar errors, which added delays to our outage external communication.  \r\n- We will publish an analysis of this incident once we have completed our internal investigation.  ",
        "when": "2020-12-14T20:17:52Z"
      },
      {
        "created": "2020-12-14T14:23:42Z",
        "modified": "2020-12-14T14:23:42Z",
        "text": "As of 4:32 PST the system affected was restored and all services recovered shortly afterwards.",
        "when": "2020-12-14T14:23:42Z"
      },
      {
        "created": "2020-12-14T13:34:14Z",
        "modified": "2020-12-14T14:45:23Z",
        "text": "Google Cloud services are experiencing issues and we have an other update at 5:30 PST",
        "when": "2020-12-14T13:34:14Z"
      }
    ],
    "uri": "/incident/zall/20013"
  },
  {
    "begin": "2020-12-10T03:38:29Z",
    "created": "2020-12-10T03:41:20Z",
    "end": "2020-12-10T04:42:15Z",
    "external_desc": "Cloud Dataflow resources in europe-west2-a may be unreachable",
    "modified": "2020-12-10T04:42:15Z",
    "most-recent-update": {
      "created": "2020-12-10T04:42:15Z",
      "modified": "2020-12-10T04:42:15Z",
      "text": "The issue with Cloud Dataflow in europe-west2-a has been resolved for all affected projects as of Wednesday, 2020-12-09 20:41 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-12-10T04:42:15Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "cloud-dataflow",
    "service_name": "Google Cloud Dataflow",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-12-10T04:42:15Z",
        "modified": "2020-12-10T04:42:15Z",
        "text": "The issue with Cloud Dataflow in europe-west2-a has been resolved for all affected projects as of Wednesday, 2020-12-09 20:41 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-12-10T04:42:15Z"
      },
      {
        "created": "2020-12-10T03:41:21Z",
        "modified": "2020-12-10T03:41:21Z",
        "text": "Description: Our engineering team continues to investigate the issue.\n\nFor regular status updates, please follow: status.cloud.google.com/incident/zall/20011, no further updates will be provided here.\n\nWe apologize to all who are affected by the disruption.\n\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-10T03:41:21Z"
      }
    ],
    "uri": "/incident/cloud-dataflow/20003"
  },
  {
    "begin": "2020-12-10T03:06:07Z",
    "created": "2020-12-10T03:36:54Z",
    "end": "2020-12-10T04:40:48Z",
    "external_desc": "Cloud SQL instances in europe-west2-a may be unreachable",
    "modified": "2020-12-10T04:40:49Z",
    "most-recent-update": {
      "created": "2020-12-10T04:40:48Z",
      "modified": "2020-12-10T04:40:48Z",
      "text": "The issue with Cloud SQL in europe-west2-a has been resolved for all affected projects as of Wednesday, 2020-12-09 20:19 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-12-10T04:40:48Z"
    },
    "number": 20006,
    "public": true,
    "service_key": "cloud-sql",
    "service_name": "Google Cloud SQL",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-12-10T04:40:48Z",
        "modified": "2020-12-10T04:40:48Z",
        "text": "The issue with Cloud SQL in europe-west2-a has been resolved for all affected projects as of Wednesday, 2020-12-09 20:19 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-12-10T04:40:48Z"
      },
      {
        "created": "2020-12-10T03:36:54Z",
        "modified": "2020-12-10T03:36:54Z",
        "text": "Description: Our engineering team continues to investigate the issue.\n\nFor regular status updates, please follow: status.cloud.google.com/incident/zall/20011, no further updates will be provided here.\n\nWe apologize to all who are affected by the disruption.\n\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-10T03:36:54Z"
      }
    ],
    "uri": "/incident/cloud-sql/20006"
  },
  {
    "begin": "2020-12-10T03:00:08Z",
    "created": "2020-12-10T03:32:16Z",
    "end": "2020-12-10T04:39:17Z",
    "external_desc": "Cloud GCE resources may be unreachable in europe-west2-a",
    "modified": "2020-12-10T04:39:17Z",
    "most-recent-update": {
      "created": "2020-12-10T04:39:17Z",
      "modified": "2020-12-10T04:39:17Z",
      "text": "The issue with Google Compute Engine has been resolved for all affected users as of Wednesday, 2020-12-09 20:39 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-12-10T04:39:17Z"
    },
    "number": 20013,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-12-10T04:39:17Z",
        "modified": "2020-12-10T04:39:17Z",
        "text": "The issue with Google Compute Engine has been resolved for all affected users as of Wednesday, 2020-12-09 20:39 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-12-10T04:39:17Z"
      },
      {
        "created": "2020-12-10T03:32:17Z",
        "modified": "2020-12-10T03:32:17Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine.\n\nOur engineering team continues to investigate the issue.\n\nFor regular status updates, please follow: status.cloud.google.com/incident/zall/20011, no further updates will be provided here.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-10T03:32:17Z"
      }
    ],
    "uri": "/incident/compute/20013"
  },
  {
    "begin": "2020-12-10T02:46:22Z",
    "created": "2020-12-10T03:34:44Z",
    "end": "2020-12-10T05:04:26Z",
    "external_desc": "Cloud Memorystore resources may be unreachable in europe-west2-a",
    "modified": "2020-12-10T05:04:26Z",
    "most-recent-update": {
      "created": "2020-12-10T05:04:26Z",
      "modified": "2020-12-10T05:04:26Z",
      "text": "The issue with Cloud Memorystore has been resolved for all affected projects as of Wednesday, 2020-12-09 21:00 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-12-10T05:04:26Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "cloud-memorystore",
    "service_name": "Cloud Memorystore",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-12-10T05:04:26Z",
        "modified": "2020-12-10T05:04:26Z",
        "text": "The issue with Cloud Memorystore has been resolved for all affected projects as of Wednesday, 2020-12-09 21:00 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-12-10T05:04:26Z"
      },
      {
        "created": "2020-12-10T04:59:27Z",
        "modified": "2020-12-10T04:59:27Z",
        "text": "Description: The underlying infrastructure issue in europe-west2-a has been mitigated, and we are seeing recoveries in most Cloud Memorystore instances.\n\nWe will continue to monitor for full recovery, and provide more information by Wednesday, 2020-12-09 22:30 US/Pacific.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-10T04:59:27Z"
      },
      {
        "created": "2020-12-10T03:34:45Z",
        "modified": "2020-12-10T03:34:45Z",
        "text": "Description: We are experiencing an issue with Cloud Memorystore.\n\nOur engineering team continues to investigate the issue.\n\nFor regular status updates, please follow: status.cloud.google.com/incident/zall/20011, no further updates will be provided here.\n\nWe apologize to all who are affected by the disruption.\n\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-10T03:34:45Z"
      }
    ],
    "uri": "/incident/cloud-memorystore/20004"
  },
  {
    "begin": "2020-12-10T02:31:38Z",
    "created": "2020-12-10T03:17:41Z",
    "end": "2020-12-10T03:55:02Z",
    "external_desc": "All Cloud Platform resources in europe-west2-a may be unreachable as of 2020-12-09 18:32 US/Pacific.",
    "modified": "2020-12-15T19:56:41Z",
    "most-recent-update": {
      "created": "2020-12-15T19:03:12Z",
      "modified": "2020-12-15T19:56:41Z",
      "text": "# ISSUE SUMMARY\r\n\r\nOn Wednesday 9 December, 2020, Google Cloud Platform experienced networking unavailability in zone europe-west2-a, resulting in some customers being unable to access their resources, for a duration of 1 hour 24 minutes. The following Google services had degraded service that extended beyond the initial 1 hour 24 minute network disruption:\r\n\r\n- 1.5% of Cloud Memorystore Redis instances were unhealthy for a total duration of 2 hours 24 minutes\r\n- 4.5% of Classic Cloud VPN tunnels in the europe-west2 region experienced unavailability after the main disruption had recovered and these tunnels remained down for a duration of 8 hours and 10 minutes\r\n- App Engine Flex experienced increased deployment error rates for a total duration of 1 hour 45 minutes\r\n\r\nWe apologize to our Cloud customers who were impacted during this disruption. We have conducted a thorough internal investigation and are taking immediate action to improve the resiliency and availability of our service.\r\n\r\n\r\n# ROOT CAUSE\r\n\r\nGoogle’s underlying networking control plane consists of multiple distributed components that make up the Software Defined Networking (SDN) stack. These components run on multiple machines so that failure of a machine or even multiple machines does not impact network capacity. To achieve this, the control plane elects a leader from a pool of machines to provide configuration to the various infrastructure components. The leader election process depends on a local instance of Google’s internal lock service to read various configurations and files for determining the leader. The control plane is responsible for Border Gateway Protocol (BGP) peering sessions between physical routers connecting a cloud zone to the Google backbone.\r\n\r\nGoogle’s internal lock service provides Access Control List (ACLs) mechanisms to control reading and writing of various files stored in the service. A change to the ACLs used by the network control plane caused the tasks responsible for leader election to no longer have access to the files required for the process. The production environment contained ACLs not present in the staging or canary environments due to those environments being rebuilt using updated processes during previous maintenance events. This meant that some of the ACLs removed in the change were in use in europe-west2-a, and the validation of the configuration change in testing and canary environments did not surface the issue.\r\n\r\nGoogle's resilience strategy relies on the principle of defense in depth. Specifically, despite the network control infrastructure being designed to be highly resilient, the network is designed to 'fail static' and run for a period of time without the control plane being present as an additional line of defense against failure. The network ran normally for a short period - several minutes - after the control plane had been unable to elect a leader task. After this period, BGP routing between europe-west2-a and the rest of the Google backbone network was withdrawn, resulting in isolation of the zone and inaccessibility of resources in the zone.\r\n\r\n\r\n# REMEDIATION AND PREVENTION\r\n\r\nGoogle engineers were automatically alerted to elevated error rates in europe-west2-a at 2020-12-09 18:29 US/Pacific and immediately started an investigation. The configuration change rollout was automatically halted as soon as the issue was detected, preventing it from reaching any other zones. At 19:30, mitigation was applied to rollback the configuration change in europe-west2-a. This completed at 19:55, mitigating the immediate issue. Some services such as Cloud MemoryStore and Cloud VPN took additional time to recover due to complications arising from the initial disruption. Services with extended recovery timelines are described in the “detailed description of impact” section below.\r\n\r\nWe are committed to preventing this situation from happening again and are implementing the following actions:\r\n\r\nIn addition to rolling back the configuration change responsible for this disruption, we are auditing all network ACLs to ensure they are consistent across environments. While the network continued to operate for a short time after the change was rolled out, we are improving the operating mode of the data plane when the control plane is unavailable for extended periods. Improvements in visibility to recent changes will be made to reduce the time to mitigation. Additional observability will be added to lock service ACLs allowing for additional validation when making changes to ACLs. We are also improving the canary and release process for future changes of this type to ensure these changes are made safely.\r\n\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\n\r\nOn Wednesday 9 December, 2020 from 18:31 to 19:55 US/Pacific Google Cloud experienced unavailability for some Google services hosted in zone europe-west2-a as described in detail below. If impact time differs significantly, it will be mentioned specifically.\r\n\r\n## Compute Engine\r\n~60% of VMs in europe-west2-a were unreachable from outside the zone. Projects affected by this incident would have observed 100% of VMs in the zone being unreachable. Communication within the zone had minor issues, but largely worked normally. VM creation and deletion operations were stalled during the outage. VMs on hosts that had hardware or other faults during the outage were not repaired and restarted onto healthy hosts during the outage.\r\n\r\n## Persistent Disk\r\nVMs in europe-west2-a experienced stuck I/O operations for 59% of standard persistent disks located in that zone. 27% of regional persistent disks in europe-west2 briefly experienced high I/O latency at the start and end of the incident. Persistent Disk snapshot creation and restore for 59% of disks located in europe-west2-a failed during the incident. Additionally, snapshot creation for Regional Persistent Disks with one replica located in zone europe-west2-a was unavailable.\r\n\r\n## Cloud SQL\r\n~79% of HA Cloud SQL instances experienced <5 minutes of downtime due to autofailover with an additional ~5% experiencing <25m of downtime after manual recovery. ~13% of HA Cloud SQL instances with legacy HA configuration did not failover because the replicas were out of sync, and were unreachable for the full duration of the incident. The remaining HA Cloud SQL instances did not failover due to stuck operations. Overall, 97.5% of Regional PD based HA instances and 23% of legacy MySQL HA instances had <25m downtime with the remaining instances being unconnectable during the outage. Google engineering is committed to improving the successful failover rate for Cloud SQL HA instances for zonal outages like this.\r\n\r\n## Google App Engine\r\nApp Engine Flex apps in europe-west2 experienced increased deployment error rates between 10% and 100% from 18:44 to 20:29.\r\nApp Engine Standard apps running in the europe-west2 region experienced increased deployment error rates of up to 9.6% that lasted from 18:38 to 18:47. ~34.7% of App Engine Standard apps in the region experienced increased serving error rates between 18:32 and 18:38.\r\n\r\n## Cloud Functions\r\n34.8% of Cloud Functions served from europe-west2 experienced increased serving error rates between 18:32 and 18:38.\r\n\r\n## Cloud Run\r\n54.8% of Cloud Run apps served from europe-west2 experienced increased serving error rates between 18:32 and 18:38.\r\n\r\n## Cloud MemoryStore\r\n~10% of Redis instances in europe-west2, were unreachable during the outage. Both standard tier and basic tier instances were affected. After the main outage was mitigated, most instances recovered, but ~1.5% of instances remained unhealthy for 60 minutes before recovering on their own.\r\n\r\n## Cloud Filestore\r\n~16% of Filestore instances in europe-west2 were unhealthy. Instances in the zone were unreachable from outside the zone, but access within the zone was largely unaffected.\r\n\r\n## Cloud Bigtable\r\n100% of single-homed Cloud Bigtable instances in europe-west2-a were unavailable during the outage, translating into 100% error rate for customer instances located in this zone.\r\n\r\n## Kubernetes Engine\r\n~67% of cluster control planes in europe-west2-a and 10% of regional clusters in europe-west2 were unavailable for the duration of the incident. Investigation into the regional cluster control plane unavailability is still ongoing. Node creation and deletion operations were stalled due to the impact to Compute Engine operations. \r\n\r\n## Cloud Interconnect\r\nElevated packet loss for zones in europe-west2. Starting at 18:31 packets destined for resources in europe-west2-a experienced loss for the duration of the incident. Additionally, interconnect attachments in europe-west2 experienced regional loss for 7 minutes at 18:31 and 8 minutes at 19:53.\r\n\r\n## Cloud Dataflow\r\n~10% of jobs in europe-west2 failed or got stuck in cancellation during the outage. ~40% of Dataflow Streaming Engine jobs in the region were degraded over the course of the incident.\r\n\r\n## Cloud VPN\r\nA number of Cloud VPN tunnels were reset during the disruption and were automatically relocated to other zones in the region. This is within the design of the product, as the loss of one zone is planned. However once zone europe-west2-a reconnected to the network, a combination of bugs in the VPN control plane were triggered by some of the now stale VPN gateways in the zone. This caused an outage to 4.5% of Classic Cloud VPN tunnels in europe-west2 for a duration of 8 hours and 10 minutes after the main disruption had recovered.\r\n\r\n## Cloud Dataproc\r\n~0.01% of Dataproc API requests to europe-west2 returned UNAVAILABLE during the incident. The majority of these requests were read-only requests (ListClusters, ListJobs, etc.)\r\n\r\n\r\n# SLA CREDITS\r\n\r\nIf you believe your paid application experienced an SLA violation as a result of this incident, please submit the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla \r\n\r\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/",
      "when": "2020-12-15T19:03:11Z"
    },
    "number": 20011,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-12-15T19:03:12Z",
        "modified": "2020-12-15T19:56:41Z",
        "text": "# ISSUE SUMMARY\r\n\r\nOn Wednesday 9 December, 2020, Google Cloud Platform experienced networking unavailability in zone europe-west2-a, resulting in some customers being unable to access their resources, for a duration of 1 hour 24 minutes. The following Google services had degraded service that extended beyond the initial 1 hour 24 minute network disruption:\r\n\r\n- 1.5% of Cloud Memorystore Redis instances were unhealthy for a total duration of 2 hours 24 minutes\r\n- 4.5% of Classic Cloud VPN tunnels in the europe-west2 region experienced unavailability after the main disruption had recovered and these tunnels remained down for a duration of 8 hours and 10 minutes\r\n- App Engine Flex experienced increased deployment error rates for a total duration of 1 hour 45 minutes\r\n\r\nWe apologize to our Cloud customers who were impacted during this disruption. We have conducted a thorough internal investigation and are taking immediate action to improve the resiliency and availability of our service.\r\n\r\n\r\n# ROOT CAUSE\r\n\r\nGoogle’s underlying networking control plane consists of multiple distributed components that make up the Software Defined Networking (SDN) stack. These components run on multiple machines so that failure of a machine or even multiple machines does not impact network capacity. To achieve this, the control plane elects a leader from a pool of machines to provide configuration to the various infrastructure components. The leader election process depends on a local instance of Google’s internal lock service to read various configurations and files for determining the leader. The control plane is responsible for Border Gateway Protocol (BGP) peering sessions between physical routers connecting a cloud zone to the Google backbone.\r\n\r\nGoogle’s internal lock service provides Access Control List (ACLs) mechanisms to control reading and writing of various files stored in the service. A change to the ACLs used by the network control plane caused the tasks responsible for leader election to no longer have access to the files required for the process. The production environment contained ACLs not present in the staging or canary environments due to those environments being rebuilt using updated processes during previous maintenance events. This meant that some of the ACLs removed in the change were in use in europe-west2-a, and the validation of the configuration change in testing and canary environments did not surface the issue.\r\n\r\nGoogle's resilience strategy relies on the principle of defense in depth. Specifically, despite the network control infrastructure being designed to be highly resilient, the network is designed to 'fail static' and run for a period of time without the control plane being present as an additional line of defense against failure. The network ran normally for a short period - several minutes - after the control plane had been unable to elect a leader task. After this period, BGP routing between europe-west2-a and the rest of the Google backbone network was withdrawn, resulting in isolation of the zone and inaccessibility of resources in the zone.\r\n\r\n\r\n# REMEDIATION AND PREVENTION\r\n\r\nGoogle engineers were automatically alerted to elevated error rates in europe-west2-a at 2020-12-09 18:29 US/Pacific and immediately started an investigation. The configuration change rollout was automatically halted as soon as the issue was detected, preventing it from reaching any other zones. At 19:30, mitigation was applied to rollback the configuration change in europe-west2-a. This completed at 19:55, mitigating the immediate issue. Some services such as Cloud MemoryStore and Cloud VPN took additional time to recover due to complications arising from the initial disruption. Services with extended recovery timelines are described in the “detailed description of impact” section below.\r\n\r\nWe are committed to preventing this situation from happening again and are implementing the following actions:\r\n\r\nIn addition to rolling back the configuration change responsible for this disruption, we are auditing all network ACLs to ensure they are consistent across environments. While the network continued to operate for a short time after the change was rolled out, we are improving the operating mode of the data plane when the control plane is unavailable for extended periods. Improvements in visibility to recent changes will be made to reduce the time to mitigation. Additional observability will be added to lock service ACLs allowing for additional validation when making changes to ACLs. We are also improving the canary and release process for future changes of this type to ensure these changes are made safely.\r\n\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\n\r\nOn Wednesday 9 December, 2020 from 18:31 to 19:55 US/Pacific Google Cloud experienced unavailability for some Google services hosted in zone europe-west2-a as described in detail below. If impact time differs significantly, it will be mentioned specifically.\r\n\r\n## Compute Engine\r\n~60% of VMs in europe-west2-a were unreachable from outside the zone. Projects affected by this incident would have observed 100% of VMs in the zone being unreachable. Communication within the zone had minor issues, but largely worked normally. VM creation and deletion operations were stalled during the outage. VMs on hosts that had hardware or other faults during the outage were not repaired and restarted onto healthy hosts during the outage.\r\n\r\n## Persistent Disk\r\nVMs in europe-west2-a experienced stuck I/O operations for 59% of standard persistent disks located in that zone. 27% of regional persistent disks in europe-west2 briefly experienced high I/O latency at the start and end of the incident. Persistent Disk snapshot creation and restore for 59% of disks located in europe-west2-a failed during the incident. Additionally, snapshot creation for Regional Persistent Disks with one replica located in zone europe-west2-a was unavailable.\r\n\r\n## Cloud SQL\r\n~79% of HA Cloud SQL instances experienced <5 minutes of downtime due to autofailover with an additional ~5% experiencing <25m of downtime after manual recovery. ~13% of HA Cloud SQL instances with legacy HA configuration did not failover because the replicas were out of sync, and were unreachable for the full duration of the incident. The remaining HA Cloud SQL instances did not failover due to stuck operations. Overall, 97.5% of Regional PD based HA instances and 23% of legacy MySQL HA instances had <25m downtime with the remaining instances being unconnectable during the outage. Google engineering is committed to improving the successful failover rate for Cloud SQL HA instances for zonal outages like this.\r\n\r\n## Google App Engine\r\nApp Engine Flex apps in europe-west2 experienced increased deployment error rates between 10% and 100% from 18:44 to 20:29.\r\nApp Engine Standard apps running in the europe-west2 region experienced increased deployment error rates of up to 9.6% that lasted from 18:38 to 18:47. ~34.7% of App Engine Standard apps in the region experienced increased serving error rates between 18:32 and 18:38.\r\n\r\n## Cloud Functions\r\n34.8% of Cloud Functions served from europe-west2 experienced increased serving error rates between 18:32 and 18:38.\r\n\r\n## Cloud Run\r\n54.8% of Cloud Run apps served from europe-west2 experienced increased serving error rates between 18:32 and 18:38.\r\n\r\n## Cloud MemoryStore\r\n~10% of Redis instances in europe-west2, were unreachable during the outage. Both standard tier and basic tier instances were affected. After the main outage was mitigated, most instances recovered, but ~1.5% of instances remained unhealthy for 60 minutes before recovering on their own.\r\n\r\n## Cloud Filestore\r\n~16% of Filestore instances in europe-west2 were unhealthy. Instances in the zone were unreachable from outside the zone, but access within the zone was largely unaffected.\r\n\r\n## Cloud Bigtable\r\n100% of single-homed Cloud Bigtable instances in europe-west2-a were unavailable during the outage, translating into 100% error rate for customer instances located in this zone.\r\n\r\n## Kubernetes Engine\r\n~67% of cluster control planes in europe-west2-a and 10% of regional clusters in europe-west2 were unavailable for the duration of the incident. Investigation into the regional cluster control plane unavailability is still ongoing. Node creation and deletion operations were stalled due to the impact to Compute Engine operations. \r\n\r\n## Cloud Interconnect\r\nElevated packet loss for zones in europe-west2. Starting at 18:31 packets destined for resources in europe-west2-a experienced loss for the duration of the incident. Additionally, interconnect attachments in europe-west2 experienced regional loss for 7 minutes at 18:31 and 8 minutes at 19:53.\r\n\r\n## Cloud Dataflow\r\n~10% of jobs in europe-west2 failed or got stuck in cancellation during the outage. ~40% of Dataflow Streaming Engine jobs in the region were degraded over the course of the incident.\r\n\r\n## Cloud VPN\r\nA number of Cloud VPN tunnels were reset during the disruption and were automatically relocated to other zones in the region. This is within the design of the product, as the loss of one zone is planned. However once zone europe-west2-a reconnected to the network, a combination of bugs in the VPN control plane were triggered by some of the now stale VPN gateways in the zone. This caused an outage to 4.5% of Classic Cloud VPN tunnels in europe-west2 for a duration of 8 hours and 10 minutes after the main disruption had recovered.\r\n\r\n## Cloud Dataproc\r\n~0.01% of Dataproc API requests to europe-west2 returned UNAVAILABLE during the incident. The majority of these requests were read-only requests (ListClusters, ListJobs, etc.)\r\n\r\n\r\n# SLA CREDITS\r\n\r\nIf you believe your paid application experienced an SLA violation as a result of this incident, please submit the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla \r\n\r\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/",
        "when": "2020-12-15T19:03:11Z"
      },
      {
        "created": "2020-12-10T04:43:02Z",
        "modified": "2020-12-10T04:43:02Z",
        "text": "The issue with Google Cloud infrastructure components is believed to be resolved for all services, however a small number of Compute resources may still be affected and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nNo further updates will be provided here.\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-12-10T04:43:02Z"
      },
      {
        "created": "2020-12-10T04:30:03Z",
        "modified": "2020-12-10T04:30:03Z",
        "text": "Description: We believe the issue with Google Cloud infrastructure components is resolved for most services as of approximately 2020-12-09 20:21.\n\nWe do not have an ETA for full resolution at this point.\n\nWe will provide an update by Wednesday, 2020-12-09 22:07 US/Pacific with current details.\n\nDiagnosis: None at this time.\n\nWorkaround: Moving resources to another zone temporarily.",
        "when": "2020-12-10T04:30:03Z"
      },
      {
        "created": "2020-12-10T04:11:39Z",
        "modified": "2020-12-10T04:11:39Z",
        "text": "Description: Mitigation work is still underway by our engineering team. We are starting to see recovery for some Google Cloud infrastructure components.\n\nWe do not have an ETA for full resolution at this point.\n\nWe will provide an update by Wednesday, 2020-12-09 21:40 US/Pacific with current details.\n\nDiagnosis: None at this time.\n\nWorkaround: Moving resources to another zone temporarily.",
        "when": "2020-12-10T04:11:39Z"
      },
      {
        "created": "2020-12-10T03:51:18Z",
        "modified": "2020-12-10T03:51:18Z",
        "text": "Description: Mitigation work is currently underway by our engineering team. \n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Wednesday, 2020-12-09 21:32 US/Pacific.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-10T03:51:18Z"
      },
      {
        "created": "2020-12-10T03:17:42Z",
        "modified": "2020-12-10T03:17:42Z",
        "text": "Description: We are experiencing an issue with Google Cloud infrastructure components affecting resources located in europe-west2-a.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Wednesday, 2020-12-09 20:46 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-10T03:17:42Z"
      }
    ],
    "uri": "/incident/zall/20011"
  },
  {
    "begin": "2020-12-04T23:57:00Z",
    "created": "2020-12-04T23:57:14Z",
    "end": "2020-12-05T03:08:37Z",
    "external_desc": "We are experiencing an intermittent issue with Cloud Firestore beginning at Friday, 2020-12-04 12:09:08 US/Pacific.",
    "modified": "2020-12-05T03:08:38Z",
    "most-recent-update": {
      "created": "2020-12-05T03:08:37Z",
      "modified": "2020-12-05T03:08:37Z",
      "text": "The issue with Cloud Firestore has been resolved for all affected users as of Friday, 2020-12-04 19:00 US/Pacific. We thank you for your patience while we worked on resolving the issue.",
      "when": "2020-12-05T03:08:37Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "cloud-firestore",
    "service_name": "Cloud Firestore",
    "severity": "high",
    "updates": [
      {
        "created": "2020-12-05T03:08:37Z",
        "modified": "2020-12-05T03:08:37Z",
        "text": "The issue with Cloud Firestore has been resolved for all affected users as of Friday, 2020-12-04 19:00 US/Pacific. We thank you for your patience while we worked on resolving the issue.",
        "when": "2020-12-05T03:08:37Z"
      },
      {
        "created": "2020-12-05T01:58:51Z",
        "modified": "2020-12-05T01:58:51Z",
        "text": "Mitigation work is currently underway by our engineering team.\r\n\r\nImpact in us-east1 has been mitigated.\r\n\r\nWe will provide more information by Friday, 2020-12-04 19:00 US/Pacific.",
        "when": "2020-12-05T01:58:51Z"
      },
      {
        "created": "2020-12-04T23:57:14Z",
        "modified": "2020-12-04T23:57:14Z",
        "text": "Mitigation work is currently underway by our engineering team.\r\n\r\nWe expect mitigation to be complete by 17:45 US/Pacific.\r\n\r\nWe will provide more information by Friday, 2020-12-04 17:30 US/Pacific.",
        "when": "2020-12-04T23:57:14Z"
      }
    ],
    "uri": "/incident/cloud-firestore/20005"
  },
  {
    "begin": "2020-12-04T00:36:42Z",
    "created": "2020-12-04T00:57:08Z",
    "end": "2020-12-04T05:41:56Z",
    "external_desc": "Increased error rate seen for Queries to Cloud Logging.",
    "modified": "2020-12-04T05:41:56Z",
    "most-recent-update": {
      "created": "2020-12-04T05:41:56Z",
      "modified": "2020-12-04T05:41:56Z",
      "text": "The issue with Cloud Logging  has been resolved for all affected users as of Thursday, 2020-12-03 21:36 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-12-04T05:41:56Z"
    },
    "number": 20010,
    "public": true,
    "service_key": "google-stackdriver",
    "service_name": "Operations",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-12-04T05:41:56Z",
        "modified": "2020-12-04T05:41:56Z",
        "text": "The issue with Cloud Logging  has been resolved for all affected users as of Thursday, 2020-12-03 21:36 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-12-04T05:41:56Z"
      },
      {
        "created": "2020-12-04T04:54:55Z",
        "modified": "2020-12-04T04:54:55Z",
        "text": "Description: Our engineering team has determined that further investigation is required to mitigate the issue.\n\nWe will provide an update by Thursday, 2020-12-03 22:00 US/Pacific with current details.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-04T04:54:55Z"
      },
      {
        "created": "2020-12-04T04:02:01Z",
        "modified": "2020-12-04T04:02:01Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Thursday, 2020-12-03 21:00 US/Pacific.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-04T04:02:01Z"
      },
      {
        "created": "2020-12-04T03:01:59Z",
        "modified": "2020-12-04T03:01:59Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Thursday, 2020-12-03 20:00 US/Pacific.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-04T03:01:59Z"
      },
      {
        "created": "2020-12-04T01:56:57Z",
        "modified": "2020-12-04T01:56:57Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Thursday, 2020-12-03 19:00 US/Pacific.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-04T01:56:57Z"
      },
      {
        "created": "2020-12-04T00:57:10Z",
        "modified": "2020-12-04T00:57:10Z",
        "text": "Description: We are experiencing errors with queries to Cloud Logging beginning at Thursday, 2020-12-03 16:25 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-12-03 18:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-12-04T00:57:10Z"
      }
    ],
    "uri": "/incident/google-stackdriver/20010"
  },
  {
    "begin": "2020-11-19T16:49:41Z",
    "created": "2020-11-19T18:18:03Z",
    "end": "2020-11-20T05:16:13Z",
    "external_desc": "Cloud Logging delays on log ingestion affecting 25% of projects.",
    "modified": "2020-11-20T05:16:13Z",
    "most-recent-update": {
      "created": "2020-11-20T05:16:13Z",
      "modified": "2020-11-20T05:16:13Z",
      "text": "The issue with Cloud Logging has been resolved for all affected projects as of Thursday, 2020-11-19 21:15 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-11-20T05:16:13Z"
    },
    "number": 20009,
    "public": true,
    "service_key": "google-stackdriver",
    "service_name": "Operations",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-11-20T05:16:13Z",
        "modified": "2020-11-20T05:16:13Z",
        "text": "The issue with Cloud Logging has been resolved for all affected projects as of Thursday, 2020-11-19 21:15 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-11-20T05:16:13Z"
      },
      {
        "created": "2020-11-20T03:31:01Z",
        "modified": "2020-11-20T03:31:01Z",
        "text": "Description: We believe the issue with Cloud Logging is partially resolved. Additional cleanup is ongoing. Some users may experience slow queries.\n\nWe expect a full resolution within 3 hours.\n\nWe will provide an update by Thursday, 2020-11-19 22:30 US/Pacific with current details.\n\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries. \n\nWorkaround: None at this time.",
        "when": "2020-11-20T03:31:01Z"
      },
      {
        "created": "2020-11-20T02:26:52Z",
        "modified": "2020-11-20T02:26:52Z",
        "text": "Description: We believe the issue with Cloud Logging is partially resolved. Additional cleanup and prevention efforts are ongoing. Some users may experience slow queries.\n\nWe do not have an ETA for full resolution at this point.\n\nWe will provide an update by Thursday, 2020-11-19 19:30 US/Pacific with current details.\n\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries. \n\nWorkaround: None at this time.",
        "when": "2020-11-20T02:26:52Z"
      },
      {
        "created": "2020-11-20T00:38:53Z",
        "modified": "2020-11-20T00:38:53Z",
        "text": "Description: We believe the issue with Cloud Logging is partially resolved. Additional cleanup and prevention efforts are ongoing, but the majority of users should see their log data available and queries succeeding. \n\nWe do not have an ETA for full resolution at this point.\n\nWe will provide an update by Thursday, 2020-11-19 18:30 US/Pacific with current details.\n\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries. \n\nWorkaround: None at this time.",
        "when": "2020-11-20T00:38:53Z"
      },
      {
        "created": "2020-11-19T23:14:03Z",
        "modified": "2020-11-19T23:14:03Z",
        "text": "Description: The backlog has been fully processed, but we are still seeing elevated error rates on queries with new data. Mitigation efforts are still ongoing. \n\nWe will provide more information by Thursday, 2020-11-19 16:45 US/Pacific.\n\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries. \n\nWorkaround: None at this time.",
        "when": "2020-11-19T23:14:03Z"
      },
      {
        "created": "2020-11-19T22:04:25Z",
        "modified": "2020-11-19T22:04:25Z",
        "text": "Description: Current ETA is ~2 hours to finish processing the backlog. \n\nWe will provide more information by Thursday, 2020-11-19 16:45 US/Pacific.\n\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries. \n\nWorkaround: None at this time.",
        "when": "2020-11-19T22:04:25Z"
      },
      {
        "created": "2020-11-19T21:40:13Z",
        "modified": "2020-11-19T21:40:13Z",
        "text": "Description: Log ingestion has been resumed, and now the backlog of recent data (about 4.5 hours) is being processed. \n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Thursday, 2020-11-19 16:45 US/Pacific.\n\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries. \n\nWorkaround: None at this time.",
        "when": "2020-11-19T21:40:12Z"
      },
      {
        "created": "2020-11-19T20:21:11Z",
        "modified": "2020-11-19T20:21:11Z",
        "text": "Description: Mitigation work is still underway by our engineering team. Ingestion is temporarily paused for a couple hours to speedup the recovery efforts.\n\nWe will provide more information by Thursday, 2020-11-19 15:00 US/Pacific.\n\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries. \n\nWorkaround: None at this time.",
        "when": "2020-11-19T20:21:10Z"
      },
      {
        "created": "2020-11-19T19:18:26Z",
        "modified": "2020-11-19T19:18:26Z",
        "text": "Description: Mitigation work is currently underway by our engineering team, the current focus is on stabilizing new requests, then proceeding to process backlog.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Thursday, 2020-11-19 12:30 US/Pacific.\n\nDiagnosis: Log writes and reads experiencing latency. 25% of customers may see symptoms.\n\nWorkaround: None at this time.",
        "when": "2020-11-19T19:18:26Z"
      },
      {
        "created": "2020-11-19T18:47:43Z",
        "modified": "2020-11-19T18:47:43Z",
        "text": "Description: Mitigation work is currently underway by our engineering team, the current focus is on stabilizing new requests, then proceeding to process backlog.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Thursday, 2020-11-19 11:50 US/Pacific.\n\nDiagnosis: Log writes and reads experiencing latency. 25% of customers may see symptoms.\n\nWorkaround: None at this time.",
        "when": "2020-11-19T18:47:43Z"
      },
      {
        "created": "2020-11-19T18:18:04Z",
        "modified": "2020-11-19T18:18:04Z",
        "text": "Description: Mitigation work is currently underway by our engineering team, the current focus is on stabilizing new requests, then proceeding to process backlog.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Thursday, 2020-11-19 11:45 US/Pacific.\n\nDiagnosis: Log writes and reads in us-central1 experiencing latency. 25% of customers may also see similar symptoms in other locations when using the global logging region.\n\nWorkaround: None at this time.",
        "when": "2020-11-19T18:18:04Z"
      }
    ],
    "uri": "/incident/google-stackdriver/20009"
  },
  {
    "begin": "2020-11-17T20:02:42Z",
    "created": "2020-11-17T20:19:31Z",
    "end": "2020-11-17T20:36:58Z",
    "external_desc": "Storage Transfer Service unable to edit job configurations",
    "modified": "2020-11-17T20:36:58Z",
    "most-recent-update": {
      "created": "2020-11-17T20:36:58Z",
      "modified": "2020-11-17T20:36:58Z",
      "text": "The issue with Google Cloud Storage transfer service is believed to be affecting a very small number of customers and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nWe thank you for your patience while we're working on resolving the issue.",
      "when": "2020-11-17T20:36:58Z"
    },
    "number": 20008,
    "public": true,
    "service_key": "storage",
    "service_name": "Google Cloud Storage",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-11-17T20:36:58Z",
        "modified": "2020-11-17T20:36:58Z",
        "text": "The issue with Google Cloud Storage transfer service is believed to be affecting a very small number of customers and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-11-17T20:36:58Z"
      },
      {
        "created": "2020-11-17T20:19:33Z",
        "modified": "2020-11-17T20:19:33Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Tuesday, 2020-11-17 14:00 US/Pacific.\n\nDiagnosis: Affected customers will see invalid input errors when attempting to modify some fields within a transfer job's configuration. \n\nWorkaround: None at this time.",
        "when": "2020-11-17T20:19:33Z"
      }
    ],
    "uri": "/incident/storage/20008"
  },
  {
    "begin": "2020-11-12T23:37:41Z",
    "created": "2020-11-13T19:27:29Z",
    "end": "2020-11-13T22:23:20Z",
    "external_desc": "We are experiencing an issue with loading several pages in the Cloud Console, including modifying External HTTP(S) Load Balancer configurations.",
    "modified": "2020-11-13T22:23:21Z",
    "most-recent-update": {
      "created": "2020-11-13T22:23:20Z",
      "modified": "2020-11-13T22:23:20Z",
      "text": "The issue with Cloud Console pages not loading has been resolved for all affected  projects. as of Friday, 2020-11-13 13:15 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-11-13T22:23:20Z"
    },
    "number": 20008,
    "public": true,
    "service_key": "developers-console",
    "service_name": "Google Cloud Console",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-11-13T22:23:20Z",
        "modified": "2020-11-13T22:23:20Z",
        "text": "The issue with Cloud Console pages not loading has been resolved for all affected  projects. as of Friday, 2020-11-13 13:15 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-11-13T22:23:20Z"
      },
      {
        "created": "2020-11-13T20:58:54Z",
        "modified": "2020-11-13T20:58:54Z",
        "text": "Description: Customers trying to modify External HTTP(S) Load Balancer configurations in Cloud Console may see their custom cache key settings inadvertently cleared. \n\nAdditionally, customers might be having issues loading other pages in the Cloud Console.\n\nThe rollout for the mitigation is currently underway and about halfway complete.\n\nWe will provide an update by Friday, 2020-11-13 14:30 US/Pacific with current details.\n\nDiagnosis: Customers trying to modify External HTTP(S) Load Balancer configurations in Cloud Console may see their custom cache key settings inadvertently cleared.\n\nWorkaround: Use gcloud commands to make changes for load balancers.",
        "when": "2020-11-13T20:58:54Z"
      },
      {
        "created": "2020-11-13T19:30:08Z",
        "modified": "2020-11-13T19:30:08Z",
        "text": "Description: Customers trying to modify External HTTP(S) Load Balancer configurations in Cloud Console may see their custom cache key settings inadvertently cleared. \n\nAdditionally, customers might be having issues loading other pages in the Cloud Console.\n\nOur engineering team has determined that further investigation is required to mitigate the issue.\n\nWe will provide an update by Friday, 2020-11-13 13:00 US/Pacific with current details.\n\nDiagnosis: Customers trying to modify External HTTP(S) Load Balancer configurations in Cloud Console may see their custom cache key settings inadvertently cleared.\n\nWorkaround: Use gcloud commands to make changes for load balancers.",
        "when": "2020-11-13T19:30:08Z"
      },
      {
        "created": "2020-11-13T19:27:30Z",
        "modified": "2020-11-13T19:27:30Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nThe mitigation is expected to complete by Friday, 2020-11-13 15:00 US/Pacific.\n\nWe will provide more information by Friday, 2020-11-13 11:30 US/Pacific.\n\nDiagnosis: Customers trying to modify External HTTP(S) Load Balancer configurations in Cloud Console may see their custom cache key settings inadvertently cleared.\n\nWorkaround: Use gcloud commands to make changes for load balancers.",
        "when": "2020-11-13T19:27:30Z"
      }
    ],
    "uri": "/incident/developers-console/20008"
  },
  {
    "begin": "2020-11-10T21:41:00Z",
    "created": "2020-11-10T22:33:26Z",
    "end": "2020-11-11T19:01:10Z",
    "external_desc": "Elevated frequency of Host Maintenance events on GCE instances with an attached GPU(s) and SSD(s)",
    "modified": "2020-11-11T19:01:10Z",
    "most-recent-update": {
      "created": "2020-11-11T19:01:10Z",
      "modified": "2020-11-11T19:01:10Z",
      "text": "The issue with Google Compute Engine instances with an attached GPU(s) and SSD(s) is believed to be affecting a very small number of projects and our Engineering Team continues to work on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nNo further updates will be provided here.\n\nWe thank you for your patience while we're working on resolving the issue.",
      "when": "2020-11-11T19:01:10Z"
    },
    "number": 20012,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-11-11T19:01:10Z",
        "modified": "2020-11-11T19:01:10Z",
        "text": "The issue with Google Compute Engine instances with an attached GPU(s) and SSD(s) is believed to be affecting a very small number of projects and our Engineering Team continues to work on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nNo further updates will be provided here.\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-11-11T19:01:10Z"
      },
      {
        "created": "2020-11-11T00:04:29Z",
        "modified": "2020-11-11T00:04:29Z",
        "text": "Description: Mitigation work is still underway by our engineering team. Further investigation of current impact and mitigation timeline is ongoing. \n\nWe will provide more information by Wednesday, 2020-11-11 13:00 US/Pacific.\n\nDiagnosis: Affected customers will experience elevated frequency of Host Maintenance events on GCE instances with an attached GPU(s) and SSD(s).\n\nWorkaround: Temporarily switch to use V100 GPU's which are unaffected by this issue.\nhttps://cloud.google.com/compute/docs/gpus",
        "when": "2020-11-11T00:04:29Z"
      },
      {
        "created": "2020-11-10T22:33:27Z",
        "modified": "2020-11-10T22:33:27Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine beginning in 2020-08.  A firmware rollout is being created that should address the issue.\n\nThe rollout is currently expected to complete next week, but mitigation efforts are still ongoing. \n\nWe will provide more information by Tuesday, 2020-11-10 16:30 US/Pacific.\n\nDiagnosis: Affected customers will experience elevated frequency of Host Maintenance events on GCE instances with an attached GPU(s) and SSD(s).\n\nWorkaround: Temporarily switch to use V100 GPU's which are unaffected by this issue.\nhttps://cloud.google.com/compute/docs/gpus",
        "when": "2020-11-10T22:33:27Z"
      }
    ],
    "uri": "/incident/compute/20012"
  },
  {
    "begin": "2020-11-05T20:22:48Z",
    "created": "2020-11-05T20:41:54Z",
    "end": "2020-11-05T21:43:49Z",
    "external_desc": "GAE Cloud Monitoring Metrics are not being ingested.",
    "modified": "2020-11-05T21:43:50Z",
    "most-recent-update": {
      "created": "2020-11-05T21:43:49Z",
      "modified": "2020-11-05T21:43:49Z",
      "text": "The issue with Google App Engine has been resolved for all affected projects as of Thursday, 2020-11-05 13:11 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-11-05T21:43:49Z"
    },
    "number": 20008,
    "public": true,
    "service_key": "appengine",
    "service_name": "Google App Engine",
    "severity": "high",
    "updates": [
      {
        "created": "2020-11-05T21:43:49Z",
        "modified": "2020-11-05T21:43:49Z",
        "text": "The issue with Google App Engine has been resolved for all affected projects as of Thursday, 2020-11-05 13:11 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-11-05T21:43:49Z"
      },
      {
        "created": "2020-11-05T20:57:17Z",
        "modified": "2020-11-05T20:57:17Z",
        "text": "Description: We have rolled back an update and believe the issue with Google App Engine is partially resolved.    Our engineering teams are working to confirm full resolution.\n\nWe do not have an ETA for full resolution at this point.\n\nWe will provide an update by Thursday, 2020-11-05 13:45 US/Pacific with current details.\n\nDiagnosis: Metric dashboards for GAE services no longer update.\n\nWorkaround: None at this time.",
        "when": "2020-11-05T20:57:17Z"
      },
      {
        "created": "2020-11-05T20:41:55Z",
        "modified": "2020-11-05T20:41:55Z",
        "text": "Description: We are experiencing an issue with Google App Engine beginning at Thursday, 2020-11-05 09:55 US/Pacific. Cloud Monitoring Metrics are no longer being ingested causing telemetry data to be unavailable.\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-11-05 13:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Metric dashboards for GAE services no longer update.\n\nWorkaround: None at this time.",
        "when": "2020-11-05T20:41:55Z"
      }
    ],
    "uri": "/incident/appengine/20008"
  },
  {
    "begin": "2020-10-30T15:33:55Z",
    "created": "2020-10-30T23:30:54Z",
    "end": "2020-10-31T00:02:25Z",
    "external_desc": "GCE instance creation/start/stop operations failing in us-central1-f",
    "modified": "2020-10-31T00:02:26Z",
    "most-recent-update": {
      "created": "2020-10-31T00:02:25Z",
      "modified": "2020-10-31T00:02:25Z",
      "text": "The issue with Google Compute Engine has been resolved for all affected users as of Friday, 2020-10-30 16:35 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-31T00:02:25Z"
    },
    "number": 20011,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-31T00:02:25Z",
        "modified": "2020-10-31T00:02:25Z",
        "text": "The issue with Google Compute Engine has been resolved for all affected users as of Friday, 2020-10-30 16:35 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-31T00:02:25Z"
      },
      {
        "created": "2020-10-30T23:56:13Z",
        "modified": "2020-10-30T23:56:13Z",
        "text": "Description: We believe the issue with Google Compute Engine operations is partially resolved. All previous operations should have completed, and customers should experience normal latency on new operations. \n\nWe will provide an update by Friday, 2020-10-30 17:45 US/Pacific with current details.\n\n\nDiagnosis: Affected customers may see delays performing instance operations, but they should eventually complete. Other Cloud Services that create instances on demand may also experience impact such as: Google Kubernetes Engine, Composer, Dataproc, and Dataflow.\n\nWorkaround: When possible try instance operations in other zones.",
        "when": "2020-10-30T23:56:13Z"
      },
      {
        "created": "2020-10-30T23:37:45Z",
        "modified": "2020-10-30T23:37:45Z",
        "text": "Description: Other Cloud Services that create instances on demand may be impacted such as: Google Kubernetes Engine, Composer, Dataproc, and Dataflow\n\nWe will provide an update by Friday, 2020-10-30 17:00 US/Pacific with current details.\n\nDiagnosis: Affected customers may see delays performing instance operations, but they should eventually complete. Other Cloud Services that create instances on demand may also experience impact such as: Google Kubernetes Engine, Composer, Dataproc, and Dataflow.\n\nWorkaround: When possible try instance operations in other zones.",
        "when": "2020-10-30T23:37:45Z"
      },
      {
        "created": "2020-10-30T23:30:55Z",
        "modified": "2020-10-30T23:30:55Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine starting on Friday, 2020-10-30 07:30 US/Pacific. The backlog is continuing to decrease, and delays on new instance creation have significantly decreased from the peak with an average of 1 minute. We are anticipating the backlog to clear in approximately 40 minutes. \n\nWe will provide an update by Friday, 2020-10-30 17:00 US/Pacific with current details.\n\nDiagnosis: Affected customers may see delays performing instance operations, but they should eventually complete. \n\nWorkaround: When possible try instance operations in other zones.",
        "when": "2020-10-30T23:30:55Z"
      }
    ],
    "uri": "/incident/compute/20011"
  },
  {
    "begin": "2020-10-29T20:09:28Z",
    "created": "2020-10-29T20:12:14Z",
    "end": "2020-10-29T21:16:52Z",
    "external_desc": "We believe the issue with Cloud Run deployments failing is fully resolved as of Thursday, 2020-10-29 14:07.",
    "modified": "2020-10-29T21:16:53Z",
    "most-recent-update": {
      "created": "2020-10-29T21:16:53Z",
      "modified": "2020-10-29T21:16:53Z",
      "text": "The issue with Cloud Run deployments failing globally has been resolved for all affected projects as of Thursday, 2020-10-29 14:07 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-29T21:16:52Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "cloud-run",
    "service_name": "Cloud Run",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-29T21:16:53Z",
        "modified": "2020-10-29T21:16:53Z",
        "text": "The issue with Cloud Run deployments failing globally has been resolved for all affected projects as of Thursday, 2020-10-29 14:07 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-29T21:16:52Z"
      },
      {
        "created": "2020-10-29T21:11:24Z",
        "modified": "2020-10-29T21:11:24Z",
        "text": "Description: We believe the issue with Cloud Run deployments failing is fully resolved as of Thursday, 2020-10-29 14:07.\n\nWe are currently monitoring the situation to ensure there is no recurrence.\n\nWe will provide an update by Thursday, 2020-10-29 14:45 US/Pacific with current details.\n\nDiagnosis: New deployments to Cloud Run will fail globally.\n\nWorkaround: None at this time.",
        "when": "2020-10-29T21:11:24Z"
      },
      {
        "created": "2020-10-29T20:40:23Z",
        "modified": "2020-10-29T20:40:23Z",
        "text": "Description: Our engineering team is currently rolling back a configuration change to mitigate the issue. We do not yet have an ETA for full resolution.\n\nExisting Cloud Run deployments are unaffected.\n\nWe will provide more information by Thursday, 2020-10-29 14:30 US/Pacific.\n\nDiagnosis: New deployments to Cloud Run will fail globally.\n\nWorkaround: None at this time.",
        "when": "2020-10-29T20:40:23Z"
      },
      {
        "created": "2020-10-29T20:12:17Z",
        "modified": "2020-10-29T20:12:17Z",
        "text": "Description: We are investigating an issue with Cloud Run deployments failing globally starting at Thursday, 2020-10-29 12:45 US/Pacific. \n\nWe will provide more information by Thursday, 2020-10-29 14:00 US/Pacific.\n\nDiagnosis: New deployments to Cloud Run may fail.\n\nWorkaround: None at this time.",
        "when": "2020-10-29T20:12:17Z"
      }
    ],
    "uri": "/incident/cloud-run/20004"
  },
  {
    "begin": "2020-10-27T20:21:53Z",
    "created": "2020-10-27T20:24:38Z",
    "end": "2020-10-27T21:09:41Z",
    "external_desc": "We've received a report of an issue with Google Cloud Storage as of Tuesday, 2020-10-27 11:00 US/Pacific.",
    "modified": "2020-10-27T21:09:41Z",
    "most-recent-update": {
      "created": "2020-10-27T21:09:41Z",
      "modified": "2020-10-27T21:09:41Z",
      "text": "The issue with Google Cloud Storage buckets in us-central1 seeing higher latency and timeout errors has been resolved for all affected projects as of Tuesday, 2020-10-27 13:30 US/Pacific.",
      "when": "2020-10-27T21:09:41Z"
    },
    "number": 20007,
    "public": true,
    "service_key": "storage",
    "service_name": "Google Cloud Storage",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-27T21:09:41Z",
        "modified": "2020-10-27T21:09:41Z",
        "text": "The issue with Google Cloud Storage buckets in us-central1 seeing higher latency and timeout errors has been resolved for all affected projects as of Tuesday, 2020-10-27 13:30 US/Pacific.",
        "when": "2020-10-27T21:09:41Z"
      },
      {
        "created": "2020-10-27T20:53:24Z",
        "modified": "2020-10-27T20:53:24Z",
        "text": "Description: We've received a report of an issue with Google Cloud Storage as of Tuesday, 2020-10-27 11:00 US/Pacific.\n\nMitigation has been effective and we believe the issue should be resolved as of Tuesday, 2020-10-27 13:30 US/Pacific. We are continuing to monitor the situation for any changes.\n\nWe will provide more information by Tuesday, 2020-10-27 14:15 US/Pacific.\n\nDiagnosis: Affected customers may experience request timeout errors. Downstream services may include Google Container Registry with images being stored in us-central1. This may cause GKE workloads to have trouble pulling new images in us-central1.\n\nWorkaround: None at this time.",
        "when": "2020-10-27T20:53:23Z"
      },
      {
        "created": "2020-10-27T20:38:23Z",
        "modified": "2020-10-27T20:38:23Z",
        "text": "Description: We are experiencing an issue with Google Cloud Storage requests timing out as of Tuesday, 2020-10-27 11:00 US/Pacific.\n\nGoogle Container Registry is also experiencing timeout errors as a result of the Google Cloud Storage issues. \n\nOur engineers are currently investigating the root cause and working to mitigate the issue.\n\nWe will provide more information by Tuesday, 2020-10-27 14:15 US/Pacific.\n\nLocation: us-central1\n\nDiagnosis: Affected customers may experience request timeout errors.\n\nWorkaround: None at this time.",
        "when": "2020-10-27T20:38:23Z"
      },
      {
        "created": "2020-10-27T20:24:40Z",
        "modified": "2020-10-27T20:24:40Z",
        "text": "Description: We've received a report of an issue with Google Cloud Storage as of Tuesday, 2020-10-27 11:00 US/Pacific.\n\nOur engineers are currently investigating the root cause.\n\nWe will provide more information by Tuesday, 2020-10-27 14:00 US/Pacific.\n\nLocation: us-central1\n\nDiagnosis: Affected customers may experience request timeout errors.\n\nWorkaround: None at this time.",
        "when": "2020-10-27T20:24:40Z"
      }
    ],
    "uri": "/incident/storage/20007"
  },
  {
    "begin": "2020-10-24T16:56:39Z",
    "created": "2020-10-24T17:18:47Z",
    "end": "2020-10-24T19:02:57Z",
    "external_desc": "We are investigating an elevated error rate in us-east1 for Cloud Storage Customers.",
    "modified": "2020-10-27T05:18:07Z",
    "most-recent-update": {
      "created": "2020-10-24T19:02:57Z",
      "modified": "2020-10-27T05:10:48Z",
      "text": "Mitigations are complete, and we are seeing service restored for all customers.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-24T19:02:57Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "storage",
    "service_name": "Google Cloud Storage",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-24T19:02:57Z",
        "modified": "2020-10-27T05:10:48Z",
        "text": "Mitigations are complete, and we are seeing service restored for all customers.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-24T19:02:57Z"
      },
      {
        "created": "2020-10-24T18:06:37Z",
        "modified": "2020-10-24T18:06:37Z",
        "text": "Description: We are experiencing an issue with Google Cloud Storage beginning at Saturday, 2020-10-24 07:40 PDT.\n\nCurrently, we have begun mitigations, and customers should begin to experience regular service within the hour. \n\nWe will provide an update by Saturday, 2020-10-24 12:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: This may appear as timeouts, 5XX errors and potential authorization errors being returned from the service. \n\nWorkaround: There is no workaround at this time.",
        "when": "2020-10-24T18:06:37Z"
      },
      {
        "created": "2020-10-24T17:18:48Z",
        "modified": "2020-10-24T17:18:48Z",
        "text": "Description: We are experiencing an issue with Google Cloud Storage beginning at Saturday, 2020-10-24 07:40 PDT.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Saturday, 2020-10-24 11:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: This may appear as timeouts, 5XX errors and potential authorization errors being returned from the service. \n\nWorkaround: There is no workaround at this time.",
        "when": "2020-10-24T17:18:48Z"
      }
    ],
    "uri": "/incident/storage/20005"
  },
  {
    "begin": "2020-10-23T13:22:29Z",
    "created": "2020-10-23T13:47:22Z",
    "end": "2020-10-23T15:00:41Z",
    "external_desc": "Some deployments to Google Cloud Functions using go113 runtime are failing",
    "modified": "2020-10-23T15:00:42Z",
    "most-recent-update": {
      "created": "2020-10-23T15:00:41Z",
      "modified": "2020-10-23T15:00:41Z",
      "text": "The issue with deployments of Google Cloud Functions using go113 runtime has been resolved for all affected users as of Friday, 2020-10-23 07:51 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-23T15:00:41Z"
    },
    "number": 20006,
    "public": true,
    "service_key": "cloud-functions",
    "service_name": "Google Cloud Functions",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-23T15:00:41Z",
        "modified": "2020-10-23T15:00:41Z",
        "text": "The issue with deployments of Google Cloud Functions using go113 runtime has been resolved for all affected users as of Friday, 2020-10-23 07:51 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-23T15:00:41Z"
      },
      {
        "created": "2020-10-23T14:54:17Z",
        "modified": "2020-10-23T14:54:17Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Friday, 2020-10-23 08:15 US/Pacific.\n\nDiagnosis: Customers affected by this issue may see an error similar to  the following:\n\nERROR: (gcloud.functions.deploy) OperationError: code=3, message=Build failed: # github.com/cloudevents/sdk-go/v2/extensions\n\nsrc/github.com/cloudevents/sdk-go/v2/extensions/distributed_tracing_extension.go:161:3: cannot use span (type trace.Span) as type *trace.Span in return argument:\n\n*trace.Span is pointer to interface, not interface; Error ID: 1093f764\n\n\nWorkaround: Customers can avoid this issue by making sure to include a \"go.mod\" file in their project. For more information see this blog post:\n\nhttps://blog.golang.org/using-go-modules",
        "when": "2020-10-23T14:54:17Z"
      },
      {
        "created": "2020-10-23T14:13:11Z",
        "modified": "2020-10-23T14:13:11Z",
        "text": "Description: We are experiencing an issue with Google Cloud Functions, affecting deployments using the \"go113\" runtime, beginning at Thursday, 2020-10-22 15:00 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2020-10-23 08:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Customers affected by this issue may see an error similar to  the following:\n\nERROR: (gcloud.functions.deploy) OperationError: code=3, message=Build failed: # github.com/cloudevents/sdk-go/v2/extensions\n\nsrc/github.com/cloudevents/sdk-go/v2/extensions/distributed_tracing_extension.go:161:3: cannot use span (type trace.Span) as type *trace.Span in return argument:\n\n*trace.Span is pointer to interface, not interface; Error ID: 1093f764\n\n\nWorkaround: Customers can avoid this issue by making sure to include a \"go.mod\" file in their project. For more information see this blog post:\n\nhttps://blog.golang.org/using-go-modules",
        "when": "2020-10-23T14:13:11Z"
      },
      {
        "created": "2020-10-23T13:47:24Z",
        "modified": "2020-10-23T13:47:24Z",
        "text": "Description: We are experiencing an issue with Google Cloud Functions, affecting deployments using the \"go113\" runtime, beginning at Thursday, 2020-10-22 15:00 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2020-10-23 08:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Customers affected by this issue may see an error similar to  the following:\n\nERROR: (gcloud.functions.deploy) OperationError: code=3, message=Build failed: # github.com/cloudevents/sdk-go/v2/extensions\n\nsrc/github.com/cloudevents/sdk-go/v2/extensions/distributed_tracing_extension.go:161:3: cannot use span (type trace.Span) as type *trace.Span in return argument:\n\n*trace.Span is pointer to interface, not interface; Error ID: 1093f764\n\n\nWorkaround: None at this time.",
        "when": "2020-10-23T13:47:24Z"
      }
    ],
    "uri": "/incident/cloud-functions/20006"
  },
  {
    "begin": "2020-10-23T01:08:25Z",
    "created": "2020-10-23T01:26:41Z",
    "end": "2020-10-23T03:11:51Z",
    "external_desc": "We're experiencing an issue with gcloud auth application-default login.",
    "modified": "2020-10-23T03:11:51Z",
    "most-recent-update": {
      "created": "2020-10-23T03:11:51Z",
      "modified": "2020-10-23T03:11:51Z",
      "text": "The issue with gcloud is believed to be affecting a very small number of users and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nNo further updates will be provided here.\n\nWe thank you for your patience while we're working on resolving the issue.",
      "when": "2020-10-23T03:11:51Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "support",
    "service_name": "Google Cloud Support",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-23T03:11:51Z",
        "modified": "2020-10-23T03:11:51Z",
        "text": "The issue with gcloud is believed to be affecting a very small number of users and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nNo further updates will be provided here.\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-10-23T03:11:51Z"
      },
      {
        "created": "2020-10-23T01:56:12Z",
        "modified": "2020-10-23T01:56:12Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Thursday, 2020-10-22 21:00 US/Pacific.\n\nDiagnosis: Customers may receive 'Sign in with Google temporarily disabled for this app' when running 'gcloud auth application-default login'.\n\nWorkaround: 1. Get in touch with your Google Workspace (formerly GSuite) administrator\n2. Visit [https://support.google.com/a/answer/7281227](https://support.google.com/a/answer/7281227)\n3. Follow the \"Manage access to apps: Trusted, Limited, or Blocked\" method\n4. Add '764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com' as a trusted Client ID.\n5. Retry your 'gcloud auth application-default login' operation within a few minutes.",
        "when": "2020-10-23T01:56:12Z"
      },
      {
        "created": "2020-10-23T01:45:32Z",
        "modified": "2020-10-23T01:54:27Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\r\n\r\nWe do not have an ETA for mitigation at this point.\r\n\r\nWe will provide more information by Thursday, 2020-10-22 20:00 US/Pacific.\r\n\r\nDiagnosis: Customers may receive 'Sign in with Google temporarily disabled for this app' when running 'gcloud auth application-default login'.\r\n\r\nWorkaround: \r\n1. Get in touch with your Google Workspace (formerly GSuite) administrator\r\n2. Visit [https://support.google.com/a/answer/7281227](https://support.google.com/a/answer/7281227)\r\n3. Follow the \"Manage access to apps: Trusted, Limited, or Blocked\" method\r\n4. Add '764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com' as a trusted Client ID.\r\n5. Retry your 'gcloud auth application-default login' operation within a few minutes.",
        "when": "2020-10-23T01:45:32Z"
      },
      {
        "created": "2020-10-23T01:26:43Z",
        "modified": "2020-10-23T01:57:16Z",
        "text": "Description: We are experiencing an issue with gcloud auth application-default login.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Thursday, 2020-10-22 19:00 US/Pacific with current details.\r\n\r\nDiagnosis: Customers may receive 'Sign in with Google temporarily disabled for this app' when running 'gcloud auth application-default login'.\r\n\r\nWorkaround: 1. Get in touch with your Google Workspace (formerly GSuite) administrator\r\n2. Visit [https://support.google.com/a/answer/7281227](https://support.google.com/a/answer/7281227)\r\n3. Follow the \"Manage access to apps: Trusted, Limited, or Blocked\" method\r\n4. Add '764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com' as a trusted Client ID.\r\n5. Retry your 'gcloud auth application-default login' operation within a few minutes.",
        "when": "2020-10-23T01:26:43Z"
      }
    ],
    "uri": "/incident/support/20004"
  },
  {
    "begin": "2020-10-20T00:42:01Z",
    "created": "2020-10-20T00:44:54Z",
    "end": "2020-10-20T03:56:22Z",
    "external_desc": "We are experiencing an issue with Google Kubernetes Engine in us-central1.",
    "modified": "2020-10-20T03:56:23Z",
    "most-recent-update": {
      "created": "2020-10-20T03:56:22Z",
      "modified": "2020-10-20T03:56:22Z",
      "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Monday, 2020-10-19 20:00 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-20T03:56:22Z"
    },
    "number": 20008,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-20T03:56:22Z",
        "modified": "2020-10-20T03:56:22Z",
        "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Monday, 2020-10-19 20:00 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-20T03:56:22Z"
      },
      {
        "created": "2020-10-20T02:59:25Z",
        "modified": "2020-10-20T02:59:25Z",
        "text": "Description: Our engineering team continues to work on mitigating the underlying networking issue.\n\nWe will provide an update by Monday, 2020-10-19 21:15 US/Pacific with current details.\n\nDiagnosis: Cluster mutation operations may result errors for affected clusters. The operations include creations and deletions of clusters, nodepools, and nodes.\n\nWorkaround: None at this time.",
        "when": "2020-10-20T02:59:25Z"
      },
      {
        "created": "2020-10-20T02:06:55Z",
        "modified": "2020-10-20T02:06:55Z",
        "text": "Description: Our engineering team has determined that further investigation is required to mitigate the underlying networking issue.\n\nWe will provide an update by Monday, 2020-10-19 20:05 US/Pacific with current details.\n\nDiagnosis: Affected clusters may fail during cluster mutation operations, including creations and deletions of clusters, nodepools, and nodes.\n\nWorkaround: None at this time.",
        "when": "2020-10-20T02:06:55Z"
      },
      {
        "created": "2020-10-20T01:38:07Z",
        "modified": "2020-10-20T01:38:07Z",
        "text": "Description: Mitigation work is still underway in the underlying networking incident. We believe that cluster mutation operations will be recovered shortly after the underlying incident is mitigated.\n\nWe will provide more information by Monday, 2020-10-19 19:15 US/Pacific.\n\nDiagnosis: Affected clusters may fail during cluster mutation operations, including creations and deletions of clusters, nodepools, and nodes.\n\nWorkaround: None at this time.",
        "when": "2020-10-20T01:38:07Z"
      },
      {
        "created": "2020-10-20T01:05:18Z",
        "modified": "2020-10-20T01:05:18Z",
        "text": "Description: Mitigation work is still underway by our engineering team. We believe that the mitigation of the underlying networking incident will resolve its affect to cluster mutation operations. We do not yet have a ETA of full mitigation at this point.\n\nWe will provide more information by Monday, 2020-10-19 18:45 US/Pacific.\n\nDiagnosis: Affected clusters may fail during cluster mutation operations, including creations and deletions of clusters, nodepools, and nodes.\n\nWorkaround: None at this time.",
        "when": "2020-10-20T01:05:18Z"
      },
      {
        "created": "2020-10-20T00:44:55Z",
        "modified": "2020-10-20T00:44:55Z",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine in the us-central1 region. We believe the cause is related to the currently ongoing networking incident in the region. Our engineering team continues to investigate the issue.\n\nWe will provide an update by Monday, 2020-10-19 18:15 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Affected clusters may fail during cluster mutation operations, including creations and deletions of clusters, nodepools, and nodes.\n\nWorkaround: None at this time.",
        "when": "2020-10-20T00:44:55Z"
      }
    ],
    "uri": "/incident/container-engine/20008"
  },
  {
    "begin": "2020-10-19T21:19:11Z",
    "created": "2020-10-19T21:20:53Z",
    "end": "2020-10-19T21:49:44Z",
    "external_desc": "We are currently experiencing an issue with Google Kubernetes Engine customers experiencing elevated rates of packet loss in southamerica-east1-[a, b, c] due to the ongoing Cloud Networking issue beginning at Monday, 2020-10-19 13:05 US/Pacific.",
    "modified": "2020-10-19T21:49:45Z",
    "most-recent-update": {
      "created": "2020-10-19T21:49:44Z",
      "modified": "2020-10-19T21:49:44Z",
      "text": "The issue with Google Kubernetes Engine has been resolved for all affected users as of Monday, 2020-10-19 14:12 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-19T21:49:44Z"
    },
    "number": 20007,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-19T21:49:44Z",
        "modified": "2020-10-19T21:49:44Z",
        "text": "The issue with Google Kubernetes Engine has been resolved for all affected users as of Monday, 2020-10-19 14:12 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-19T21:49:44Z"
      },
      {
        "created": "2020-10-19T21:20:54Z",
        "modified": "2020-10-19T21:20:54Z",
        "text": "Description: We are currently experiencing an issue with Google Kubernetes Engine customers experiencing elevated rates of packet loss in southamerica-east1-[a, b, c] due to the ongoing Cloud Networking issue beginning at Monday, 2020-10-19 13:05 US/Pacific.\n\nPlease follow (https://status.cloud.google.com/incident/cloud-networking/20010) for current details and future updates.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-10-19T21:20:54Z"
      }
    ],
    "uri": "/incident/container-engine/20007"
  },
  {
    "begin": "2020-10-19T20:58:47Z",
    "created": "2020-10-19T21:04:13Z",
    "end": "2020-10-19T21:37:18Z",
    "external_desc": "We are currently experiencing an issue with Google Compute Engine customers experiencing elevated rates of packet loss in southamerica-east1-{a, b, c} due to the ongoing Cloud Networking issue beginning at Monday, 2020-10-19 13:05 US/Pacific.",
    "modified": "2020-10-19T21:37:19Z",
    "most-recent-update": {
      "created": "2020-10-19T21:37:18Z",
      "modified": "2020-10-19T21:37:18Z",
      "text": "The issue with Google Compute Engine in southamerica-east1 has been resolved for all affected projects as of Monday, 2020-10-19 14:12 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-19T21:37:18Z"
    },
    "number": 20010,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-19T21:37:18Z",
        "modified": "2020-10-19T21:37:18Z",
        "text": "The issue with Google Compute Engine in southamerica-east1 has been resolved for all affected projects as of Monday, 2020-10-19 14:12 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-19T21:37:18Z"
      },
      {
        "created": "2020-10-19T21:04:14Z",
        "modified": "2020-10-19T21:04:14Z",
        "text": "Description: We are currently experiencing an issue with Google Compute Engine customers experiencing elevated rates of packet loss in southamerica-east1-[a, b, c] due to the ongoing Cloud Networking issue beginning at Monday, 2020-10-19 13:05 US/Pacific.\n\nPlease follow (https://status.cloud.google.com/incident/cloud-networking/20010) for current details and future updates.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-10-19T21:04:14Z"
      }
    ],
    "uri": "/incident/compute/20010"
  },
  {
    "begin": "2020-10-19T20:40:43Z",
    "created": "2020-10-19T21:13:16Z",
    "end": "2020-10-19T21:44:23Z",
    "external_desc": "We've received a report of an issue with Cloud Bigtable as of Monday, 2020-10-19 13:18:57 PDT",
    "modified": "2020-10-19T21:44:24Z",
    "most-recent-update": {
      "created": "2020-10-19T21:44:23Z",
      "modified": "2020-10-19T21:44:23Z",
      "text": "The issue with Cloud Bigtable has been resolved for all affected projects as of Monday, 2020-10-19 14:05 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-19T21:44:23Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-bigtable",
    "service_name": "Google Cloud Bigtable",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-19T21:44:23Z",
        "modified": "2020-10-19T21:44:23Z",
        "text": "The issue with Cloud Bigtable has been resolved for all affected projects as of Monday, 2020-10-19 14:05 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-19T21:44:23Z"
      },
      {
        "created": "2020-10-19T21:17:52Z",
        "modified": "2020-10-19T21:17:52Z",
        "text": "Description: We are experiencing an issue with Cloud Bigtable.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Monday, 2020-10-19 15:50 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-10-19T21:17:52Z"
      },
      {
        "created": "2020-10-19T21:13:17Z",
        "modified": "2020-10-19T21:13:17Z",
        "text": "Description: We are currently experiencing an issue with Cloud Bigtable customers experiencing elevated error rates in southamerica-east1-[a, b, c] due to the ongoing Cloud Networking issue beginning at Monday, 2020-10-19 13:05 US/Pacific.\n\nPlease follow (https://status.cloud.google.com/incident/cloud-networking/20010) for current details and future updates.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-10-19T21:13:17Z"
      }
    ],
    "uri": "/incident/cloud-bigtable/20002"
  },
  {
    "begin": "2020-10-19T20:20:49Z",
    "created": "2020-10-19T21:09:16Z",
    "end": "2020-10-19T21:23:45Z",
    "external_desc": "Google Cloud Storage customers making requests to southamerica-east1 will experience elevated error rates due to the ongoing Cloud Networking issue as of Monday, 2020-10-19 13:05 US/Pacific.",
    "modified": "2020-10-19T21:23:46Z",
    "most-recent-update": {
      "created": "2020-10-19T21:23:45Z",
      "modified": "2020-10-19T21:23:45Z",
      "text": "The issue with Google Cloud Storage in southamerica-east1 has been resolved for all affected users as of Monday, 2020-10-19 14:12 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-19T21:23:45Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "storage",
    "service_name": "Google Cloud Storage",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-19T21:23:45Z",
        "modified": "2020-10-19T21:23:45Z",
        "text": "The issue with Google Cloud Storage in southamerica-east1 has been resolved for all affected users as of Monday, 2020-10-19 14:12 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-19T21:23:45Z"
      },
      {
        "created": "2020-10-19T21:09:17Z",
        "modified": "2020-10-19T21:09:17Z",
        "text": "Description: Google Cloud Storage customers making requests to southamerica-east1 will experience elevated error rates due to the ongoing Cloud Networking issue as of Monday, 2020-10-19 13:05 US/Pacific.\n\nPlease follow (https://status.cloud.google.com/incident/cloud-networking/20010) for current details and future updates.\n\nDiagnosis: None at this time.\n\nWorkaround: Other GCS regions are unaffected.",
        "when": "2020-10-19T21:09:17Z"
      }
    ],
    "uri": "/incident/storage/20004"
  },
  {
    "begin": "2020-10-19T20:19:06Z",
    "created": "2020-10-19T20:45:41Z",
    "end": "2020-10-19T21:34:43Z",
    "external_desc": "We are experiencing an issue with Cloud Networking beginning in the southamerica-east1 region starting at Monday, 2020-10-19 13:03 US/Pacific.",
    "modified": "2020-10-20T01:25:46Z",
    "most-recent-update": {
      "created": "2020-10-19T21:34:43Z",
      "modified": "2020-10-19T21:34:43Z",
      "text": "The issue with Google Cloud Networking has been resolved for all affected users as of Monday, 2020-10-19 14:11 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-19T21:34:43Z"
    },
    "number": 20010,
    "public": true,
    "service_key": "cloud-networking",
    "service_name": "Google Cloud Networking",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-19T21:34:43Z",
        "modified": "2020-10-19T21:34:43Z",
        "text": "The issue with Google Cloud Networking has been resolved for all affected users as of Monday, 2020-10-19 14:11 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-19T21:34:43Z"
      },
      {
        "created": "2020-10-19T21:14:20Z",
        "modified": "2020-10-20T01:25:45Z",
        "text": "Description: We are experiencing an issue with Cloud Networking beginning in the southamerica-east1 region starting at Monday, 2020-10-19 13:03 PDT.  This issue is impacting Google Coud Storage, Compute Engine, Kubernetes Engine and Cloud Bigtable.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Monday, 2020-10-19 15:30 US/Pacific with current details.\r\n\r\n\r\nDiagnosis: None at this time.\r\n\r\nWorkaround: None at this time.",
        "when": "2020-10-19T21:14:20Z"
      },
      {
        "created": "2020-10-19T20:57:21Z",
        "modified": "2020-10-20T01:21:50Z",
        "text": "Description: We are experiencing an issue with Cloud Networking beginning in the southamerica-east1 region starting at Monday, 2020-10-19 13:03 US/Pacific.  This issue is impacting Google Coud Storage, Compute Engine, Kubernetes Engine and Cloud Bigtable.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Monday, 2020-10-19 14:45 US/Pacific with current details.\r\n\r\nWe apologize to all who are affected by the disruption.\r\n\r\nDiagnosis: None at this time.\r\n\r\nWorkaround: None at this time.",
        "when": "2020-10-19T20:57:21Z"
      },
      {
        "created": "2020-10-19T20:55:52Z",
        "modified": "2020-10-20T01:21:32Z",
        "text": "Description: We are experiencing an issue with Cloud Networking beginning in the southamerica-east1 region starting at Monday, 2020-10-19 13:03 US/Pacific.  This issue is impacting GCS, GCE, and GKE.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Monday, 2020-10-19 14:45 US/Pacific with current details.\r\n\r\nWe apologize to all who are affected by the disruption.\r\n\r\nDiagnosis: None at this time.\r\n\r\nWorkaround: None at this time.",
        "when": "2020-10-19T20:55:52Z"
      },
      {
        "created": "2020-10-19T20:45:43Z",
        "modified": "2020-10-20T01:10:58Z",
        "text": "Description: We are experiencing an issue with Cloud Networking beginning at Monday, 2020-10-19 13:03 US/Pacific.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Monday, 2020-10-19 14:25 US/Pacific with current details.\r\n\r\nWe apologize to all who are affected by the disruption.\r\n\r\nDiagnosis: None at this time.\r\n\r\nWorkaround: None at this time.",
        "when": "2020-10-19T20:45:43Z"
      }
    ],
    "uri": "/incident/cloud-networking/20010"
  },
  {
    "begin": "2020-10-07T21:27:06Z",
    "created": "2020-10-07T21:58:39Z",
    "end": "2020-10-08T13:54:35Z",
    "external_desc": "We are currently working to mitigate the issue of Cloud Composer create/update environment requests failing in asia-northeast1, asia-northeast2, asia-northeast3, asia-southeast1, europe-west1, europe-west3, europe-west6, europe-west4, northamerica-northeast1, southamerica-east1,us-central1, us-east1, us-west1, us-west2, and us-west4. ",
    "modified": "2020-10-08T13:54:35Z",
    "most-recent-update": {
      "created": "2020-10-08T13:54:35Z",
      "modified": "2020-10-08T13:54:35Z",
      "text": "The issue with Cloud Composer has been resolved for all affected projects as of Thursday, 2020-10-08 06:54 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-08T13:54:35Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "composer",
    "service_name": "Google Cloud Composer",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-08T13:54:35Z",
        "modified": "2020-10-08T13:54:35Z",
        "text": "The issue with Cloud Composer has been resolved for all affected projects as of Thursday, 2020-10-08 06:54 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-08T13:54:35Z"
      },
      {
        "created": "2020-10-08T06:07:10Z",
        "modified": "2020-10-08T06:07:10Z",
        "text": "Description: We are currently working to mitigate the issue of Cloud Composer create/update environment requests failing in asia-northeast1, asia-northeast2, asia-northeast3, asia-southeast1, europe-west1, europe-west3, europe-west6, europe-west4, northamerica-northeast1,southamerica-east1,us-central1, us-east1, us-west1, us-west2, and us-west4. .\n\nOur engineers are currently rolling back a configuration change to mitigate. \n\nWe will provide more information by Thursday, 2020-10-08 07:00 US/Pacific.\n\nDiagnosis: Create/update environment requests are failing. Existing workloads are unaffected.\n\nWorkaround: None at this time.",
        "when": "2020-10-08T06:07:10Z"
      },
      {
        "created": "2020-10-07T22:50:01Z",
        "modified": "2020-10-07T22:50:01Z",
        "text": "Description: We are currently working to mitigate the issue of Cloud Composer create/update environment requests failing in asia-northeast1, asia-northeast2, asia-northeast3, europe-west3, europe-west6, northamerica-northeast1, southamerica-east1, and us-west4.\n\nOur engineers are currently rolling back a configuration change to mitigate. We expect the rollback to complete within the next 7 hours.\n\nWe will provide more information by Wednesday, 2020-10-07 23:00 US/Pacific.\n\nDiagnosis: Create/update environment requests are failing in asia-northeast1, asia-northeast2, asia-northeast3, europe-west3, europe-west6, northamerica-northeast1, southamerica-east1, and us-west4. Existing workloads are unaffected.\n\nWorkaround: None at this time.",
        "when": "2020-10-07T22:50:01Z"
      },
      {
        "created": "2020-10-07T21:58:40Z",
        "modified": "2020-10-07T21:58:40Z",
        "text": "Description: We are investigating an issue of Cloud Composer create/update requests failing in asia-northeast1, asia-northeast2, asia-northeast3, europe-west3, europe-west6, northamerica-northeast1, southamerica-east1, and us-west4. Existing workloads are unaffected.\n\nWe will provide more information by Wednesday, 2020-10-07 16:00 US/Pacific.\n\nDiagnosis: Create/update environment requests are failing in asia-northeast1, asia-northeast2, asia-northeast3, europe-west3, europe-west6, northamerica-northeast1, southamerica-east1, and us-west4. Existing workloads are unaffected.\n\nWorkaround: None at this time.",
        "when": "2020-10-07T21:58:40Z"
      }
    ],
    "uri": "/incident/composer/20005"
  },
  {
    "begin": "2020-10-06T14:41:56Z",
    "created": "2020-10-06T15:16:26Z",
    "end": "2020-10-06T16:17:08Z",
    "external_desc": "App Engine Standard returning elevated HTTP 500 errors in us-central1",
    "modified": "2020-10-06T16:17:08Z",
    "most-recent-update": {
      "created": "2020-10-06T16:17:08Z",
      "modified": "2020-10-06T16:17:08Z",
      "text": "The issue with Google App Engine has been resolved for all affected users as of Tuesday, 2020-10-06 09:13 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-06T16:17:08Z"
    },
    "number": 20007,
    "public": true,
    "service_key": "appengine",
    "service_name": "Google App Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-06T16:17:08Z",
        "modified": "2020-10-06T16:17:08Z",
        "text": "The issue with Google App Engine has been resolved for all affected users as of Tuesday, 2020-10-06 09:13 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-06T16:17:08Z"
      },
      {
        "created": "2020-10-06T15:56:23Z",
        "modified": "2020-10-06T15:56:23Z",
        "text": "Description: We are experiencing an issue with Google App Engine in us-central1 beginning at Tuesday, 2020-10-06 06:45 US/Pacific.\n\nSymptoms: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard deployments in us-central1. These failures are viewable in Cloud Logging.\n\nMitigation work is currently underway by our engineering team.\n\nThe mitigation is expected to complete by Tuesday, 2020-10-06 09:15 US/Pacific.\n\nWe will provide more information by Tuesday, 2020-10-06 09:15 US/Pacific.\n\nDiagnosis:  Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard instance in us-central1.\n\nWorkaround: None at this time.",
        "when": "2020-10-06T15:56:23Z"
      },
      {
        "created": "2020-10-06T15:38:55Z",
        "modified": "2020-10-06T15:38:55Z",
        "text": "Description: We are experiencing an issue with Google App Engine in us-central1 beginning at Tuesday, 2020-10-06 06:45 US/Pacific.\n\nSymptoms: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard deployments in us-central1. These failures are viewable in Cloud Logging.\n\nMitigation work is currently underway by our engineering team.\n\nWe will provide more information by Tuesday, 2020-10-06 09:00 US/Pacific.\n\nDiagnosis:  Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard instance in us-central1.\n\nWorkaround: None at this time.",
        "when": "2020-10-06T15:38:55Z"
      },
      {
        "created": "2020-10-06T15:36:33Z",
        "modified": "2020-10-06T15:36:33Z",
        "text": "Description: We are experiencing an issue with Google App Engine beginning at Tuesday, 2020-10-06 06:45 US/Pacific.\n\nSymptoms: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard deployments. These failures are viewable in Cloud Logging.\n\nMitigation work is currently underway by our engineering team.\n\nWe will provide more information by Tuesday, 2020-10-06 09:00 US/Pacific.\n\nDiagnosis:  Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard.\n\nWorkaround: None at this time.",
        "when": "2020-10-06T15:36:33Z"
      },
      {
        "created": "2020-10-06T15:16:27Z",
        "modified": "2020-10-06T15:16:27Z",
        "text": "Description: We are experiencing an issue with Google App Engine beginning at Tuesday, 2020-10-06 06:45 US/Pacific.\n\nSymptoms: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard deployments. These failures are viewable in Cloud Logging.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Tuesday, 2020-10-06 08:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis:  Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard.\n\nWorkaround: None at this time.",
        "when": "2020-10-06T15:16:27Z"
      }
    ],
    "uri": "/incident/appengine/20007"
  },
  {
    "begin": "2020-10-06T13:45:00Z",
    "created": "2020-10-06T18:07:16Z",
    "end": "2020-10-06T16:13:00Z",
    "external_desc": "Cloud ML was experiencing elevated errors",
    "modified": "2020-10-06T18:07:16Z",
    "most-recent-update": {
      "created": "2020-10-06T18:07:16Z",
      "modified": "2020-10-06T18:07:16Z",
      "text": "We were experiencing an issue with Cloud Machine Learning where deployments may fail and prediction operations were failing at elevated rates in us-central1 beginning on Tuesday, 2020-10-06 06:45 US/Pacific.\r\n\r\nThe issue with Cloud Machine Learning has been resolved for all affected users as of Tuesday, 2020-10-06 09:13 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-06T18:07:16Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "cloud-ml",
    "service_name": "Cloud Machine Learning",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-06T18:07:16Z",
        "modified": "2020-10-06T18:07:16Z",
        "text": "We were experiencing an issue with Cloud Machine Learning where deployments may fail and prediction operations were failing at elevated rates in us-central1 beginning on Tuesday, 2020-10-06 06:45 US/Pacific.\r\n\r\nThe issue with Cloud Machine Learning has been resolved for all affected users as of Tuesday, 2020-10-06 09:13 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-06T18:07:16Z"
      }
    ],
    "uri": "/incident/cloud-ml/20003"
  },
  {
    "begin": "2020-10-06T13:45:00Z",
    "created": "2020-10-06T15:31:14Z",
    "end": "2020-10-06T16:23:05Z",
    "external_desc": "Cases failing to load in Cloud Console or Google Support Center",
    "modified": "2020-10-06T16:23:05Z",
    "most-recent-update": {
      "created": "2020-10-06T16:23:05Z",
      "modified": "2020-10-06T16:23:05Z",
      "text": "The issue with Google Cloud Support Center has been resolved for all affected users as of Tuesday, 2020-10-06 09:15 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-10-06T16:23:05Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "support",
    "service_name": "Google Cloud Support",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-06T16:23:05Z",
        "modified": "2020-10-06T16:23:05Z",
        "text": "The issue with Google Cloud Support Center has been resolved for all affected users as of Tuesday, 2020-10-06 09:15 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-10-06T16:23:05Z"
      },
      {
        "created": "2020-10-06T15:57:04Z",
        "modified": "2020-10-06T15:57:04Z",
        "text": "DESCRIPTION: We believe the issue with Google Cloud Support Center is partially resolved. Mitigation actions have been performed and we're currently monitoring for any lingering issues. We will provide an update by Tuesday, 2020-10-06 10:52 US/Pacific with current details.\r\n\r\nSymptoms: Cases failing to load in Cloud Console or Google Support Center\r\n\r\nOur engineering team is currently investigating the issue.\r\n\r\nWe will provide an update by Tuesday, 2020-10-06 09:00 US/Pacific with current details.\r\n\r\nWe apologize to all who are affected by the disruption\r\n\r\nSELF-DIAGNOSIS: Cases failing to load in Cloud Console or Google Support Center WORKAROUND: If you need to open a new case please reach out via the following form: https://support.google.com/cloud/contact/prod_issue",
        "when": "2020-10-06T15:57:04Z"
      },
      {
        "created": "2020-10-06T15:31:14Z",
        "modified": "2020-10-06T15:31:14Z",
        "text": "DESCRIPTION: We are experiencing an issue with Google Cloud Support Center beginning at Tuesday, 2020-10-06 06:45 US/Pacific.\r\n\r\nSymptoms:  Cases failing to load in Cloud Console or Google Support Center\r\n\r\nOur engineering team is currently investigating the issue.\r\n\r\nWe will provide an update by Tuesday, 2020-10-06 09:00 US/Pacific with current details.\r\n\r\nWe apologize to all who are affected by the disruption\r\n\r\nSELF-DIAGNOSIS: Cases failing to load in Cloud Console or Google Support Center\r\nWORKAROUND: If you need to open a new case please reach out via the following form: https://support.google.com/cloud/contact/prod_issue",
        "when": "2020-10-06T15:31:14Z"
      }
    ],
    "uri": "/incident/support/20003"
  },
  {
    "begin": "2020-09-25T14:08:29Z",
    "created": "2020-09-25T16:27:06Z",
    "end": "2020-09-25T17:36:02Z",
    "external_desc": "We are experiencing an issue with Cloud Logging beginning at Friday, 2020-09-25 06:50 US/Pacific. Symptoms are increased error rates and potentially latency upon reading, filtering or querying logs. Writing logs are not affected. Mitigation work is already underway by our engineering team. The mitigation is expected to complete by Friday, 2020-09-25 11:00 US/Pacific. We will provide more information by Friday, 2020-09-25 11:30 US/Pacific at the latest.",
    "modified": "2020-09-25T17:36:02Z",
    "most-recent-update": {
      "created": "2020-09-25T17:36:02Z",
      "modified": "2020-09-25T17:36:02Z",
      "text": "The issue with Cloud Logging has been resolved for all affected projects as of Friday, 2020-09-25 10:30 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-25T17:36:02Z"
    },
    "number": 20008,
    "public": true,
    "service_key": "google-stackdriver",
    "service_name": "Operations",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-25T17:36:02Z",
        "modified": "2020-09-25T17:36:02Z",
        "text": "The issue with Cloud Logging has been resolved for all affected projects as of Friday, 2020-09-25 10:30 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-25T17:36:02Z"
      },
      {
        "created": "2020-09-25T17:20:56Z",
        "modified": "2020-09-25T17:20:56Z",
        "text": "Description: Mitigation work is already underway by our engineering team.\n\nCurrent data indicates that error rates decreased approximately by half from 25% to 11% in projects affected by this issue.\n\nThe mitigation is expected to complete by Friday, 2020-09-25 11:00 US/Pacific.\n\nWe will provide more information by Friday, 2020-09-25 11:30 US/Pacific at the latest.\n\nDiagnosis: Listing or reading logs return an error message such as: \"An unknown error has occurred. No additional information was provided.\".\n\nWorkaround: None at the moment.",
        "when": "2020-09-25T17:20:56Z"
      },
      {
        "created": "2020-09-25T16:30:02Z",
        "modified": "2020-09-25T16:30:02Z",
        "text": "Description: We are experiencing an intermittent issue with Cloud Logging beginning at Friday, 2020-09-25 06:50 US/Pacific.\n\nSymptoms: increased error rates and potentially latency upon filtering or querying logs.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2020-09-25 10:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Listing or reading logs return an error message such as: \"An unknown error has occurred. No additional information was provided.\".\n\nWorkaround: None at the moment.",
        "when": "2020-09-25T16:30:02Z"
      },
      {
        "created": "2020-09-25T16:27:07Z",
        "modified": "2020-09-25T16:27:07Z",
        "text": "Description: We are experiencing an intermittent issue with Cloud Logging beginning at Friday, 2020-09-25 06:50 US/Pacific.\n\nSymptoms: increased error rates and potentially latency upon filtering or querying logs.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2020-09-25 09:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Listing or reading logs return an error message such as: \"An unknown error has occurred. No additional information was provided.\".\n\nWorkaround: None at the moment.",
        "when": "2020-09-25T16:27:07Z"
      }
    ],
    "uri": "/incident/google-stackdriver/20008"
  },
  {
    "begin": "2020-09-25T01:00:50Z",
    "created": "2020-09-25T01:28:57Z",
    "end": "2020-09-25T01:33:43Z",
    "external_desc": "We are experiencing an issue with multiple GCP products.",
    "modified": "2020-10-08T15:12:37Z",
    "most-recent-update": {
      "created": "2020-10-01T04:55:05Z",
      "modified": "2020-10-08T15:12:37Z",
      "text": "# BACKGROUND\r\n\r\nGoogle’s Global Service Load Balancer (GSLB) is a collection of software and services that load balance traffic across Google properties. There are two main components, a control plane, and a data plane. The control plane provides programming to the data plane on how to handle requests. A key component of the data plane is the  Google Front End (GFE). The GFE is an HTTP/TCP reverse proxy which is used to serve requests to many Google properties including: Search, Ads, G Suite (Gmail, Chat, Meet, Docs, Drive, etc.), Cloud External HTTP(S) Load Balancing, Proxy/SSL Load Balancing, and many Cloud APIs. \r\n\r\nGoogle’s Global Load Balancers are implemented using a GFE architecture that has two tiers in some cases. The first tier of GFEs are situated as close to the user as possible to minimize latency during connection setup. First tier GFEs route requests either directly to applications, or in some cases to a second tier of GFEs providing additional functionality, before routing to applications. This architecture allows clients to have low latency connections anywhere in the world, while taking advantage of Google’s global network to serve requests to backends, regardless of region.\r\n\r\nThe pool of GFE instances which were impacted in this incident are part of the second tier, handling a subset of Google services. Therefore, this incident only impacted services routed through this specific pool.\r\n\r\n# ISSUE SUMMARY\r\n\r\nOn Thursday 24 September, 2020 at 18:00 US/Pacific, one of Google’s several second-tier GFE pools experienced intermittent failures resulting in impact to several downstream services. Almost all services recovered within the initial 33 minutes of the incident; exceptions are outlined in the detailed impact section below. Affected customers experienced elevated error rates and latency when connecting to Google APIs. Existing workloads (i.e. running instances on GCE, or containers on GKE) were not impacted unless they needed to invoke impacted APIs.\r\n\r\nService impact can be divided into two categories, direct and indirect. Services which have a request path that flows through the impacted GFE pool would have been directly impacted. Calls to these services would have experienced higher latency or elevated errors in the form of HTTP 502 response codes. Alternatively, services which did not directly rely on this pool of impacted GFEs may invoke other services, such as authentication, that depend on this shared pool of GFEs. This indirect impact would have varied between customers. One example of this, which we expect to be one of the most common forms of indirect impact, would be use of an oauth token that needed to be refreshed or retrieved. While a service such as Cloud Spanner may not have been serving errors, customers using the Cloud Spanner Client may have seen errors when the client attempted to refresh credentials, depending on the API used to refresh/obtain the credential. A detailed description of impact can be found below.\r\n\r\nTo our Cloud customers whose businesses were impacted during this disruption, we sincerely apologize – we have conducted a thorough internal investigation and are taking immediate action to improve the resiliency, performance, and availability of our services.\r\n\r\n# ROOT CAUSE\r\nFor any given pool of tasks, the GFE control plane has a global view of capacity, service configurations, and network conditions, which are all combined and sent to GFEs to create efficient request serving paths. This global view allows requests to be routed seamlessly to other regions, which is useful in scenarios like failover or for load balancing between regions. GFEs are grouped into pools for a variety of traffic profiles, health checking requirements, and other factors; the impacted second-layer GFE pool was used by multiple services. \r\n\r\nThe GFE control plane picks up service configuration changes and distributes them to GFEs. For this incident, two service changes contained an error that resulted in a significant increase in the number of backends accessed by GFEs in this pool. The particular nature of these changes additionally meant that they would be distributed to all GFEs in this pool globally, instead of being limited to a particular region. While the global aspect was intended, the magnitude of backend increases was not. The greatly increased number of programmed backends caused GFEs to exceed their memory allocation in many locations. \r\n\r\nGFE has many internal protections which are activated when there is memory pressure, such as closing idle connections or refusing to accept new connections, allowing them to keep running despite a memory shortage. Tasks which exceeded memory limits were terminated. The combination of a reduced number of available GFEs and a reduction in accepted connections meant that traffic to services behind the impacted GFE pool dropped by 50%.\r\n\r\n# REMEDIATION AND PREVENTION\r\nGoogle engineers were alerted to the outage three minutes after impact began at 2020-09-24 18:03, and immediately began an investigation. At 18:15 the first service change, which significantly increased the number of programmed backends, was rolled back.  At 18:18 the second service configuration change was rolled back.  Google engineers started seeing recovery at 18:20 and at 18:33 the issue was fully mitigated.\r\n\r\nGFE is one of the most critical pieces of infrastructure at Google and has multiple lines of defense in depth, both in software and operating procedure. As the result of this outage, we are adding additional protections to both in order to eliminate this class of failure. As an immediate step we have limited the type of configuration changes that can be made until additional safeguards are in place. Those additional safeguards will include stricter validation of configuration changes; specifically, rejecting changes that cause a large increase in backend count across multiple services. In addition to a check in the control plane, we will be augmenting existing protections in the GFE against unbounded growth in any resource dimension, such as backend counts. We will also be performing an audit of existing configurations and converting risky configurations to alternative setups. A restriction will be placed on certain configuration options, only allowing use with additional review and allow lists. Finally, an audit will be performed of services in shared GFE pools, with additional pools being created to reduce impact radius, should an issue in this part of the infrastructure surface again.\r\n\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\nOn 2020-09-24 from 18:00 to 18:33 US/Pacific (unless otherwise noted) the following services were impacted globally:\r\n\r\n### OAuth\r\nThe following OAuth paths were impacted and returned errors for 50% of requests during the impact period. Impact perceived by customers may have been less as many client libraries make requests to these paths asynchronous to refresh tokens before they expire and retry their requests upon failure, potentially receiving successful responses:\r\n\r\n    - oauth2.googleapis.com/token\r\n    - accounts.google.com/o/oauth2/token \r\n    - www.youtube.com/o/oauth2/token\r\n    - www.googleapis.com/o/oauth2/token \r\n    - www.googleapis.com/oauth2/{v3,v4}/token\r\n    - accounts.{google,youtube}.com/o/oauth2/{revoke,device/code,tokeninfo}\r\n    - www.googleapis.com/oauth2/v3/authadvice\r\n    - www.googleapis.com/oauth2/v2/IssueToken\r\n    - oauthaccountmanager.googleapis.com\r\n\r\n_\r\n\r\n\r\nThe following APIs were NOT affected: \r\n\r\n    - www.googleapis.com/oauth2/{v1,v2,v3}/certs\r\n    - contents.googleapis.com/oauth2/{v1,v2,v3}/certs\r\n    - contents6.googleapis.com/oauth2/{v1,v2,v3}/certs\r\n    - iamcredentials.googleapis.com and accounts.google.com (other than specific URLs mentioned above) were not affected.\r\n\r\n\r\n\r\n_\r\n\r\n\r\n\r\n\r\n### Chat\r\nGoogle Chat experienced an elevated rate of HTTP 500 & 502 errors (averaging 34%) between 18:00 and 18:04, decreasing to a 7% error rate from 18:04 to 18:14, with a mean latency of 500ms. This resulted in affected users being unable to load the Chat page or to send Chat messages.\r\n\r\n\r\n### Classic Hangouts\r\nClassic Hangouts experienced an elevated error rate of HTTP 500 errors (reducing Hangouts traffic by 44%) between 18:00 and 18:25. The service error rate was below 1% for Hangouts requests within the product, including sending messages.\r\n\r\n### Meet\r\nGoogle Meet experienced error rates up to 23% of requests between 18:02 and 18:23. Affected users observed call startup failures which affected 85% of session attempts. Existing Meet sessions were not affected.\r\n\r\n### Voice\r\nGoogle Voice experienced a 66% drop in traffic between 18:00 and 18:24. Additionally, the service had an elevated error rate below 1% between 18:01 and 18:14, and an average of 100% increase in mean latency between 18:03 and 18:12.\r\n\r\n### Calendar\r\nGoogle Calendar web traffic observed up to a 60% reduction in traffic, and an elevated HTTP 500 error rate of 4.8% between 18:01 and 18:06, which decreased to and remained below 1% for the remainder of the outage. Calendar API traffic observed up to a 53% reduction in traffic, with an average error rate of 2% for the same period. The traffic reduction corresponded with HTTP 500 errors being served to users.\r\n\r\n### Groups\r\nGoogle Groups web traffic dropped roughly 50% for the classic UI, and 30% for the new UI. Users experienced an average elevated HTTP 500 error rate between 0.12 and 3%.\r\n\r\n### Gmail\r\nGmail observed a 35% drop in traffic due to the GFE responding with HTTP 500 errors. The service error rate remained below 1% for the duration of the incident. This affected Gmail page loading and web interactions with the product.\r\n\r\n### Docs\r\nGoogle Docs witnessed a 33% drop in traffic between 18:00 and 18:23, corresponding with the GFE returning HTTP 500 errors to user interactions. Additionally, between 18:01 and 18:06 the service error rate rose to 1.4%, before decreasing and remaining at approximately 0.3% until 18:23.\r\n\r\n### Drive\r\nGoogle Drive observed a 60% traffic drop between 18:00 and 18:23, corresponding with the GFE returning HTTP 500 errors to user interactions. The Drive API experienced a peak error rate of 7% between 18:02 to 18:04, and then between 1% and 2% until 18:25. Google Drive web saw up to a 4% error rate between 18:01 and 18:06. 50th percentile latency was unaffected, but 95th percentile rose up to 1.3s between 18:02 and 18:06.\r\n\r\n### Cloud Bigtable\r\nSome clients using the impacted OAuth authentication methods described above were unable to refresh their credentials and thus unable to access Cloud Bigtable. Clients using alternative authentication methods were not impacted. Impacted clients experienced elevated error rates and latency. The main impact was to clients accessing Cloud Bigtable from outside of GCP, there was a 38% drop in this traffic during the impact period.\r\n\r\n### Cloud Build API\r\nCloud Build API experienced elevated error rates due to a 50% loss of incoming traffic over 26 minutes before reaching the service front end. Additionally, 4% of Cloud Builds failed due receiving errors from other Google services\r\n\r\n### Cloud Key Management Service (KMS)\r\nCloud KMS was unable to receive API requests from GFE for ~33 minutes starting at 18:00 impacting non-Customer Managed Encryption Key (CMEK) customers.  CMEK customers were not impacted. \r\n\r\n### Cloud Logging\r\nCloud Logging experienced increased error rates (25% average, up to 40% at peak) from 18:05 to 18:50.  Customers would have experienced errors when viewing logs in the Cloud Console. Data ingestion was not impacted.\r\n\r\n### Cloud Monitoring\r\nCloud Monitoring API experienced elevated error rates (50% average, up to 80% at peak) of uptime checks and requests from 18:00 - 18:26.  This affected cloud uptime workers running uptime checks.  \r\n\r\n### Cloud Networking API\r\nCloud Networking API experienced up to 50% error rate for Network Load Balancer Creation from 18:00 to 18:20 due to downstream service errors. Additionally up to 35% of HTTP(S) Load Balancer or TCP/SSL Proxy Load Balancer creation requests failed from 18:00 - 18:28 due to downstream service errors. Traffic for existing load balancers was unaffected. \r\n\r\n### Google Compute Engine API\r\nThe Google Compute Engine (GCE) API experienced an error rate of up to 50% from 18:00 - 18:25 with affected users experiencing HTTP 502 error response codes. This would have prevented loading the GCE portion of the Cloud Console as well listing, modifying, and creating GCE resources via other API clients. This applies only to the GCE API. GCE instance connectivity and availability was not impacted. Please note that some GCP services were served by the impacted GFE pool, so customer workloads running inside compute instances may have seen impact if they depend on other GCP services that experienced impact. Autoscaler continued to function nominally during the outage window.\r\n\r\n### Cloud Profiler\r\nCloud Profiler API experienced an elevated rate of HTTP 502 errors due to an up to 50% reduction in global traffic for all requests.\r\n\r\n### Cloud Run API\r\nCloud Run API experienced an elevated rate of HTTP 502 errors up to 70% from 18:00 to 18:30. Existing Cloud Run deployments were unaffected.\r\n\r\n### Cloud Spanner\r\nCloud Spanner clients experienced elevated error rates due to authentication issues which caused a 20% drop in traffic. Impacted customers saw increased latency and errors accessing Cloud Spanner. Clients using alternative authentication methods, such as GKE Workload Identity, were not impacted.\r\n  \r\n### Game Servers\r\nGame Servers experienced elevated request latencies of up to 4x normal levels during the incident window, resulting in some clients experiencing connection timeouts and increased retry attempts. The service did not experience elevated error rates.\r\n\r\n### Google Cloud Console\r\n4.18% of customers experienced \"The attempted action failed\" error messages when attempting to load pages in the Cloud Console during the incident window. This prevented some customers from viewing the UI of networking, compute, billing, monitoring, and other products and services within the Cloud Console platform. \r\n\r\n### Google Cloud SQL\r\n0.08% of Cloud SQL's fleet experienced instance metrics and logging delays from 18:07 - 18:37 for a duration of 30 minutes. The Cloud SQL API did not serve errors during the outage, but incoming traffic dropped by ~30%. No spurious auto-failovers or auto-repairs were executed as a result of the incident. There were no actual instance failures. \r\n\r\n### Google Kubernetes Engine\r\nRequests to the Google Kubernetes Engine (GKE) control plane experienced increased timeouts and HTTP 502 error.  Up to 6.6% of cluster masters reported errors during the time of the incident. Up to 5.5% of newly added nodes to clusters may have experienced errors due to issues communicating with impacted cluster masters. \r\n\r\n### Firebase Crashlytics\r\n66% of Crashlytics imports from AWS were impacted from 18:01 - 19:01 US/Pacific for a duration of 60 minutes. This created an import backlog which was quickly worked through 10 minutes after the incident ended.\r\n\r\n### Dialogflow and Speech-to-text API\r\nRequests to Dialogflow returned up to 72% errors in the form of HTTP 502 response codes. Requests to Google Speech API may have seen up to 68% errors in the form of HTTP 502 response codes.\r\n\r\n### Cloud Firestore and Datastore\r\nCloud Firestore saw 80% of listen streams become disconnected and up to 50% error rates for query/get requests across all regions except nam5 and eur3.\r\n\r\n# SLA CREDITS\r\nIf you believe your paid application experienced an SLA violation as a result of this incident, please populate the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\r\n\r\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/.\r\n\r\nFor G Suite, please request an SLA credit through one of the Support channels: https://support.google.com/a/answer/104721\r\n\r\nG Suite Service Level Agreement can be found at https://gsuite.google.com/intl/en/terms/sla.html",
      "when": "2020-10-01T04:55:05Z"
    },
    "number": 20010,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-10-01T04:55:05Z",
        "modified": "2020-10-08T15:12:37Z",
        "text": "# BACKGROUND\r\n\r\nGoogle’s Global Service Load Balancer (GSLB) is a collection of software and services that load balance traffic across Google properties. There are two main components, a control plane, and a data plane. The control plane provides programming to the data plane on how to handle requests. A key component of the data plane is the  Google Front End (GFE). The GFE is an HTTP/TCP reverse proxy which is used to serve requests to many Google properties including: Search, Ads, G Suite (Gmail, Chat, Meet, Docs, Drive, etc.), Cloud External HTTP(S) Load Balancing, Proxy/SSL Load Balancing, and many Cloud APIs. \r\n\r\nGoogle’s Global Load Balancers are implemented using a GFE architecture that has two tiers in some cases. The first tier of GFEs are situated as close to the user as possible to minimize latency during connection setup. First tier GFEs route requests either directly to applications, or in some cases to a second tier of GFEs providing additional functionality, before routing to applications. This architecture allows clients to have low latency connections anywhere in the world, while taking advantage of Google’s global network to serve requests to backends, regardless of region.\r\n\r\nThe pool of GFE instances which were impacted in this incident are part of the second tier, handling a subset of Google services. Therefore, this incident only impacted services routed through this specific pool.\r\n\r\n# ISSUE SUMMARY\r\n\r\nOn Thursday 24 September, 2020 at 18:00 US/Pacific, one of Google’s several second-tier GFE pools experienced intermittent failures resulting in impact to several downstream services. Almost all services recovered within the initial 33 minutes of the incident; exceptions are outlined in the detailed impact section below. Affected customers experienced elevated error rates and latency when connecting to Google APIs. Existing workloads (i.e. running instances on GCE, or containers on GKE) were not impacted unless they needed to invoke impacted APIs.\r\n\r\nService impact can be divided into two categories, direct and indirect. Services which have a request path that flows through the impacted GFE pool would have been directly impacted. Calls to these services would have experienced higher latency or elevated errors in the form of HTTP 502 response codes. Alternatively, services which did not directly rely on this pool of impacted GFEs may invoke other services, such as authentication, that depend on this shared pool of GFEs. This indirect impact would have varied between customers. One example of this, which we expect to be one of the most common forms of indirect impact, would be use of an oauth token that needed to be refreshed or retrieved. While a service such as Cloud Spanner may not have been serving errors, customers using the Cloud Spanner Client may have seen errors when the client attempted to refresh credentials, depending on the API used to refresh/obtain the credential. A detailed description of impact can be found below.\r\n\r\nTo our Cloud customers whose businesses were impacted during this disruption, we sincerely apologize – we have conducted a thorough internal investigation and are taking immediate action to improve the resiliency, performance, and availability of our services.\r\n\r\n# ROOT CAUSE\r\nFor any given pool of tasks, the GFE control plane has a global view of capacity, service configurations, and network conditions, which are all combined and sent to GFEs to create efficient request serving paths. This global view allows requests to be routed seamlessly to other regions, which is useful in scenarios like failover or for load balancing between regions. GFEs are grouped into pools for a variety of traffic profiles, health checking requirements, and other factors; the impacted second-layer GFE pool was used by multiple services. \r\n\r\nThe GFE control plane picks up service configuration changes and distributes them to GFEs. For this incident, two service changes contained an error that resulted in a significant increase in the number of backends accessed by GFEs in this pool. The particular nature of these changes additionally meant that they would be distributed to all GFEs in this pool globally, instead of being limited to a particular region. While the global aspect was intended, the magnitude of backend increases was not. The greatly increased number of programmed backends caused GFEs to exceed their memory allocation in many locations. \r\n\r\nGFE has many internal protections which are activated when there is memory pressure, such as closing idle connections or refusing to accept new connections, allowing them to keep running despite a memory shortage. Tasks which exceeded memory limits were terminated. The combination of a reduced number of available GFEs and a reduction in accepted connections meant that traffic to services behind the impacted GFE pool dropped by 50%.\r\n\r\n# REMEDIATION AND PREVENTION\r\nGoogle engineers were alerted to the outage three minutes after impact began at 2020-09-24 18:03, and immediately began an investigation. At 18:15 the first service change, which significantly increased the number of programmed backends, was rolled back.  At 18:18 the second service configuration change was rolled back.  Google engineers started seeing recovery at 18:20 and at 18:33 the issue was fully mitigated.\r\n\r\nGFE is one of the most critical pieces of infrastructure at Google and has multiple lines of defense in depth, both in software and operating procedure. As the result of this outage, we are adding additional protections to both in order to eliminate this class of failure. As an immediate step we have limited the type of configuration changes that can be made until additional safeguards are in place. Those additional safeguards will include stricter validation of configuration changes; specifically, rejecting changes that cause a large increase in backend count across multiple services. In addition to a check in the control plane, we will be augmenting existing protections in the GFE against unbounded growth in any resource dimension, such as backend counts. We will also be performing an audit of existing configurations and converting risky configurations to alternative setups. A restriction will be placed on certain configuration options, only allowing use with additional review and allow lists. Finally, an audit will be performed of services in shared GFE pools, with additional pools being created to reduce impact radius, should an issue in this part of the infrastructure surface again.\r\n\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\nOn 2020-09-24 from 18:00 to 18:33 US/Pacific (unless otherwise noted) the following services were impacted globally:\r\n\r\n### OAuth\r\nThe following OAuth paths were impacted and returned errors for 50% of requests during the impact period. Impact perceived by customers may have been less as many client libraries make requests to these paths asynchronous to refresh tokens before they expire and retry their requests upon failure, potentially receiving successful responses:\r\n\r\n    - oauth2.googleapis.com/token\r\n    - accounts.google.com/o/oauth2/token \r\n    - www.youtube.com/o/oauth2/token\r\n    - www.googleapis.com/o/oauth2/token \r\n    - www.googleapis.com/oauth2/{v3,v4}/token\r\n    - accounts.{google,youtube}.com/o/oauth2/{revoke,device/code,tokeninfo}\r\n    - www.googleapis.com/oauth2/v3/authadvice\r\n    - www.googleapis.com/oauth2/v2/IssueToken\r\n    - oauthaccountmanager.googleapis.com\r\n\r\n_\r\n\r\n\r\nThe following APIs were NOT affected: \r\n\r\n    - www.googleapis.com/oauth2/{v1,v2,v3}/certs\r\n    - contents.googleapis.com/oauth2/{v1,v2,v3}/certs\r\n    - contents6.googleapis.com/oauth2/{v1,v2,v3}/certs\r\n    - iamcredentials.googleapis.com and accounts.google.com (other than specific URLs mentioned above) were not affected.\r\n\r\n\r\n\r\n_\r\n\r\n\r\n\r\n\r\n### Chat\r\nGoogle Chat experienced an elevated rate of HTTP 500 & 502 errors (averaging 34%) between 18:00 and 18:04, decreasing to a 7% error rate from 18:04 to 18:14, with a mean latency of 500ms. This resulted in affected users being unable to load the Chat page or to send Chat messages.\r\n\r\n\r\n### Classic Hangouts\r\nClassic Hangouts experienced an elevated error rate of HTTP 500 errors (reducing Hangouts traffic by 44%) between 18:00 and 18:25. The service error rate was below 1% for Hangouts requests within the product, including sending messages.\r\n\r\n### Meet\r\nGoogle Meet experienced error rates up to 23% of requests between 18:02 and 18:23. Affected users observed call startup failures which affected 85% of session attempts. Existing Meet sessions were not affected.\r\n\r\n### Voice\r\nGoogle Voice experienced a 66% drop in traffic between 18:00 and 18:24. Additionally, the service had an elevated error rate below 1% between 18:01 and 18:14, and an average of 100% increase in mean latency between 18:03 and 18:12.\r\n\r\n### Calendar\r\nGoogle Calendar web traffic observed up to a 60% reduction in traffic, and an elevated HTTP 500 error rate of 4.8% between 18:01 and 18:06, which decreased to and remained below 1% for the remainder of the outage. Calendar API traffic observed up to a 53% reduction in traffic, with an average error rate of 2% for the same period. The traffic reduction corresponded with HTTP 500 errors being served to users.\r\n\r\n### Groups\r\nGoogle Groups web traffic dropped roughly 50% for the classic UI, and 30% for the new UI. Users experienced an average elevated HTTP 500 error rate between 0.12 and 3%.\r\n\r\n### Gmail\r\nGmail observed a 35% drop in traffic due to the GFE responding with HTTP 500 errors. The service error rate remained below 1% for the duration of the incident. This affected Gmail page loading and web interactions with the product.\r\n\r\n### Docs\r\nGoogle Docs witnessed a 33% drop in traffic between 18:00 and 18:23, corresponding with the GFE returning HTTP 500 errors to user interactions. Additionally, between 18:01 and 18:06 the service error rate rose to 1.4%, before decreasing and remaining at approximately 0.3% until 18:23.\r\n\r\n### Drive\r\nGoogle Drive observed a 60% traffic drop between 18:00 and 18:23, corresponding with the GFE returning HTTP 500 errors to user interactions. The Drive API experienced a peak error rate of 7% between 18:02 to 18:04, and then between 1% and 2% until 18:25. Google Drive web saw up to a 4% error rate between 18:01 and 18:06. 50th percentile latency was unaffected, but 95th percentile rose up to 1.3s between 18:02 and 18:06.\r\n\r\n### Cloud Bigtable\r\nSome clients using the impacted OAuth authentication methods described above were unable to refresh their credentials and thus unable to access Cloud Bigtable. Clients using alternative authentication methods were not impacted. Impacted clients experienced elevated error rates and latency. The main impact was to clients accessing Cloud Bigtable from outside of GCP, there was a 38% drop in this traffic during the impact period.\r\n\r\n### Cloud Build API\r\nCloud Build API experienced elevated error rates due to a 50% loss of incoming traffic over 26 minutes before reaching the service front end. Additionally, 4% of Cloud Builds failed due receiving errors from other Google services\r\n\r\n### Cloud Key Management Service (KMS)\r\nCloud KMS was unable to receive API requests from GFE for ~33 minutes starting at 18:00 impacting non-Customer Managed Encryption Key (CMEK) customers.  CMEK customers were not impacted. \r\n\r\n### Cloud Logging\r\nCloud Logging experienced increased error rates (25% average, up to 40% at peak) from 18:05 to 18:50.  Customers would have experienced errors when viewing logs in the Cloud Console. Data ingestion was not impacted.\r\n\r\n### Cloud Monitoring\r\nCloud Monitoring API experienced elevated error rates (50% average, up to 80% at peak) of uptime checks and requests from 18:00 - 18:26.  This affected cloud uptime workers running uptime checks.  \r\n\r\n### Cloud Networking API\r\nCloud Networking API experienced up to 50% error rate for Network Load Balancer Creation from 18:00 to 18:20 due to downstream service errors. Additionally up to 35% of HTTP(S) Load Balancer or TCP/SSL Proxy Load Balancer creation requests failed from 18:00 - 18:28 due to downstream service errors. Traffic for existing load balancers was unaffected. \r\n\r\n### Google Compute Engine API\r\nThe Google Compute Engine (GCE) API experienced an error rate of up to 50% from 18:00 - 18:25 with affected users experiencing HTTP 502 error response codes. This would have prevented loading the GCE portion of the Cloud Console as well listing, modifying, and creating GCE resources via other API clients. This applies only to the GCE API. GCE instance connectivity and availability was not impacted. Please note that some GCP services were served by the impacted GFE pool, so customer workloads running inside compute instances may have seen impact if they depend on other GCP services that experienced impact. Autoscaler continued to function nominally during the outage window.\r\n\r\n### Cloud Profiler\r\nCloud Profiler API experienced an elevated rate of HTTP 502 errors due to an up to 50% reduction in global traffic for all requests.\r\n\r\n### Cloud Run API\r\nCloud Run API experienced an elevated rate of HTTP 502 errors up to 70% from 18:00 to 18:30. Existing Cloud Run deployments were unaffected.\r\n\r\n### Cloud Spanner\r\nCloud Spanner clients experienced elevated error rates due to authentication issues which caused a 20% drop in traffic. Impacted customers saw increased latency and errors accessing Cloud Spanner. Clients using alternative authentication methods, such as GKE Workload Identity, were not impacted.\r\n  \r\n### Game Servers\r\nGame Servers experienced elevated request latencies of up to 4x normal levels during the incident window, resulting in some clients experiencing connection timeouts and increased retry attempts. The service did not experience elevated error rates.\r\n\r\n### Google Cloud Console\r\n4.18% of customers experienced \"The attempted action failed\" error messages when attempting to load pages in the Cloud Console during the incident window. This prevented some customers from viewing the UI of networking, compute, billing, monitoring, and other products and services within the Cloud Console platform. \r\n\r\n### Google Cloud SQL\r\n0.08% of Cloud SQL's fleet experienced instance metrics and logging delays from 18:07 - 18:37 for a duration of 30 minutes. The Cloud SQL API did not serve errors during the outage, but incoming traffic dropped by ~30%. No spurious auto-failovers or auto-repairs were executed as a result of the incident. There were no actual instance failures. \r\n\r\n### Google Kubernetes Engine\r\nRequests to the Google Kubernetes Engine (GKE) control plane experienced increased timeouts and HTTP 502 error.  Up to 6.6% of cluster masters reported errors during the time of the incident. Up to 5.5% of newly added nodes to clusters may have experienced errors due to issues communicating with impacted cluster masters. \r\n\r\n### Firebase Crashlytics\r\n66% of Crashlytics imports from AWS were impacted from 18:01 - 19:01 US/Pacific for a duration of 60 minutes. This created an import backlog which was quickly worked through 10 minutes after the incident ended.\r\n\r\n### Dialogflow and Speech-to-text API\r\nRequests to Dialogflow returned up to 72% errors in the form of HTTP 502 response codes. Requests to Google Speech API may have seen up to 68% errors in the form of HTTP 502 response codes.\r\n\r\n### Cloud Firestore and Datastore\r\nCloud Firestore saw 80% of listen streams become disconnected and up to 50% error rates for query/get requests across all regions except nam5 and eur3.\r\n\r\n# SLA CREDITS\r\nIf you believe your paid application experienced an SLA violation as a result of this incident, please populate the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\r\n\r\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/.\r\n\r\nFor G Suite, please request an SLA credit through one of the Support channels: https://support.google.com/a/answer/104721\r\n\r\nG Suite Service Level Agreement can be found at https://gsuite.google.com/intl/en/terms/sla.html",
        "when": "2020-10-01T04:55:05Z"
      },
      {
        "created": "2020-09-25T21:48:54Z",
        "modified": "2020-09-25T21:49:40Z",
        "text": "With all services restored to normal operation, Google’s engineering teams are now conducting a thorough post-mortem to ensure we understand all the contributing factors and downstream impact to GCP and G Suite from this incident. The root cause of this disruption is well understood and safeguards have been put in place to prevent any possible recurrence of the issue.\r\n\r\nAt this time we have determined that the following products were affected:\r\n\r\n### Cloud Build API\r\nGoogle Front End (GFE) prevented API requests from reaching the service. CreateBuild requests that did make it to the servers were more likely to fail due to user code calling other GCP services.\r\n\r\n### Cloud Firestore and Datastore\r\nCloud Firestore saw 80% of listen streams become disconnected and a 50% drop in query/get requests across all regions except nam5 and eur3.\r\n\r\n### Cloud Key Management Service (KMS)\r\nGoogle Front End (GFE) prevented API requests from reaching the service.\r\n\r\n### Cloud Logging\r\nUnavailable for viewing in the Cloud Console, but data ingestion was not impacted.\r\n\r\n### Cloud Monitoring\r\nElevated error rates of uptime checks and requests to the Cloud Monitoring API\r\n\r\n### Cloud Compute Engine\r\nRequests to compute.googleapis.com would have seen an increase in 502 errors. Existing instances were not impacted.\r\n\r\n### Cloud Spanner\r\nCloud Spanner experienced elevated latency spikes which may have resulted in connection timeouts. \r\n\r\n### Game Servers\r\nMinor impact to cluster availability due to dependencies on other services.\r\n\r\n### Google Cloud Console\r\nMultiple pages and some core functionality of the Cloud Console impacted.\r\n\r\n### Google Cloud SQL\r\nMinor connectivity problems.  Instance log reporting to stackdriver was delayed.  There was a ~50% drop in SqlInstancesService.List API requests.\r\n\r\n### Google Kubernetes Engine\r\nMinor impact to cluster availability due to dependencies on other services.\r\n\r\n### Firebase Crashlytics\r\nFrom 18:00 - 18:24, Crashlytics imports from AWS were impacted. This created an import backlog which was quickly worked through 10 minutes after the incident ended.\r\n\r\nWe are conducting an internal investigation of this issue and will make appropriate improvements to our systems to help prevent or minimize future recurrence. We will provide a detailed report of this incident, including both GCP and G Suite impact, once we have completed our internal investigation. This detailed report will also contain information regarding SLA credits.",
        "when": "2020-09-25T21:48:53Z"
      },
      {
        "created": "2020-09-25T02:31:43Z",
        "modified": "2020-09-25T02:31:43Z",
        "text": "We believe the issue with multiple GCP products has been resolved for most traffic at 2020-09-24 18:33 US/Pacific.\n\nAffected products include: Cloud Run, Firestore Watch, Cloud SQL, Cloud Spanner, GKE, Cloud Logging, Cloud Monitoring, Cloud Console, Cloud KMS, Game Server\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-25T02:31:43Z"
      },
      {
        "created": "2020-09-25T02:19:04Z",
        "modified": "2020-09-25T02:19:04Z",
        "text": "Description: We are experiencing an issue with multiple GCP products, beginning at Thursday, 2020-09-24 17:58 US/Pacific.\n\nSymptoms: Increased error rate \n\nAffected products include: Cloud Run, Firestore Watch, Cloud SQL, Cloud Spanner, GKE, Cloud Logging, Cloud Monitoring, Cloud Console, Cloud KMS, Game Server\n\nMitigation work is currently underway by our engineering team.\n\nWe will provide an update by Thursday, 2020-09-24 20:00 US/Pacific with current details.",
        "when": "2020-09-25T02:19:04Z"
      },
      {
        "created": "2020-09-25T02:05:57Z",
        "modified": "2020-09-25T02:05:57Z",
        "text": "Description: We are experiencing an issue with multiple GCP products, beginning at Thursday, 2020-09-24 17:58 US/Pacific.\n\nSymptoms: Increased error rate.\n\nAffected products include: Cloud Run, Firestore Watch, Cloud SQL, Cloud Spanner, GKE, Cloud Logging, Cloud Monitoring, Cloud Console, Cloud KMS, Game Server\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-09-24 20:00 US/Pacific with current details.",
        "when": "2020-09-25T02:05:57Z"
      },
      {
        "created": "2020-09-25T01:46:10Z",
        "modified": "2020-09-25T01:46:10Z",
        "text": "Description: We are experiencing an issue with multiple GCP products, beginning at Thursday, 2020-09-24 17:58 US/Pacific.\n\nSymptoms: Increased error rate.\n\nAffected products include: Cloud Run, Firestore Watch, Cloud SQL, Cloud Spanner, GKE, Cloud Logging, Cloud Monitoring, Cloud Console\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-09-24 19:30 US/Pacific with current details.",
        "when": "2020-09-25T01:46:10Z"
      },
      {
        "created": "2020-09-25T01:28:58Z",
        "modified": "2020-09-25T01:28:58Z",
        "text": "Description: We are experiencing an issue with multiple GCP products.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-09-24 19:00 US/Pacific with current details.",
        "when": "2020-09-25T01:28:58Z"
      }
    ],
    "uri": "/incident/zall/20010"
  },
  {
    "begin": "2020-09-25T00:58:00Z",
    "created": "2020-09-25T02:04:44Z",
    "end": "2020-09-25T01:33:00Z",
    "external_desc": "We are experiencing an issue with Firestore.",
    "modified": "2020-09-25T02:34:30Z",
    "most-recent-update": {
      "created": "2020-09-25T02:22:36Z",
      "modified": "2020-09-25T02:31:38Z",
      "text": "Cloud FIrestore has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "when": "2020-09-25T02:22:35Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "cloud-firestore",
    "service_name": "Cloud Firestore",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-25T02:22:36Z",
        "modified": "2020-09-25T02:31:38Z",
        "text": "Cloud FIrestore has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "when": "2020-09-25T02:22:35Z"
      },
      {
        "created": "2020-09-25T02:04:44Z",
        "modified": "2020-09-25T02:04:44Z",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\r\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "when": "2020-09-25T02:04:44Z"
      }
    ],
    "uri": "/incident/cloud-firestore/20004"
  },
  {
    "begin": "2020-09-25T00:58:00Z",
    "created": "2020-09-25T02:02:34Z",
    "end": "2020-09-25T01:33:00Z",
    "external_desc": "We are experiencing an issue with Cloud KMS.",
    "modified": "2020-09-25T02:34:26Z",
    "most-recent-update": {
      "created": "2020-09-25T02:25:37Z",
      "modified": "2020-09-25T02:32:28Z",
      "text": "Cloud KMS has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "when": "2020-09-25T02:25:36Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "cloud-kms",
    "service_name": "Cloud Key Management Service",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-25T02:25:37Z",
        "modified": "2020-09-25T02:32:28Z",
        "text": "Cloud KMS has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "when": "2020-09-25T02:25:36Z"
      },
      {
        "created": "2020-09-25T02:02:34Z",
        "modified": "2020-09-25T02:02:34Z",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\r\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "when": "2020-09-25T02:02:34Z"
      }
    ],
    "uri": "/incident/cloud-kms/20003"
  },
  {
    "begin": "2020-09-25T00:58:00Z",
    "created": "2020-09-25T02:11:53Z",
    "end": "2020-09-25T01:33:00Z",
    "external_desc": "We are experiencing an issue with Cloud Networking.",
    "modified": "2020-09-25T02:35:20Z",
    "most-recent-update": {
      "created": "2020-09-25T02:35:20Z",
      "modified": "2020-09-25T02:35:20Z",
      "text": "Cloud Networking has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "when": "2020-09-25T02:35:20Z"
    },
    "number": 20009,
    "public": true,
    "service_key": "cloud-networking",
    "service_name": "Google Cloud Networking",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-25T02:35:20Z",
        "modified": "2020-09-25T02:35:20Z",
        "text": "Cloud Networking has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "when": "2020-09-25T02:35:20Z"
      },
      {
        "created": "2020-09-25T02:11:53Z",
        "modified": "2020-09-25T02:11:53Z",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\r\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "when": "2020-09-25T02:11:53Z"
      }
    ],
    "uri": "/incident/cloud-networking/20009"
  },
  {
    "begin": "2020-09-25T00:58:00Z",
    "created": "2020-09-25T01:56:49Z",
    "end": "2020-09-25T01:33:00Z",
    "external_desc": "We are experiencing an issue with Cloud Run.",
    "modified": "2020-09-25T02:36:34Z",
    "most-recent-update": {
      "created": "2020-09-25T02:36:34Z",
      "modified": "2020-09-25T02:36:34Z",
      "text": "Cloud Run has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "when": "2020-09-25T02:36:34Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "cloud-run",
    "service_name": "Cloud Run",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-25T02:36:34Z",
        "modified": "2020-09-25T02:36:34Z",
        "text": "Cloud Run has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "when": "2020-09-25T02:36:34Z"
      },
      {
        "created": "2020-09-25T01:56:49Z",
        "modified": "2020-09-25T01:56:49Z",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\r\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "when": "2020-09-25T01:56:49Z"
      }
    ],
    "uri": "/incident/cloud-run/20003"
  },
  {
    "begin": "2020-09-25T00:58:00Z",
    "created": "2020-09-25T01:59:12Z",
    "end": "2020-09-25T01:33:00Z",
    "external_desc": "We are experiencing an issue with Cloud Spanner.",
    "modified": "2020-09-25T02:38:06Z",
    "most-recent-update": {
      "created": "2020-09-25T02:38:05Z",
      "modified": "2020-09-25T02:38:05Z",
      "text": "Cloud Spanner has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "when": "2020-09-25T02:38:05Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "cloud-spanner",
    "service_name": "Cloud Spanner",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-25T02:38:05Z",
        "modified": "2020-09-25T02:38:05Z",
        "text": "Cloud Spanner has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "when": "2020-09-25T02:38:05Z"
      },
      {
        "created": "2020-09-25T01:59:13Z",
        "modified": "2020-09-25T01:59:13Z",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\r\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "when": "2020-09-25T01:59:13Z"
      }
    ],
    "uri": "/incident/cloud-spanner/20004"
  },
  {
    "begin": "2020-09-25T00:58:00Z",
    "created": "2020-09-25T01:58:18Z",
    "end": "2020-09-25T01:33:00Z",
    "external_desc": "We are experiencing an issue with Cloud SQL.",
    "modified": "2020-09-25T02:38:44Z",
    "most-recent-update": {
      "created": "2020-09-25T02:38:44Z",
      "modified": "2020-09-25T02:38:44Z",
      "text": "Cloud SQL has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "when": "2020-09-25T02:38:44Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "cloud-sql",
    "service_name": "Google Cloud SQL",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-25T02:38:44Z",
        "modified": "2020-09-25T02:38:44Z",
        "text": "Cloud SQL has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "when": "2020-09-25T02:38:44Z"
      },
      {
        "created": "2020-09-25T01:58:18Z",
        "modified": "2020-09-25T01:58:18Z",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\r\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "when": "2020-09-25T01:58:18Z"
      }
    ],
    "uri": "/incident/cloud-sql/20005"
  },
  {
    "begin": "2020-09-25T00:58:00Z",
    "created": "2020-09-25T02:00:49Z",
    "end": "2020-09-25T01:33:00Z",
    "external_desc": "We are experiencing an issue with Google Kubernetes Engine",
    "modified": "2020-09-25T02:39:52Z",
    "most-recent-update": {
      "created": "2020-09-25T02:39:52Z",
      "modified": "2020-09-25T02:39:52Z",
      "text": "Google Kubernetes Engine has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "when": "2020-09-25T02:39:52Z"
    },
    "number": 20006,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-25T02:39:52Z",
        "modified": "2020-09-25T02:39:52Z",
        "text": "Google Kubernetes Engine has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "when": "2020-09-25T02:39:52Z"
      },
      {
        "created": "2020-09-25T02:00:49Z",
        "modified": "2020-09-25T02:00:49Z",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\r\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "when": "2020-09-25T02:00:49Z"
      }
    ],
    "uri": "/incident/container-engine/20006"
  },
  {
    "begin": "2020-09-25T00:58:00Z",
    "created": "2020-09-25T02:08:06Z",
    "end": "2020-09-25T01:33:00Z",
    "external_desc": "We are experiencing an issue with Cloud Logging and Cloud Monitoring.",
    "modified": "2020-09-25T02:41:12Z",
    "most-recent-update": {
      "created": "2020-09-25T02:41:12Z",
      "modified": "2020-09-25T02:41:12Z",
      "text": "Cloud Monitoring and Cloud Logging have been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "when": "2020-09-25T02:41:12Z"
    },
    "number": 20007,
    "public": true,
    "service_key": "google-stackdriver",
    "service_name": "Operations",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-25T02:41:12Z",
        "modified": "2020-09-25T02:41:12Z",
        "text": "Cloud Monitoring and Cloud Logging have been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "when": "2020-09-25T02:41:12Z"
      },
      {
        "created": "2020-09-25T02:08:06Z",
        "modified": "2020-09-25T02:08:06Z",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\r\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "when": "2020-09-25T02:08:06Z"
      }
    ],
    "uri": "/incident/google-stackdriver/20007"
  },
  {
    "begin": "2020-09-24T08:40:38Z",
    "created": "2020-09-24T08:50:11Z",
    "end": "2020-09-25T03:03:00Z",
    "external_desc": "Cloud Shell Connectivity Issues in asia-southeast1 and an issue with the Pricing UI not loading for some billing accounts with a custom price model has been resolved. ",
    "modified": "2020-09-25T03:03:00Z",
    "most-recent-update": {
      "created": "2020-09-25T03:03:00Z",
      "modified": "2020-09-25T03:03:00Z",
      "text": "The issue with Cloud Shell has been resolved for all affected users as of Thursday, 2020-09-24 18:30 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-25T03:03:00Z"
    },
    "number": 20006,
    "public": true,
    "service_key": "developers-console",
    "service_name": "Google Cloud Console",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-25T03:03:00Z",
        "modified": "2020-09-25T03:03:00Z",
        "text": "The issue with Cloud Shell has been resolved for all affected users as of Thursday, 2020-09-24 18:30 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-25T03:03:00Z"
      },
      {
        "created": "2020-09-25T02:17:36Z",
        "modified": "2020-09-25T02:17:36Z",
        "text": "Description: Cloud Shell Issue Description:\nWe are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. The investigation will take a few hours. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\n\nWe will provide an update by Thursday, 2020-09-24 23:30 US/Pacific with current details.\n\nDiagnosis: Cloud Shell Diagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\n\nWorkaround: Cloud Shell Workaround: As a workaround you can use gcloud sdk on your local command line.",
        "when": "2020-09-25T02:17:36Z"
      },
      {
        "created": "2020-09-24T21:42:19Z",
        "modified": "2020-09-24T21:42:19Z",
        "text": "Description: Cloud Shell Issue Description:\nWe are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. The investigation will take a few hours. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\n\nWe will provide an update by Thursday, 2020-09-24 18:30 US/Pacific with current details.\n\nDiagnosis: Cloud Shell Diagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\n\nWorkaround: Cloud Shell Workaround: As a workaround you can use gcloud sdk on your local command line.",
        "when": "2020-09-24T21:42:19Z"
      },
      {
        "created": "2020-09-24T20:51:03Z",
        "modified": "2020-09-24T20:51:03Z",
        "text": "Description: Cloud Shell Issue Description:\nWe are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\n\nCloud Console Billing UI Issue Description:\nCloud Console is experiencing an issue with Pricing UI page not loading for some billing accounts associated with a custom price model globally.\nWe are currently rolling back the code change that is responsible for this issue. We expect to complete this in the next hour.\n\nWe will provide an update by Thursday, 2020-09-24 15:00 US/Pacific with current details.\n\nDiagnosis: Cloud Shell Diagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\n\nCloud Console Billing UI Diagnosis:\nAffected customers' Billing UI page may not load properly.\n\nWorkaround: Cloud Shell Workaround: As a workaround you can use gcloud sdk on your local command line.\n\nCloud Billing UI Workaround: None at this time.",
        "when": "2020-09-24T20:51:03Z"
      },
      {
        "created": "2020-09-24T20:15:37Z",
        "modified": "2020-09-24T20:15:37Z",
        "text": "Description: Cloud Shell Issue Description:\nWe are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\n\nCloud Console Billing UI Issue Description:\nAdditionally, Cloud Console is experiencing an issue with Pricing UI page not loading for some billing accounts associated with a custom price model globally.\n\nWe will provide an update by Thursday, 2020-09-24 14:00 US/Pacific with current details.\n\nDiagnosis: Cloud Shell Diagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\n\nCloud Console Billing UI Diagnosis:\nAffected customers' Billing UI page may not load properly.\n\nWorkaround: Cloud Shell Workaround: As a workaround you can use gcloud sdk on your local command line.\n\nCloud Billing UI Workaround: None at this time.",
        "when": "2020-09-24T20:15:37Z"
      },
      {
        "created": "2020-09-24T19:46:39Z",
        "modified": "2020-09-24T19:46:39Z",
        "text": "Cloud Shell Issue Description:\r\nWe are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\r\n\r\nCloud Console Billing UI Issue Description:\r\nAdditionally, Cloud Console is experiencing an issue with Pricing UI page not loading for some billing accounts associated with a custom price model globally.\r\n\r\nWe will provide an update by Thursday, 2020-09-24 14:00 US/Pacific with current details.\r\n\r\nCloud Shell Diagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\r\n\r\nCloud Console Billing UI Diagnosis:\r\nAffected customers' Billing UI page may not load properly.\r\n\r\nCloud Shell Workaround: As a workaround you can use command line on your local machine.\r\n\r\nCloud Billing UI Workaround: None at this time.",
        "when": "2020-09-24T19:46:39Z"
      },
      {
        "created": "2020-09-24T19:24:24Z",
        "modified": "2020-09-24T19:24:24Z",
        "text": "Description: We are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\n\nWe will provide an update by Thursday, 2020-09-24 13:30 US/Pacific with current details.\n\nDiagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\n\nWorkaround: As a workaround you can use command line on your local machine.",
        "when": "2020-09-24T19:24:24Z"
      },
      {
        "created": "2020-09-24T17:28:24Z",
        "modified": "2020-09-24T17:28:24Z",
        "text": "Description: It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\n\nWe will provide an update by Thursday, 2020-09-24 12:30 US/Pacific with current details.\n\nDiagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\n\nWorkaround: As a workaround you can use command line on your local machine.",
        "when": "2020-09-24T17:28:24Z"
      },
      {
        "created": "2020-09-24T16:22:44Z",
        "modified": "2020-09-24T16:22:44Z",
        "text": "Description: A potential root cause has been identified, and we are working to have a mitigation rolled out. \n\nWe will provide more information by Thursday, 2020-09-24 10:30 US/Pacific.\n\nDiagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or errors when attempting to create a new Cloud Shell instance.\n\nWorkaround: As a workaround you can use command line on your local machine.",
        "when": "2020-09-24T16:22:44Z"
      },
      {
        "created": "2020-09-24T13:51:42Z",
        "modified": "2020-09-24T13:51:42Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe will provide more information by Thursday, 2020-09-24 09:26 US/Pacific.\n\nDiagnosis: Error message Cloud Shell is temporarily not available please try after some time\n\nWorkaround: As a workaround you can use command line on your local machine",
        "when": "2020-09-24T13:51:42Z"
      },
      {
        "created": "2020-09-24T12:35:26Z",
        "modified": "2020-09-24T12:35:26Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Thursday, 2020-09-24 07:01 US/Pacific.\n\nDiagnosis: Error message Cloud Shell is temporarily not available please try after some time\n\nWorkaround: As a workaround you can use command line on your local machine",
        "when": "2020-09-24T12:35:26Z"
      },
      {
        "created": "2020-09-24T08:50:12Z",
        "modified": "2020-09-24T08:50:12Z",
        "text": "Description: We are experiencing an issue with Cloud Shell in asia-southeast1 beginning at Wednesday, 2020-09-24 22:00:00 US/Pacific.\n\nSymptoms: error message Cloud Shell is temporarily not available please try after some time.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-09-24 06:00 US/Pacific with current details.\n\nDiagnosis: Error message Cloud Shell is temporarily not available please try after some time\n\nWorkaround: As a workaround you can use command line on your local machine",
        "when": "2020-09-24T08:50:12Z"
      }
    ],
    "uri": "/incident/developers-console/20006"
  },
  {
    "begin": "2020-09-22T08:49:47Z",
    "created": "2020-09-22T09:30:09Z",
    "end": "2020-09-22T11:45:33Z",
    "external_desc": "We have received reports of an issue with the BigQuery UI",
    "modified": "2020-09-22T11:45:34Z",
    "most-recent-update": {
      "created": "2020-09-22T11:45:33Z",
      "modified": "2020-09-22T11:45:33Z",
      "text": "The issue with the Google BigQuery UI in the Cloud Console has been resolved for all affected users as of Tuesday, 2020-09-22 04:05 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-22T11:45:33Z"
    },
    "number": 20008,
    "public": true,
    "service_key": "bigquery",
    "service_name": "Google BigQuery",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-22T11:45:33Z",
        "modified": "2020-09-22T11:45:33Z",
        "text": "The issue with the Google BigQuery UI in the Cloud Console has been resolved for all affected users as of Tuesday, 2020-09-22 04:05 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-22T11:45:33Z"
      },
      {
        "created": "2020-09-22T10:29:37Z",
        "modified": "2020-09-22T10:29:37Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe will provide more information by Tuesday, 2020-09-22 05:00 US/Pacific.\n\nDiagnosis: Customers affected by this issue receive a blank page, or an error message, when trying to access Big Query via the Cloud Console.\n\nWorkaround: Where possible, customers can use the API to acces Big Query directly.",
        "when": "2020-09-22T10:29:37Z"
      },
      {
        "created": "2020-09-22T09:30:09Z",
        "modified": "2020-09-22T09:30:09Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Tuesday, 2020-09-22 03:30 US/Pacific.\n\nDiagnosis: Customers affected by this issue receive a blank page, or an error message, when trying to access Big Query via the Cloud Console.\n\nWorkaround: Where possible, customers can use the API to acces Big Query directly.",
        "when": "2020-09-22T09:30:09Z"
      }
    ],
    "uri": "/incident/bigquery/20008"
  },
  {
    "begin": "2020-09-18T20:04:40Z",
    "created": "2020-09-18T20:04:44Z",
    "end": "2020-09-18T22:54:08Z",
    "external_desc": "Cloud Console pages with prefix of :*/billing/:accountId/\" are returning errors",
    "modified": "2020-09-18T22:54:09Z",
    "most-recent-update": {
      "created": "2020-09-18T22:54:09Z",
      "modified": "2020-09-18T22:54:09Z",
      "text": "The issue with Cloud Console has been resolved for all affected projects as of Friday, 2020-09-18 15:53 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T22:54:08Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "developers-console",
    "service_name": "Google Cloud Console",
    "severity": "high",
    "updates": [
      {
        "created": "2020-09-18T22:54:09Z",
        "modified": "2020-09-18T22:54:09Z",
        "text": "The issue with Cloud Console has been resolved for all affected projects as of Friday, 2020-09-18 15:53 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T22:54:08Z"
      },
      {
        "created": "2020-09-18T21:30:52Z",
        "modified": "2020-09-18T21:30:52Z",
        "text": "This issue with Cloud Console has not yet been fully resolved.   Issues persist when attempting to access /freetrial/signup/tos.\r\n\r\nWe do not have an ETA for mitigation at this point.   \r\n\r\nWe will provide more information by  Friday, 2020-09-18 15:45 US/Pacific.",
        "when": "2020-09-18T22:45:00Z"
      },
      {
        "created": "2020-09-18T22:08:59Z",
        "modified": "2020-09-18T22:08:59Z",
        "text": "SUMMARY\r\nVarious Cloud Console pages are returning errors\r\n\r\nDESCRIPTION\r\nOur engineering team has determined that further investigation is required to mitigate the issue. We will provide an update by Friday, 2020-09-18 16:30 US/Pacific with current details.\r\n\r\nDIAGNOSIS\r\nThe affected pages are the following: /freetrial/signup/tos /billing/:accountId/payment /billing/:accountId/setting /billing/:accountId/budgets/:budgetId/edit /billing/:accountId/budgets/create /billing/:accountId/export/bigquery /billing/:accountId/export/bigquery/edit /billing/:accountId/export/bigquery/pricing /billing/:accountId/export/gcs /billing/:accountId/export/gcs/edit /billing/:accountId/reports/committed_use_discount_utilization /billing/:accountId/budgets /billing/:accountId/reports /billing/:accountId/reports/cost-breakdown /billing/:accountId/reports/tabula",
        "when": "2020-09-18T22:08:59Z"
      },
      {
        "created": "2020-09-18T21:02:23Z",
        "modified": "2020-09-18T21:02:23Z",
        "text": "The issue with Cloud Console has been resolved for all affected projects as of Friday, 2020-09-18 14:01 US/Pacific.  \n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T21:02:23Z"
      },
      {
        "created": "2020-09-18T20:51:28Z",
        "modified": "2020-09-18T20:51:28Z",
        "text": "Description: We believe the issue with Cloud Console is partially resolved.\n\nFull resolution is expected to complete by Friday, 2020-09-18 14:30 US/Pacific.\n\nWe will provide an update by Friday, 2020-09-18 14:30 US/Pacific with current details.\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-09-18T20:51:28Z"
      },
      {
        "created": "2020-09-18T20:29:55Z",
        "modified": "2020-09-18T20:29:55Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.    Error rates for the affected pages are going down, but the problem has not cleared yet.  \n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide more information by Friday, 2020-09-18 15:10 US/Pacific.\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-09-18T20:29:55Z"
      },
      {
        "created": "2020-09-18T20:04:45Z",
        "modified": "2020-09-18T20:04:45Z",
        "text": "Description: We are experiencing an issue with Cloud Console beginning at Friday, 2020-09-18 11:34:48 US/Pacific.\n\nSymptoms: Error message \"This page isn't available at the moment (the server timed out). Try refreshing in a few minutes. \"  when attempting to access this page\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Friday, 2020-09-18 14:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-09-18T20:04:45Z"
      }
    ],
    "uri": "/incident/developers-console/20005"
  },
  {
    "begin": "2020-09-18T01:49:53Z",
    "created": "2020-09-18T01:50:15Z",
    "end": "2020-09-18T02:33:34Z",
    "external_desc": "We are experiencing an issue with Bigtable in asia-east2",
    "modified": "2020-09-18T02:33:34Z",
    "most-recent-update": {
      "created": "2020-09-18T02:33:34Z",
      "modified": "2020-09-18T02:33:34Z",
      "text": "The issue with Cloud Bigtable has been resolved for all affected projects as of Thursday, 2020-09-17 18:40 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:33:34Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-bigtable",
    "service_name": "Google Cloud Bigtable",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:33:34Z",
        "modified": "2020-09-18T02:33:34Z",
        "text": "The issue with Cloud Bigtable has been resolved for all affected projects as of Thursday, 2020-09-17 18:40 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:33:34Z"
      },
      {
        "created": "2020-09-18T01:50:15Z",
        "modified": "2020-09-18T01:50:15Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009. No further updates will be made through this incident.",
        "when": "2020-09-18T01:50:15Z"
      }
    ],
    "uri": "/incident/cloud-bigtable/20001"
  },
  {
    "begin": "2020-09-18T01:19:01Z",
    "created": "2020-09-18T01:36:05Z",
    "end": "2020-09-18T02:31:37Z",
    "external_desc": "We are experiencing an issue with Cloud Run in asia-east2",
    "modified": "2020-09-18T02:31:37Z",
    "most-recent-update": {
      "created": "2020-09-18T02:31:37Z",
      "modified": "2020-09-18T02:31:37Z",
      "text": "The issue with Cloud Run has been resolved for all affected projects as of Thursday, 2020-09-17 19:04 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:31:37Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-run",
    "service_name": "Cloud Run",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:31:37Z",
        "modified": "2020-09-18T02:31:37Z",
        "text": "The issue with Cloud Run has been resolved for all affected projects as of Thursday, 2020-09-17 19:04 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:31:37Z"
      },
      {
        "created": "2020-09-18T01:36:06Z",
        "modified": "2020-09-18T01:36:06Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009. No further updates will be made through this incident.",
        "when": "2020-09-18T01:36:06Z"
      }
    ],
    "uri": "/incident/cloud-run/20002"
  },
  {
    "begin": "2020-09-18T01:16:43Z",
    "created": "2020-09-18T01:35:11Z",
    "end": "2020-09-18T02:34:34Z",
    "external_desc": "We are experiencing an issue with Secret Manager in asia-east2",
    "modified": "2020-09-18T02:34:34Z",
    "most-recent-update": {
      "created": "2020-09-18T02:34:34Z",
      "modified": "2020-09-18T02:34:34Z",
      "text": "The issue with Secret Manager has been resolved for all affected projects as of Thursday, 2020-09-17 18:37 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:34:34Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "sercret-manager",
    "service_name": "Secret Manager ",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:34:34Z",
        "modified": "2020-09-18T02:34:34Z",
        "text": "The issue with Secret Manager has been resolved for all affected projects as of Thursday, 2020-09-17 18:37 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:34:34Z"
      },
      {
        "created": "2020-09-18T01:35:11Z",
        "modified": "2020-09-18T01:35:11Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009. No further updates will be made through this incident.",
        "when": "2020-09-18T01:35:11Z"
      }
    ],
    "uri": "/incident/sercret-manager/20001"
  },
  {
    "begin": "2020-09-18T01:10:36Z",
    "created": "2020-09-18T01:10:39Z",
    "end": "2020-09-18T02:30:09Z",
    "external_desc": "We're experiences issues with Google Cloud infrastructure in asia-east2",
    "modified": "2020-09-18T02:30:10Z",
    "most-recent-update": {
      "created": "2020-09-18T02:30:09Z",
      "modified": "2020-09-18T02:30:09Z",
      "text": "The issue with multiple GCP products has been resolved for all affected users as of Thursday, 2020-09-17 19:29 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:30:09Z"
    },
    "number": 20009,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:30:09Z",
        "modified": "2020-09-18T02:30:09Z",
        "text": "The issue with multiple GCP products has been resolved for all affected users as of Thursday, 2020-09-17 19:29 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:30:09Z"
      },
      {
        "created": "2020-09-18T02:26:17Z",
        "modified": "2020-09-18T02:26:17Z",
        "text": "Description: We are experiencing issues across multiple GCP products in asia-east2. \n\nMitigation work is currently underway by our engineering team. \n\nAffected products include: GKE, Firestore, Artifact Registry, Cloud Function, App Engine, Data Catalog, Cloud Gaming, Cloud SQL, IAM, Cloud Pub/Sub, Cloud Bigtable, Cloud Tasks, Cloud KMS, Cloud Spanner, Secrets Manager, Cloud Run, Cloud Healthcare, Cloud Console, Dataproc\n\nWe will provide more information by Thursday, 2020-09-17 20:00 US/Pacific.\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-09-18T02:26:17Z"
      },
      {
        "created": "2020-09-18T02:07:51Z",
        "modified": "2020-09-18T02:07:51Z",
        "text": "Description: We are experiencing issues across multiple GCP products in asia-east2. \n\nMitigation work is currently underway by our engineering team. \n\nAffected products include: GKE, Firestore, Artifact Registry, Cloud Function, App Engine, Data Catalog, Cloud Gaming, Cloud SQL, IAM, Cloud Pub/Sub, Cloud Bigtable, Cloud Tasks, Cloud KMS, Cloud Spanner, Secrets Manager, Cloud Run, Cloud Healthcare, Cloud Console\n\nWe will provide more information by Thursday, 2020-09-17 20:00 US/Pacific.\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-09-18T02:07:51Z"
      },
      {
        "created": "2020-09-18T01:52:34Z",
        "modified": "2020-09-18T01:52:34Z",
        "text": "Description: We are experiencing issues across multiple GCP products in asia-east2. \n\nMitigation work is currently underway by our engineering team. \n\nAffected products include: GKE, BigQuery, Firestore, Artifact Registry, Cloud Function, App Engine, Data Catalog, Cloud Gaming, Cloud SQL, IAM, Cloud Pub/Sub, Cloud Bigtable, Cloud Tasks, Cloud KMS, Cloud Spanner, Secrets Manager, Cloud Run, Cloud Healthcare\n\nWe will provide more information by Thursday, 2020-09-17 19:30 US/Pacific.\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-09-18T01:52:34Z"
      },
      {
        "created": "2020-09-18T01:39:12Z",
        "modified": "2020-09-18T01:39:12Z",
        "text": "Description: We are experiencing issues across multiple GCP products in asia-east2. \n\nAffected products include: GKE, BigQuery, Firestore, Artifact Registry, Cloud Function, App Engine, Data Catalog, Cloud Gaming, Cloud SQL, IAM, Cloud Pub/Sub, Cloud Bigtable, Cloud Tasks, Cloud KMS, Cloud Spanner, Secrets Manager, Cloud Run, Cloud Healthcare\n\nSymptoms: Increased error rates\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-09-17 19:15 US/Pacific with current details.\n\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-09-18T01:39:12Z"
      },
      {
        "created": "2020-09-18T01:30:18Z",
        "modified": "2020-09-18T01:30:18Z",
        "text": "Description: We are experiencing issues across multiple GCP products in asia-east2. \n\nAffected products include: GKE, BigQuery, Firestore, Artifact Registry, Cloud Function, App Engine, Data Catalog, Cloud Gaming, Cloud SQL, Cloud Pub/Sub, Cloud Bigtable, Cloud Tasks, Cloud KMS, Cloud Spanner.\n\nSymptoms: Increased error rates\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-09-17 19:00 US/Pacific with current details.\n\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-09-18T01:30:18Z"
      },
      {
        "created": "2020-09-18T01:10:40Z",
        "modified": "2020-09-18T01:10:40Z",
        "text": "Description: We are experiencing an issue with Google Cloud infrastructure components.\n\nSymptoms: Increased error rate\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-09-17 18:45 US/Pacific with current details.\n\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-09-18T01:10:40Z"
      }
    ],
    "uri": "/incident/zall/20009"
  },
  {
    "begin": "2020-09-18T01:09:59Z",
    "created": "2020-09-18T01:31:24Z",
    "end": "2020-09-18T02:30:29Z",
    "external_desc": "We are experiencing an issue with Cloud Spanner in asia-east2",
    "modified": "2020-10-02T01:16:37Z",
    "most-recent-update": {
      "created": "2020-09-18T02:30:29Z",
      "modified": "2020-09-18T02:30:29Z",
      "text": "The issue with Cloud Spanner has been resolved for all affected projects as of Thursday, 2020-09-17 19:21 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:30:29Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "cloud-spanner",
    "service_name": "Cloud Spanner",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:30:29Z",
        "modified": "2020-09-18T02:30:29Z",
        "text": "The issue with Cloud Spanner has been resolved for all affected projects as of Thursday, 2020-09-17 19:21 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:30:29Z"
      },
      {
        "created": "2020-09-18T01:31:25Z",
        "modified": "2020-10-02T01:16:36Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009  No further updates will be made through this incident.",
        "when": "2020-09-18T01:31:25Z"
      }
    ],
    "uri": "/incident/cloud-spanner/20003"
  },
  {
    "begin": "2020-09-18T01:03:12Z",
    "created": "2020-09-18T01:34:29Z",
    "end": "2020-09-18T02:29:21Z",
    "external_desc": "We are experiencing an issue with Cloud KMS in asia-east2",
    "modified": "2020-09-18T02:29:21Z",
    "most-recent-update": {
      "created": "2020-09-18T02:29:21Z",
      "modified": "2020-09-18T02:29:21Z",
      "text": "The issue with Cloud Key Management Service has been resolved for all affected projects as of Thursday, 2020-09-17 18:35 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:29:21Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-kms",
    "service_name": "Cloud Key Management Service",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:29:21Z",
        "modified": "2020-09-18T02:29:21Z",
        "text": "The issue with Cloud Key Management Service has been resolved for all affected projects as of Thursday, 2020-09-17 18:35 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:29:21Z"
      },
      {
        "created": "2020-09-18T01:34:30Z",
        "modified": "2020-09-18T01:34:30Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009. No further updates will be made through this incident.",
        "when": "2020-09-18T01:34:30Z"
      }
    ],
    "uri": "/incident/cloud-kms/20002"
  },
  {
    "begin": "2020-09-18T01:02:48Z",
    "created": "2020-09-18T01:31:54Z",
    "end": "2020-09-18T02:35:31Z",
    "external_desc": "We are experiencing an issue with Cloud Tasks in asia-east2",
    "modified": "2020-09-18T02:35:31Z",
    "most-recent-update": {
      "created": "2020-09-18T02:35:31Z",
      "modified": "2020-09-18T02:35:31Z",
      "text": "The issue with Cloud Tasks has been resolved for all affected projects as of Thursday, 2020-09-17 19:04 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:35:31Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-tasks",
    "service_name": "Google Cloud Tasks",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:35:31Z",
        "modified": "2020-09-18T02:35:31Z",
        "text": "The issue with Cloud Tasks has been resolved for all affected projects as of Thursday, 2020-09-17 19:04 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:35:31Z"
      },
      {
        "created": "2020-09-18T01:31:54Z",
        "modified": "2020-09-18T01:31:54Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009. No further updates will be made through this incident.",
        "when": "2020-09-18T01:31:54Z"
      }
    ],
    "uri": "/incident/cloud-tasks/20001"
  },
  {
    "begin": "2020-09-18T00:58:36Z",
    "created": "2020-09-18T01:33:34Z",
    "end": "2020-09-18T02:36:35Z",
    "external_desc": "We are experiencing an issue with Cloud Pub/Sub in asia-east2",
    "modified": "2020-09-18T02:36:36Z",
    "most-recent-update": {
      "created": "2020-09-18T02:36:35Z",
      "modified": "2020-09-18T02:36:35Z",
      "text": "The issue with Cloud Pub/Sub has been resolved for all affected projects as of Thursday, 2020-09-17 18:37 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:36:35Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-pubsub",
    "service_name": "Google Cloud Pub/Sub",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:36:35Z",
        "modified": "2020-09-18T02:36:35Z",
        "text": "The issue with Cloud Pub/Sub has been resolved for all affected projects as of Thursday, 2020-09-17 18:37 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:36:35Z"
      },
      {
        "created": "2020-09-18T01:33:35Z",
        "modified": "2020-09-18T01:33:35Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009. No further updates will be made through this incident.",
        "when": "2020-09-18T01:33:35Z"
      }
    ],
    "uri": "/incident/cloud-pubsub/20002"
  },
  {
    "begin": "2020-09-18T00:58:25Z",
    "created": "2020-09-18T01:26:21Z",
    "end": "2020-09-18T02:39:17Z",
    "external_desc": "We are experiencing an issue with Cloud Identity & Access Management in asia-east2",
    "modified": "2020-09-18T02:39:18Z",
    "most-recent-update": {
      "created": "2020-09-18T02:39:17Z",
      "modified": "2020-09-18T02:39:17Z",
      "text": "The issue with Cloud Identity & Security has been resolved for all affected projects as of Thursday, 2020-09-17 18:40 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:39:17Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-iam",
    "service_name": "Identity and Access Management",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:39:17Z",
        "modified": "2020-09-18T02:39:17Z",
        "text": "The issue with Cloud Identity & Security has been resolved for all affected projects as of Thursday, 2020-09-17 18:40 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:39:17Z"
      },
      {
        "created": "2020-09-18T01:26:21Z",
        "modified": "2020-09-18T01:26:21Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009. No further updates will be made through this incident.",
        "when": "2020-09-18T01:26:21Z"
      }
    ],
    "uri": "/incident/cloud-iam/20002"
  },
  {
    "begin": "2020-09-18T00:57:57Z",
    "created": "2020-09-18T01:27:11Z",
    "end": "2020-09-18T02:22:17Z",
    "external_desc": "We are experiencing an issue with Cloud SQL in asia-east2",
    "modified": "2020-09-18T02:22:17Z",
    "most-recent-update": {
      "created": "2020-09-18T02:22:17Z",
      "modified": "2020-09-18T02:22:17Z",
      "text": "The issue with Cloud SQL has been resolved for all affected projects as of Thursday, 2020-09-17 18:46 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:22:17Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "cloud-sql",
    "service_name": "Google Cloud SQL",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:22:17Z",
        "modified": "2020-09-18T02:22:17Z",
        "text": "The issue with Cloud SQL has been resolved for all affected projects as of Thursday, 2020-09-17 18:46 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:22:17Z"
      },
      {
        "created": "2020-09-18T01:27:11Z",
        "modified": "2020-09-18T01:27:11Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009. No further updates will be made through this incident.",
        "when": "2020-09-18T01:27:11Z"
      }
    ],
    "uri": "/incident/cloud-sql/20004"
  },
  {
    "begin": "2020-09-18T00:52:16Z",
    "created": "2020-09-18T01:27:59Z",
    "end": "2020-09-18T02:21:01Z",
    "external_desc": "We are experiencing an issue with Cloud Functions in asia-east2",
    "modified": "2020-10-02T17:55:12Z",
    "most-recent-update": {
      "created": "2020-09-18T02:21:01Z",
      "modified": "2020-09-18T02:21:01Z",
      "text": "The issue with Google Cloud Functions has been resolved for all affected projects as of Thursday, 2020-09-17 18:37 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:21:01Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "cloud-functions",
    "service_name": "Google Cloud Functions",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:21:01Z",
        "modified": "2020-09-18T02:21:01Z",
        "text": "The issue with Google Cloud Functions has been resolved for all affected projects as of Thursday, 2020-09-17 18:37 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:21:01Z"
      },
      {
        "created": "2020-09-18T01:28:00Z",
        "modified": "2020-10-02T17:55:12Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009\r\n\r\nNo further updates will be made through this incident.",
        "when": "2020-09-18T01:28:00Z"
      }
    ],
    "uri": "/incident/cloud-functions/20005"
  },
  {
    "begin": "2020-09-18T00:51:31Z",
    "created": "2020-09-18T01:28:49Z",
    "end": "2020-09-18T02:19:41Z",
    "external_desc": "We are experiencing an issue with Cloud Memorystore in asia-east2",
    "modified": "2020-09-18T02:19:42Z",
    "most-recent-update": {
      "created": "2020-09-18T02:19:42Z",
      "modified": "2020-09-18T02:19:42Z",
      "text": "The issue with Cloud Memorystore has been resolved for all affected users as of Thursday, 2020-09-17 18:40 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:19:41Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "cloud-memorystore",
    "service_name": "Cloud Memorystore",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:19:42Z",
        "modified": "2020-09-18T02:19:42Z",
        "text": "The issue with Cloud Memorystore has been resolved for all affected users as of Thursday, 2020-09-17 18:40 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:19:41Z"
      },
      {
        "created": "2020-09-18T01:28:50Z",
        "modified": "2020-09-18T01:28:50Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009. No further updates will be made through this incident.",
        "when": "2020-09-18T01:28:50Z"
      }
    ],
    "uri": "/incident/cloud-memorystore/20003"
  },
  {
    "begin": "2020-09-18T00:49:36Z",
    "created": "2020-09-18T01:29:20Z",
    "end": "2020-09-18T02:18:25Z",
    "external_desc": "We are experiencing an issue with App Engine in asia-east2",
    "modified": "2020-10-02T16:11:10Z",
    "most-recent-update": {
      "created": "2020-09-18T02:18:26Z",
      "modified": "2020-09-18T02:18:26Z",
      "text": "The issue with Google App Engine has been resolved for all affected projects as of Thursday, 2020-09-17 18:43 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:18:25Z"
    },
    "number": 20006,
    "public": true,
    "service_key": "appengine",
    "service_name": "Google App Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:18:26Z",
        "modified": "2020-09-18T02:18:26Z",
        "text": "The issue with Google App Engine has been resolved for all affected projects as of Thursday, 2020-09-17 18:43 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:18:25Z"
      },
      {
        "created": "2020-09-18T01:29:21Z",
        "modified": "2020-10-02T16:11:10Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009 \r\n\r\nNo further updates will be made through this incident.",
        "when": "2020-09-18T01:29:21Z"
      }
    ],
    "uri": "/incident/appengine/20006"
  },
  {
    "begin": "2020-09-18T00:36:42Z",
    "created": "2020-09-18T01:32:46Z",
    "end": "2020-09-18T02:38:34Z",
    "external_desc": "We are experiencing an issue with BigQuery in asia-east2",
    "modified": "2020-10-02T17:53:21Z",
    "most-recent-update": {
      "created": "2020-09-18T02:38:34Z",
      "modified": "2020-09-18T02:38:34Z",
      "text": "The issue with Google BigQuery has been resolved for all affected projects as of Thursday, 2020-09-17 19:18 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:38:34Z"
    },
    "number": 20007,
    "public": true,
    "service_key": "bigquery",
    "service_name": "Google BigQuery",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:38:34Z",
        "modified": "2020-09-18T02:38:34Z",
        "text": "The issue with Google BigQuery has been resolved for all affected projects as of Thursday, 2020-09-17 19:18 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:38:34Z"
      },
      {
        "created": "2020-09-18T01:32:46Z",
        "modified": "2020-10-02T17:53:21Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009\r\n \r\nNo further updates will be made through this incident.",
        "when": "2020-09-18T01:32:46Z"
      }
    ],
    "uri": "/incident/bigquery/20007"
  },
  {
    "begin": "2020-09-18T00:34:10Z",
    "created": "2020-09-18T01:23:54Z",
    "end": "2020-09-18T02:15:37Z",
    "external_desc": "We are experiencing an issue with GKE in asia-east2",
    "modified": "2020-09-18T02:15:37Z",
    "most-recent-update": {
      "created": "2020-09-18T02:15:37Z",
      "modified": "2020-09-18T02:15:37Z",
      "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Thursday, 2020-09-17 19:02 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:15:37Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:15:37Z",
        "modified": "2020-09-18T02:15:37Z",
        "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Thursday, 2020-09-17 19:02 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:15:37Z"
      },
      {
        "created": "2020-09-18T01:23:55Z",
        "modified": "2020-09-18T01:23:55Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/zall/20009. No further updates will be made through this incident.",
        "when": "2020-09-18T01:23:55Z"
      }
    ],
    "uri": "/incident/container-engine/20005"
  },
  {
    "begin": "2020-09-18T00:32:00Z",
    "created": "2020-09-18T02:14:10Z",
    "end": "2020-09-18T01:38:00Z",
    "external_desc": "An issue with Datastore in asia-east2 has been resolved",
    "modified": "2020-09-18T02:14:10Z",
    "most-recent-update": {
      "created": "2020-09-18T02:14:10Z",
      "modified": "2020-09-18T02:14:10Z",
      "text": "Datastore has been affected in the asia-east2 region by the Google incident https://status.cloud.google.com/incident/zall/20009 since 2020-09-17 17:32 US/Pacific. The issue was resolved for all projects as of Thursday, 2020-09-17 18:38 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:14:10Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-datastore",
    "service_name": "Google Cloud Datastore",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:14:10Z",
        "modified": "2020-09-18T02:14:10Z",
        "text": "Datastore has been affected in the asia-east2 region by the Google incident https://status.cloud.google.com/incident/zall/20009 since 2020-09-17 17:32 US/Pacific. The issue was resolved for all projects as of Thursday, 2020-09-17 18:38 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:14:10Z"
      }
    ],
    "uri": "/incident/cloud-datastore/20001"
  },
  {
    "begin": "2020-09-18T00:32:00Z",
    "created": "2020-09-18T02:12:02Z",
    "end": "2020-09-18T01:38:00Z",
    "external_desc": "An issue with Firestore in asia-east2 has been resolved",
    "modified": "2020-09-18T02:12:03Z",
    "most-recent-update": {
      "created": "2020-09-18T02:12:02Z",
      "modified": "2020-09-18T02:12:02Z",
      "text": "Firestore has been affected in the asia-east2 region by the Google incident https://status.cloud.google.com/incident/zall/20009 since 2020-09-17 17:32 US/Pacific. The issue was resolved for all projects as of Thursday, 2020-09-17 18:38 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:12:02Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "cloud-firestore",
    "service_name": "Cloud Firestore",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:12:02Z",
        "modified": "2020-09-18T02:12:02Z",
        "text": "Firestore has been affected in the asia-east2 region by the Google incident https://status.cloud.google.com/incident/zall/20009 since 2020-09-17 17:32 US/Pacific. The issue was resolved for all projects as of Thursday, 2020-09-17 18:38 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:12:02Z"
      }
    ],
    "uri": "/incident/cloud-firestore/20003"
  },
  {
    "begin": "2020-09-18T00:02:00Z",
    "created": "2020-09-18T02:06:02Z",
    "end": "2020-09-18T01:38:00Z",
    "external_desc": "An issue with Cloud Healthcare API in asia-east2 has been resolved",
    "modified": "2020-09-18T02:08:12Z",
    "most-recent-update": {
      "created": "2020-09-18T02:06:02Z",
      "modified": "2020-09-18T02:06:02Z",
      "text": "Cloud Healthcare API has been affected in the asia-east2 region by the Google incident https://status.cloud.google.com/incident/zall/20009 since 2020-09-17 17:02 US/Pacific. The issue was resolved for all projects as of Thursday, 2020-09-17 18:38 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-09-18T02:06:02Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "healthcare",
    "service_name": "Healthcare and Life Sciences",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-18T02:06:02Z",
        "modified": "2020-09-18T02:06:02Z",
        "text": "Cloud Healthcare API has been affected in the asia-east2 region by the Google incident https://status.cloud.google.com/incident/zall/20009 since 2020-09-17 17:02 US/Pacific. The issue was resolved for all projects as of Thursday, 2020-09-17 18:38 US/Pacific.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-09-18T02:06:02Z"
      }
    ],
    "uri": "/incident/healthcare/20001"
  },
  {
    "begin": "2020-08-27T18:29:00Z",
    "created": "2020-08-27T18:29:31Z",
    "end": "2020-08-27T21:03:46Z",
    "external_desc": "Cloud Security Command Center is experiencing latency and timeouts for configuration view or update requests",
    "modified": "2020-08-27T21:03:47Z",
    "most-recent-update": {
      "created": "2020-08-27T21:03:46Z",
      "modified": "2020-08-27T21:03:46Z",
      "text": "We believe the issue with Cloud Security Command Center was fully resolved for all users as of Thursday, 2020-08-27 12:00 US/Pacific.\r\n\r\nCustomers who submitted configuration changes and encountered errors should retry.\r\n\r\nIf you have questions or are still impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.\r\n\r\nNo further updates will be provided here.",
      "when": "2020-08-27T21:03:46Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-security-command-center",
    "service_name": "Cloud Security Command Center",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-08-27T21:03:46Z",
        "modified": "2020-08-27T21:03:46Z",
        "text": "We believe the issue with Cloud Security Command Center was fully resolved for all users as of Thursday, 2020-08-27 12:00 US/Pacific.\r\n\r\nCustomers who submitted configuration changes and encountered errors should retry.\r\n\r\nIf you have questions or are still impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\r\n\r\nWe thank you for your patience while we worked on resolving the issue.\r\n\r\nNo further updates will be provided here.",
        "when": "2020-08-27T21:03:46Z"
      },
      {
        "created": "2020-08-27T20:34:35Z",
        "modified": "2020-08-27T20:34:35Z",
        "text": "We believe the issue with Cloud Security Command Center has been resolved for most users as of Thursday, 2020-08-27 12:00 US/Pacific.\r\n\r\nCustomers who submitted configuration changes and encountered errors should retry.\r\n\r\nWe are currently investigating whether there is was any additional impact to customers who submitted configuration changes during this incident. \r\n\r\nWe will provide an update by Thursday, 2020-08-27 14:30 US/Pacific with current details.\r\n\r\nWe thank you for your patience while we work on resolving the issue.",
        "when": "2020-08-27T20:34:35Z"
      },
      {
        "created": "2020-08-27T19:31:38Z",
        "modified": "2020-08-27T19:31:38Z",
        "text": "We believe the issue with Cloud Security Command Center is partially resolved for most users as of Thursday, 2020-08-27 12:00 US/Pacific.\r\n\r\nCustomers who submitted configuration changes and encountered errors should retry.\r\n\r\nWe do not have an ETA for full resolution at this point.\r\n\r\nWe will provide an update by Thursday, 2020-08-27 13:30 US/Pacific with current details.\r\n\r\nWe thank you for your patience while we work on resolving the issue.",
        "when": "2020-08-27T19:31:38Z"
      },
      {
        "created": "2020-08-27T19:02:58Z",
        "modified": "2020-08-27T19:02:58Z",
        "text": "Our engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Thursday, 2020-08-27 12:30 US/Pacific with current details.\r\n\r\nWe apologize to all who are affected by the disruption.",
        "when": "2020-08-27T19:02:58Z"
      },
      {
        "created": "2020-08-27T18:29:32Z",
        "modified": "2020-08-27T18:29:32Z",
        "text": "We are experiencing an issue with Cloud Security Command Center \r\n\r\nSymptoms: Latency or timeouts on requests to view or update configurations.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Thursday, 2020-08-27 12:03 US/Pacific with current details.\r\n\r\nWe apologize to all who are affected by the disruption.",
        "when": "2020-08-27T18:29:32Z"
      }
    ],
    "uri": "/incident/cloud-security-command-center/20001"
  },
  {
    "begin": "2020-08-20T10:06:34Z",
    "created": "2020-08-20T10:07:04Z",
    "end": "2020-08-20T11:23:00Z",
    "external_desc": "We are experiencing issues with Cloud Logging",
    "modified": "2020-08-20T11:23:00Z",
    "most-recent-update": {
      "created": "2020-08-20T11:23:00Z",
      "modified": "2020-08-20T11:23:00Z",
      "text": "The issue with Cloud Logging has been resolved for all affected projects as of Thursday, 2020-08-20 04:22 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-08-20T11:23:00Z"
    },
    "number": 20006,
    "public": true,
    "service_key": "google-stackdriver",
    "service_name": "Operations",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-08-20T11:23:00Z",
        "modified": "2020-08-20T11:23:00Z",
        "text": "The issue with Cloud Logging has been resolved for all affected projects as of Thursday, 2020-08-20 04:22 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-08-20T11:23:00Z"
      },
      {
        "created": "2020-08-20T10:52:00Z",
        "modified": "2020-08-20T10:52:00Z",
        "text": "Description: We believe the issue with Cloud Logging is partially resolved.\n\nWe do not have an ETA for full resolution at this point.\n\nWe will provide an update by Thursday, 2020-08-20 07:51 US/Pacific with current details.",
        "when": "2020-08-20T10:52:00Z"
      },
      {
        "created": "2020-08-20T10:07:05Z",
        "modified": "2020-08-20T10:07:05Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nThere is currently no ETA for the full service recovery.\n\nWe will provide more information by Thursday, 2020-08-20 04:00 US/Pacific.",
        "when": "2020-08-20T10:07:05Z"
      }
    ],
    "uri": "/incident/google-stackdriver/20006"
  },
  {
    "begin": "2020-08-20T06:40:23Z",
    "created": "2020-08-20T06:45:20Z",
    "end": "2020-08-20T10:30:40Z",
    "external_desc": "We are experiencing issues across multiple GCP products",
    "modified": "2020-08-24T23:58:08Z",
    "most-recent-update": {
      "created": "2020-08-24T23:58:08Z",
      "modified": "2020-08-24T23:58:08Z",
      "text": "A detailed incident report has been posted on the G Suite Status Dashboard [1].\r\n[1] https://www.google.com/appsstatus#hl=en&v=issue&sid=1&iid=a45de3b26d6c5872f4cfe8e3424d7a82",
      "when": "2020-08-24T23:58:08Z"
    },
    "number": 20008,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "high",
    "updates": [
      {
        "created": "2020-08-24T23:58:08Z",
        "modified": "2020-08-24T23:58:08Z",
        "text": "A detailed incident report has been posted on the G Suite Status Dashboard [1].\r\n[1] https://www.google.com/appsstatus#hl=en&v=issue&sid=1&iid=a45de3b26d6c5872f4cfe8e3424d7a82",
        "when": "2020-08-24T23:58:08Z"
      },
      {
        "created": "2020-08-20T11:19:40Z",
        "modified": "2020-08-20T11:19:40Z",
        "text": "The issue with App Engine, Cloud Storage and Cloud Logging has been resolved for all affected users as of Thursday, 2020-08-20 04:12 US/Pacific.\n\nWe will publish an analysis of this incident once we have completed our internal investigation.",
        "when": "2020-08-20T11:19:40Z"
      },
      {
        "created": "2020-08-20T10:45:22Z",
        "modified": "2020-08-20T10:45:22Z",
        "text": "Description: The issue with App Engine, Cloud Storage and Cloud Logging is partially resolved.\n\nOur engineers continue to work on restoring services to all users.\n\nWe will provide an update by Thursday, 2020-08-20 04:45 US/Pacific with current details.\n\nDiagnosis: Deployment errors with AppEngine, high latencies while accessing GCS buckets and missing log entries in Cloud Logging.\n\nWorkaround: None at this time.",
        "when": "2020-08-20T10:45:22Z"
      },
      {
        "created": "2020-08-20T10:31:48Z",
        "modified": "2020-08-20T10:31:48Z",
        "text": "Description: We believe the issue with App Engine, Cloud Storage and Cloud Logging is partially resolved.\n\nThe affected services must be fully operational for the vast majority of users and we are awaiting a full recovery in the nearest future.\n\nWe will provide an update by Thursday, 2020-08-20 04:30 US/Pacific with current details.\n\nDiagnosis: Deployment errors with AppEngine, high latencies while accessing GCS buckets and missing log entries in Cloud Logging.\n\nWorkaround: None at this time.",
        "when": "2020-08-20T10:31:48Z"
      },
      {
        "created": "2020-08-20T09:15:55Z",
        "modified": "2020-08-20T09:15:55Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nCurrent data indicates that there was no impact to BigQuery users. Affected products include:  App Engine, Cloud Storage and Cloud Logging.\n\nThere is currently no ETA for the full service recovery.\n\nWe will provide more information by Thursday, 2020-08-20 03:30 US/Pacific.\n\nDiagnosis: Deployment errors with AppEngine, high latencies while accessing GCS buckets and missing log entries in Cloud Logging.\n\nWorkaround: None at this time.",
        "when": "2020-08-20T09:15:55Z"
      },
      {
        "created": "2020-08-20T07:56:09Z",
        "modified": "2020-08-20T07:56:09Z",
        "text": "Description: We are experiencing issues across multiple GCP products. Affected products include:  App Engine, Cloud Storage, Cloud Logging, BigQuery.\n\nMitigation work is currently underway by our engineering team and we are seeing a decrease in error rates at the moment.\n\nWe will provide an update by Thursday, 2020-08-20 02:00 US/Pacific with current details.\n\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-08-20T07:56:09Z"
      },
      {
        "created": "2020-08-20T07:11:00Z",
        "modified": "2020-08-20T07:11:00Z",
        "text": "Description: We are experiencing issues across multiple GCP products. Affected products include:  App Engine, Cloud Storage, Cloud Logging, BigQuery.\n\nMitigation work is currently underway by our engineering team.\n\nWe will provide an update by Thursday, 2020-08-20 00:45 US/Pacific with current details.\n\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-08-20T07:11:00Z"
      },
      {
        "created": "2020-08-20T06:45:22Z",
        "modified": "2020-08-20T06:45:22Z",
        "text": "Description: We are experiencing issues across multiple GCP products. Affected products include:  App Engine, Cloud Storage, Cloud Logging.\n\nMitigation work is currently underway by our engineering team.\n\nWe will provide an update by Thursday, 2020-08-20 00:15 US/Pacific with current details.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-08-20T06:45:22Z"
      }
    ],
    "uri": "/incident/zall/20008"
  },
  {
    "begin": "2020-08-20T05:59:54Z",
    "created": "2020-08-20T06:31:54Z",
    "end": "2020-08-20T12:17:47Z",
    "external_desc": "We are experiencing issues with Google App Engine, increased error rate for instance creation",
    "modified": "2020-08-20T12:17:48Z",
    "most-recent-update": {
      "created": "2020-08-20T12:17:48Z",
      "modified": "2020-08-20T12:17:48Z",
      "text": "The issue with App Engine has been resolved for all affected users as of Thursday, 2020-08-20 04:12 US/Pacific.\r\n\r\nWe will publish an analysis of this incident once we have completed our internal investigation.",
      "when": "2020-08-20T12:17:47Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "appengine",
    "service_name": "Google App Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-08-20T12:17:48Z",
        "modified": "2020-08-20T12:17:48Z",
        "text": "The issue with App Engine has been resolved for all affected users as of Thursday, 2020-08-20 04:12 US/Pacific.\r\n\r\nWe will publish an analysis of this incident once we have completed our internal investigation.",
        "when": "2020-08-20T12:17:47Z"
      },
      {
        "created": "2020-08-20T06:53:57Z",
        "modified": "2020-08-20T07:25:30Z",
        "text": "We are experiencing an issue with Google Cloud Storage infrastructure affecting multiple products beginning at Wednesday, 2020-08-19 21:15 US/Pacific.\r\n\r\nPlease follow https://status.cloud.google.com/incident/zall/20008 for further updates. No more updates will be provided here.",
        "when": "2020-08-20T06:53:57Z"
      },
      {
        "created": "2020-08-20T06:36:40Z",
        "modified": "2020-08-20T07:25:56Z",
        "text": "Description: We are experiencing an issue with Google App Engine beginning at Wednesday, 2020-08-19 21:15 US/Pacific.\r\n\r\nSymptoms: error rate on requests.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Thursday, 2020-08-20 00:04 US/Pacific with current details.\r\n\r\nWe apologize to all who are affected by the disruption.\r\n\r\nPlease follow https://status.cloud.google.com/incident/zall/20008 for further updates. No more updates will be provided here\r\n\r\n\r\nDiagnosis: Instance Creation Fails\r\n\r\nWorkaround: None at this time",
        "when": "2020-08-20T06:36:40Z"
      },
      {
        "created": "2020-08-20T06:31:56Z",
        "modified": "2020-08-20T07:26:23Z",
        "text": "Description: We are experiencing an issue with Google App Engine beginning at Wednesday, 2020-08-19 21:15 US/Pacific.\r\n\r\nSymptoms: error rate on requests.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Thursday, 2020-08-20 00:04 US/Pacific with current details.\r\n\r\nWe apologize to all who are affected by the disruption.\r\n\r\nPlease follow https://status.cloud.google.com/incident/zall/20008 for further updates. No more updates will be provided here\r\n\r\nDiagnosis: Instance Creation Fails\r\n\r\nWorkaround: None at this time",
        "when": "2020-08-20T06:31:56Z"
      }
    ],
    "uri": "/incident/appengine/20005"
  },
  {
    "begin": "2020-08-20T05:00:00Z",
    "created": "2020-08-20T07:11:45Z",
    "end": "2020-08-20T11:12:00Z",
    "external_desc": "We are experiencing issues across multiple GCP products caused by an issue",
    "modified": "2020-09-03T18:31:13Z",
    "most-recent-update": {
      "created": "2020-09-01T17:17:04Z",
      "modified": "2020-09-01T17:17:04Z",
      "text": "The issue with App Engine, Cloud Storage and Cloud Logging has been resolved for all affected users as of Thursday, 2020-08-20 04:12 US/Pacific.\r\n\r\nA detailed incident report has been posted on the G Suite Status Dashboard [1].\r\n\r\n [1] https://www.google.com/appsstatus#hl=en&v=issue&sid=1&iid=a45de3b26d6c5872f4cfe8e3424d7a82",
      "when": "2020-08-20T11:12:00Z"
    },
    "number": 20006,
    "public": true,
    "service_key": "bigquery",
    "service_name": "Google BigQuery",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-09-01T17:17:04Z",
        "modified": "2020-09-01T17:17:04Z",
        "text": "The issue with App Engine, Cloud Storage and Cloud Logging has been resolved for all affected users as of Thursday, 2020-08-20 04:12 US/Pacific.\r\n\r\nA detailed incident report has been posted on the G Suite Status Dashboard [1].\r\n\r\n [1] https://www.google.com/appsstatus#hl=en&v=issue&sid=1&iid=a45de3b26d6c5872f4cfe8e3424d7a82",
        "when": "2020-08-20T11:12:00Z"
      },
      {
        "created": "2020-08-20T07:11:45Z",
        "modified": "2020-08-20T07:28:24Z",
        "text": "We are experiencing an issue with Google Cloud Storage infrastructure affecting multiple products beginning at Wednesday, 2020-08-19 21:15 US/Pacific.\r\n\r\nPlease follow https://status.cloud.google.com/incident/zall/20008 for further updates. No more updates will be provided here.",
        "when": "2020-08-20T07:11:45Z"
      }
    ],
    "uri": "/incident/bigquery/20006"
  },
  {
    "begin": "2020-08-20T05:00:00Z",
    "created": "2020-08-20T07:00:06Z",
    "end": "2020-08-20T12:15:19Z",
    "external_desc": "We are experiencing issues across multiple GCP products caused by an issue",
    "modified": "2020-08-20T12:15:20Z",
    "most-recent-update": {
      "created": "2020-08-20T12:15:20Z",
      "modified": "2020-08-20T12:15:20Z",
      "text": "The issue with Cloud Storage has been resolved for all affected users as of Thursday, 2020-08-20 04:12 US/Pacific.\r\n\r\nWe will publish an analysis of this incident once we have completed our internal investigation.",
      "when": "2020-08-20T12:15:19Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "storage",
    "service_name": "Google Cloud Storage",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-08-20T12:15:20Z",
        "modified": "2020-08-20T12:15:20Z",
        "text": "The issue with Cloud Storage has been resolved for all affected users as of Thursday, 2020-08-20 04:12 US/Pacific.\r\n\r\nWe will publish an analysis of this incident once we have completed our internal investigation.",
        "when": "2020-08-20T12:15:19Z"
      },
      {
        "created": "2020-08-20T07:00:07Z",
        "modified": "2020-08-20T07:27:48Z",
        "text": "We are experiencing an issue with Google Cloud Storage infrastructure affecting multiple products beginning at Wednesday, 2020-08-19 21:15 US/Pacific.\r\n\r\nPlease follow https://status.cloud.google.com/incident/zall/20008 for further updates. No more updates will be provided here.",
        "when": "2020-08-20T07:00:07Z"
      }
    ],
    "uri": "/incident/storage/20003"
  },
  {
    "begin": "2020-07-30T15:38:32Z",
    "created": "2020-07-30T15:49:42Z",
    "end": "2020-07-30T20:17:00Z",
    "external_desc": "We are experiencing an issue with Google Compute Engine instances running RHEL and CentOS 7 and 8. Instances running RHEL and CentOS 7 and 8 that run yum update may fail to boot after restart.",
    "modified": "2020-07-30T20:17:00Z",
    "most-recent-update": {
      "created": "2020-07-30T20:17:00Z",
      "modified": "2020-07-30T20:17:00Z",
      "text": "The issue with Google Compute Engine instances running RHEL and CentOS 7 and 8 is being actively investigated by Redhat. \n\nMore details on this issue are available in the following article and bugs: \n\n- https://access.redhat.com/solutions/5272311\n- https://bugzilla.redhat.com/show_bug.cgi?id=1861977 (RHEL 8)\n- https://bugzilla.redhat.com/show_bug.cgi?id=1862045 (RHEL 7)\n- https://issuetracker.google.com/162523000\n\nPlease follow our public issue tracker posting (https://issuetracker.google.com/162523000) for updates on this issue going forward. No further updates will be provided here.",
      "when": "2020-07-30T20:17:00Z"
    },
    "number": 20009,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-30T20:17:00Z",
        "modified": "2020-07-30T20:17:00Z",
        "text": "The issue with Google Compute Engine instances running RHEL and CentOS 7 and 8 is being actively investigated by Redhat. \n\nMore details on this issue are available in the following article and bugs: \n\n- https://access.redhat.com/solutions/5272311\n- https://bugzilla.redhat.com/show_bug.cgi?id=1861977 (RHEL 8)\n- https://bugzilla.redhat.com/show_bug.cgi?id=1862045 (RHEL 7)\n- https://issuetracker.google.com/162523000\n\nPlease follow our public issue tracker posting (https://issuetracker.google.com/162523000) for updates on this issue going forward. No further updates will be provided here.",
        "when": "2020-07-30T20:17:00Z"
      },
      {
        "created": "2020-07-30T17:52:44Z",
        "modified": "2020-07-30T17:52:44Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine instances running RHEL and CentOS 7 and 8. More details on this issue are available in the following article and bugs: \n\nhttps://access.redhat.com/solutions/5272311\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1861977 (RHEL 8) https://bugzilla.redhat.com/show_bug.cgi?id=1862045 (RHEL 7)\n\nSymptoms: Instances running RHEL and CentOS 7 and 8 that run yum update may fail to boot after restart with errors messages referring to a combination of: \"X64 Exception Type - 0D(#GP - General Protection)  CPU Apic ID\", \"FXSAVE_STATE\" or \"Find image based on IP\".\n\nThis issue affects instances with specific versions of the shim package installed. To find the currently installed shim version, use the following command: `rpm -q shim-x64`\n\nAffected shim versions:\n\nCentOS 7: shim-x64-15-7.el7_9.x86_64\nCentOS 8: shim-x64-15-13.el8.x86_64\nRHEL 7: shim-x64-15-7.el7_8.x86_64\nRHEL 8: shim-x64-15-14.el8_2.x86_64\n\nWorkaround: Do not update or reboot instances running RHEL or CentOS 7 and 8. If you are on an affected shim version, run `yum downgrade shim\\* grub2\\* mokutil` to downgrade to the correct version. This command may not work on CentOS 8. If you have already rebooted, you will need to attach the disk to another instance, chroot into the disk, then run the yum downgrade command. \n\nWe will provide an update by Thursday, 2020-07-30 14:00 US/Pacific with current details.\n\nDiagnosis: Instances running RHEL and CentOS 7 and 8 that run yum update may fail to boot after restart with errors messages referring to a combination of: \"X64 Exception Type - 0D(#GP - General Protection)  CPU Apic ID\", \"FXSAVE_STATE\" or \"Find image based on IP\".\n\nThis issue affects instances with specific versions of the shim package installed. To find the currently installed shim version, use the following command: `rpm -q shim-x64`\n\nAffected shim versions:\n\nCentOS 7: shim-x64-15-7.el7_9.x86_64\nCentOS 8: shim-x64-15-13.el8.x86_64\nRHEL 7: shim-x64-15-7.el7_8.x86_64\nRHEL 8: shim-x64-15-14.el8_2.x86_64\n\nWorkaround: Do not update or reboot instances running RHEL or CentOS 7 and 8. If you are on an affected shim version, run `yum downgrade shim\\* grub2\\* mokutil` to downgrade to the correct version. This command may not work on CentOS 8. If you have already rebooted, you will need to attach the disk to another instance, chroot into the disk, then run the yum downgrade command.",
        "when": "2020-07-30T17:52:44Z"
      },
      {
        "created": "2020-07-30T16:52:16Z",
        "modified": "2020-07-30T16:52:16Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine RHEL and CentOS 7 and 8 instances.\n\nSymptoms: Instances running RHEL and CentOS 7 and 8 that run yum update may fail to boot after restart with errors messages referring to a combination of: \"X64 Exception Type - 0D(#GP - General Protection)  CPU Apic ID\", \"FXSAVE_STATE\" or \"Find image based on IP\".\n\nThis issue affects instances with specific versions of the shim package installed. To find the currently installed shim version, use the following command: `rpm -q shim-x64`\n\nAffected shim versions:\n\nCentOS 7: shim-x64-15-7.el7_9.x86_64\nCentOS 8: shim-x64-15-13.el8.x86_64\nRHEL 7: shim-x64-15-7.el7_8.x86_64\nRHEL 8: shim-x64-15-14.el8_2.x86_64\n\nWorkaround: Do not update or reboot instances running RHEL or CentOS 7 and 8. If you are on an affected shim version, run `yum downgrade shim\\* grub2\\* mokutil` to downgrade to the correct version. This command may not work on CentOS 8. If you have already rebooted, you will need to attach the disk to another instance, chroot into the disk, then run the yum downgrade command.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-07-30 11:00 US/Pacific with current details.\n\n\nDiagnosis: Instances running RHEL and CentOS 7 and 8 that run yum update may fail to boot after restart with errors messages referring to a combination of: \"X64 Exception Type - 0D(#GP - General Protection)  CPU Apic ID\", \"FXSAVE_STATE\" or \"Find image based on IP\".\n\nThis issue affects instances with specific versions of the shim package installed. To find the currently installed shim version, use the following command: `rpm -q shim-x64`\n\nAffected shim versions:\n\nCentOS 7: shim-x64-15-7.el7_9.x86_64\nCentOS 8: shim-x64-15-13.el8.x86_64\nRHEL 7: shim-x64-15-7.el7_8.x86_64\nRHEL 8: shim-x64-15-14.el8_2.x86_64\n\nWorkaround: Do not update or reboot instances running RHEL or CentOS 7 and 8. If you are on an affected shim version, run `yum downgrade shim\\* grub2\\* mokutil` to downgrade to the correct version. This command may not work on CentOS 8. If you have already rebooted, you will need to attach the disk to another instance, chroot into the disk, then run the yum downgrade command.",
        "when": "2020-07-30T16:52:16Z"
      },
      {
        "created": "2020-07-30T16:41:44Z",
        "modified": "2020-07-30T16:41:44Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine RHEL and CentOS 7 and 8 instances.\n\nSymptoms: Instances running RHEL and CentOS 7 and 8 that run yum update may fail to boot after restart. Customers should not update or reboot instances running RHEL or CentOS 7 and 8.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-07-30 10:30 US/Pacific with current details.\n\nDiagnosis: Instances running RHEL and CentOS 7 and 8 that run yum update may fail to boot after restart with errors messages referring to a combination of: \"X64 Exception Type - 0D(#GP - General Protection)  CPU Apic ID\", \"FXSAVE_STATE\" or \"Find image based on IP\".\n\nThis issue affects instances with specific versions of the shim package installed. To find the currently installed shim version, use the following command: rpm -q shim-x64\n\nAffected shim versions:\nCentOS 7: shim-x64-15-7.el7_9.x86_64\nCentOS 8: shim-x64-15-13.el8.x86_64\nRHEL 7: shim-x64-15-7.el7_8.x86_64\nRHEL 8: shim-x64-15-14.el8_2.x86_64\n\nWorkaround: Do not update or reboot instances running RHEL or CentOS 7 and 8. If you are on an affected shim version, run \"yum downgrade shim\\* grub2\\* mokutil\" to downgrade to the correct version. This command may not work on CentOS 8. If you have already rebooted, you will need to attach the disk to another instance, chroot into the disk, then run the yum downgrade command.",
        "when": "2020-07-30T16:41:44Z"
      },
      {
        "created": "2020-07-30T16:27:25Z",
        "modified": "2020-07-30T16:27:25Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine RHEL and CentOS 7 and 8 instances.\n\nSymptoms: Instances running RHEL and CentOS 7 and 8 that run yum update may fail to boot after restart. Customers should not update or reboot instances running RHEL or CentOS 7 and 8.\n\nOur engineering team continues to investigate the issue. We are also preparing instructions for recovery from this issue for affected instances.\n\nWe will provide an update by Thursday, 2020-07-30 10:15 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Instances running RHEL and CentOS 7 and 8 that run yum update may fail to boot after restart.\n\nWorkaround: Do not update or reboot instances running RHEL or CentOS 7 and 8.",
        "when": "2020-07-30T16:27:25Z"
      },
      {
        "created": "2020-07-30T15:49:44Z",
        "modified": "2020-07-30T15:49:44Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine RHEL and CentOS 7 and 8 instances.\n\nSymptoms: Instances running RHEL and CentOS 7 and 8 that run yum update may fail to boot after restart. Customers should not update or reboot instances running RHEL or CentOS 7 and 8.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-07-30 09:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Instances running RHEL and CentOS 7 and 8 that run yum update may fail to boot after restart.\n\nWorkaround: Do not update or reboot instances running RHEL or CentOS 7 and 8.",
        "when": "2020-07-30T15:49:44Z"
      }
    ],
    "uri": "/incident/compute/20009"
  },
  {
    "begin": "2020-07-29T20:17:53Z",
    "created": "2020-07-29T21:10:18Z",
    "end": "2020-07-29T20:35:13Z",
    "external_desc": "We believe the issue of connectivity loss affecting Cloud Networking in us-central1 has been resolved for all affected customers as of 13:35 US/Pacific and we are still monitoring the situation for a potential recurrence.",
    "modified": "2020-07-30T14:13:20Z",
    "most-recent-update": {
      "created": "2020-07-29T23:31:14Z",
      "modified": "2020-07-29T23:31:14Z",
      "text": "The issue with Cloud Networking has been resolved for all affected users as of Wednesday, 2020-07-29 13:35 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-29T23:31:13Z"
    },
    "number": 20008,
    "public": true,
    "service_key": "cloud-networking",
    "service_name": "Google Cloud Networking",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-29T23:31:14Z",
        "modified": "2020-07-29T23:31:14Z",
        "text": "The issue with Cloud Networking has been resolved for all affected users as of Wednesday, 2020-07-29 13:35 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-29T23:31:13Z"
      },
      {
        "created": "2020-07-29T22:47:33Z",
        "modified": "2020-07-29T22:47:33Z",
        "text": "Description: We believe the issue of connectivity loss affecting Cloud Networking in us-central1 has been resolved for all affected customers as of 13:35 US/Pacific, and we are still monitoring the situation for a potential recurrence.\n\nWe will provide an update by Wednesday, 2020-07-29 16:50 US/Pacific with current details.\n\nDiagnosis: Connectivity issues in us-central1 resulting in failures and elevated latency. \n\nWorkaround: None at this time.",
        "when": "2020-07-29T22:47:32Z"
      },
      {
        "created": "2020-07-29T21:40:44Z",
        "modified": "2020-07-29T21:40:44Z",
        "text": "Description: We believe the issue with connectivity loss affecting Cloud Networking in us-central1 was resolved for most customers at 13:35 US/Pacific and we are monitoring the situation for a potential recurrence.\n\nWe do not have an ETA for full resolution at this point.\n\nWe will provide an update by Wednesday, 2020-07-29 15:50 US/Pacific with current details.\n\nDiagnosis: Connectivity issues in us-central1\n\nWorkaround: None at this time.",
        "when": "2020-07-29T21:40:44Z"
      },
      {
        "created": "2020-07-29T21:10:18Z",
        "modified": "2020-07-29T21:10:18Z",
        "text": "Description: We are experiencing an issue with Cloud Networking beginning at Wednesday, 2020-07-29 13:17 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Wednesday, 2020-07-29 15:01 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Connectivity issues in us-central1\n\nWorkaround: None at this time.",
        "when": "2020-07-29T21:10:18Z"
      }
    ],
    "uri": "/incident/cloud-networking/20008"
  },
  {
    "begin": "2020-07-28T08:55:25Z",
    "created": "2020-07-28T09:29:00Z",
    "end": "2020-07-28T12:30:41Z",
    "external_desc": "Issue with Compute Engine API",
    "modified": "2020-07-28T12:30:42Z",
    "most-recent-update": {
      "created": "2020-07-28T12:30:42Z",
      "modified": "2020-07-28T12:30:42Z",
      "text": "The issue with Compute Engine APIs is believed to be affecting a very small fraction of requests from customer projects and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nNo further updates will be provided here.\n\nWe thank you for your patience while we're working on resolving the issue.",
      "when": "2020-07-28T12:30:41Z"
    },
    "number": 20008,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-28T12:30:42Z",
        "modified": "2020-07-28T12:30:42Z",
        "text": "The issue with Compute Engine APIs is believed to be affecting a very small fraction of requests from customer projects and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nNo further updates will be provided here.\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-07-28T12:30:41Z"
      },
      {
        "created": "2020-07-28T11:27:38Z",
        "modified": "2020-07-28T11:27:38Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\n\nThe mitigation is expected to complete by Tuesday, 2020-07-28 05:00 US/Pacific.\n\nWe will provide more information by Tuesday, 2020-07-28 05:30 US/Pacific.\n\nDiagnosis: Calls to setCommonInstanceMetadata, and some other endpoints, fail or take a long time to execute. This also a\n\nWorkaround: Customers should retry any failed operations.",
        "when": "2020-07-28T11:27:38Z"
      },
      {
        "created": "2020-07-28T10:27:03Z",
        "modified": "2020-07-28T10:27:03Z",
        "text": "Description: We've received a report of an issue with Google Compute Engine as of Tuesday, 2020-07-28 00:57 US/Pacific.\n\nAbout 20% of calls to the API endpoint setCommonInstanceMetadata are failing or taking a long time. This is commonly used by GKE which is also affected by this outage. Some other API calls may also be affected.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide more information by Tuesday, 2020-07-28 04:30 US/Pacific.\n\nWe apologize to all who are affected by the disruption.\n\n\nDiagnosis: Calls to setCommonInstanceMetadata, and some other endpoints, fail or take a long time to execute. This also a\n\nWorkaround: Customers should retry any failed operations.",
        "when": "2020-07-28T10:27:03Z"
      },
      {
        "created": "2020-07-28T09:29:02Z",
        "modified": "2020-07-28T09:29:02Z",
        "text": "Description: We've received a report of an issue with Google Compute Engine as of Tuesday, 2020-07-28 00:57 US/Pacific.\n\nAbout 20% of calls to the API endpoint setCommonInstanceMetadata are failing or taking a long time. This is commonly used by GKE which is also affected by this outage. Some other API calls may also be affected.\n\nWe will provide more information by Tuesday, 2020-07-28 03:30 US/Pacific.\n\nDiagnosis: Calls to setCommonInstanceMetadata, and some other endpoints, fail or take a long time to execute.\n\nWorkaround: Customers should retry any failed operations.",
        "when": "2020-07-28T09:29:02Z"
      }
    ],
    "uri": "/incident/compute/20008"
  },
  {
    "begin": "2020-07-23T23:02:17Z",
    "created": "2020-07-23T23:29:42Z",
    "end": "2020-07-23T23:08:00Z",
    "external_desc": "Google BigQuery is currently experiencing an elevated rate of job failures.",
    "modified": "2020-08-20T07:08:44Z",
    "most-recent-update": {
      "created": "2020-07-24T08:02:44Z",
      "modified": "2020-07-24T08:02:44Z",
      "text": "The issue with Google BigQuery experiencing an elevated rate of job failures is believed to be affecting a very small number of projects and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nWe thank you for your patience while we're working on resolving the issue.",
      "when": "2020-07-24T08:02:44Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "bigquery",
    "service_name": "Google BigQuery",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-24T08:02:44Z",
        "modified": "2020-07-24T08:02:44Z",
        "text": "The issue with Google BigQuery experiencing an elevated rate of job failures is believed to be affecting a very small number of projects and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-07-24T08:02:44Z"
      },
      {
        "created": "2020-07-24T06:28:30Z",
        "modified": "2020-07-24T06:28:30Z",
        "text": "Description: Mitigation work is making progress, and we are seeing error rates down from the peak at 1% to under 0.01%.\n\nWe are mitigating the affected projects in batch and individually. If you already have a support case open with an affected project, we will let you know individually once your project is mitigated.\n\nWe will provide more information by Friday, 2020-07-24 01:00 US/Pacific.\n\nDiagnosis: You may be affected if you notice Google BigQuery jobs failing with an \"Internal Error\" message.\n\nWorkaround: Retry the failed jobs periodically, as they will start succeeding once your project is mitigated.",
        "when": "2020-07-24T06:28:30Z"
      },
      {
        "created": "2020-07-24T05:20:07Z",
        "modified": "2020-07-24T05:20:07Z",
        "text": "Description: As the full mitigation is taking longer than we have expected, we are trying to resolve individual projects manually at the same time. If you already have a support case open with an affected project, we will let you know individually once your project is mitigated.\n\nWe will provide more information by Thursday, 2020-07-23 23:30 US/Pacific.\n\nDiagnosis: You may be affected if you notice Google BigQuery jobs failing with an \"Internal Error\" message.\n\nWorkaround: Retry the failed jobs periodically, as they will start succeeding once your project is mitigated.",
        "when": "2020-07-24T05:20:07Z"
      },
      {
        "created": "2020-07-24T04:15:40Z",
        "modified": "2020-07-24T04:15:40Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe will provide more information by Thursday, 2020-07-23 22:30 US/Pacific.\n\nDiagnosis: You may be affected if you notice Google BigQuery jobs failing with an \"Internal Error\" message.\n\nWorkaround: Retry the failed jobs periodically, as they will start succeeding once your project is mitigated.",
        "when": "2020-07-24T04:15:40Z"
      },
      {
        "created": "2020-07-24T03:21:12Z",
        "modified": "2020-07-24T03:21:12Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe are making progress in the mitigation, but it is taking longer than our initially expected timeline.\n\nWe will provide more information by Thursday, 2020-07-23 21:30 US/Pacific.\n\nDiagnosis: You may be affected if you notice Google BigQuery jobs failing with an \"Internal Error\" message.\n\nWorkaround: Retry the failed jobs periodically, as they will start succeeding once your project is mitigated.",
        "when": "2020-07-24T03:21:11Z"
      },
      {
        "created": "2020-07-24T02:39:52Z",
        "modified": "2020-07-24T02:39:52Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nThe mitigation is expected to complete by Thursday, 2020-07-23 20:30 US/Pacific.\n\nWe will provide more information by Thursday, 2020-07-23 20:45 US/Pacific.\n\nDiagnosis: You may be affected if you notice Google BigQuery jobs failing with an \"Internal Error\" message.\n\nWorkaround: Retry the failed jobs periodically, as they will start succeeding once your project is mitigated.",
        "when": "2020-07-24T02:39:52Z"
      },
      {
        "created": "2020-07-24T00:52:39Z",
        "modified": "2020-07-24T00:52:39Z",
        "text": "Description: Mitigation work is still underway by our engineering team. Affected projects are being mitigated in batches, so retrying the failed job periodically may succeed.\n\nWe will provide an update by Thursday, 2020-07-23 20:00 US/Pacific with current details.\n\nDiagnosis: You may be affected if you notice Google BigQuery jobs failing with an \"Internal Error\" message.\n\nWorkaround: Retry the failed jobs periodically, as they will start succeeding once your project is mitigated.",
        "when": "2020-07-24T00:52:39Z"
      },
      {
        "created": "2020-07-23T23:39:18Z",
        "modified": "2020-07-23T23:39:18Z",
        "text": "Description: Google BigQuery is currently experiencing an elevated rate of job failures in the US multi-region.\n\nSymptoms: Google BigQuery job failures returning an \"Internal Error\" message.\n\nMitigation is under way and our engineering team is working on it.\n\nWe will provide an update by Thursday, 2020-07-23 18:05 US/Pacific with current details.\n\nDiagnosis: You may be affected if you notice Google BigQuery jobs failing with an \"Internal Error\" message.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T23:39:18Z"
      },
      {
        "created": "2020-07-23T23:34:35Z",
        "modified": "2020-07-23T23:34:35Z",
        "text": "Description: Google BigQuery is currently experiencing an elevated rate of job failures in the US multi-region.\n\nSymptoms: Google BigQuery job failures returning an \"Internal Error\" message.\n\nMitigation is under way and our engineering team is working on it.\n\nWe will provide an update by Thursday, 2020-07-23 18:00 US/Pacific with current details.\n\nDiagnosis: You may be affected if you notice Google BigQuery jobs failing with an \"Internal Error\" message.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T23:34:34Z"
      },
      {
        "created": "2020-07-23T23:29:43Z",
        "modified": "2020-07-23T23:29:43Z",
        "text": "Description: We are experiencing an intermittent issue with some Google BigQuery jobs failing with \"Internal Error\" messages.\n\nSymptoms: Intermittent BigQuery job failure with corresponding \"Internal Error\" messages.\n\nOur engineering team continues to mitigate the issue.\n\nWe will provide an update by Thursday, 2020-07-23 17:30 US/Pacific with current details.\n\nDiagnosis: You may be affected if you notice Google BigQuery jobs failing with an \"Internal Error\" message.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T23:29:43Z"
      }
    ],
    "uri": "/incident/bigquery/20005"
  },
  {
    "begin": "2020-07-23T20:18:31Z",
    "created": "2020-07-23T20:45:30Z",
    "end": "2020-07-23T22:00:48Z",
    "external_desc": "We are experiencing an issue affecting multiple Cloud services.",
    "modified": "2020-07-23T22:00:49Z",
    "most-recent-update": {
      "created": "2020-07-23T22:00:48Z",
      "modified": "2020-07-23T22:00:48Z",
      "text": "The issue with Google Compute Engine has been resolved as of Thursday, 2020-07-23 13:50 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-23T22:00:48Z"
    },
    "number": 20007,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-23T22:00:48Z",
        "modified": "2020-07-23T22:00:48Z",
        "text": "The issue with Google Compute Engine has been resolved as of Thursday, 2020-07-23 13:50 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-23T22:00:48Z"
      },
      {
        "created": "2020-07-23T21:05:57Z",
        "modified": "2020-07-23T21:05:57Z",
        "text": "Description: We believe the issue with Google Compute Engine is partially resolved.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/zall/20006\nWhere we will provide the next update by Thursday, 2020-07-23 14:30 US/Pacific.",
        "when": "2020-07-23T21:05:57Z"
      },
      {
        "created": "2020-07-23T20:45:30Z",
        "modified": "2020-07-23T20:45:30Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine.\n\nOur engineering team continues to investigate the issue.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/zall/20006\nWhere we will provide the next update by Thursday, 2020-07-23 14:00 US/Pacific.",
        "when": "2020-07-23T20:45:30Z"
      }
    ],
    "uri": "/incident/compute/20007"
  },
  {
    "begin": "2020-07-23T20:17:21Z",
    "created": "2020-07-23T20:35:32Z",
    "end": "2020-07-23T22:11:35Z",
    "external_desc": "We are experiencing an issue with Cloud Monitoring.",
    "modified": "2020-07-23T22:11:35Z",
    "most-recent-update": {
      "created": "2020-07-23T22:11:35Z",
      "modified": "2020-07-23T22:11:35Z",
      "text": "The issue with Cloud Monitoring has been resolved for all affected projects as of Thursday, 2020-07-23 13:43 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-23T22:11:35Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "google-stackdriver",
    "service_name": "Operations",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-23T22:11:35Z",
        "modified": "2020-07-23T22:11:35Z",
        "text": "The issue with Cloud Monitoring has been resolved for all affected projects as of Thursday, 2020-07-23 13:43 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-23T22:11:35Z"
      },
      {
        "created": "2020-07-23T21:27:36Z",
        "modified": "2020-07-23T21:27:36Z",
        "text": "Description: We believe the issue with Cloud Monitoring has been mitigated.\n\nWe are currently monitoring the situation for any potential recurrences.\n\nWe believe this issue is related to an ongoing incident with Google Cloud Infrastructure Components. For regular status updates, please follow: https://status.cloud.google.com/incident/zall/20006\n\n\nDiagnosis: Elevated latency and error rates.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T21:27:36Z"
      },
      {
        "created": "2020-07-23T20:35:32Z",
        "modified": "2020-07-23T20:35:32Z",
        "text": "Description: We are experiencing an issue with Cloud Monitoring.\n\nWe believe this issue is related to an ongoing incident with Google Cloud Infrastructure Components. For regular status updates, please follow: https://status.cloud.google.com/incident/zall/20006\n\nDiagnosis: Elevated latency and error rates.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T20:35:32Z"
      }
    ],
    "uri": "/incident/google-stackdriver/20005"
  },
  {
    "begin": "2020-07-23T20:11:13Z",
    "created": "2020-07-23T20:15:49Z",
    "end": "2020-07-23T22:42:49Z",
    "external_desc": "We were experiencing an issue affecting multiple Cloud services.",
    "modified": "2020-07-23T22:42:49Z",
    "most-recent-update": {
      "created": "2020-07-23T22:42:49Z",
      "modified": "2020-07-23T22:42:49Z",
      "text": "The issue with multiple Cloud services has been resolved for all affected users as of Thursday, 2020-07-23 13:50 US/Pacific.\n\nThe following services were affected: \n- Cloud Dialogflow \n- Cloud Support Phone Calls\n- Cloud Networking L7 Load Balancers\n- Cloud Monitoring\n- Google App Engine Flexible\n- Compute Engine\n- Google BigQuery\n- Cloud Storage\n\nIf you have questions or feel that you may still be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. No further updates will be provided here.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-23T22:42:49Z"
    },
    "number": 20006,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-23T22:42:49Z",
        "modified": "2020-07-23T22:42:49Z",
        "text": "The issue with multiple Cloud services has been resolved for all affected users as of Thursday, 2020-07-23 13:50 US/Pacific.\n\nThe following services were affected: \n- Cloud Dialogflow \n- Cloud Support Phone Calls\n- Cloud Networking L7 Load Balancers\n- Cloud Monitoring\n- Google App Engine Flexible\n- Compute Engine\n- Google BigQuery\n- Cloud Storage\n\nIf you have questions or feel that you may still be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. No further updates will be provided here.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-23T22:42:49Z"
      },
      {
        "created": "2020-07-23T22:08:36Z",
        "modified": "2020-07-23T22:08:36Z",
        "text": "Description: The issue with multiple Cloud services beginning at Thursday 2020-07-23 11:45 US/Pacific has been partially resolved for most affected users as of Thursday, 2020-07-23 13:50 US/Pacific.\n\nWe thank you for your patience while we work on resolving the issue.\n\nThe following services were affected: \n- Cloud Dialogflow \n- Cloud Support Phone Calls\n- Cloud Networking L7 Load Balancers\n- Cloud Monitoring\n- Google App Engine Flex\n- Compute Engine\n- Google BigQuery\n- Google Cloud Storage\n\nWe will provide an update by Thursday, 2020-07-23 15:45 US/Pacific with current details.\n\nDiagnosis: Customers may see increased error rates and latency with Cloud services.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T22:08:36Z"
      },
      {
        "created": "2020-07-23T21:31:24Z",
        "modified": "2020-07-23T21:31:24Z",
        "text": "Description: We were experiencing an issue with multiple Cloud services beginning at around Thursday, 2020-07-23 11:45 US/Pacific. \n\nMitigation has been put in place with most services having recovered. We are currently monitoring the recently mitigated services for potential recurrences of the issue.\n\nWe believe the issue is partially resolved for the following Cloud services: \n- Cloud Dialogflow \n- Cloud Support Phone Calls\n- Cloud Networking L7 Load Balancers\n- Cloud Monitoring\n- Google App Engine Flex\n- Compute Engine\n- Google BigQuery\n\nWe will provide an update by Thursday, 2020-07-23 15:00 US/Pacific with current details.\n\nDiagnosis: Customers may see increased error rates and latency with Cloud services.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T21:31:24Z"
      },
      {
        "created": "2020-07-23T21:01:17Z",
        "modified": "2020-07-23T21:01:17Z",
        "text": "Description: We are experiencing an issue affecting multiple Cloud services including: Compute Engine, Cloud Networking L7 Load Balancers, and Cloud Monitoring, beginning at around Thursday, 2020-07-23 11:45 US/Pacific US/Pacific. \n\nMitigation work continues with our engineering teams, with some services starting to recover.\n\nWe believe the issue is currently mitigated for the following Cloud services: \n- Cloud Dialogflow \n- Cloud Support Phone Calls\n- Google App Engine - Flexible\n\nWe will provide an update by Thursday, 2020-07-23 14:30 US/Pacific with current details.\n\nDiagnosis: Customers may see increased error rates and latency with Cloud services.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T21:01:17Z"
      },
      {
        "created": "2020-07-23T20:34:28Z",
        "modified": "2020-07-23T20:34:28Z",
        "text": "Description: We are experiencing an issue affecting multiple Cloud services, beginning at around Thursday, 2020-07-23 12:00 US/Pacific US/Pacific. \n\nMitigation work is currently underway by our engineering teams.\n\nWe will provide an update by Thursday, 2020-07-23 14:00 US/Pacific with current details.\n\nDiagnosis: Customers may see increased error rates and latency with Cloud services.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T20:34:28Z"
      },
      {
        "created": "2020-07-23T20:15:51Z",
        "modified": "2020-07-23T20:15:51Z",
        "text": "Description: We are currently investigating an issue affecting multiple Cloud services, beginning at around Thursday, 2020-07-23 12:00 US/Pacific US/Pacific.\n\nOur engineering team is investigating the issue.\n\nWe will provide an update by Thursday, 2020-07-23 14:00 US/Pacific with current details.",
        "when": "2020-07-23T20:15:51Z"
      }
    ],
    "uri": "/incident/zall/20006"
  },
  {
    "begin": "2020-07-23T20:03:51Z",
    "created": "2020-07-23T20:38:15Z",
    "end": "2020-07-23T22:01:54Z",
    "external_desc": "We are experiencing an issue affecting multiple Cloud services.",
    "modified": "2020-07-23T22:01:54Z",
    "most-recent-update": {
      "created": "2020-07-23T22:01:54Z",
      "modified": "2020-07-23T22:01:54Z",
      "text": "The issue with Google App Engine has been resolved as of Thursday, 2020-07-23 13:50 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-23T22:01:54Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "appengine",
    "service_name": "Google App Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-23T22:01:54Z",
        "modified": "2020-07-23T22:01:54Z",
        "text": "The issue with Google App Engine has been resolved as of Thursday, 2020-07-23 13:50 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-23T22:01:54Z"
      },
      {
        "created": "2020-07-23T21:02:28Z",
        "modified": "2020-07-23T21:02:28Z",
        "text": "Description: We believe the issue with Google App Engine is partially resolved.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/zall/20006\n\nWhere we will provide an update by Thursday, 2020-07-23 14:30 US/Pacific with current details.",
        "when": "2020-07-23T21:02:28Z"
      },
      {
        "created": "2020-07-23T20:38:16Z",
        "modified": "2020-07-23T20:38:16Z",
        "text": "Description: We are experiencing an issue affecting multiple Cloud services including Google App Engine, beginning at around Thursday, 2020-07-23 12:00 US/Pacific US/Pacific. \n\nMitigation work is currently underway by our engineering teams.\n\nWe will provide an update by Thursday, 2020-07-23 14:00 US/Pacific with current details.",
        "when": "2020-07-23T20:38:16Z"
      }
    ],
    "uri": "/incident/appengine/20004"
  },
  {
    "begin": "2020-07-23T19:16:43Z",
    "created": "2020-07-23T20:44:44Z",
    "end": "2020-07-23T22:11:09Z",
    "external_desc": "Cloud Networking L7 Load Balancers May Be Serving Stale Configurations",
    "modified": "2020-07-23T22:11:09Z",
    "most-recent-update": {
      "created": "2020-07-23T22:11:09Z",
      "modified": "2020-07-23T22:11:09Z",
      "text": "The issue with Cloud Networking has been resolved for all affected users as of Thursday, 2020-07-23 13:42 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-23T22:11:09Z"
    },
    "number": 20007,
    "public": true,
    "service_key": "cloud-networking",
    "service_name": "Google Cloud Networking",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-23T22:11:09Z",
        "modified": "2020-07-23T22:11:09Z",
        "text": "The issue with Cloud Networking has been resolved for all affected users as of Thursday, 2020-07-23 13:42 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-23T22:11:09Z"
      },
      {
        "created": "2020-07-23T21:09:01Z",
        "modified": "2020-07-23T21:09:01Z",
        "text": "Description: We believe the issue with Cloud Networking L7 Load Balancers (Internal HTTP(S) Load Balancers), where changes made to these load balancers are not being applied beginning at Thursday, 2020-07-23 11:45 US/Pacific is partially resolved.\n\nWe do not have an ETA for full resolution at this point.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/zall/20006\n\nDiagnosis: Changes made to Cloud Networking L7 Load Balancers (Internal HTTP(S) Load Balancers) may not be deployed.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T21:09:01Z"
      },
      {
        "created": "2020-07-23T20:48:02Z",
        "modified": "2020-07-23T20:48:02Z",
        "text": "Description: We believe the issue with Cloud Networking L7 Load Balancers (Internal HTTP(S) Load Balancers), where changes made to these load balancers are not being applied beginning at Thursday, 2020-07-23 11:45 US/Pacific is partially resolved.\n\nWe do not have an ETA for full resolution at this point.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/zall/20006\nWhere we will provide the next update by Thursday, 2020-07-23 14:00 US/Pacific.\n\nDiagnosis: Changes made to Cloud Networking L7 Load Balancers (Internal HTTP(S) Load Balancers) may not be deployed.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T20:48:02Z"
      },
      {
        "created": "2020-07-23T20:44:44Z",
        "modified": "2020-07-23T20:44:44Z",
        "text": "Description: We are experiencing an issue with Cloud Networking L7 Load Balancers (Internal HTTP(S) Load Balancers), where changes made to these load balancers are not being applied beginning at Thursday, 2020-07-23 11:45 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/zall/20006\nWhere we will provide the next update by Thursday, 2020-07-23 14:00 US/Pacific.\n\nDiagnosis: Changes made to Cloud Networking L7 Load Balancers (Internal HTTP(S) Load Balancers) may not be deployed.\n\nWorkaround: None at this time.",
        "when": "2020-07-23T20:44:44Z"
      }
    ],
    "uri": "/incident/cloud-networking/20007"
  },
  {
    "begin": "2020-07-23T18:45:00Z",
    "created": "2020-07-23T22:04:09Z",
    "end": "2020-07-23T20:50:00Z",
    "external_desc": "BigQuery is Experiencing Elevated Latencies and Error Rates",
    "modified": "2020-07-23T22:08:04Z",
    "most-recent-update": {
      "created": "2020-07-23T22:04:10Z",
      "modified": "2020-07-23T22:04:10Z",
      "text": "We are investigating an issue with Google BigQuery where requests are experiencing elevated latencies and error rates affecting Jobs and queries.\r\n\r\nWe believe this issue has been fully mitigated and is no longer affecting Jobs and queries.\r\n\r\nFor regular status updates, please follow: https://status.cloud.google.com/incident/zall/20006",
      "when": "2020-07-23T22:04:10Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "bigquery",
    "service_name": "Google BigQuery",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-23T22:04:10Z",
        "modified": "2020-07-23T22:04:10Z",
        "text": "We are investigating an issue with Google BigQuery where requests are experiencing elevated latencies and error rates affecting Jobs and queries.\r\n\r\nWe believe this issue has been fully mitigated and is no longer affecting Jobs and queries.\r\n\r\nFor regular status updates, please follow: https://status.cloud.google.com/incident/zall/20006",
        "when": "2020-07-23T22:04:10Z"
      }
    ],
    "uri": "/incident/bigquery/20004"
  },
  {
    "begin": "2020-07-22T07:33:36Z",
    "created": "2020-07-22T07:33:43Z",
    "end": "2020-07-22T09:05:51Z",
    "external_desc": "We're experiencing an issue with Google Cloud Support system",
    "modified": "2020-07-22T09:05:52Z",
    "most-recent-update": {
      "created": "2020-07-22T09:05:51Z",
      "modified": "2020-07-22T09:05:51Z",
      "text": "The issue with Google Cloud Support is believed to be resolved for all affected users as of Wednesday, 2020-07-22 02:04 US/Pacific. We will still monitor the situation and update you if anything changes.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-22T09:05:51Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "support",
    "service_name": "Google Cloud Support",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-22T09:05:51Z",
        "modified": "2020-07-22T09:05:51Z",
        "text": "The issue with Google Cloud Support is believed to be resolved for all affected users as of Wednesday, 2020-07-22 02:04 US/Pacific. We will still monitor the situation and update you if anything changes.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-22T09:05:51Z"
      },
      {
        "created": "2020-07-22T08:16:15Z",
        "modified": "2020-07-22T08:16:15Z",
        "text": "Description: We are experiencing an  issue with Google Cloud Support, beginning at Wednesday, 2020-07-21 22:00 US/Pacific.\n\nSymptoms: Users are unable to create new support cases. Google Cloud Support Center is also affected.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Wednesday, 2020-07-22 03:30 US/Pacific with current details.\n\nDiagnosis: None at this time\n\nWorkaround: Customers may continue to file cases using a Web form: https://support.google.com/cloud/contact/prod_issue",
        "when": "2020-07-22T08:16:15Z"
      },
      {
        "created": "2020-07-22T07:33:44Z",
        "modified": "2020-07-22T07:33:44Z",
        "text": "Description: We are experiencing an  issue with Google Cloud Support, beginning at Wednesday, 2020-07-21 22:00 US/Pacific.\n\nSymptoms: Users are unable to create new support cases.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Wednesday, 2020-07-22 01:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: None at this time\n\nWorkaround: Customers may continue to file cases using a Web form: https://support.google.com/cloud/contact/prod_issue",
        "when": "2020-07-22T07:33:44Z"
      }
    ],
    "uri": "/incident/support/20002"
  },
  {
    "begin": "2020-07-21T09:34:00Z",
    "created": "2020-07-21T18:29:12Z",
    "end": "2020-07-21T10:53:00Z",
    "external_desc": "Customers May be Unable to Create Support Cases via the Cloud Console",
    "modified": "2020-07-21T18:29:12Z",
    "most-recent-update": {
      "created": "2020-07-21T18:29:12Z",
      "modified": "2020-07-21T18:29:12Z",
      "text": "We had experienced an issue with Google Support systems, from Tuesday, 2020-07-21 09:34 US/Pacific to Tuesday, 07/21/2020 10:53 US/Pacific, preventing customers from creating or updating Support cases. Cloud Console pages that are nested under https://console.cloud.google.com/support may have also failed to load or update.\r\n\r\nWe believe this issue is mitigated for all users at this time. If you believe you are still impacted by this issue, email and phone Support channels remain functional.\r\n\r\nWe apologize to all who were affected by the disruption.",
      "when": "2020-07-21T18:29:12Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "support",
    "service_name": "Google Cloud Support",
    "severity": "high",
    "updates": [
      {
        "created": "2020-07-21T18:29:12Z",
        "modified": "2020-07-21T18:29:12Z",
        "text": "We had experienced an issue with Google Support systems, from Tuesday, 2020-07-21 09:34 US/Pacific to Tuesday, 07/21/2020 10:53 US/Pacific, preventing customers from creating or updating Support cases. Cloud Console pages that are nested under https://console.cloud.google.com/support may have also failed to load or update.\r\n\r\nWe believe this issue is mitigated for all users at this time. If you believe you are still impacted by this issue, email and phone Support channels remain functional.\r\n\r\nWe apologize to all who were affected by the disruption.",
        "when": "2020-07-21T18:29:12Z"
      }
    ],
    "uri": "/incident/support/20001"
  },
  {
    "begin": "2020-07-15T15:04:26Z",
    "created": "2020-07-15T15:04:27Z",
    "end": "2020-07-15T16:35:58Z",
    "external_desc": "New Dataproc Deployments May Time Out and Fail",
    "modified": "2020-07-15T16:35:58Z",
    "most-recent-update": {
      "created": "2020-07-15T16:35:58Z",
      "modified": "2020-07-15T16:35:58Z",
      "text": "The issue with Cloud Dataproc deployment errors has been resolved for all affected users as of Wednesday, 2020-07-15 09:33 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-15T16:35:58Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "cloud-dataproc",
    "service_name": "Google Cloud Dataproc",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-15T16:35:58Z",
        "modified": "2020-07-15T16:35:58Z",
        "text": "The issue with Cloud Dataproc deployment errors has been resolved for all affected users as of Wednesday, 2020-07-15 09:33 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-15T16:35:58Z"
      },
      {
        "created": "2020-07-15T15:24:27Z",
        "modified": "2020-07-15T15:24:27Z",
        "text": "Description: We are experiencing an issue where deployments to Google Cloud Dataproc are seeing elevated errors and may fail intermittently, beginning at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006 where we will provide the next update by Wednesday, 2020-07-15 10:30 US/Pacific.\n\nDiagnosis: New deployments may time out and fail.\n\nWorkaround: Retry the deployment.",
        "when": "2020-07-15T15:24:26Z"
      },
      {
        "created": "2020-07-15T15:13:02Z",
        "modified": "2020-07-15T15:13:02Z",
        "text": "Description: We are experiencing an issue where deployments to Google Cloud Dataproc are seeing elevated errors and may fail intermittently, beginning at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006 where we will provide the next update by Wednesday, 2020-07-15 08:55 US/Pacific.\n\nDiagnosis: New deployments may time out and fail.\n\nWorkaround: Retry the deployment.",
        "when": "2020-07-15T15:13:02Z"
      },
      {
        "created": "2020-07-15T15:04:28Z",
        "modified": "2020-07-15T15:04:28Z",
        "text": "Description: We are experiencing an issue where deployments to Google Cloud Dataproc are seeing elevated errors and may fail intermittently, beginning at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006 where we will provide the next update by Wednesday, 2020-07-15 08:20 US/Pacific.\n\nDiagnosis: New deployments may time out and fail.\n\nWorkaround: Retry the deployment.",
        "when": "2020-07-15T15:04:28Z"
      }
    ],
    "uri": "/incident/cloud-dataproc/20004"
  },
  {
    "begin": "2020-07-15T14:51:23Z",
    "created": "2020-07-15T14:51:25Z",
    "end": "2020-07-15T15:51:48Z",
    "external_desc": "New App Engine Deployments May Time Out and Fail",
    "modified": "2020-07-15T15:51:48Z",
    "most-recent-update": {
      "created": "2020-07-15T15:51:48Z",
      "modified": "2020-07-15T15:51:48Z",
      "text": "The issue with new deployments to Google App Engine has been resolved for all affected users as of Wednesday, 2020-07-15 08:50 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-15T15:51:48Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "appengine",
    "service_name": "Google App Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-15T15:51:48Z",
        "modified": "2020-07-15T15:51:48Z",
        "text": "The issue with new deployments to Google App Engine has been resolved for all affected users as of Wednesday, 2020-07-15 08:50 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-15T15:51:48Z"
      },
      {
        "created": "2020-07-15T14:51:26Z",
        "modified": "2020-07-15T14:51:26Z",
        "text": "Description: We are experiencing an issue where deployments to Google App Engine are seeing elevated errors and may fail intermittently, beginning at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006 where we will provide the next update by Wednesday, 2020-07-15 08:20 US/Pacific.\n\nDiagnosis: New deployments may time out and fail.\n\nWorkaround: Retry the deployment.",
        "when": "2020-07-15T14:51:26Z"
      }
    ],
    "uri": "/incident/appengine/20003"
  },
  {
    "begin": "2020-07-15T14:44:55Z",
    "created": "2020-07-15T15:00:13Z",
    "end": "2020-07-15T16:01:35Z",
    "external_desc": "Cloud Data Fusion Deployments May Time Out and Fail",
    "modified": "2020-07-15T16:01:35Z",
    "most-recent-update": {
      "created": "2020-07-15T16:01:35Z",
      "modified": "2020-07-15T16:01:35Z",
      "text": "The issue with Cloud Data Fusion deployments errors has been resolved for all affected users as of Wednesday, 2020-07-15 08:58 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-15T16:01:35Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "cloud-data-fusion",
    "service_name": "Cloud Data Fusion",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-15T16:01:35Z",
        "modified": "2020-07-15T16:01:35Z",
        "text": "The issue with Cloud Data Fusion deployments errors has been resolved for all affected users as of Wednesday, 2020-07-15 08:58 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-15T16:01:35Z"
      },
      {
        "created": "2020-07-15T15:40:31Z",
        "modified": "2020-07-15T15:40:31Z",
        "text": "Description: We are experiencing an issue where deployments to Cloud Data Fusion are seeing elevated errors and may fail intermittently, beginning at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006 where we will provide the next update by Wednesday, 2020-07-15 10:45 US/Pacific.\n\nDiagnosis: New deployments may time out and fail.\n\nWorkaround: Retry the deployment.",
        "when": "2020-07-15T15:40:31Z"
      },
      {
        "created": "2020-07-15T15:12:18Z",
        "modified": "2020-07-15T15:12:18Z",
        "text": "Description: We are experiencing an issue where deployments to Cloud Data Fusion are seeing elevated errors and may fail intermittently, beginning at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006 where we will provide the next update by Wednesday, 2020-07-15 08:45 US/Pacific.\n\nDiagnosis: New deployments may time out and fail.\n\nWorkaround: Retry the deployment.",
        "when": "2020-07-15T15:12:18Z"
      },
      {
        "created": "2020-07-15T15:00:14Z",
        "modified": "2020-07-15T15:00:14Z",
        "text": "Description: We are experiencing an issue where deployments to Cloud Data Fusion are seeing elevated errors and may fail intermittently, beginning at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006 where we will provide the next update by Wednesday, 2020-07-15 08:20 US/Pacific.\n\nDiagnosis: New deployments may time out and fail.\n\nWorkaround: Retry the deployment.",
        "when": "2020-07-15T15:00:14Z"
      }
    ],
    "uri": "/incident/cloud-data-fusion/20003"
  },
  {
    "begin": "2020-07-15T13:54:32Z",
    "created": "2020-07-15T14:28:52Z",
    "end": "2020-07-15T15:57:56Z",
    "external_desc": "GKE Operations which Create or Delete VMs May Fail or Experience Elevated Latencies",
    "modified": "2020-07-15T15:57:56Z",
    "most-recent-update": {
      "created": "2020-07-15T15:57:56Z",
      "modified": "2020-07-15T15:57:56Z",
      "text": "The issue with operations which create or delete VMs using Google Kubernetes Engine has been resolved for all affected users as of Wednesday, 2020-07-15 08:55 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-15T15:57:56Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-15T15:57:56Z",
        "modified": "2020-07-15T15:57:56Z",
        "text": "The issue with operations which create or delete VMs using Google Kubernetes Engine has been resolved for all affected users as of Wednesday, 2020-07-15 08:55 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-15T15:57:56Z"
      },
      {
        "created": "2020-07-15T15:26:37Z",
        "modified": "2020-07-15T15:26:37Z",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine beginning at Wednesday, 2020-07-15 05:10 US/Pacific.\n\nAll GKE operations that create or delete VMs (including creating clusters and adding nodepools)  may fail or see elevated errors and latencies. This affects multiple regions, primarily regional and zonal clusters in us-central1.\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\nCluster auto upgrades are currently paused.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006\n\nDiagnosis: All GKE operations that create or delete VMs (including creating clusters and adding nodepools)  may fail or see elevated errors and latencies. This affects multiple regions, primarily regional and zonal clusters in us-central1.\n\nWorkaround: Retry the deployment.",
        "when": "2020-07-15T15:26:37Z"
      },
      {
        "created": "2020-07-15T15:25:47Z",
        "modified": "2020-07-15T15:25:47Z",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine beginning at Wednesday, 2020-07-15 05:10 US/Pacific.\n\nAll GKE operations that create or delete VMs (including creating clusters and adding nodepools)  may fail or see elevated errors. This affects multiple regions, primarily regional and zonal clusters in us-central1.\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\nCluster auto upgrades are currently paused.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006\n\nDiagnosis: All GKE operations that create or delete VMs (including creating clusters and adding nodepools)  may fail or see elevated errors. This affects multiple regions, primarily regional clusters in us-central1 and zonal clusters in us-central1-a, b, c, and d.\n\nWorkaround: Retry the deployment.",
        "when": "2020-07-15T15:25:47Z"
      },
      {
        "created": "2020-07-15T15:23:24Z",
        "modified": "2020-07-15T15:23:24Z",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine beginning at Wednesday, 2020-07-15 05:10 US/Pacific.\n\nAll GKE operations that create or delete VMs (including creating clusters and adding nodepools)  may fail or see elevated errors. This affects regional clusters in us-central1 and europe-west1 and zonal clusters in us-central1-a, b, c, and d.\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\nCluster auto upgrades are currently paused.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006",
        "when": "2020-07-15T15:23:24Z"
      },
      {
        "created": "2020-07-15T14:53:29Z",
        "modified": "2020-07-15T14:53:29Z",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine beginning at Wednesday, 2020-07-15 05:10 US/Pacific.\n\nAll GKE operations that create or delete VMs (including creating clusters and adding nodepools)  may fail or see elevated errors. This affects regional clusters in us-central1 and europe-west1 and zonal clusters in us-central1-a, b, c, and d.\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006 where we will provide the next update by Wednesday, 2020-07-15 08:20 US/Pacific.",
        "when": "2020-07-15T14:53:29Z"
      },
      {
        "created": "2020-07-15T14:28:52Z",
        "modified": "2020-07-15T14:28:52Z",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine beginning at Wednesday, 2020-07-15 05:10 US/Pacific.\n\nAll GKE operations that create or delete VMs (including creating clusters and adding nodepools)  may fail or see elevated errors. This affects regional clusters in us-central1 and europe-west1 and zonal clusters in us-central1-a, b, c, and d.\n\nOur engineering team continues to investigate the issue.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006 where we will provide the next update by Wednesday, 2020-07-15 08:00 US/Pacific.",
        "when": "2020-07-15T14:28:52Z"
      }
    ],
    "uri": "/incident/container-engine/20004"
  },
  {
    "begin": "2020-07-15T12:37:12Z",
    "created": "2020-07-15T14:52:48Z",
    "end": "2020-07-15T15:54:24Z",
    "external_desc": "New Cloud Function Deployments May Time Out and Fail",
    "modified": "2020-07-15T15:54:24Z",
    "most-recent-update": {
      "created": "2020-07-15T15:54:24Z",
      "modified": "2020-07-15T15:54:24Z",
      "text": "The issue with new deployments to Google Cloud Functions has been resolved for all affected users as of Wednesday, 2020-07-15 08:50 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
      "when": "2020-07-15T15:54:24Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "cloud-functions",
    "service_name": "Google Cloud Functions",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-15T15:54:24Z",
        "modified": "2020-07-15T15:54:24Z",
        "text": "The issue with new deployments to Google Cloud Functions has been resolved for all affected users as of Wednesday, 2020-07-15 08:50 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-15T15:54:24Z"
      },
      {
        "created": "2020-07-15T14:52:49Z",
        "modified": "2020-07-15T14:52:49Z",
        "text": "Description: We are experiencing an issue where deployments to Google Cloud Functions are seeing elevated errors and may fail intermittently, beginning at Wednesday, 2020-07-15 05:07 US/Pacific. (For those affected by App Engine, we have moved App Engine to its own thread, see: https://status.cloud.google.com/incident/appengine/20003).\n\nMitigation work is underway by our engineering team. There is no ETA at this point.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/compute/20006 where we will provide the next update by Wednesday, 2020-07-15 08:20 US/Pacific.\n\nDiagnosis: New deployments may time out and fail.\n\nWorkaround: Retry the deployment.",
        "when": "2020-07-15T14:52:48Z"
      }
    ],
    "uri": "/incident/cloud-functions/20004"
  },
  {
    "begin": "2020-07-15T05:34:37Z",
    "created": "2020-07-15T13:11:48Z",
    "end": "2020-07-15T09:14:33Z",
    "external_desc": "Issue creating and deleting Compute Engine instances",
    "modified": "2020-07-16T01:01:21Z",
    "most-recent-update": {
      "created": "2020-07-16T01:00:58Z",
      "modified": "2020-07-16T01:00:58Z",
      "text": "Initially, we believed that this incident affected all instance create and delete operations, which was inaccurate. Approximately 2% of requests globally were failing and the issue was transient, allowing retried operations to succeed. \r\n\r\nAll existing instances continued to operate as expected, with only create or delete operations being affected. Upon evaluation of Google’s incident scope and severity, this incident’s severity has been adjusted from Outage to Disruption.",
      "when": "2020-07-16T01:00:58Z"
    },
    "number": 20006,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-16T01:00:58Z",
        "modified": "2020-07-16T01:00:58Z",
        "text": "Initially, we believed that this incident affected all instance create and delete operations, which was inaccurate. Approximately 2% of requests globally were failing and the issue was transient, allowing retried operations to succeed. \r\n\r\nAll existing instances continued to operate as expected, with only create or delete operations being affected. Upon evaluation of Google’s incident scope and severity, this incident’s severity has been adjusted from Outage to Disruption.",
        "when": "2020-07-16T01:00:58Z"
      },
      {
        "created": "2020-07-15T16:14:33Z",
        "modified": "2020-07-15T16:14:33Z",
        "text": "The issue with creating and deleting Google Compute Engine instances has been resolved for all affected projects as of Wednesday, 2020-07-15 08:56 US/Pacific.\n\nWe thank you for your patience while we worked on resolving the issue.",
        "when": "2020-07-15T16:14:33Z"
      },
      {
        "created": "2020-07-15T16:10:54Z",
        "modified": "2020-07-15T16:10:54Z",
        "text": "Description: We are experiencing an issue creating and deleting Google Compute Engine instances, starting at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nThis is also affecting other products which rely on Compute Engine including Cloud Build, which is in turn used by services including App Engine and Cloud Functions. Other products affected are Cloud Data Fusion, Cloud Dataproc, Cloud Dataflow, and Google Kubernetes Engine. As well, instances created may experience DNS propagation delays.\n\nCurrent data indicates that approximately 2% of requests globally are affected by this issue.\n\nMitigation work has been completed by our engineering team and we are monitoring recovery.\n\nFull resolution is expected to complete by Wednesday, 2020-07-15 09:05 US/Pacific.\n\nWe will provide an update by Wednesday, 2020-07-15 09:20 US/Pacific with current details.\n\n\nDiagnosis: Attempts to create a new instance or to delete an instance fail with an error.\n\nWorkaround: Retrying the instance operation may succeed.",
        "when": "2020-07-15T16:10:54Z"
      },
      {
        "created": "2020-07-15T15:50:31Z",
        "modified": "2020-07-15T15:50:31Z",
        "text": "Description: We are experiencing an issue creating and deleting Google Compute Engine instances, starting at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nThis is also affecting other products which rely on Compute Engine including Cloud Build, which is in turn used by services including App Engine and Cloud Functions. Other products affected are Cloud Data Fusion, Cloud Dataproc, Cloud Dataflow, and Google Kubernetes Engine.\n\nCurrent data indicates that approximately 2% of requests globally are affected by this issue.\n\nMitigation work has been completed by our engineering team and we are monitoring recovery.\n\nFull resolution is expected to complete by Wednesday, 2020-07-15 09:05 US/Pacific.\n\nWe will provide an update by Wednesday, 2020-07-15 09:15 US/Pacific with current details.\n\n\nDiagnosis: Attempts to create a new instance or to delete an instance fail with an error.\n\nWorkaround: Retrying the instance operation may succeed.",
        "when": "2020-07-15T15:50:31Z"
      },
      {
        "created": "2020-07-15T15:11:30Z",
        "modified": "2020-07-15T15:11:30Z",
        "text": "Description: We are experiencing an issue creating and deleting Google Compute Engine instances, starting at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nThis is also affecting other products which rely on Compute Engine including Cloud Build, which is in turn used by services including App Engine and Cloud Functions. Other products affected are Cloud Data Fusion, Cloud Dataproc, and Google Kubernetes Engine.\n\nMitigation work is still underway by our engineering team.\n\nCurrent data indicates that approximately 2% of requests globally are affected by this issue.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide an update by Wednesday, 2020-07-15 09:00 US/Pacific with current details.\n\nDiagnosis: Attempts to create a new instance or to delete an instance fail with an error.\n\nWorkaround: Retrying the instance operation may succeed.",
        "when": "2020-07-15T15:11:30Z"
      },
      {
        "created": "2020-07-15T14:48:10Z",
        "modified": "2020-07-15T14:48:10Z",
        "text": "Description: We are experiencing an issue creating and deleting Google Compute Engine instances, starting at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nThis is also affecting other products which rely on Compute Engine including Cloud Build, which is in turn used by services including App Engine and Cloud Functions.\n\nMitigation work is currently underway by our engineering team.\n\nWe do not have an ETA for mitigation at this point.\n\nWe will provide an update by Wednesday, 2020-07-15 08:20 US/Pacific with current details.\n\nDiagnosis: Attempts to create a new instance or to delete an instance fail with an error.\n\nWorkaround: Retrying the instance operation may succeed.",
        "when": "2020-07-15T14:48:10Z"
      },
      {
        "created": "2020-07-15T13:59:39Z",
        "modified": "2020-07-15T13:59:39Z",
        "text": "Description: We are experiencing an issue creating and deleting Google Compute Engine instances, starting at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nThis is also affecting other products which rely on Compute Engine including Cloud Build, which is in turn used by services including App Engine and Cloud Functions.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Wednesday, 2020-07-15 08:00 US/Pacific with current details.\n\nDiagnosis: Attempts to create a new instance or to delete an instance fail with an error.\n\nWorkaround: None at this time.",
        "when": "2020-07-15T13:59:39Z"
      },
      {
        "created": "2020-07-15T13:11:50Z",
        "modified": "2020-07-15T13:11:50Z",
        "text": "Description: We are experiencing an issue creating new instances with Google Compute Engine, starting at Wednesday, 2020-07-15 05:07 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Wednesday, 2020-07-15 07:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Attempts to create a new instance fail with an error.\n\nWorkaround: None at this time.",
        "when": "2020-07-15T13:11:50Z"
      }
    ],
    "uri": "/incident/compute/20006"
  },
  {
    "begin": "2020-07-02T15:39:19Z",
    "created": "2020-07-02T15:57:54Z",
    "end": "2020-07-02T16:36:59Z",
    "external_desc": "We are experiencing issues with creation of new Google Cloud Load Balancers and updates to existing ones.",
    "modified": "2020-07-02T16:36:59Z",
    "most-recent-update": {
      "created": "2020-07-02T16:36:59Z",
      "modified": "2020-07-02T16:36:59Z",
      "text": "The issue with Google Cloud Load Balancer has been resolved for all affected users as of Thursday, 2020-07-02 09:36 US/Pacific.\n\nWe thank you for your patience while we're working on resolving the issue.",
      "when": "2020-07-02T16:36:59Z"
    },
    "number": 20006,
    "public": true,
    "service_key": "cloud-networking",
    "service_name": "Google Cloud Networking",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-02T16:36:59Z",
        "modified": "2020-07-02T16:36:59Z",
        "text": "The issue with Google Cloud Load Balancer has been resolved for all affected users as of Thursday, 2020-07-02 09:36 US/Pacific.\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-07-02T16:36:59Z"
      },
      {
        "created": "2020-07-02T15:57:54Z",
        "modified": "2020-07-02T15:57:54Z",
        "text": "Description: We are experiencing an issue with Cloud Cloud Load Balancer as of Thursday, 2020-07-02 08:39 US/Pacific.\n\nCustomers will not be able to create new HTTP services or update certain\naspects of existing services (timeouts, health checks, backend port). They will\nstill be able to drain, add groups, and add/remove VMs.\n\nWe will provide more information by Thursday, 2020-07-02 10:15 US/Pacific.\n\nDiagnosis: Customers will not be able to create new HTTP services or update certain\naspects of existing services (timeouts, health checks, backend port).\n\nWorkaround: None at this time.",
        "when": "2020-07-02T15:57:54Z"
      }
    ],
    "uri": "/incident/cloud-networking/20006"
  },
  {
    "begin": "2020-06-29T15:38:07Z",
    "created": "2020-06-29T16:12:27Z",
    "end": "2020-06-29T20:15:24Z",
    "external_desc": "GKE Clusters in us-east1c may be unavailable",
    "modified": "2020-06-30T16:36:43Z",
    "most-recent-update": {
      "created": "2020-06-29T20:15:24Z",
      "modified": "2020-06-29T20:15:24Z",
      "text": "The issue with Google Kubernetes Engine has been resolved for the majority of affected projects as of Monday, 2020-06-29 11:15 US/Pacific.\n\nIf you have questions or feel that you may be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. \n\nWe will publish analysis of this incident once we have completed our internal investigation.\n\nWe thank you for your patience while we're working on resolving the issue.",
      "when": "2020-06-29T20:15:24Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-06-29T20:15:24Z",
        "modified": "2020-06-29T20:15:24Z",
        "text": "The issue with Google Kubernetes Engine has been resolved for the majority of affected projects as of Monday, 2020-06-29 11:15 US/Pacific.\n\nIf you have questions or feel that you may be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. \n\nWe will publish analysis of this incident once we have completed our internal investigation.\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-06-29T20:15:24Z"
      },
      {
        "created": "2020-06-29T18:41:28Z",
        "modified": "2020-06-30T16:36:42Z",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine in us-east1-c where clusters may be unavailable or unreachable beginning at Monday, 2020-06-29 07:15 US/Pacific US/Pacific.\r\n\r\nMitigation work is currently underway by our engineering team.\r\n\r\nFor regular status updates, please follow: https://status.cloud.google.com/incident/cloud-networking/20005",
        "when": "2020-06-29T18:41:28Z"
      },
      {
        "created": "2020-06-29T18:13:14Z",
        "modified": "2020-06-29T18:13:14Z",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine in us-east1-c where clusters may be unavailable or unreachable beginning at Monday, 2020-06-29 07:15 US/Pacific US/Pacific.\n\nMitigation work is currently underway by our engineering team.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/cloud-networking/20005 where we will provide the next update by Monday, 2020-06-29 11:45 US/Pacific.",
        "when": "2020-06-29T18:13:14Z"
      },
      {
        "created": "2020-06-29T17:29:12Z",
        "modified": "2020-06-29T17:29:12Z",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine in us-east1-c where clusters may be unavailable or unreachable beginning at Monday, 2020-06-29 07:15 US/Pacific US/Pacific.\n\nMitigation work is currently underway by our engineering team.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/cloud-networking/20005 where we will provide the next update by Monday, 2020-06-29 11:00 US/Pacific.",
        "when": "2020-06-29T17:29:12Z"
      },
      {
        "created": "2020-06-29T17:07:59Z",
        "modified": "2020-06-29T17:07:59Z",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine in us-east1-c where clusters may be unavailable or unreachable beginning at Monday, 2020-06-29 07:15 US/Pacific US/Pacific.\n\nMitigation work is currently underway by our engineering team.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/cloud-networking/20005 where we will provide the next update by Monday, 2020-06-29 10:30 US/Pacific.",
        "when": "2020-06-29T17:07:59Z"
      },
      {
        "created": "2020-06-29T16:12:27Z",
        "modified": "2020-06-29T16:12:27Z",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine in us-east1-c where clusters may be unavailable or unreachable beginning at Monday, 2020-06-29 07:15 US/Pacific US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/cloud-networking/20005 where we will provide the next update by Monday, 2020-06-29 10:10 US/Pacific.",
        "when": "2020-06-29T16:12:27Z"
      }
    ],
    "uri": "/incident/container-engine/20003"
  },
  {
    "begin": "2020-06-29T15:36:20Z",
    "created": "2020-06-29T16:12:02Z",
    "end": "2020-06-29T18:29:15Z",
    "external_desc": "We are experiencing an issue with Cloud Memorystore in us-east1-c and us-east1-d.",
    "modified": "2020-06-29T18:29:15Z",
    "most-recent-update": {
      "created": "2020-06-29T18:29:15Z",
      "modified": "2020-06-29T18:29:15Z",
      "text": "The issue with Cloud Memorystore has been resolved for all affected users as of Monday, 2020-06-29 11:27 US/Pacific.\n\nFor current information on the broader incident, and for any public incident reports that may follow, please see https://status.cloud.google.com/incident/cloud-networking/20005\n\nWe thank you for your patience while we're working on resolving the issue.",
      "when": "2020-06-29T18:29:15Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-memorystore",
    "service_name": "Cloud Memorystore",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-06-29T18:29:15Z",
        "modified": "2020-06-29T18:29:15Z",
        "text": "The issue with Cloud Memorystore has been resolved for all affected users as of Monday, 2020-06-29 11:27 US/Pacific.\n\nFor current information on the broader incident, and for any public incident reports that may follow, please see https://status.cloud.google.com/incident/cloud-networking/20005\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-06-29T18:29:15Z"
      },
      {
        "created": "2020-06-29T16:12:03Z",
        "modified": "2020-06-29T16:12:03Z",
        "text": "Description: We are experiencing an issue with Cloud Networking in us-east1-c and us-east1-d, beginning at Monday,2020-06-29 08:15 US/Pacific, affecting multiple Google Cloud Services, including Cloud Memorystore.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/cloud-networking/20005",
        "when": "2020-06-29T16:12:03Z"
      }
    ],
    "uri": "/incident/cloud-memorystore/20002"
  },
  {
    "begin": "2020-06-29T15:30:46Z",
    "created": "2020-06-29T15:56:42Z",
    "end": "2020-06-29T16:56:46Z",
    "external_desc": "We are experiencing an issue with Google Compute Engine in us-east1-c and us-east1-d",
    "modified": "2020-06-30T16:33:46Z",
    "most-recent-update": {
      "created": "2020-06-29T17:00:12Z",
      "modified": "2020-06-30T16:33:45Z",
      "text": "The issue with Google Compute Engine in zones us-east1-c and us-east1-d where existing VMs may be unavailable or unreachable, and new VM creation may fail beginning on Monday, 2020-06-29 08:20 US/Pacific has been resolved for all affected users as of Monday, 2020-06-29 09:45 US/Pacific.\r\n\r\nThe impact to us-east1-d has been mitigated by Monday, 2020-06-29 08:45 US/Pacific.\r\n\r\nThe impact to us-east1-c has been mitigated by Monday, 2020-06-29 09:45 US/Pacific.\r\n\r\nFor additional information on the broader outage and any follow up reports, please see  https://status.cloud.google.com/incident/cloud-networking/20005\r\n\r\nWe thank you for your patience while we're working on resolving the issue.",
      "when": "2020-06-29T17:00:11Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-06-29T17:00:12Z",
        "modified": "2020-06-30T16:33:45Z",
        "text": "The issue with Google Compute Engine in zones us-east1-c and us-east1-d where existing VMs may be unavailable or unreachable, and new VM creation may fail beginning on Monday, 2020-06-29 08:20 US/Pacific has been resolved for all affected users as of Monday, 2020-06-29 09:45 US/Pacific.\r\n\r\nThe impact to us-east1-d has been mitigated by Monday, 2020-06-29 08:45 US/Pacific.\r\n\r\nThe impact to us-east1-c has been mitigated by Monday, 2020-06-29 09:45 US/Pacific.\r\n\r\nFor additional information on the broader outage and any follow up reports, please see  https://status.cloud.google.com/incident/cloud-networking/20005\r\n\r\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-06-29T17:00:11Z"
      },
      {
        "created": "2020-06-29T16:56:46Z",
        "modified": "2020-06-29T17:38:46Z",
        "text": "The issue with Google Compute Engine in zones us-east1-c and us-east1-d where existing VMs may be unavailable or unreachable, and new VM creation may fail beginning on Monday, 2020-06-29 08:20 US/Pacific has been resolved for all affected users as of Monday, 2020-06-29 09:45 US/Pacific.\r\n\r\nWe are experiencing an issue with Google Compute Engine in zones us-east1-c and us-east1-d where existing VMs may be unavailable or unreachable, and new VM creation may fail beginning on Monday, 2020-06-29 08:20 US/Pacific.\r\n\r\nThe impact to us-east1-d has been mitigated by Monday, 2020-06-29 08:45 US/Pacific.\r\n\r\nThe impact to us-east1-c has been mitigated by Monday, 2020-06-29 09:45 US/Pacific.\r\n\r\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-06-29T16:56:46Z"
      },
      {
        "created": "2020-06-29T16:52:57Z",
        "modified": "2020-06-29T17:39:50Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine in zones us-east1-c and us-east1-d where existing VMs may be unavailable or unreachable, and new VM creation may fail beginning on Monday, 2020-06-29 08:20 US/Pacific.\r\n\r\nThe impact to us-east1-d has been mitigated by Monday, 2020-06-29 08:45 US/Pacific.\r\n\r\nThe impact to us-east1-c is ongoing.\r\n\r\nSymptoms: Existing VMs may appear as unavailable and may be unreachable. New VM creation may fail.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nFor regular status updates, please follow: https://status.cloud.google.com/incident/cloud-networking/20005 where we will provide the next update by Monday, 2020-06-29 10:00 US/Pacific.",
        "when": "2020-06-29T16:52:57Z"
      },
      {
        "created": "2020-06-29T16:18:08Z",
        "modified": "2020-06-29T16:18:08Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine affecting all zones in region us-east1 where existing VMs may be unavailable or unreachable, and new VM creation may fail beginning on Monday, 2020-06-29 08:15 US/Pacific.\n\nSymptoms: Existing VMs may appear as unavailable and may be unreachable. New VM creation may fail.\n\nOur engineering team continues to investigate the issue.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/cloud-networking/20005 where we will provide the next update by Monday, 2020-06-29 10:10 US/Pacific.",
        "when": "2020-06-29T16:18:08Z"
      },
      {
        "created": "2020-06-29T15:56:43Z",
        "modified": "2020-06-29T15:56:43Z",
        "text": "Description: We are experiencing an issue with Google Compute Engine in all zones in us-east1 where existing VMs may be unavailable or unreachable, and new VM creation may fail beginning on Monday, 2020-06-29 08:15 US/Pacific.\n\nSymptoms: Existing VMs may appear as unavailable and may be unreachable. New VM creation may fail.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Monday, 2020-06-29 09:52 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.",
        "when": "2020-06-29T15:56:43Z"
      }
    ],
    "uri": "/incident/compute/20004"
  },
  {
    "begin": "2020-06-29T15:20:37Z",
    "created": "2020-06-29T15:48:37Z",
    "end": "2020-06-29T20:06:45Z",
    "external_desc": "We are experiencing an issue with Cloud Networking in us-east1-c and us-east1-d",
    "modified": "2020-07-08T19:40:43Z",
    "most-recent-update": {
      "created": "2020-07-08T19:40:43Z",
      "modified": "2020-07-08T19:40:43Z",
      "text": "# ISSUE SUMMARY\r\n\r\nOn 2020-06-29 07:47 US/Pacific, Google Cloud experienced unavailability for some services hosted from our us-east1-c and us-east1-d zones. The unavailability primarily impacted us-east1-c but did have a short impact on us-east1-d. For approximately 1 hour and 30 minutes, 22.5% of Google Compute Engine (GCE) instances in us-east1-c, were unavailable. For approximately 7 minutes, 1.8% of GCE instances in us-east1-d, were unavailable. In addition, 0.0267% Persistent Disk (PD) devices hosted in us-east1-c were unavailable for up to 28 hours and the us-east1 region as a whole experienced 5% packet loss between 07:55 and 08:05 for Public IP and Network LB Traffic.\r\n\r\nWe sincerely apologize and are taking steps detailed below to ensure this doesn’t happen again.\r\n\r\n# BACKGROUND\r\n\r\nGoogle Cloud Platform is built on various layers of abstraction in order to provide scale and distinct failure domains. One of those abstractions is Zones and clusters [1]. Zonal services such as Google Compute Engine (GCE) assign projects to one cluster to handle the majority of the compute needs when a project requests resources in a cloud zone. If a cluster backing a zone becomes degraded, services in that zone have resilience built in to handle some level of machine failures. Regional services, depending on the architecture, may see a short degradation before automatically recovering, or see no impact at all. Regional services with tasks in a degraded cluster are generally migrated to other functional clusters in the same region to reduce overall impact. In the Detailed Impact section below, the impact is only to projects and services mapped to the affected clusters, unless otherwise noted. \r\n\r\nDatacenter power delivery is architected in three tiers. The primary tier of power delivery is utility power, with multiple grid feeds and robust substations. Backing up utility power are generators, each generator powers a different part of each cluster, and additional backup generators and fuel are available if required in the event that a part of this backup power system fails.The fuel supply system for the generators is broken into two parts, storage tanks which store fuel in bulk, and a system which pumps that fuel to generators for consumption.  The final tier of power delivery are batteries which provide power conditioning and a short run times when power from the other two tiers is interrupted.\r\n\r\n[1] https://cloud.google.com/compute/docs/regions-zones#zones_and_clusters\r\n\r\n# ROOT CAUSE\r\n\r\nDuring planned substation maintenance by the site’s electrical utility provider, two clusters supporting the us-east1 region were transferred to backup generator power for the duration of the maintenance, which was scheduled as a four hour window. Three hours into the maintenance window, 17% of the operating generators began to run out of fuel due to fuel delivery system failures even though there was adequate fuel available in the storage tanks. Multiple redundancies built into the backup power system were automatically activated as primary generators began to run out of fuel, however, as more primary generators ran out of fuel the part of the cluster they were supporting shutdown.\r\n \r\n\r\n# REMEDIATION AND PREVENTION\r\n\r\nGoogle engineers were alerted to the power issue impacting us-east1-c and us-east1-d at 2020-06-29 07:50 US/Pacific and immediately started an investigation. Impact to us-east1-d was resolved automatically by cluster level services. Other than some Persistent Disk devices, service impact in us-east1-d ended by 08:24. Onsite datacenter operators identified a fuel supply issue as the root cause of the power loss and quickly established a mitigation plan. Once a workaround for the fuel supply issue was deployed, the operators began restoring the affected generators to active service at 08:49. Almost at the same time, at 08:55, the planned substation maintenance had concluded and utility power returned to service.  Between the restored utility power and recovered generators, power was fully restored to both clusters by 08:59.\r\n\r\nIn a datacenter recovery scenario there is a sequential process that must be followed for downstream service recovery to succeed. By 2020-06-29 09:34, most GCE instances had recovered as the necessary upstream services were restored.  All services had recovered by 10:50 except for a small percentage of Persistent Disk impacted instances.  A more detailed timeline of individual service impact is included below in the “DETAILED DESCRIPTION OF IMPACT” section below.\r\n\r\nIn the days following this incident the same system was put under load. There was an unplanned utility power outage for the same location on 2020-06-30 (the next day) due to a lightning strike near a substation transformer. The system was again tested on 2020-07-02 when a final maintenance operation was conducted on the site substation.\r\n\r\nWe are committed to preventing this situation from happening again and are implementing the following actions:  \r\n\r\nResolving the issues identified with the fuel supply system which led to this incident. \r\nAn audit of sites which have a similar fuel system has been conducted and onsite personnel have been provided updated procedures and training for dealing with this situation should it occur again. \r\n\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\nOn 2020-06-29 from 07:47 to 10:50 US/Pacific, Google Cloud experienced unavailability for some services hosted from cloud zones us-east1-c and us-east1-d as described in detail below:\r\n\r\n## Google Compute Engine \r\n\r\n22.5% of Google Compute Engine (GCE) instances in the us-east1-c zone were unavailable starting 2020-06-29 07:57 US/Pacific for 1 hour and 30 minutes. Up to  1.8% of instances in the us-east1-d zone were unavailable starting 2020-06-29 08:17 for 7 minutes.  A small percentage of the instances in us-east1-c continued to be unavailable for up to 28 hours due to manual recovery of PD devices. \r\n\r\n\r\n## Persistent Disk\r\n\r\nPersistent Disk (PD) experienced 23% of PD devices becoming degraded in us-east1-c starting at 2020-06-29 07:53 to 2020-06-29 09:28 US/Pacific for a duration of 1 hour and 35 minutes.  0.0267% of PD devices were unable to recover automatically and required manual recovery which completed at 2020-06-30 09:54 resulting in 26 hours of additional unavailability. \r\n\r\nThe delay in recovery was primarily due to a configuration setting in PD clients that set metadata initialization retry attempts to a maximum value (with exponential backoff). Upon power loss, 0.0267% of PD devices in us-east1-c  reached this limit and were unable to recover automatically as they had exhausted their retry attempts before power had been fully restored. To prevent this scenario from recurring, we are significantly increasing the number of retry attempts that will be performed by PD metadata initialization to ensure PD can recover from extended periods of power loss.\r\n\r\nA secondary factor resulting in the delay of some customer VMs was due to filesystem errors triggered by the PD unavailability. PD itself maintains defense-in-depth through a variety of end-to-end integrity mechanisms which prevented any PD corruption during this incident. However, some filesystems are not designed to be robust against cases where some parts of the block device presented by PD fail to initialize while others are still usable. This issue was technically external to PD, and only repairable by customers using filesystem repair utilities. The PD product team assisted affected customers in their manual recovery efforts during the extended incident window.\r\n\r\n\r\nAdditionally, up to 0.429% of PD devices in us-east1-d were unhealthy for approximately 1 hour from 2020-06-29 08:15 to 2020-06-29 09:10.  All PD devices in us-east1-d recovered automatically once power had been restored.\r\n\r\n\r\n## Cloud Networking \r\n\r\nThe us-east1 region as a whole experienced a 5% packet loss between 07:55 and 08:05 for Public IP and Network LB Traffic as Maglevs [1] servicing the region in the impacted cluster became unavailable.\r\n\r\nCloud VPN saw 7% of Classic VPN tunnels in us-east1 reset between 07:57 and 08:07. As tunnels disconnected, they were rescheduled automatically in other clusters in the region. HA VPN tunnels were not impacted.\r\n\r\nCloud Router saw 13% of BGP sessions in us-east1 flap between 07:57 and 08:07, Cloud Router tasks in the impacted cluster were rescheduled automatically in other clusters in the region.\r\n\r\nCloud HTTP(S) Load Balancing saw a 166% spike in baseline HTTP 500 errors between 08:00 to 08:10.\r\n\r\nStarting at 09:38 the network control plane in the impacted cluster began to initialize but ran into an issue that required manual intervention to resolve. Between 09:38 and 10:14 instances continued to be inaccessible until the control plane initialized, updates were also not being propagated down to the cluster control plane. Due to this, some resources such as Internal Load Balancers and instances that were deleted during this time period, and then recreated at any time between 9:38 and 12:47 would have seen availability issues. This was resolved with additional intervention from the SRE team. \r\n\r\nTo reduce time to recover for similar classes of issues, we are increasing the robustness of the control plane to better handle such exceptional failure conditions. We are also implementing additional monitoring and alerting to more quickly detect update propagation issues under exceptional failure conditions\r\n\r\n[1] https://cloud.google.com/blog/products/gcp/google-shares-software-network-load-balancer-design-powering-gcp-networking \r\n\r\n## Cloud SQL\r\n\r\nGoogle Cloud SQL experienced a 7% drop in network connections that resulted in database unavailability from 2020-06-29 08:00 - 10:50 US/Pacific affecting <1.5% of instances in us-east1 due to power loss. This degraded Cloud SQL dependencies (Persistent Disk and GCE) in us-east1-c and us-east1-d for a period of 2 hours and 50 minutes.\r\n\r\n\r\n## Filestore + Memorystore\r\n\r\nCloud Filestore and Memorystore instances in us-east1-c were unavailable due to power loss from 2020-06-29 07:56 - 10:24 US/Pacific for a duration of 2 hours and 28 minutes. 7.4% of Redis non-HA (zonal) instances in us-east1 were unavailable and 5.9% of Redis HA (regional) standard tier instances in us-east1 failed over. All Cloud Filestore and Cloud Memorystore instances recovered by 10:24.\r\n\r\n\r\n## Google Kubernetes Engine\r\n\r\nGoogle Kubernetes Engine (GKE) customers were unable to create or delete clusters in either the us-east1-c zone or the us-east1 region from 2020-06-29 8:00 to 2020-06-29 10:30 US/Pacific. Additionally, customers could not create nodepools in the us-east1-c zone during that same period. A maximum of 29% of zonal clusters in us-east1-c and 2% of zonal clusters in us-east1-d could not be administered; all but a small subset of clusters recovered by 11:00, and the remaining clusters recovered by 14:30.  Existing regional clusters in us-east1 were not affected except for customers who had workloads on nodes in us-east1-c that they could not or were unable to migrate.\r\n\r\n## Google Cloud Storage\r\n\r\nGoogle Cloud Storage (GCS) in us-east1 experienced 10 minutes of impact when availability fell down to 99.7%, with a 3-minute burst down to 98.6% availability.  GCS multi-region experienced a total of 40 minutes of impact, down to 99.55% availability. \r\n\r\n# SLA CREDITS\r\nIf you believe your paid application experienced an SLA violation as a result of this incident, please submit the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\r\n\r\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/",
      "when": "2020-07-08T19:40:43Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "cloud-networking",
    "service_name": "Google Cloud Networking",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-07-08T19:40:43Z",
        "modified": "2020-07-08T19:40:43Z",
        "text": "# ISSUE SUMMARY\r\n\r\nOn 2020-06-29 07:47 US/Pacific, Google Cloud experienced unavailability for some services hosted from our us-east1-c and us-east1-d zones. The unavailability primarily impacted us-east1-c but did have a short impact on us-east1-d. For approximately 1 hour and 30 minutes, 22.5% of Google Compute Engine (GCE) instances in us-east1-c, were unavailable. For approximately 7 minutes, 1.8% of GCE instances in us-east1-d, were unavailable. In addition, 0.0267% Persistent Disk (PD) devices hosted in us-east1-c were unavailable for up to 28 hours and the us-east1 region as a whole experienced 5% packet loss between 07:55 and 08:05 for Public IP and Network LB Traffic.\r\n\r\nWe sincerely apologize and are taking steps detailed below to ensure this doesn’t happen again.\r\n\r\n# BACKGROUND\r\n\r\nGoogle Cloud Platform is built on various layers of abstraction in order to provide scale and distinct failure domains. One of those abstractions is Zones and clusters [1]. Zonal services such as Google Compute Engine (GCE) assign projects to one cluster to handle the majority of the compute needs when a project requests resources in a cloud zone. If a cluster backing a zone becomes degraded, services in that zone have resilience built in to handle some level of machine failures. Regional services, depending on the architecture, may see a short degradation before automatically recovering, or see no impact at all. Regional services with tasks in a degraded cluster are generally migrated to other functional clusters in the same region to reduce overall impact. In the Detailed Impact section below, the impact is only to projects and services mapped to the affected clusters, unless otherwise noted. \r\n\r\nDatacenter power delivery is architected in three tiers. The primary tier of power delivery is utility power, with multiple grid feeds and robust substations. Backing up utility power are generators, each generator powers a different part of each cluster, and additional backup generators and fuel are available if required in the event that a part of this backup power system fails.The fuel supply system for the generators is broken into two parts, storage tanks which store fuel in bulk, and a system which pumps that fuel to generators for consumption.  The final tier of power delivery are batteries which provide power conditioning and a short run times when power from the other two tiers is interrupted.\r\n\r\n[1] https://cloud.google.com/compute/docs/regions-zones#zones_and_clusters\r\n\r\n# ROOT CAUSE\r\n\r\nDuring planned substation maintenance by the site’s electrical utility provider, two clusters supporting the us-east1 region were transferred to backup generator power for the duration of the maintenance, which was scheduled as a four hour window. Three hours into the maintenance window, 17% of the operating generators began to run out of fuel due to fuel delivery system failures even though there was adequate fuel available in the storage tanks. Multiple redundancies built into the backup power system were automatically activated as primary generators began to run out of fuel, however, as more primary generators ran out of fuel the part of the cluster they were supporting shutdown.\r\n \r\n\r\n# REMEDIATION AND PREVENTION\r\n\r\nGoogle engineers were alerted to the power issue impacting us-east1-c and us-east1-d at 2020-06-29 07:50 US/Pacific and immediately started an investigation. Impact to us-east1-d was resolved automatically by cluster level services. Other than some Persistent Disk devices, service impact in us-east1-d ended by 08:24. Onsite datacenter operators identified a fuel supply issue as the root cause of the power loss and quickly established a mitigation plan. Once a workaround for the fuel supply issue was deployed, the operators began restoring the affected generators to active service at 08:49. Almost at the same time, at 08:55, the planned substation maintenance had concluded and utility power returned to service.  Between the restored utility power and recovered generators, power was fully restored to both clusters by 08:59.\r\n\r\nIn a datacenter recovery scenario there is a sequential process that must be followed for downstream service recovery to succeed. By 2020-06-29 09:34, most GCE instances had recovered as the necessary upstream services were restored.  All services had recovered by 10:50 except for a small percentage of Persistent Disk impacted instances.  A more detailed timeline of individual service impact is included below in the “DETAILED DESCRIPTION OF IMPACT” section below.\r\n\r\nIn the days following this incident the same system was put under load. There was an unplanned utility power outage for the same location on 2020-06-30 (the next day) due to a lightning strike near a substation transformer. The system was again tested on 2020-07-02 when a final maintenance operation was conducted on the site substation.\r\n\r\nWe are committed to preventing this situation from happening again and are implementing the following actions:  \r\n\r\nResolving the issues identified with the fuel supply system which led to this incident. \r\nAn audit of sites which have a similar fuel system has been conducted and onsite personnel have been provided updated procedures and training for dealing with this situation should it occur again. \r\n\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\nOn 2020-06-29 from 07:47 to 10:50 US/Pacific, Google Cloud experienced unavailability for some services hosted from cloud zones us-east1-c and us-east1-d as described in detail below:\r\n\r\n## Google Compute Engine \r\n\r\n22.5% of Google Compute Engine (GCE) instances in the us-east1-c zone were unavailable starting 2020-06-29 07:57 US/Pacific for 1 hour and 30 minutes. Up to  1.8% of instances in the us-east1-d zone were unavailable starting 2020-06-29 08:17 for 7 minutes.  A small percentage of the instances in us-east1-c continued to be unavailable for up to 28 hours due to manual recovery of PD devices. \r\n\r\n\r\n## Persistent Disk\r\n\r\nPersistent Disk (PD) experienced 23% of PD devices becoming degraded in us-east1-c starting at 2020-06-29 07:53 to 2020-06-29 09:28 US/Pacific for a duration of 1 hour and 35 minutes.  0.0267% of PD devices were unable to recover automatically and required manual recovery which completed at 2020-06-30 09:54 resulting in 26 hours of additional unavailability. \r\n\r\nThe delay in recovery was primarily due to a configuration setting in PD clients that set metadata initialization retry attempts to a maximum value (with exponential backoff). Upon power loss, 0.0267% of PD devices in us-east1-c  reached this limit and were unable to recover automatically as they had exhausted their retry attempts before power had been fully restored. To prevent this scenario from recurring, we are significantly increasing the number of retry attempts that will be performed by PD metadata initialization to ensure PD can recover from extended periods of power loss.\r\n\r\nA secondary factor resulting in the delay of some customer VMs was due to filesystem errors triggered by the PD unavailability. PD itself maintains defense-in-depth through a variety of end-to-end integrity mechanisms which prevented any PD corruption during this incident. However, some filesystems are not designed to be robust against cases where some parts of the block device presented by PD fail to initialize while others are still usable. This issue was technically external to PD, and only repairable by customers using filesystem repair utilities. The PD product team assisted affected customers in their manual recovery efforts during the extended incident window.\r\n\r\n\r\nAdditionally, up to 0.429% of PD devices in us-east1-d were unhealthy for approximately 1 hour from 2020-06-29 08:15 to 2020-06-29 09:10.  All PD devices in us-east1-d recovered automatically once power had been restored.\r\n\r\n\r\n## Cloud Networking \r\n\r\nThe us-east1 region as a whole experienced a 5% packet loss between 07:55 and 08:05 for Public IP and Network LB Traffic as Maglevs [1] servicing the region in the impacted cluster became unavailable.\r\n\r\nCloud VPN saw 7% of Classic VPN tunnels in us-east1 reset between 07:57 and 08:07. As tunnels disconnected, they were rescheduled automatically in other clusters in the region. HA VPN tunnels were not impacted.\r\n\r\nCloud Router saw 13% of BGP sessions in us-east1 flap between 07:57 and 08:07, Cloud Router tasks in the impacted cluster were rescheduled automatically in other clusters in the region.\r\n\r\nCloud HTTP(S) Load Balancing saw a 166% spike in baseline HTTP 500 errors between 08:00 to 08:10.\r\n\r\nStarting at 09:38 the network control plane in the impacted cluster began to initialize but ran into an issue that required manual intervention to resolve. Between 09:38 and 10:14 instances continued to be inaccessible until the control plane initialized, updates were also not being propagated down to the cluster control plane. Due to this, some resources such as Internal Load Balancers and instances that were deleted during this time period, and then recreated at any time between 9:38 and 12:47 would have seen availability issues. This was resolved with additional intervention from the SRE team. \r\n\r\nTo reduce time to recover for similar classes of issues, we are increasing the robustness of the control plane to better handle such exceptional failure conditions. We are also implementing additional monitoring and alerting to more quickly detect update propagation issues under exceptional failure conditions\r\n\r\n[1] https://cloud.google.com/blog/products/gcp/google-shares-software-network-load-balancer-design-powering-gcp-networking \r\n\r\n## Cloud SQL\r\n\r\nGoogle Cloud SQL experienced a 7% drop in network connections that resulted in database unavailability from 2020-06-29 08:00 - 10:50 US/Pacific affecting <1.5% of instances in us-east1 due to power loss. This degraded Cloud SQL dependencies (Persistent Disk and GCE) in us-east1-c and us-east1-d for a period of 2 hours and 50 minutes.\r\n\r\n\r\n## Filestore + Memorystore\r\n\r\nCloud Filestore and Memorystore instances in us-east1-c were unavailable due to power loss from 2020-06-29 07:56 - 10:24 US/Pacific for a duration of 2 hours and 28 minutes. 7.4% of Redis non-HA (zonal) instances in us-east1 were unavailable and 5.9% of Redis HA (regional) standard tier instances in us-east1 failed over. All Cloud Filestore and Cloud Memorystore instances recovered by 10:24.\r\n\r\n\r\n## Google Kubernetes Engine\r\n\r\nGoogle Kubernetes Engine (GKE) customers were unable to create or delete clusters in either the us-east1-c zone or the us-east1 region from 2020-06-29 8:00 to 2020-06-29 10:30 US/Pacific. Additionally, customers could not create nodepools in the us-east1-c zone during that same period. A maximum of 29% of zonal clusters in us-east1-c and 2% of zonal clusters in us-east1-d could not be administered; all but a small subset of clusters recovered by 11:00, and the remaining clusters recovered by 14:30.  Existing regional clusters in us-east1 were not affected except for customers who had workloads on nodes in us-east1-c that they could not or were unable to migrate.\r\n\r\n## Google Cloud Storage\r\n\r\nGoogle Cloud Storage (GCS) in us-east1 experienced 10 minutes of impact when availability fell down to 99.7%, with a 3-minute burst down to 98.6% availability.  GCS multi-region experienced a total of 40 minutes of impact, down to 99.55% availability. \r\n\r\n# SLA CREDITS\r\nIf you believe your paid application experienced an SLA violation as a result of this incident, please submit the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\r\n\r\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/",
        "when": "2020-07-08T19:40:43Z"
      },
      {
        "created": "2020-06-29T20:06:45Z",
        "modified": "2020-06-29T20:06:45Z",
        "text": "The issue with Cloud Networking and Persistent Disk has been resolved for the majority of affected projects as of Monday, 2020-06-29 10:20 US/Pacific, and we expect full mitigation to occur for remaining projects within the hour.\n\nIf you have questions or feel that you may be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. \n\nWe will publish analysis of this incident once we have completed our internal investigation.\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-06-29T20:06:45Z"
      },
      {
        "created": "2020-06-29T19:17:35Z",
        "modified": "2020-06-29T19:17:35Z",
        "text": "Description: We are experiencing an issue with Cloud Networking in us-east1-c and us-east1-d, beginning on Monday, 2020-06-29 07:54 US/Pacific, affecting multiple Google Cloud Services.\n\nServices in us-east1-d have been fully restored.\nServices in us-east1-c are fully restored except for Persistent Disk which is partially restored. No ETA for full recovery of Persistent Disk yet.\n\nImpact is due to power failure. A more detailed analysis will be available at a later time.\n\nOur engineering team is working on recovery of impacted services.\n\nWe will provide an update by Monday, 2020-06-29 13:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\n\nDiagnosis: Some services in us-east1-c and us-east1-d are failing, customers impacted by this incident would likely experience a total unavailability of zonal services hosted in us-east1-c or us-east1-d. It is possible for customers to experience service interruption in none, one, or both zones.\n\nWorkaround: Other zones in the region are not impacted. If possible, migrating workloads would mitigate impact. If workloads are unable to be migrated, there is no workaround at this time.",
        "when": "2020-06-29T19:17:35Z"
      },
      {
        "created": "2020-06-29T18:45:56Z",
        "modified": "2020-06-29T18:45:56Z",
        "text": "Description: We are experiencing an issue with Cloud Networking in us-east1-c and us-east1-d, beginning on Monday, 2020-06-29 07:54 US/Pacific, affecting multiple Google Cloud Services.\n\nServices in us-east1-d have been fully restored.\nServices in us-east1-c are fully restored except for Persistent Disk which is partially restored. No ETA for full recovery of Persistent Disk yet.\n\nImpact is due to power failure. A more detailed analysis will be available at a later time.\n\nOur engineering team is working on recovery of impacted services.\n\nWe will provide an update by Monday, 2020-06-29 12:20 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\n\nDiagnosis: Some services in us-east1-c and us-east1-d are failing, customers impacted by this incident would likely experience a total unavailability of zonal services hosted in us-east1-c or us-east1-d. It is possible for customers to experience service interruption in none, one, or both zones.\n\nWorkaround: Other zones in the region are not impacted. If possible, migrating workloads would mitigate impact. If workloads are unable to be migrated, there is no workaround at this time.",
        "when": "2020-06-29T18:45:56Z"
      },
      {
        "created": "2020-06-29T18:00:45Z",
        "modified": "2020-06-29T18:00:45Z",
        "text": "Description: We are experiencing an issue with Cloud Networking in us-east1-c and us-east1-d, beginning on Monday, 2020-06-29 07:54 US/Pacific, affecting multiple Google Cloud Services.\n\nServices in us-east1-d have been restored.\nMost services in us-east1-c are restored except for Persistent Disk. No ETA for Persistent disk recovery as of now.\n\nImpact is due to power failure. A more detailed analysis will be available at a later time.\n\nOur engineering team is working on recovery of impacted services.\n\nWe will provide an update by Monday, 2020-06-29 11:45 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\n\nDiagnosis: Some services in us-east1-c and us-east1-d are failing, customers impacted by this incident would likely experience a total unavailability of zonal services hosted in us-east1-c or us-east1-d. It is possible for customers to experience service interruption in none, one, or both zones.\n\nWorkaround: Other zones in the region are not impacted. If possible, migrating workloads would mitigate impact. If workloads are unable to be migrated, there is no workaround at this time.",
        "when": "2020-06-29T18:00:45Z"
      },
      {
        "created": "2020-06-29T17:31:35Z",
        "modified": "2020-06-29T17:31:35Z",
        "text": "Description: We are experiencing an issue with Cloud Networking in us-east1-c and us-east1-d, beginning on Monday, 2020-06-29 07:54 US/Pacific, affecting multiple Google Cloud Services.\n\nServices in us-east1-d have been restored.\nMost services in us-east1-c are restored except for Persistent Disk. No ETA for Persistent disk recovery as of now.\n\nImpact is due to power failure. A more detailed analysis will be available at a later time.\n\nOur engineering team is working on recovery of impacted services.\n\nWe will provide an update by Monday, 2020-06-29 11:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Some services in us-east1-c and us-east1-d are failing, customers impacted by this incident would likely experience a total unavailability of zonal services hosted in us-east1-c or us-east1-d. It is possible for customers to experience service interruption in none, one, or both zones.\n\nWorkaround: Other zones in the region are not impacted. If possible, migrating workloads would mitigate impact. If workloads are unable to be migrated, there is no workaround at this time.",
        "when": "2020-06-29T17:31:35Z"
      },
      {
        "created": "2020-06-29T17:00:30Z",
        "modified": "2020-06-29T17:00:30Z",
        "text": "Description: We are experiencing an issue with Cloud Networking in us-east1-c and us-east1-d, beginning on Monday, 2020-06-29 07:54 US/Pacific, affecting multiple Google Cloud Services.\n\nServices in us-east1-d have been restored.\nServices in us-east1-c are still being restored. No ETA as of now.\n\nImpact is due to power failure. A more detailed analysis will be available at a later time.\n\nOur engineering team is working on recovery of impacted services.\n\nWe will provide an update by Monday, 2020-06-29 10:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\n\nDiagnosis: Some services in us-east1-c and us-east1-d are failing, customers impacted by this incident would likely experience a total unavailability of zonal services hosted in us-east1-c or us-east1-d. It is possible for customers to experience service interruption in none, one, or both zones.\n\nWorkaround: Other zones in the region are not impacted. If possible, migrating workloads would mitigate impact. If workloads are unable to be migrated, there is no workaround at this time.",
        "when": "2020-06-29T17:00:30Z"
      },
      {
        "created": "2020-06-29T16:22:43Z",
        "modified": "2020-06-29T16:22:43Z",
        "text": "Description: We are experiencing an issue with Cloud Networking in us-east1-c and us-east1-d, beginning on Monday, 2020-06-29 07:54 US/Pacific, affecting multiple Google Cloud Services.\n\nWe expect services in us-east1-d to be recovering within the next 30 minutes, there is no eta for service recovery for us-east1-c yet.\n\nImpact is due to power failure. A more detailed analysis will be available at a later time.\n\nOur engineering team is working on recovery of impacted services..\n\nWe will provide an update by Monday, 2020-06-29 10:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\n\nDiagnosis: Some services in us-east1-c and us-east1-d are failing, customers impacted by this incident would likely experience a total unavailability of zonal services hosted in us-east1-c or us-east1-d. It is possible for customers to experience service interruption in none, one, or both zones.\n\nWorkaround: Other zones in the region are not impacted. If possible, migrating workloads would mitigate impact. If workloads are unable to be migrated, there is no workaround at this time.",
        "when": "2020-06-29T16:22:43Z"
      },
      {
        "created": "2020-06-29T15:48:37Z",
        "modified": "2020-06-29T15:48:37Z",
        "text": "Description: We are experiencing an issue with Cloud Networking in us-east1-c and us-east1-d, beginning at Monday,2020-06-29 08:15 US/Pacific, affecting multiple Google Cloud Services.\n\nSymptoms: Connections to and from VMs in us-east1-c and us-east1-d may fail.\n\nOur engineering team continues to investigate the issue..\n\nWe will provide an update by Monday, 2020-06-29 10:10 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: VM networking in us-east1-c and us-east1-d are failing.\n\nWorkaround: None at this time.",
        "when": "2020-06-29T15:48:37Z"
      }
    ],
    "uri": "/incident/cloud-networking/20005"
  },
  {
    "begin": "2020-06-29T15:15:42Z",
    "created": "2020-06-29T17:20:34Z",
    "end": "2020-06-29T18:40:41Z",
    "external_desc": "We are experiencing issues with Google Compute Engine Autoscaling in us-east1-c",
    "modified": "2020-06-29T18:40:41Z",
    "most-recent-update": {
      "created": "2020-06-29T18:40:41Z",
      "modified": "2020-06-29T18:40:41Z",
      "text": "The issue with Google Compute Engine has been resolved for all affected users as of Monday, 2020-06-29 11:39 US/Pacific.\n\nFor current information on the broader incident, and for any public incident reports that may follow, please see https://status.cloud.google.com/incident/cloud-networking/20005.\n\nWe thank you for your patience while we're working on resolving the issue.",
      "when": "2020-06-29T18:40:41Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-06-29T18:40:41Z",
        "modified": "2020-06-29T18:40:41Z",
        "text": "The issue with Google Compute Engine has been resolved for all affected users as of Monday, 2020-06-29 11:39 US/Pacific.\n\nFor current information on the broader incident, and for any public incident reports that may follow, please see https://status.cloud.google.com/incident/cloud-networking/20005.\n\nWe thank you for your patience while we're working on resolving the issue.",
        "when": "2020-06-29T18:40:41Z"
      },
      {
        "created": "2020-06-29T18:12:56Z",
        "modified": "2020-06-29T18:12:56Z",
        "text": "Description: We are experiencing an intermittent issue with Google Compute Engine Managed Instance Group's Autoscaler beginning on Monday, 2020-06-29 08:15 US/Pacific.\n\nMitigation work is underway.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/cloud-networking/20005 where we will provide the next update by Monday, 2020-06-29 11:45 US/Pacific .\n\nDiagnosis: Autoscaling of instances in Managed Instance Groups may not occur due to instances being unreachable.\n\nWorkaround: None at this time.",
        "when": "2020-06-29T18:12:56Z"
      },
      {
        "created": "2020-06-29T17:28:24Z",
        "modified": "2020-06-29T17:28:24Z",
        "text": "Description: We are experiencing an intermittent issue with Google Compute Engine Managed Instance Group's Autoscaler beginning on Monday, 2020-06-29 08:15 US/Pacific.\n\nMitigation work is underway.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/cloud-networking/20005 where we will provide the next update by Monday, 2020-06-29 11:00 US/Pacific .\n\nDiagnosis: Autoscaling of instances in Managed Instance Groups may not occur due to instances being unreachable.\n\nWorkaround: None at this time.",
        "when": "2020-06-29T17:28:24Z"
      },
      {
        "created": "2020-06-29T17:20:34Z",
        "modified": "2020-06-29T17:20:34Z",
        "text": "Description: We are experiencing an intermittent issue with Google Compute Engine Managed Instance Group's Autoscaler beginning on Monday, 2020-06-29 08:15 US/Pacific.\n\nOur engineering team continues to investigate the issue.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/cloud-networking/20005 where we will provide the next update by Monday, 2020-06-29 10:30 US/Pacific .\n\nDiagnosis: Autoscaling of instances in Managed Instance Groups may not occur due to instances being unreachable.\n\nWorkaround: None at this time.",
        "when": "2020-06-29T17:20:34Z"
      }
    ],
    "uri": "/incident/compute/20005"
  },
  {
    "begin": "2020-04-08T14:15:28Z",
    "created": "2020-04-08T15:11:51Z",
    "end": "2020-04-08T16:29:56Z",
    "external_desc": "We've received a report of an issue with Cloud Dataproc.",
    "modified": "2020-04-08T16:29:56Z",
    "most-recent-update": {
      "created": "2020-04-08T16:29:56Z",
      "modified": "2020-04-08T16:29:56Z",
      "text": "Our engineers have determined this issue to be linked to a single Google incident.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/zall/20005.\n\nOur engineers believe that Cloud Dataproc is no longer affected by the main Google incident as of Wednesday, 2020-04-08 07:59 US/Pacific. \nNo further updates will be provided here.",
      "when": "2020-04-08T16:29:56Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "cloud-dataproc",
    "service_name": "Google Cloud Dataproc",
    "severity": "high",
    "updates": [
      {
        "created": "2020-04-08T16:29:56Z",
        "modified": "2020-04-08T16:29:56Z",
        "text": "Our engineers have determined this issue to be linked to a single Google incident.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/zall/20005.\n\nOur engineers believe that Cloud Dataproc is no longer affected by the main Google incident as of Wednesday, 2020-04-08 07:59 US/Pacific. \nNo further updates will be provided here.",
        "when": "2020-04-08T16:29:56Z"
      },
      {
        "created": "2020-04-08T15:11:51Z",
        "modified": "2020-04-08T15:11:51Z",
        "text": "Description: We are experiencing an issue with Cloud Dataproc\n\nOur engineering team continues to investigate the issue.\n\nFor regular status updates, please follow: https://status.cloud.google.com/incident/zall/20005.\nFurther updates here will be provided by Wednesday, 2020-04-08 13:00 US/Pacific .",
        "when": "2020-04-08T15:11:51Z"
      }
    ],
    "uri": "/incident/cloud-dataproc/20003"
  },
  {
    "begin": "2020-04-08T13:48:45Z",
    "created": "2020-04-08T14:44:40Z",
    "end": "2020-04-08T14:42:50Z",
    "external_desc": "We are investigating an issue with elevated error rates across multiple Google Cloud Platform Services",
    "modified": "2020-04-13T16:21:40Z",
    "most-recent-update": {
      "created": "2020-04-13T16:19:58Z",
      "modified": "2020-04-13T16:21:40Z",
      "text": "# ISSUE SUMMARY (All times in US/Pacific daylight time)\r\n\r\nOn Wednesday 08 April, 2020 beginning at 06:48 US/Pacific, Google Cloud Identity and Access Management (IAM) experienced significantly elevated error rates for a duration of 54 minutes. IAM is used by several Google services to manage user information, and the elevated IAM error rates resulted in degraded performance that extended beyond 54 minutes for the following Cloud services:\r\n\r\n    - Google BigQuery’s streaming service experienced degraded performance for 116 minutes;\r\n    - Cloud IAM’s external API returned elevated errors for 102 minutes;\r\n    - 3% of Cloud SQL HA instances were degraded for durations ranging from 54 to 192 minutes.\r\n\r\n\r\n\r\nTo our Cloud customers whose businesses were impacted during this disruption, we sincerely apologize – we have conducted a thorough internal investigation and are taking immediate action to improve the resiliency, performance, and availability of our service. \r\n\r\n\r\n# ROOT CAUSE\r\n\r\nMany Cloud services depend on a distributed Access Control List (ACL) in Cloud Identity and Access Management (IAM) for validating permissions, activating new APIs, or creating new Cloud resources. Cloud IAM in turn relies on a centralized and planet-scale system to manage and evaluate access control for data stored within Google, known as Zanzibar [1]. Cloud IAM consists of regional and global instances; regional instances are isolated from each other and from the global instance for reliability. However, some specific IAM checks, such as checking an organizational policy, reference the global IAM instance.\r\n\r\nThe trigger of this incident was a rarely-exercised type of configuration change in Zanzibar which also impacted Cloud IAM. A typical change to this configuration mutates existing configuration namespaces, and is gradually rolled out through a sequence of canary steps. However, in this case, a new configuration namespace was added, and a latent issue with our canarying system allowed this specific type of configuration change to propagate globally in a rapid manner. As the configuration was pushed to production, the global Cloud IAM service quickly began to experience internal errors. This resulted in downstream operations with a dependency on global Cloud IAM to fail.\r\n\r\n[1] https://research.google/pubs/pub48190/\r\n\r\n\r\n# REMEDIATION AND PREVENTION\r\n\r\nGoogle engineers were automatically alerted to elevated error rates affecting Cloud IAM at 2020-04-08 06:52 US/Pacific and immediately began investigating. By 07:27, the engineering team responsible for managing Zanzibar identified the configuration change responsible for the issue, and swiftly reverted the change to mitigate. The mitigation finished propagating by 07:42, partially resolving the incident for a majority of internal services. Specific services such as the external Cloud IAM API, high-availability Cloud SQL, and Google BigQuery streaming took additional time to recover due to complications arising from the initial outage. Services with extended recovery timelines are described in the “detailed description of impact” section below.\r\n\r\nGoogle's standard production practice is to push any change gradually, in increments designed to maximize the probability of detecting problems before they have broad impact. Furthermore, we adhere to a philosophy of defence-in-depth: when problems occur, rapid mitigations (typically rollbacks) are used to restore service within service level objectives. In this outage, a combination of bugs resulted in these practices failing to be applied effectively. In addition to rolling back the configuration change responsible for this outage, we are fixing the issue with our canarying and release system that allowed this specific class of change to rapidly roll out globally; instead, such changes will in the future be subject to multiple layers of canarying, with automated rollback if problems are detected, and a progressive deployment over the course of multiple days. Both Cloud IAM and Zanzibar will enter a change freeze to prevent the possibility of further disruption to either service before these changes are implemented.\r\n\r\n\r\nWe truly understand how important regional reliability is for our users and deeply apologize for this incident. \r\n\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\n\r\nOn Wednesday 08 April, 2020 from 6:48 to 7:42 US/Pacific, Cloud IAM experienced an outage, which had varying degrees of impact on downstream services as described in detail below. \r\n\r\n## Cloud IAM\r\nExperienced a 100% error rate globally on all internal Cloud IAM API requests from 6:48 - 7:42. Upon the internal Cloud IAM service becoming unavailable (which impacted downstream Cloud services), the external Cloud IAM API also began returning HTTP 500 INTERNAL_ERROR codes. The rate and volume of incoming requests (due to aggressive retry policies) triggered the system’s Denial of Service (DoS) protection mechanism. The automatic DoS protection throttled the service, implementing a rate-limit on incoming requests resulting in query failures and a large volume of retry attempts. Upon the incident’s mitigation, the DoS protection was removed but took additional time to propagate across the fleet. Its removal finished propagating by 8:30, returning the service to normal operation.\r\n\r\n## Gmail\r\nExperienced delays receiving and sending emails from 6:50 to 7:39. For inbound emails, 20% G Suite emails, 21% of G Suite customers, and 0.3% of consumer emails were affected. For outbound emails (including Gmail-to-Gmail) 1.3% of G Suite emails, and 0.3% of consumer emails were affected. Message delay period varied, with the 50th percentile peaking at 3.7 seconds, up to 2580 seconds for the 90th percentile.\r\n\r\n## Compute Engine\r\nExperienced a 100% error rate when performing firewall modifications or create, update, or delete instance operations globally from 6:48 to 7:42. \r\n\r\n## Cloud SQL\r\nExperienced a 100% error rate when performing instance creation, deletion, backup, and failover operations globally for  high-availability (HA) instances from 6:48 - 7:42, due to the inability to authenticate VMs via the Cloud IAM service. \r\n\r\nAdditionally, Cloud SQL experienced extended impact from this outage for 3% of HA instances. Such instances initiated failover when upstream health metrics were not propagated due to the Cloud IAM issues. HA instances automatically failed over in an attempt to recover from what was believed to be failures occurring on the master instances. Upon failing over, these instances became stuck in a failed state. The Cloud IAM outage prevented the master’s underlying data disk from being attached to the failover instance, leaving the failover instance in a stuck state. These stuck instances required manual engineer intervention to bring them back online. Affected instances impact ranged from 6:48 - 10:00 for a total duration of 3 hours and 12 minutes.\r\n\r\nTo prevent HA Cloud SQL instances from encountering these failures in the future, we will change the auto-failover system to avoid triggering based on IAM issues. We are also re-examining the auto-failover system more generally to make sure it can distinguish a real outage from a system-communications issue going forward.\r\n\r\n## Cloud Pub/Sub\r\nExperienced 100% error rates globally for Topic administration operations (create, get, and list) from 6:48 - 7:42.\r\n\r\n## Kubernetes Engine\r\nExperienced a 100% error rate for cluster creation requests globally from 6:49 - 7:42.\r\n\r\n## BigQuery\r\nDatasets.get and projects.getServiceAccount experienced nearly 100% failures globally from 6:48 - 7:42. Other dataset operations experienced elevated error rates up to 40% for the duration of the incident. BigQuery streaming was also impacted in us-east1 for 6 minutes, us-east4 for 20 minutes, asia-east1 for 12 minutes, asia-east2 for 40 minutes, europe-north1 for 11 minutes, and the EU multi-region for 52 minutes. With most of the above regions experiencing up to a maximum of 30% average error rates. The EU multi-region, US multi-region, and us-east2 regions specifically experienced higher error rates, reaching nearly 100% for the duration of their impact windows.\r\n\r\nAdditionally, BigQuery streaming in the US multi-region experienced issues coping with traffic volume once IAM recovered. BigQuery streaming in the US multi-region experienced a 55% error rate from 7:42 - 8:44 for a total impact duration of 1 hour and 56 minutes.\r\n\r\n## App Engine\r\nExperienced a 100% error rate when creating, updating, or deleting app deployments globally from 6:48 to 7:42. Public apps did not have HTTP serving affected.\r\n\r\n## Cloud Run\r\nExperienced a 100% error rate when creating, updating, or deleting deployments globally from 6:48 to 7:42. Public services did not have HTTP serving affected.\r\n\r\n## Cloud Functions\r\nExperienced a 100% error rate when creating, updating, or deleting functions with access control [2] globally from 6:48 to 7:42. Public functions did not have HTTP serving affected.\r\n\r\n[2] https://cloud.google.com/functions/docs/concepts/iam\r\n\r\n## Cloud Monitoring\r\nExperienced intermittent errors when listing workspaces via the Cloud Monitoring UI from 6:42 - 7:42.\r\n\r\n## Cloud Logging\r\nExperienced average and peak error rates of 60% for ListLogEntries API calls from 6:48 - 7:42. Affected customers received INTERNAL_ERRORs. Additionally, create, update, and delete sink calls experienced a nearly 100% error rate during the impact window. Log Ingestion and other Cloud Logging APIs were unaffected.\r\n\r\n## Cloud Dataflow\r\nExperienced 100% error rates on several administrative operations including job creation, deletion, and autoscaling from 6:55 - 7:42. \r\n\r\n## Cloud Dataproc\r\nExperienced a 100% error rate when attempting to create clusters globally from 6:50 - 7:42.\r\n\r\n## Cloud Data Fusion\r\nExperienced a 100% error rate for create instance operations globally from 6:48 - 7:42. \r\n\r\n## Cloud Composer\r\nExperienced 100% error rates when creating, updating, or deleting Cloud Composer environments globally between 6:48 - 7:42. Existing environments were unaffected.\r\n\r\n## Cloud AI Platform Notebooks\r\nExperienced elevated average error rates of 97.2% (peaking to 100%) from 6:52 - 7:48 in the following regions: asia-east1, asia-northeast1, asia-southeast1, australia-southeast1, europe-west1, northamerica-northeast1, us-central1, us-east1, us-east4, and us-west1.\r\n\r\n## Cloud KMS\r\nExperienced a 100% error rate for Create operations globally from 6:49 - 7:40.\r\n\r\n## Cloud Tasks\r\nExperienced an average error rate of 8% (up to 15%) for CreateTasks, and a 96% error rate for AddTasks in the following regions: asia-northeast3, asia-south1, australia-southeast1, europe-west1, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east4, and us-west3.. Delivery of existing tasks were unaffected, but downstream services may have experienced other issues as documented. \r\n\r\n## Cloud Scheduler\r\nExperienced 100% error rates for CreateJob and UpdateJob requests globally from 6:48 - 7:42.\r\n\r\n## App Engine Task Queues\r\nExperienced an average error rate of 18% (up to 25% at peak) for UpdateTask requests from 6:48 - 7:42.\r\n\r\n## Cloud Build\r\nExperienced no API errors, however, all builds submitted between 6:48 and 7:42 were queued until the issue was resolved.\r\n\r\n## Cloud Deployment Manager\r\nExperienced an elevated average error rate of 20%, peaking to 36% for operations globally between 6:49 and 7:39. \r\n\r\n## Data Catalogue\r\nExperienced a 100% error rate for API operations globally from 6:48 - 7:42.\r\n\r\n## Firebase Real-time Database\r\nExperienced elevated average error rates of 7% for REST API and long-polling requests (peaking to 10%) during the incident window. \r\n\r\n## Firebase Test Lab\r\nExperienced elevated average error rates of 85% (peaking to 100%) globally for Android tests running on virtual devices in Google Compute Engine instances. Impact lasted from 6:48 - 7:54 for a duration of 1 hour and 6 minutes.\r\n\r\n## Firebase Hosting\r\nExperienced a 100% error rate when creating new versions globally from 6:48 - 7:42.\r\n\r\n## Firebase Console\r\nExperienced a 100% error rate for developer resources globally. Additionally, the Firedata API experienced an average error rate of 20% for API operations from 6:48 - 7:42\r\n\r\nAffected customers experienced a range of issues related to the Firebase Console and API. API invocations returned empty lists of projects, HTTP 404 errors, affected customers were unable to create, delete, update, or list many Firebase entities including (Android, iOS, and Web Apps), hosting sites, Real-time Database instances, Firebase-linked GCP buckets. Firebase developers were also unable to update billing settings. Firebase Cloud Functions could not be deployed successfully. Some customers experienced quota exhaustion errors due to extensive retry attempts. \r\n\r\n## Cloud IoT\r\nExperienced a 100% error rate when performing DeleteRegistry API calls from 6:48 - 7:42. Though DeleteRegistry API calls threw errors, the deletions issued did complete successfully.\r\n\r\n## Cloud Memorystore\r\nExperienced a 100% error rate for create, update, cancel, delete, and ListInstances operations on Redis instances globally from 6:48 - 7:42.\r\n\r\n## Cloud Filestore\r\nExperienced an average error rate of 70% for instance and snapshot creation, update, list, and deletion operations, with a peak error rate of 92% globally between 6:48 and 7:45.\r\n\r\n## Cloud Healthcare and Cloud Life Sciences\r\nExperienced a 100% error rate for CreateDataset operations globally from 6:48 - 7:42.\r\n\r\n\r\n# SLA CREDITS\r\nIf you believe your paid application experienced an SLA violation as a result of this incident, please populate the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\r\n\r\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/.\r\n\r\nFor G Suite, please request an SLA credit through one of the Support channels: https://support.google.com/a/answer/104721\r\n\r\nG Suite Service Level Agreement can be found at https://gsuite.google.com/intl/en/terms/sla.html",
      "when": "2020-04-13T16:19:58Z"
    },
    "number": 20005,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "high",
    "updates": [
      {
        "created": "2020-04-13T16:19:58Z",
        "modified": "2020-04-13T16:21:40Z",
        "text": "# ISSUE SUMMARY (All times in US/Pacific daylight time)\r\n\r\nOn Wednesday 08 April, 2020 beginning at 06:48 US/Pacific, Google Cloud Identity and Access Management (IAM) experienced significantly elevated error rates for a duration of 54 minutes. IAM is used by several Google services to manage user information, and the elevated IAM error rates resulted in degraded performance that extended beyond 54 minutes for the following Cloud services:\r\n\r\n    - Google BigQuery’s streaming service experienced degraded performance for 116 minutes;\r\n    - Cloud IAM’s external API returned elevated errors for 102 minutes;\r\n    - 3% of Cloud SQL HA instances were degraded for durations ranging from 54 to 192 minutes.\r\n\r\n\r\n\r\nTo our Cloud customers whose businesses were impacted during this disruption, we sincerely apologize – we have conducted a thorough internal investigation and are taking immediate action to improve the resiliency, performance, and availability of our service. \r\n\r\n\r\n# ROOT CAUSE\r\n\r\nMany Cloud services depend on a distributed Access Control List (ACL) in Cloud Identity and Access Management (IAM) for validating permissions, activating new APIs, or creating new Cloud resources. Cloud IAM in turn relies on a centralized and planet-scale system to manage and evaluate access control for data stored within Google, known as Zanzibar [1]. Cloud IAM consists of regional and global instances; regional instances are isolated from each other and from the global instance for reliability. However, some specific IAM checks, such as checking an organizational policy, reference the global IAM instance.\r\n\r\nThe trigger of this incident was a rarely-exercised type of configuration change in Zanzibar which also impacted Cloud IAM. A typical change to this configuration mutates existing configuration namespaces, and is gradually rolled out through a sequence of canary steps. However, in this case, a new configuration namespace was added, and a latent issue with our canarying system allowed this specific type of configuration change to propagate globally in a rapid manner. As the configuration was pushed to production, the global Cloud IAM service quickly began to experience internal errors. This resulted in downstream operations with a dependency on global Cloud IAM to fail.\r\n\r\n[1] https://research.google/pubs/pub48190/\r\n\r\n\r\n# REMEDIATION AND PREVENTION\r\n\r\nGoogle engineers were automatically alerted to elevated error rates affecting Cloud IAM at 2020-04-08 06:52 US/Pacific and immediately began investigating. By 07:27, the engineering team responsible for managing Zanzibar identified the configuration change responsible for the issue, and swiftly reverted the change to mitigate. The mitigation finished propagating by 07:42, partially resolving the incident for a majority of internal services. Specific services such as the external Cloud IAM API, high-availability Cloud SQL, and Google BigQuery streaming took additional time to recover due to complications arising from the initial outage. Services with extended recovery timelines are described in the “detailed description of impact” section below.\r\n\r\nGoogle's standard production practice is to push any change gradually, in increments designed to maximize the probability of detecting problems before they have broad impact. Furthermore, we adhere to a philosophy of defence-in-depth: when problems occur, rapid mitigations (typically rollbacks) are used to restore service within service level objectives. In this outage, a combination of bugs resulted in these practices failing to be applied effectively. In addition to rolling back the configuration change responsible for this outage, we are fixing the issue with our canarying and release system that allowed this specific class of change to rapidly roll out globally; instead, such changes will in the future be subject to multiple layers of canarying, with automated rollback if problems are detected, and a progressive deployment over the course of multiple days. Both Cloud IAM and Zanzibar will enter a change freeze to prevent the possibility of further disruption to either service before these changes are implemented.\r\n\r\n\r\nWe truly understand how important regional reliability is for our users and deeply apologize for this incident. \r\n\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\n\r\nOn Wednesday 08 April, 2020 from 6:48 to 7:42 US/Pacific, Cloud IAM experienced an outage, which had varying degrees of impact on downstream services as described in detail below. \r\n\r\n## Cloud IAM\r\nExperienced a 100% error rate globally on all internal Cloud IAM API requests from 6:48 - 7:42. Upon the internal Cloud IAM service becoming unavailable (which impacted downstream Cloud services), the external Cloud IAM API also began returning HTTP 500 INTERNAL_ERROR codes. The rate and volume of incoming requests (due to aggressive retry policies) triggered the system’s Denial of Service (DoS) protection mechanism. The automatic DoS protection throttled the service, implementing a rate-limit on incoming requests resulting in query failures and a large volume of retry attempts. Upon the incident’s mitigation, the DoS protection was removed but took additional time to propagate across the fleet. Its removal finished propagating by 8:30, returning the service to normal operation.\r\n\r\n## Gmail\r\nExperienced delays receiving and sending emails from 6:50 to 7:39. For inbound emails, 20% G Suite emails, 21% of G Suite customers, and 0.3% of consumer emails were affected. For outbound emails (including Gmail-to-Gmail) 1.3% of G Suite emails, and 0.3% of consumer emails were affected. Message delay period varied, with the 50th percentile peaking at 3.7 seconds, up to 2580 seconds for the 90th percentile.\r\n\r\n## Compute Engine\r\nExperienced a 100% error rate when performing firewall modifications or create, update, or delete instance operations globally from 6:48 to 7:42. \r\n\r\n## Cloud SQL\r\nExperienced a 100% error rate when performing instance creation, deletion, backup, and failover operations globally for  high-availability (HA) instances from 6:48 - 7:42, due to the inability to authenticate VMs via the Cloud IAM service. \r\n\r\nAdditionally, Cloud SQL experienced extended impact from this outage for 3% of HA instances. Such instances initiated failover when upstream health metrics were not propagated due to the Cloud IAM issues. HA instances automatically failed over in an attempt to recover from what was believed to be failures occurring on the master instances. Upon failing over, these instances became stuck in a failed state. The Cloud IAM outage prevented the master’s underlying data disk from being attached to the failover instance, leaving the failover instance in a stuck state. These stuck instances required manual engineer intervention to bring them back online. Affected instances impact ranged from 6:48 - 10:00 for a total duration of 3 hours and 12 minutes.\r\n\r\nTo prevent HA Cloud SQL instances from encountering these failures in the future, we will change the auto-failover system to avoid triggering based on IAM issues. We are also re-examining the auto-failover system more generally to make sure it can distinguish a real outage from a system-communications issue going forward.\r\n\r\n## Cloud Pub/Sub\r\nExperienced 100% error rates globally for Topic administration operations (create, get, and list) from 6:48 - 7:42.\r\n\r\n## Kubernetes Engine\r\nExperienced a 100% error rate for cluster creation requests globally from 6:49 - 7:42.\r\n\r\n## BigQuery\r\nDatasets.get and projects.getServiceAccount experienced nearly 100% failures globally from 6:48 - 7:42. Other dataset operations experienced elevated error rates up to 40% for the duration of the incident. BigQuery streaming was also impacted in us-east1 for 6 minutes, us-east4 for 20 minutes, asia-east1 for 12 minutes, asia-east2 for 40 minutes, europe-north1 for 11 minutes, and the EU multi-region for 52 minutes. With most of the above regions experiencing up to a maximum of 30% average error rates. The EU multi-region, US multi-region, and us-east2 regions specifically experienced higher error rates, reaching nearly 100% for the duration of their impact windows.\r\n\r\nAdditionally, BigQuery streaming in the US multi-region experienced issues coping with traffic volume once IAM recovered. BigQuery streaming in the US multi-region experienced a 55% error rate from 7:42 - 8:44 for a total impact duration of 1 hour and 56 minutes.\r\n\r\n## App Engine\r\nExperienced a 100% error rate when creating, updating, or deleting app deployments globally from 6:48 to 7:42. Public apps did not have HTTP serving affected.\r\n\r\n## Cloud Run\r\nExperienced a 100% error rate when creating, updating, or deleting deployments globally from 6:48 to 7:42. Public services did not have HTTP serving affected.\r\n\r\n## Cloud Functions\r\nExperienced a 100% error rate when creating, updating, or deleting functions with access control [2] globally from 6:48 to 7:42. Public functions did not have HTTP serving affected.\r\n\r\n[2] https://cloud.google.com/functions/docs/concepts/iam\r\n\r\n## Cloud Monitoring\r\nExperienced intermittent errors when listing workspaces via the Cloud Monitoring UI from 6:42 - 7:42.\r\n\r\n## Cloud Logging\r\nExperienced average and peak error rates of 60% for ListLogEntries API calls from 6:48 - 7:42. Affected customers received INTERNAL_ERRORs. Additionally, create, update, and delete sink calls experienced a nearly 100% error rate during the impact window. Log Ingestion and other Cloud Logging APIs were unaffected.\r\n\r\n## Cloud Dataflow\r\nExperienced 100% error rates on several administrative operations including job creation, deletion, and autoscaling from 6:55 - 7:42. \r\n\r\n## Cloud Dataproc\r\nExperienced a 100% error rate when attempting to create clusters globally from 6:50 - 7:42.\r\n\r\n## Cloud Data Fusion\r\nExperienced a 100% error rate for create instance operations globally from 6:48 - 7:42. \r\n\r\n## Cloud Composer\r\nExperienced 100% error rates when creating, updating, or deleting Cloud Composer environments globally between 6:48 - 7:42. Existing environments were unaffected.\r\n\r\n## Cloud AI Platform Notebooks\r\nExperienced elevated average error rates of 97.2% (peaking to 100%) from 6:52 - 7:48 in the following regions: asia-east1, asia-northeast1, asia-southeast1, australia-southeast1, europe-west1, northamerica-northeast1, us-central1, us-east1, us-east4, and us-west1.\r\n\r\n## Cloud KMS\r\nExperienced a 100% error rate for Create operations globally from 6:49 - 7:40.\r\n\r\n## Cloud Tasks\r\nExperienced an average error rate of 8% (up to 15%) for CreateTasks, and a 96% error rate for AddTasks in the following regions: asia-northeast3, asia-south1, australia-southeast1, europe-west1, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east4, and us-west3.. Delivery of existing tasks were unaffected, but downstream services may have experienced other issues as documented. \r\n\r\n## Cloud Scheduler\r\nExperienced 100% error rates for CreateJob and UpdateJob requests globally from 6:48 - 7:42.\r\n\r\n## App Engine Task Queues\r\nExperienced an average error rate of 18% (up to 25% at peak) for UpdateTask requests from 6:48 - 7:42.\r\n\r\n## Cloud Build\r\nExperienced no API errors, however, all builds submitted between 6:48 and 7:42 were queued until the issue was resolved.\r\n\r\n## Cloud Deployment Manager\r\nExperienced an elevated average error rate of 20%, peaking to 36% for operations globally between 6:49 and 7:39. \r\n\r\n## Data Catalogue\r\nExperienced a 100% error rate for API operations globally from 6:48 - 7:42.\r\n\r\n## Firebase Real-time Database\r\nExperienced elevated average error rates of 7% for REST API and long-polling requests (peaking to 10%) during the incident window. \r\n\r\n## Firebase Test Lab\r\nExperienced elevated average error rates of 85% (peaking to 100%) globally for Android tests running on virtual devices in Google Compute Engine instances. Impact lasted from 6:48 - 7:54 for a duration of 1 hour and 6 minutes.\r\n\r\n## Firebase Hosting\r\nExperienced a 100% error rate when creating new versions globally from 6:48 - 7:42.\r\n\r\n## Firebase Console\r\nExperienced a 100% error rate for developer resources globally. Additionally, the Firedata API experienced an average error rate of 20% for API operations from 6:48 - 7:42\r\n\r\nAffected customers experienced a range of issues related to the Firebase Console and API. API invocations returned empty lists of projects, HTTP 404 errors, affected customers were unable to create, delete, update, or list many Firebase entities including (Android, iOS, and Web Apps), hosting sites, Real-time Database instances, Firebase-linked GCP buckets. Firebase developers were also unable to update billing settings. Firebase Cloud Functions could not be deployed successfully. Some customers experienced quota exhaustion errors due to extensive retry attempts. \r\n\r\n## Cloud IoT\r\nExperienced a 100% error rate when performing DeleteRegistry API calls from 6:48 - 7:42. Though DeleteRegistry API calls threw errors, the deletions issued did complete successfully.\r\n\r\n## Cloud Memorystore\r\nExperienced a 100% error rate for create, update, cancel, delete, and ListInstances operations on Redis instances globally from 6:48 - 7:42.\r\n\r\n## Cloud Filestore\r\nExperienced an average error rate of 70% for instance and snapshot creation, update, list, and deletion operations, with a peak error rate of 92% globally between 6:48 and 7:45.\r\n\r\n## Cloud Healthcare and Cloud Life Sciences\r\nExperienced a 100% error rate for CreateDataset operations globally from 6:48 - 7:42.\r\n\r\n\r\n# SLA CREDITS\r\nIf you believe your paid application experienced an SLA violation as a result of this incident, please populate the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\r\n\r\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/.\r\n\r\nFor G Suite, please request an SLA credit through one of the Support channels: https://support.google.com/a/answer/104721\r\n\r\nG Suite Service Level Agreement can be found at https://gsuite.google.com/intl/en/terms/sla.html",
        "when": "2020-04-13T16:19:58Z"
      },
      {
        "created": "2020-04-08T15:57:50Z",
        "modified": "2020-04-08T15:57:50Z",
        "text": "As of 08:36 US/Pacific, the issue affecting multiple Google Cloud services has been resolved for all users.\r\n\r\nWe will publish an analysis of this incident once we have completed our internal investigation.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-04-08T15:57:50Z"
      },
      {
        "created": "2020-04-08T15:10:32Z",
        "modified": "2020-04-09T17:42:46Z",
        "text": "Description: We are experiencing an issue in Cloud IAM which is impacting multiple services.\r\n\r\nMitigation work is currently underway by our engineering team. We believe that most impact was mitigated at 07:40 US/Pacific, allowing many services to recover. Impact is now believed to be limited more directly to use of the IAM API.\r\n\r\nWe will provide an update by Wednesday, 2020-04-08 09:00 US/Pacific with current details.\r\n\r\nDiagnosis: App Engine, Cloud Functions, Cloud Run, Dataproc, Cloud Logging, Cloud Monitoring, Firebase Console, Cloud Build, Cloud Pub/Sub, BigQuery, Compute Engine, Cloud Tasks, Cloud Memorystore, Firebase Test Lab, Firebase Hosting, Cloud Networking, Cloud Data Fusion,  Cloud Kubernetes Engine, Cloud Composer, Cloud SQL, and Firebase Realtime Database may experience elevated error rates.\r\n\r\nAdditionally, customers may be unable to file support cases.\r\n\r\nWorkaround: Customers may continue to file cases using https://support.google.com/cloud/contact/prod_issue or via phone.",
        "when": "2020-04-08T15:10:32Z"
      },
      {
        "created": "2020-04-08T14:49:14Z",
        "modified": "2020-04-08T14:49:14Z",
        "text": "Description: We are experiencing an issue with Google Cloud infrastructure components  beginning on Wednesday, 2020-04-08 06:52 US/Pacific.\n\nSymptoms: elevated error rates across multiple products.\n\nCustomers may be experiencing an issue with Google Cloud Support in which users are unable to create new support cases.\n\nCustomers may continue to file cases using a https://support.google.com/cloud/contact/prod_issue or via phone.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Wednesday, 2020-04-08 08:15 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Customers may be unable to create new support cases.\n\nWorkaround: Customers may continue to file cases using a https://support.google.com/cloud/contact/prod_issue or via phone.",
        "when": "2020-04-08T14:49:14Z"
      },
      {
        "created": "2020-04-08T14:44:40Z",
        "modified": "2020-04-08T14:44:40Z",
        "text": "Description: We are experiencing an issue with Google Cloud infrastructure components.\n\nSymptoms: elevated error rates across multiple products.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Wednesday, 2020-04-08 08:15 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nWorkaround: None at this time.",
        "when": "2020-04-08T14:44:40Z"
      }
    ],
    "uri": "/incident/zall/20005"
  },
  {
    "begin": "2020-04-06T10:39:17Z",
    "created": "2020-04-06T10:44:39Z",
    "end": "2020-04-06T12:54:43Z",
    "external_desc": "BigQuery serving INTERNAL_ERROR in EU region",
    "modified": "2020-04-06T12:54:44Z",
    "most-recent-update": {
      "created": "2020-04-06T12:54:43Z",
      "modified": "2020-04-06T12:54:43Z",
      "text": "The issue with Google BigQuery has been resolved for all affected projects as of Monday, 2020-04-06 04:05 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-04-06T12:54:43Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "bigquery",
    "service_name": "Google BigQuery",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-04-06T12:54:43Z",
        "modified": "2020-04-06T12:54:43Z",
        "text": "The issue with Google BigQuery has been resolved for all affected projects as of Monday, 2020-04-06 04:05 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-04-06T12:54:43Z"
      },
      {
        "created": "2020-04-06T11:30:16Z",
        "modified": "2020-04-06T11:30:16Z",
        "text": "Description: We believe the issue with Google BigQuery is resolved since Monday, 2020-04-06 04:05.\n\nWe will provide an update by Monday, 2020-04-06 06:00 US/Pacific with current details.",
        "when": "2020-04-06T11:30:15Z"
      },
      {
        "created": "2020-04-06T11:16:27Z",
        "modified": "2020-04-06T11:16:27Z",
        "text": "Description: We believe the issue with Google BigQuery is resolved since Monday, 2020-04-06 04:05.\n\nWe will provide an update by Monday, 2020-04-06 04:30 US/Pacific with current details.",
        "when": "2020-04-06T11:16:27Z"
      },
      {
        "created": "2020-04-06T10:51:27Z",
        "modified": "2020-04-06T10:51:27Z",
        "text": "Description: We believe the issue with Google BigQuery is resolved since Monday, 2020-04-06 03:30.\n\nWe will provide an update by Monday, 2020-04-06 04:15 US/Pacific with current details.",
        "when": "2020-04-06T10:51:27Z"
      },
      {
        "created": "2020-04-06T10:44:41Z",
        "modified": "2020-04-06T10:44:41Z",
        "text": "Description: We are experiencing an issue with Google BigQuery.\n\nSymptoms: BigQuery serves INTERNAL_ERROR to customers.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Monday, 2020-04-06 04:15 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.",
        "when": "2020-04-06T10:44:41Z"
      }
    ],
    "uri": "/incident/bigquery/20003"
  },
  {
    "begin": "2020-03-31T00:52:05Z",
    "created": "2020-03-31T01:06:57Z",
    "end": "2020-03-31T14:45:56Z",
    "external_desc": "We are experiencing an intermittent issue with Google Cloud infrastructure components.",
    "modified": "2020-03-31T14:45:56Z",
    "most-recent-update": {
      "created": "2020-03-31T14:45:56Z",
      "modified": "2020-03-31T14:45:56Z",
      "text": "The issue with Google Cloud infrastructure components has been resolved for all affected users as of Tuesday, 2020-03-31 07:45 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-31T14:45:56Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-31T14:45:56Z",
        "modified": "2020-03-31T14:45:56Z",
        "text": "The issue with Google Cloud infrastructure components has been resolved for all affected users as of Tuesday, 2020-03-31 07:45 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-31T14:45:56Z"
      },
      {
        "created": "2020-03-31T13:22:06Z",
        "modified": "2020-03-31T13:22:06Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe will provide more information by Tuesday, 2020-03-31 07:45 US/Pacific.\n\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T13:22:06Z"
      },
      {
        "created": "2020-03-31T12:44:06Z",
        "modified": "2020-03-31T12:44:06Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe will provide more information by Tuesday, 2020-03-31 06:45 US/Pacific.\n\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T12:44:06Z"
      },
      {
        "created": "2020-03-31T11:40:47Z",
        "modified": "2020-03-31T11:40:47Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe will provide more information by Tuesday, 2020-03-31 05:30 US/Pacific.\n\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T11:40:47Z"
      },
      {
        "created": "2020-03-31T10:26:14Z",
        "modified": "2020-03-31T10:26:14Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe will provide more information by Tuesday, 2020-03-31 04:30 US/Pacific.\n\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T10:26:14Z"
      },
      {
        "created": "2020-03-31T09:32:49Z",
        "modified": "2020-03-31T09:32:49Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe will provide more information by Tuesday, 2020-03-31 03:30 US/Pacific.\n\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T09:32:49Z"
      },
      {
        "created": "2020-03-31T08:31:40Z",
        "modified": "2020-03-31T08:31:40Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe will provide more information by Tuesday, 2020-03-31 02:30 US/Pacific.\n\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T08:31:40Z"
      },
      {
        "created": "2020-03-31T07:09:19Z",
        "modified": "2020-03-31T07:09:19Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe will provide more information by Tuesday, 2020-03-31 01:30 US/Pacific.\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T07:09:19Z"
      },
      {
        "created": "2020-03-31T05:29:18Z",
        "modified": "2020-03-31T05:29:18Z",
        "text": "Description: Mitigation work is still underway by our engineering team.\n\nWe will provide more information by Tuesday, 2020-03-31 00:15 US/Pacific.\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T05:29:18Z"
      },
      {
        "created": "2020-03-31T04:22:10Z",
        "modified": "2020-03-31T04:22:10Z",
        "text": "Description: Our current data indicates that error rates have decreased with intermittent spikes. Our engineering team is continuing the mitigation for a full resolution.\n\nWe will provide more information by Monday, 2020-03-30 22:30 US/Pacific.\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T04:22:10Z"
      },
      {
        "created": "2020-03-31T02:58:32Z",
        "modified": "2020-03-31T02:58:32Z",
        "text": "Description: Mitigation work is still underway by our engineering team. Current data indicates that error rates are decreasing globally.\n\nWe will provide more information by Monday, 2020-03-30 21:15 US/Pacific.\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T02:58:32Z"
      },
      {
        "created": "2020-03-31T02:12:28Z",
        "modified": "2020-03-31T02:12:28Z",
        "text": "Description: Mitigation work is currently underway by our engineering team.\n\nWe will provide more information by Monday, 2020-03-30 20:00 US/Pacific.\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T02:12:28Z"
      },
      {
        "created": "2020-03-31T01:50:23Z",
        "modified": "2020-03-31T01:50:23Z",
        "text": "Description: We are experiencing an issue with Google Cloud infrastructure components.\n\nSymptoms: intermittent Cloud SQL instance creation and deletion failures, and elevated error rates across multiple Google Cloud Platform services.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Monday, 2020-03-30 19:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Affected customers will experience intermittent failures in Cloud SQL instance creations and deletions, and increased error rates in related products which include: Cloud SQL, Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T01:50:23Z"
      },
      {
        "created": "2020-03-31T01:06:57Z",
        "modified": "2020-03-31T01:06:57Z",
        "text": "Description: We are experiencing an issue with Google Cloud infrastructure components.\n\nSymptoms: Cloud SQL instance creation failures, and elevated error rates across multiple Google Cloud Platform services.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Monday, 2020-03-30 19:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Affected customers will experience failures in Cloud SQL instance creations, and increased error rates in related products which include: Cloud Data Fusion, and Cloud Composer.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T01:06:57Z"
      }
    ],
    "uri": "/incident/zall/20004"
  },
  {
    "begin": "2020-03-31T00:24:55Z",
    "created": "2020-03-31T00:47:20Z",
    "end": "2020-03-31T14:37:15Z",
    "external_desc": "We've received a report of an issue with Cloud Composer.",
    "modified": "2020-03-31T14:37:15Z",
    "most-recent-update": {
      "created": "2020-03-31T14:37:15Z",
      "modified": "2020-03-31T14:37:15Z",
      "text": "The issue with Cloud Composer has been resolved for all affected users as of Tuesday, 2020-03-31 07:35 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-31T14:37:15Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "composer",
    "service_name": "Google Cloud Composer",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-31T14:37:15Z",
        "modified": "2020-03-31T14:37:15Z",
        "text": "The issue with Cloud Composer has been resolved for all affected users as of Tuesday, 2020-03-31 07:35 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-31T14:37:15Z"
      },
      {
        "created": "2020-03-31T13:19:55Z",
        "modified": "2020-03-31T13:19:55Z",
        "text": "Description: Mitigation work is underway by our engineering team.\n\nWe already see Cloud Composer Environment creations succeeding.\n\nWe will provide more information by Tuesday, 2020-03-31 07:42 US/Pacific.\n\nDiagnosis: Impacted customers will experience failures in Cloud Composer Environment creations.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T13:19:55Z"
      },
      {
        "created": "2020-03-31T01:17:59Z",
        "modified": "2020-03-31T01:17:59Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please\nvisit [https://status.cloud.google.com/incident/zall/20004](https://status.cloud.google.com/incident/zall/20004).  No further updates will be made through\nthis incident. We will provide an update by Monday, 2020-03-30 19:00 US/Pacific with current details.\n\n\nDiagnosis: Impacted customers will experience failures in Cloud Composer Environment creations.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T01:17:59Z"
      },
      {
        "created": "2020-03-31T01:14:59Z",
        "modified": "2020-03-31T01:19:42Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please\r\nvisit [https://status.cloud.google.com/incident/zall/20004](https://status.cloud.google.com/incident/zall/20004).  No further updates will be made through\r\nthis incident. We will provide an update by Monday, 2020-03-30 19:00 US/Pacific with current details.\r\n\r\n\r\nDiagnosis: Impacted customers will experience failures in Cloud Composer Environment creations.\r\n\r\nWorkaround: None at this time.",
        "when": "2020-03-31T01:14:59Z"
      },
      {
        "created": "2020-03-31T00:47:21Z",
        "modified": "2020-03-31T00:47:21Z",
        "text": "Description: We are experiencing an issue with Cloud Composer.\n\nSymptoms: increased error rates on environment creations.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Monday, 2020-03-30 18:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Impacted customers will experience failures in Cloud Composer Environment creations.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T00:47:21Z"
      }
    ],
    "uri": "/incident/composer/20004"
  },
  {
    "begin": "2020-03-31T00:18:01Z",
    "created": "2020-03-31T00:38:26Z",
    "end": "2020-03-31T13:58:37Z",
    "external_desc": "We've received a report of an issue with Cloud SQL.",
    "modified": "2020-03-31T13:58:37Z",
    "most-recent-update": {
      "created": "2020-03-31T13:58:37Z",
      "modified": "2020-03-31T13:58:37Z",
      "text": "Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20004](https://status.cloud.google.com/incident/zall/20004). No further updates will be made through this incident.",
      "when": "2020-03-31T13:58:37Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "cloud-sql",
    "service_name": "Google Cloud SQL",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-31T13:58:37Z",
        "modified": "2020-03-31T13:58:37Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20004](https://status.cloud.google.com/incident/zall/20004). No further updates will be made through this incident.",
        "when": "2020-03-31T13:58:37Z"
      },
      {
        "created": "2020-03-31T01:02:37Z",
        "modified": "2020-03-31T01:02:37Z",
        "text": "Description: We are experiencing an issue with Cloud SQL.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Monday, 2020-03-30 19:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\n\nDiagnosis: Impacted customers will experience failures in Cloud SQL instance creations.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T01:02:37Z"
      },
      {
        "created": "2020-03-31T00:38:27Z",
        "modified": "2020-03-31T00:38:27Z",
        "text": "Description: We are experiencing an issue with Cloud SQL.\n\nSymptoms: increased error rates in creation requests.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Monday, 2020-03-30 18:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Impacted customers will experience failures in Cloud SQL instance creations.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T00:38:27Z"
      }
    ],
    "uri": "/incident/cloud-sql/20003"
  },
  {
    "begin": "2020-03-31T00:11:24Z",
    "created": "2020-03-31T00:45:45Z",
    "end": "2020-03-31T14:01:01Z",
    "external_desc": "We've received a report of an issue with Cloud Data Fusion.",
    "modified": "2020-03-31T14:01:01Z",
    "most-recent-update": {
      "created": "2020-03-31T14:01:01Z",
      "modified": "2020-03-31T14:01:01Z",
      "text": "Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please\nvisit [https://status.cloud.google.com/incident/zall/20004](https://status.cloud.google.com/incident/zall/20004).  No further updates will be made through this incident.",
      "when": "2020-03-31T14:01:01Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-data-fusion",
    "service_name": "Cloud Data Fusion",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-31T14:01:01Z",
        "modified": "2020-03-31T14:01:01Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please\nvisit [https://status.cloud.google.com/incident/zall/20004](https://status.cloud.google.com/incident/zall/20004).  No further updates will be made through this incident.",
        "when": "2020-03-31T14:01:01Z"
      },
      {
        "created": "2020-03-31T00:45:45Z",
        "modified": "2020-03-31T00:45:45Z",
        "text": "Description: We are experiencing an issue with Cloud Data Fusion.\n\nSymptoms: increased error rates in instance creations.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Monday, 2020-03-30 18:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Impacted customers will experience failures in Cloud Data Fusion instance creations.\n\nWorkaround: None at this time.",
        "when": "2020-03-31T00:45:45Z"
      }
    ],
    "uri": "/incident/cloud-data-fusion/20002"
  },
  {
    "begin": "2020-03-27T20:26:03Z",
    "created": "2020-03-27T20:28:16Z",
    "end": "2020-03-27T21:15:45Z",
    "external_desc": "We are investigating reports of connectivity issues between GCP regions us-east4 and us-east1 to other Cloud Providers in similar geographies.",
    "modified": "2020-03-27T21:15:45Z",
    "most-recent-update": {
      "created": "2020-03-27T21:15:45Z",
      "modified": "2020-03-27T21:15:45Z",
      "text": "The issue with connectivity between the GCP us-east1, us-east4, and us-central1 regions to other Cloud Providers has been resolved for all affected projects as of Friday, 2020-03-27 13:37 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T21:15:45Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "cloud-networking",
    "service_name": "Google Cloud Networking",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T21:15:45Z",
        "modified": "2020-03-27T21:15:45Z",
        "text": "The issue with connectivity between the GCP us-east1, us-east4, and us-central1 regions to other Cloud Providers has been resolved for all affected projects as of Friday, 2020-03-27 13:37 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T21:15:45Z"
      },
      {
        "created": "2020-03-27T21:00:00Z",
        "modified": "2020-03-27T21:00:00Z",
        "text": "Description: We have applied mitigation actions and believe the connectivity issue between the GCP us-east1, us-east4 and us-central1 regions to other Cloud Providers is partially resolved. The issue first began at 2020-03-27 12:24 US/Pacific.\n\nWe are seeing error rates decrease.\n\nWe will provide more information by Friday, 2020-03-27 14:45 US/Pacific.\n\n\nDiagnosis: Customers may experience increased latency or connection timeouts between GCP and other Cloud Providers.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T21:00:00Z"
      },
      {
        "created": "2020-03-27T20:28:17Z",
        "modified": "2020-03-27T20:28:17Z",
        "text": "Description: We are investigating reports of Connectivity issues between GCP regions us-east4 and us-east1 experiencing issues connecting to other Cloud Providers in similar geographies.\n\nWe will provide more information by Friday, 2020-03-27 14:00 US/Pacific.\n\n\nDiagnosis: Customers may experience increased latency or connection timeouts between GCP and other Cloud Providers.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T20:28:17Z"
      }
    ],
    "uri": "/incident/cloud-networking/20004"
  },
  {
    "begin": "2020-03-27T03:15:54Z",
    "created": "2020-03-27T03:15:55Z",
    "end": "2020-03-27T13:55:10Z",
    "external_desc": "We Are Investigating an Issue with the Cloud Console",
    "modified": "2020-03-27T13:55:10Z",
    "most-recent-update": {
      "created": "2020-03-27T13:55:10Z",
      "modified": "2020-03-27T13:55:10Z",
      "text": "The issue with Cloud Console has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T13:55:10Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "developers-console",
    "service_name": "Google Cloud Console",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T13:55:10Z",
        "modified": "2020-03-27T13:55:10Z",
        "text": "The issue with Cloud Console has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T13:55:10Z"
      },
      {
        "created": "2020-03-27T05:17:50Z",
        "modified": "2020-03-27T05:17:50Z",
        "text": "The issue with Cloud Run has been resolved for all affected projects as of Thursday, 2020-03-26 21:25 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T05:00:00Z"
      },
      {
        "created": "2020-03-27T03:15:55Z",
        "modified": "2020-03-27T03:15:55Z",
        "text": "Description: We are investigating an issue with the Cloud Console beginning on Thursday, 2020-03-26 16:50 US/Pacific.  \n\nOur engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.\n\n\n\nWorkaround: None at this time",
        "when": "2020-03-27T03:15:55Z"
      }
    ],
    "uri": "/incident/developers-console/20004"
  },
  {
    "begin": "2020-03-27T02:55:17Z",
    "created": "2020-03-27T02:55:21Z",
    "end": "2020-03-27T03:31:56Z",
    "external_desc": "We are investigating an issue in Cloud Console",
    "modified": "2020-03-27T03:31:57Z",
    "most-recent-update": {
      "created": "2020-03-27T03:31:56Z",
      "modified": "2020-03-27T03:31:56Z",
      "text": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003).",
      "when": "2020-03-27T03:31:56Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "developers-console",
    "service_name": "Google Cloud Console",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T03:31:56Z",
        "modified": "2020-03-27T03:31:56Z",
        "text": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003).",
        "when": "2020-03-27T03:31:56Z"
      },
      {
        "created": "2020-03-27T02:55:22Z",
        "modified": "2020-03-27T02:55:22Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.\n\nDiagnosis: Impacted customers will experience errors while using Cloud Console\n\nWorkaround: None at this time",
        "when": "2020-03-27T02:55:22Z"
      }
    ],
    "uri": "/incident/developers-console/20003"
  },
  {
    "begin": "2020-03-27T02:48:47Z",
    "created": "2020-03-27T03:00:41Z",
    "end": "2020-03-27T13:56:41Z",
    "external_desc": "We've received a report of an issue with Google Compute Engine.",
    "modified": "2020-03-27T13:56:41Z",
    "most-recent-update": {
      "created": "2020-03-27T13:56:41Z",
      "modified": "2020-03-27T13:56:41Z",
      "text": "The issue with Google Compute Engine has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T13:56:41Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T13:56:41Z",
        "modified": "2020-03-27T13:56:41Z",
        "text": "The issue with Google Compute Engine has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T13:56:41Z"
      },
      {
        "created": "2020-03-27T05:16:06Z",
        "modified": "2020-03-27T05:16:06Z",
        "text": "The issue with Cloud Run has been resolved for all affected projects as of Thursday, 2020-03-26 21:25 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T05:00:00Z"
      },
      {
        "created": "2020-03-27T03:00:41Z",
        "modified": "2020-03-27T03:00:41Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T03:00:41Z"
      }
    ],
    "uri": "/incident/compute/20003"
  },
  {
    "begin": "2020-03-27T01:17:11Z",
    "created": "2020-03-27T01:19:20Z",
    "end": "2020-03-27T13:57:51Z",
    "external_desc": "We are experiencing an issue with Google Cloud SQL globally.",
    "modified": "2020-03-27T13:57:51Z",
    "most-recent-update": {
      "created": "2020-03-27T13:57:51Z",
      "modified": "2020-03-27T13:57:51Z",
      "text": "The issue with Cloud SQL has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T13:57:51Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-sql",
    "service_name": "Google Cloud SQL",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T13:57:51Z",
        "modified": "2020-03-27T13:57:51Z",
        "text": "The issue with Cloud SQL has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T13:57:51Z"
      },
      {
        "created": "2020-03-27T01:19:20Z",
        "modified": "2020-03-27T01:19:20Z",
        "text": "Description: We are experiencing an issue with Google Cloud SQL globally.\n\nOur engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.\n\nDiagnosis: Cloud SQL database creation is failing.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T01:19:20Z"
      }
    ],
    "uri": "/incident/cloud-sql/20001"
  },
  {
    "begin": "2020-03-27T01:09:00Z",
    "created": "2020-03-27T01:54:28Z",
    "end": "2020-03-27T14:01:39Z",
    "external_desc": "Cloud SQL environment creations are failing globally.",
    "modified": "2020-03-27T14:01:39Z",
    "most-recent-update": {
      "created": "2020-03-27T14:01:39Z",
      "modified": "2020-03-27T14:01:39Z",
      "text": "The issue with Cloud SQL environment creation has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T14:01:39Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-sql",
    "service_name": "Google Cloud SQL",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T14:01:39Z",
        "modified": "2020-03-27T14:01:39Z",
        "text": "The issue with Cloud SQL environment creation has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T14:01:39Z"
      },
      {
        "created": "2020-03-27T09:23:04Z",
        "modified": "2020-03-27T09:23:04Z",
        "text": "Description: Our engineers have established that the issue is related to the ongoing incident with Google Cloud infrastructure components beginning on Thursday, 2020-03-26 16:50 US/Pacific. For regular status updates on the incident, please visit https://status.cloud.google.com/incident/zall/20003\r\n\r\nDiagnosis: Cloud SQL new instance and replica creation may intermittently fail\r\n\r\nWorkaround: None at this time.",
        "when": "2020-03-27T09:23:04Z"
      },
      {
        "created": "2020-03-27T01:54:29Z",
        "modified": "2020-03-27T09:23:31Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.\r\n\r\nDiagnosis: Cloud SQL new instance and replica creation may intermittently fail\r\n\r\nWorkaround: None at this time.",
        "when": "2020-03-27T01:54:29Z"
      }
    ],
    "uri": "/incident/cloud-sql/20002"
  },
  {
    "begin": "2020-03-27T01:05:00Z",
    "created": "2020-03-27T01:05:34Z",
    "end": "2020-03-27T02:19:36Z",
    "external_desc": "We have received a report of an issue with Google Cloud AI.",
    "modified": "2020-03-27T02:19:37Z",
    "most-recent-update": {
      "created": "2020-03-27T02:19:36Z",
      "modified": "2020-03-27T02:19:36Z",
      "text": "The issue with Cloud AI has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T02:19:36Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-ml",
    "service_name": "Cloud Machine Learning",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T02:19:36Z",
        "modified": "2020-03-27T02:19:36Z",
        "text": "The issue with Cloud AI has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T02:19:36Z"
      },
      {
        "created": "2020-03-27T01:05:34Z",
        "modified": "2020-03-27T01:05:34Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T01:05:34Z"
      }
    ],
    "uri": "/incident/cloud-ml/20002"
  },
  {
    "begin": "2020-03-27T01:04:58Z",
    "created": "2020-03-27T01:04:58Z",
    "end": "2020-03-27T14:20:05Z",
    "external_desc": "We are experiencing an issue with Cloud Identity & Security beginning at Thursday, 2020-03-26 16:50 US/Pacific",
    "modified": "2020-03-27T14:20:05Z",
    "most-recent-update": {
      "created": "2020-03-27T14:20:05Z",
      "modified": "2020-03-27T14:20:05Z",
      "text": "The issue with Cloud Identity & Security has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T14:20:05Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-iam",
    "service_name": "Identity and Access Management",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T14:20:05Z",
        "modified": "2020-03-27T14:20:05Z",
        "text": "The issue with Cloud Identity & Security has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T14:20:05Z"
      },
      {
        "created": "2020-03-27T01:04:59Z",
        "modified": "2020-03-27T01:04:59Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-03-27T01:04:59Z"
      }
    ],
    "uri": "/incident/cloud-iam/20001"
  },
  {
    "begin": "2020-03-27T01:01:00Z",
    "created": "2020-03-27T01:01:08Z",
    "end": "2020-03-27T01:55:14Z",
    "external_desc": "We have received a report of issues with Google Compute Engine.",
    "modified": "2020-03-27T01:55:15Z",
    "most-recent-update": {
      "created": "2020-03-27T01:55:15Z",
      "modified": "2020-03-27T01:55:15Z",
      "text": "The issue with Compute Engine has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:55:14Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "compute",
    "service_name": "Google Compute Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:55:15Z",
        "modified": "2020-03-27T01:55:15Z",
        "text": "The issue with Compute Engine has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:55:14Z"
      },
      {
        "created": "2020-03-27T01:01:09Z",
        "modified": "2020-03-27T01:01:09Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T01:01:09Z"
      }
    ],
    "uri": "/incident/compute/20002"
  },
  {
    "begin": "2020-03-27T00:51:00Z",
    "created": "2020-03-27T00:52:23Z",
    "end": "2020-03-27T01:33:10Z",
    "external_desc": "We've received a report of an issue with Cloud Dataflow.",
    "modified": "2020-03-27T01:33:10Z",
    "most-recent-update": {
      "created": "2020-03-27T01:33:10Z",
      "modified": "2020-03-27T01:33:10Z",
      "text": "The issue with Cloud Dataflow has been resolved for all affected users as of Thursday, 2020-03-26 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:33:10Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-dataflow",
    "service_name": "Google Cloud Dataflow",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:33:10Z",
        "modified": "2020-03-27T01:33:10Z",
        "text": "The issue with Cloud Dataflow has been resolved for all affected users as of Thursday, 2020-03-26 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:33:10Z"
      },
      {
        "created": "2020-03-27T01:22:12Z",
        "modified": "2020-03-27T01:22:12Z",
        "text": "We believe the issue with Cloud Dataflow is partially resolved.\r\nWe do not have an ETA for full resolution at this point.\r\n\r\nWe will provide an update by Thursday, 2020-03-26 20:00 US/Pacific with current details.",
        "when": "2020-03-27T01:22:12Z"
      },
      {
        "created": "2020-03-27T00:52:24Z",
        "modified": "2020-03-27T00:52:24Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:52:24Z"
      }
    ],
    "uri": "/incident/cloud-dataflow/20002"
  },
  {
    "begin": "2020-03-27T00:40:38Z",
    "created": "2020-03-27T00:47:13Z",
    "end": "2020-03-27T01:27:44Z",
    "external_desc": "The issue with Cloud Key Management Service is believed to be linked to a single Google incident.",
    "modified": "2020-03-27T01:27:44Z",
    "most-recent-update": {
      "created": "2020-03-27T01:27:44Z",
      "modified": "2020-03-27T01:27:44Z",
      "text": "The issue with Cloud Key Management Service has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:27:44Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-kms",
    "service_name": "Cloud Key Management Service",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:27:44Z",
        "modified": "2020-03-27T01:27:44Z",
        "text": "The issue with Cloud Key Management Service has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:27:44Z"
      },
      {
        "created": "2020-03-27T00:47:13Z",
        "modified": "2020-03-27T00:47:13Z",
        "text": "Description: The issue with Cloud Key Management Service beginning on Thursday, 2020-03-26 16:50 US/Pacific is believed to be linked to a single Google incident.\n\nFor regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003).\n\nAn update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:47:13Z"
      }
    ],
    "uri": "/incident/cloud-kms/20001"
  },
  {
    "begin": "2020-03-27T00:39:38Z",
    "created": "2020-03-27T00:45:39Z",
    "end": "2020-03-27T02:10:55Z",
    "external_desc": "We've received a report of an issue with Cloud Asset Inventory.",
    "modified": "2020-03-27T02:10:56Z",
    "most-recent-update": {
      "created": "2020-03-27T02:10:56Z",
      "modified": "2020-03-27T02:10:56Z",
      "text": "The issue with Cloud Asset Inventory has been resolved for all affected projects as of Thursday, 2020-03-26 19:10 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T02:10:55Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "asset-inventory",
    "service_name": "Cloud Asset Inventory",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T02:10:56Z",
        "modified": "2020-03-27T02:10:56Z",
        "text": "The issue with Cloud Asset Inventory has been resolved for all affected projects as of Thursday, 2020-03-26 19:10 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T02:10:55Z"
      },
      {
        "created": "2020-03-27T00:45:39Z",
        "modified": "2020-03-27T00:45:39Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:45:39Z"
      }
    ],
    "uri": "/incident/asset-inventory/20001"
  },
  {
    "begin": "2020-03-27T00:37:23Z",
    "created": "2020-03-27T00:47:23Z",
    "end": "2020-03-27T01:42:25Z",
    "external_desc": "We've received a report of an issue with Cloud Networking.",
    "modified": "2020-03-27T01:42:26Z",
    "most-recent-update": {
      "created": "2020-03-27T01:42:26Z",
      "modified": "2020-03-27T01:42:26Z",
      "text": "The issue with Cloud Networking has been resolved for all affected users as of Thursday, 2020-03-26 18:36 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:42:25Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "cloud-networking",
    "service_name": "Google Cloud Networking",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:42:26Z",
        "modified": "2020-03-27T01:42:26Z",
        "text": "The issue with Cloud Networking has been resolved for all affected users as of Thursday, 2020-03-26 18:36 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:42:25Z"
      },
      {
        "created": "2020-03-27T00:47:23Z",
        "modified": "2020-03-27T00:47:23Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T00:47:23Z"
      }
    ],
    "uri": "/incident/cloud-networking/20003"
  },
  {
    "begin": "2020-03-27T00:36:46Z",
    "created": "2020-03-27T00:39:45Z",
    "end": "2020-03-27T13:59:52Z",
    "external_desc": "We've received a report of an issue with Cloud Data Fusion.",
    "modified": "2020-03-27T13:59:52Z",
    "most-recent-update": {
      "created": "2020-03-27T13:59:52Z",
      "modified": "2020-03-27T13:59:52Z",
      "text": "The issue with Cloud Data Fusion has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T13:59:52Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-data-fusion",
    "service_name": "Cloud Data Fusion",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T13:59:52Z",
        "modified": "2020-03-27T13:59:52Z",
        "text": "The issue with Cloud Data Fusion has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T13:59:52Z"
      },
      {
        "created": "2020-03-27T03:02:15Z",
        "modified": "2020-03-27T03:02:15Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 23:00 US/Pacific.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T03:02:15Z"
      },
      {
        "created": "2020-03-27T00:39:45Z",
        "modified": "2020-03-27T00:39:45Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:39:45Z"
      }
    ],
    "uri": "/incident/cloud-data-fusion/20001"
  },
  {
    "begin": "2020-03-27T00:35:18Z",
    "created": "2020-03-27T00:37:43Z",
    "end": "2020-03-27T14:04:05Z",
    "external_desc": "Cloud Composer environment creations are failing globally.",
    "modified": "2020-03-27T14:04:05Z",
    "most-recent-update": {
      "created": "2020-03-27T14:04:05Z",
      "modified": "2020-03-27T14:04:05Z",
      "text": "The issue with Cloud Composer has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T14:04:05Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "composer",
    "service_name": "Google Cloud Composer",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T14:04:05Z",
        "modified": "2020-03-27T14:04:05Z",
        "text": "The issue with Cloud Composer has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T14:04:05Z"
      },
      {
        "created": "2020-03-27T00:37:43Z",
        "modified": "2020-03-27T00:37:43Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.\n\nDiagnosis: Cloud Composer environment creations are failing globally.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T00:37:43Z"
      }
    ],
    "uri": "/incident/composer/20003"
  },
  {
    "begin": "2020-03-27T00:34:30Z",
    "created": "2020-03-27T00:38:26Z",
    "end": "2020-03-27T01:45:36Z",
    "external_desc": "We've received a report of an issue with Cloud Spanner.",
    "modified": "2020-03-27T01:45:36Z",
    "most-recent-update": {
      "created": "2020-03-27T01:45:36Z",
      "modified": "2020-03-27T01:45:36Z",
      "text": "The issue with Cloud Spanner has been resolved for all affected projects as of Thursday, 2020-03-26 18:45 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:45:36Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-spanner",
    "service_name": "Cloud Spanner",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:45:36Z",
        "modified": "2020-03-27T01:45:36Z",
        "text": "The issue with Cloud Spanner has been resolved for all affected projects as of Thursday, 2020-03-26 18:45 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:45:36Z"
      },
      {
        "created": "2020-03-27T00:38:27Z",
        "modified": "2020-03-27T00:38:27Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:38:27Z"
      }
    ],
    "uri": "/incident/cloud-spanner/20002"
  },
  {
    "begin": "2020-03-27T00:32:29Z",
    "created": "2020-03-27T00:40:14Z",
    "end": "2020-03-27T01:44:22Z",
    "external_desc": "We've received a report of an issue with Google Cloud Storage.",
    "modified": "2020-03-27T01:44:22Z",
    "most-recent-update": {
      "created": "2020-03-27T01:44:22Z",
      "modified": "2020-03-27T01:44:22Z",
      "text": "The issue with Google Cloud Storage has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:44:22Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "storage",
    "service_name": "Google Cloud Storage",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:44:22Z",
        "modified": "2020-03-27T01:44:22Z",
        "text": "The issue with Google Cloud Storage has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:44:22Z"
      },
      {
        "created": "2020-03-27T00:40:15Z",
        "modified": "2020-03-27T00:40:15Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:40:14Z"
      }
    ],
    "uri": "/incident/storage/20002"
  },
  {
    "begin": "2020-03-27T00:27:07Z",
    "created": "2020-03-27T00:39:13Z",
    "end": "2020-03-27T13:32:07Z",
    "external_desc": "We've received a report of an issue with Cloud Run.",
    "modified": "2020-03-27T15:03:24Z",
    "most-recent-update": {
      "created": "2020-03-27T15:03:07Z",
      "modified": "2020-03-27T15:03:07Z",
      "text": "The issue with Cloud Run has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T15:03:07Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-run",
    "service_name": "Cloud Run",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T15:03:07Z",
        "modified": "2020-03-27T15:03:07Z",
        "text": "The issue with Cloud Run has been resolved for all affected users as of Friday, 2020-03-27 06:32 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T15:03:07Z"
      },
      {
        "created": "2020-03-27T02:58:18Z",
        "modified": "2020-03-27T02:58:18Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T02:58:18Z"
      },
      {
        "created": "2020-03-27T01:41:57Z",
        "modified": "2020-03-27T01:41:57Z",
        "text": "Description: We believe the issue with Cloud Run is partially resolved.\n\nWe do not have an ETA for full resolution at this point.\n\nWe will provide an update by Thursday, 2020-03-26 20:00 US/Pacific with current details.",
        "when": "2020-03-27T01:41:57Z"
      },
      {
        "created": "2020-03-27T00:39:13Z",
        "modified": "2020-03-27T00:39:13Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:39:13Z"
      }
    ],
    "uri": "/incident/cloud-run/20001"
  },
  {
    "begin": "2020-03-27T00:25:08Z",
    "created": "2020-03-27T00:41:52Z",
    "end": "2020-03-27T01:26:20Z",
    "external_desc": "The issue with Cloud Memorystore is believed to be linked to a single Google incident. ",
    "modified": "2020-03-27T01:26:21Z",
    "most-recent-update": {
      "created": "2020-03-27T01:26:20Z",
      "modified": "2020-03-27T01:26:20Z",
      "text": "The issue with Cloud Memorystore has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:26:20Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-memorystore",
    "service_name": "Cloud Memorystore",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:26:20Z",
        "modified": "2020-03-27T01:26:20Z",
        "text": "The issue with Cloud Memorystore has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:26:20Z"
      },
      {
        "created": "2020-03-27T00:41:52Z",
        "modified": "2020-03-27T00:41:52Z",
        "text": "Description: The issue with Cloud Memorystore beginning on Thursday, 2020-03-26 16:50 US/Pacific is believed to be linked to a single Google incident. \n\nFor regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003).\n\nAn update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:41:52Z"
      }
    ],
    "uri": "/incident/cloud-memorystore/20001"
  },
  {
    "begin": "2020-03-27T00:18:28Z",
    "created": "2020-03-27T00:37:22Z",
    "end": "2020-03-27T02:15:21Z",
    "external_desc": "We've received a report of an issue with Cloud Dataproc.",
    "modified": "2020-03-27T02:15:21Z",
    "most-recent-update": {
      "created": "2020-03-27T02:15:21Z",
      "modified": "2020-03-27T02:15:21Z",
      "text": "The issue with Cloud Dataproc has been resolved for all affected users as of Thursday, 2020-03-26 18:56 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T02:15:21Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-dataproc",
    "service_name": "Google Cloud Dataproc",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T02:15:21Z",
        "modified": "2020-03-27T02:15:21Z",
        "text": "The issue with Cloud Dataproc has been resolved for all affected users as of Thursday, 2020-03-26 18:56 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T02:15:21Z"
      },
      {
        "created": "2020-03-27T00:37:22Z",
        "modified": "2020-03-27T00:37:22Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:37:22Z"
      }
    ],
    "uri": "/incident/cloud-dataproc/20002"
  },
  {
    "begin": "2020-03-27T00:16:29Z",
    "created": "2020-03-27T00:50:53Z",
    "end": "2020-03-27T01:31:36Z",
    "external_desc": "Cloud Composer environment creations are failing globally.",
    "modified": "2020-03-27T01:31:36Z",
    "most-recent-update": {
      "created": "2020-03-27T01:31:36Z",
      "modified": "2020-03-27T01:31:36Z",
      "text": "The issue with Cloud Monitoring has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:31:36Z"
    },
    "number": 20004,
    "public": true,
    "service_key": "google-stackdriver",
    "service_name": "Operations",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:31:36Z",
        "modified": "2020-03-27T01:31:36Z",
        "text": "The issue with Cloud Monitoring has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:31:36Z"
      },
      {
        "created": "2020-03-27T00:50:54Z",
        "modified": "2020-03-27T00:50:54Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.\n\nDiagnosis: Cloud Composer environment creations are failing globally.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T00:50:54Z"
      }
    ],
    "uri": "/incident/google-stackdriver/20004"
  },
  {
    "begin": "2020-03-27T00:16:11Z",
    "created": "2020-03-27T00:36:09Z",
    "end": "2020-03-27T02:08:29Z",
    "external_desc": "We've received a report of an issue with Google Kubernetes Engine.",
    "modified": "2020-03-27T02:08:29Z",
    "most-recent-update": {
      "created": "2020-03-27T02:08:29Z",
      "modified": "2020-03-27T02:08:29Z",
      "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T02:08:29Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T02:08:29Z",
        "modified": "2020-03-27T02:08:29Z",
        "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T02:08:29Z"
      },
      {
        "created": "2020-03-27T00:36:09Z",
        "modified": "2020-03-27T00:36:09Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:36:09Z"
      }
    ],
    "uri": "/incident/container-engine/20002"
  },
  {
    "begin": "2020-03-27T00:13:51Z",
    "created": "2020-03-27T00:39:18Z",
    "end": "2020-03-27T01:24:38Z",
    "external_desc": "The issue with Google App Engine is believed to be linked to a single Google incident. ",
    "modified": "2020-03-27T01:24:39Z",
    "most-recent-update": {
      "created": "2020-03-27T01:24:38Z",
      "modified": "2020-03-27T01:24:38Z",
      "text": "The issue with Google App Engine has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:24:38Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "appengine",
    "service_name": "Google App Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:24:38Z",
        "modified": "2020-03-27T01:24:38Z",
        "text": "The issue with Google App Engine has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:24:38Z"
      },
      {
        "created": "2020-03-27T00:39:19Z",
        "modified": "2020-03-27T00:39:19Z",
        "text": "Description: The issue with Google App Engine beginning on Thursday, 2020-03-26 16:50 US/Pacific is believed to be linked to a single Google incident. \n\nFor regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003).\n\nAn update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:39:19Z"
      }
    ],
    "uri": "/incident/appengine/20002"
  },
  {
    "begin": "2020-03-27T00:12:51Z",
    "created": "2020-03-27T00:34:33Z",
    "end": "2020-03-27T01:23:25Z",
    "external_desc": "The issue with Cloud Pub/Sub is believed to be linked to a single Google Incident",
    "modified": "2020-03-27T01:23:25Z",
    "most-recent-update": {
      "created": "2020-03-27T01:23:25Z",
      "modified": "2020-03-27T01:23:25Z",
      "text": "The issue with Cloud Pub/Sub has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:23:25Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-pubsub",
    "service_name": "Google Cloud Pub/Sub",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:23:25Z",
        "modified": "2020-03-27T01:23:25Z",
        "text": "The issue with Cloud Pub/Sub has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:23:25Z"
      },
      {
        "created": "2020-03-27T00:40:00Z",
        "modified": "2020-03-27T00:40:00Z",
        "text": "Description: The issue with Cloud Pub/Sub beginning on Thursday, 2020-03-26 16:50 US/Pacific is believed to be linked to a single Google incident. \n\nFor regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003).\n\nAn update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:40:00Z"
      },
      {
        "created": "2020-03-27T00:34:34Z",
        "modified": "2020-03-27T00:34:34Z",
        "text": "Description: The issue with Cloud Pub/Sub is believed to be linked to a single Google incident. \n\nFor regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003).\n\nAn update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:34:34Z"
      }
    ],
    "uri": "/incident/cloud-pubsub/20001"
  },
  {
    "begin": "2020-03-27T00:08:50Z",
    "created": "2020-03-27T00:34:38Z",
    "end": "2020-03-27T02:18:27Z",
    "external_desc": "We've received a report of an issue with Cloud Firestore.",
    "modified": "2020-03-27T02:18:28Z",
    "most-recent-update": {
      "created": "2020-03-27T02:18:27Z",
      "modified": "2020-03-27T02:18:27Z",
      "text": "The issue with Cloud Firestore has been resolved for all affected users as of Thursday, 2020-03-26 18:54 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T02:18:27Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "cloud-firestore",
    "service_name": "Cloud Firestore",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T02:18:27Z",
        "modified": "2020-03-27T02:18:27Z",
        "text": "The issue with Cloud Firestore has been resolved for all affected users as of Thursday, 2020-03-26 18:54 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T02:18:27Z"
      },
      {
        "created": "2020-03-27T01:17:43Z",
        "modified": "2020-03-27T01:17:43Z",
        "text": "Description: We believe the issue with Cloud Firestore is partially resolved.\n\nWe do not have an ETA for full resolution at this point.\n\nWe will provide an update by Thursday, 2020-03-26 21:00 US/Pacific with current details.\n\nDiagnosis: None at this time.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T01:17:43Z"
      },
      {
        "created": "2020-03-27T00:34:38Z",
        "modified": "2020-03-27T00:34:38Z",
        "text": "Description: Our engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:34:38Z"
      }
    ],
    "uri": "/incident/cloud-firestore/20002"
  },
  {
    "begin": "2020-03-26T23:53:28Z",
    "created": "2020-03-27T00:04:05Z",
    "end": "2020-03-27T01:42:51Z",
    "external_desc": "We are experiencing issues with Google BigQuery in the asia-east1 and asia-east2 regions as of Thursday, 2020-03-26 16:53 US/Pacific.",
    "modified": "2020-03-27T01:42:52Z",
    "most-recent-update": {
      "created": "2020-03-27T01:42:51Z",
      "modified": "2020-03-27T01:42:51Z",
      "text": "The issue with Google BigQuery has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:42:51Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "bigquery",
    "service_name": "Google BigQuery",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:42:51Z",
        "modified": "2020-03-27T01:42:51Z",
        "text": "The issue with Google BigQuery has been resolved for all affected projects as of Thursday, 2020-03-26 17:40 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:42:51Z"
      },
      {
        "created": "2020-03-27T00:32:41Z",
        "modified": "2020-03-27T00:32:41Z",
        "text": "Description: We are experiencing issues with Google BigQuery in the asia-east1 and asia-east2 regions as of Thursday, 2020-03-26 16:53 US/Pacific.\n\nAffected customers may experience an elevated error rate (up to 100%) when submitting dataset insertion operations.\n\nOur engineers have determined this issue to be linked to a single Google\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.\n\n\nDiagnosis: Affected customers may experience an elevated error rate (up to 100%) when submitting dataset insertion operations.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T00:32:41Z"
      },
      {
        "created": "2020-03-27T00:04:05Z",
        "modified": "2020-03-27T00:04:05Z",
        "text": "Description: We are experiencing issues with Google BigQuery in the asia-east1 and asia-east2 regions as of Thursday, 2020-03-26 16:53 US/Pacific.\n\nAffected customers may experience an elevated error rate (up to 100%) when submitting dataset insertion operations.\n\nWe will provide more information by Thursday, 2020-03-26 17:30 US/Pacific.\n\nDiagnosis: Affected customers may experience an elevated error rate (up to 100%) when submitting dataset insertion operations.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T00:04:05Z"
      }
    ],
    "uri": "/incident/bigquery/20002"
  },
  {
    "begin": "2020-03-26T23:50:00Z",
    "created": "2020-03-27T00:46:28Z",
    "end": "2020-03-27T01:04:00Z",
    "external_desc": "We've received a report of an issue with Cloud Filestore",
    "modified": "2020-03-27T01:52:16Z",
    "most-recent-update": {
      "created": "2020-03-27T01:52:15Z",
      "modified": "2020-03-27T01:52:15Z",
      "text": "The issue with Cloud Filestore has been resolved for all affected projects as of Thursday, 2020-03-26 18:04 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-27T01:52:15Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-filestore",
    "service_name": "Cloud Filestore",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-27T01:52:15Z",
        "modified": "2020-03-27T01:52:15Z",
        "text": "The issue with Cloud Filestore has been resolved for all affected projects as of Thursday, 2020-03-26 18:04 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T01:52:15Z"
      },
      {
        "created": "2020-03-27T00:46:28Z",
        "modified": "2020-03-27T00:46:28Z",
        "text": "Our engineers have determined this issue to be linked to a single Google\r\nincident.  For regular status updates, please visit [https://status.cloud.google.com/incident/zall/20003](https://status.cloud.google.com/incident/zall/20003). An update will be posted here by Thursday, 2020-03-26 21:00 US/Pacific.",
        "when": "2020-03-27T00:46:28Z"
      }
    ],
    "uri": "/incident/cloud-filestore/20001"
  },
  {
    "begin": "2020-03-26T23:14:54Z",
    "created": "2020-03-27T00:23:36Z",
    "end": "2020-03-27T12:55:01Z",
    "external_desc": "Elevated error rates across multiple Google Cloud Platform services.",
    "modified": "2020-04-02T01:27:20Z",
    "most-recent-update": {
      "created": "2020-04-02T00:15:20Z",
      "modified": "2020-04-02T01:27:20Z",
      "text": "# ISSUE SUMMARY\r\n\r\nOn Thursday 26 March, 2020 at 16:14 US/Pacific, Cloud IAM experienced elevated error rates which caused disruption across many services for a duration of 3.5 hours, and stale data (resulting in continued disruption in administrative operations for a subset of services) for a duration of 14 hours. Google's commitment to user privacy and data security means that IAM is a common dependency across many GCP services. To our Cloud customers whose business was impacted during this disruption, we sincerely apologize – this is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability. We have conducted an internal investigation and are taking steps to improve the resiliency of our service. \r\n\r\n\r\n# ROOT CAUSE\r\n\r\nMany Cloud services depend on a distributed Access Control List (ACL) in Identity and Access Management (IAM) for validating permissions, activating new APIs, or creating new cloud resources. These permissions are stored in a distributed database and are heavily cached. Two processes keep the database up-to-date; one real-time, and one batch. However, if the real-time pipeline falls too far behind, stale data is served which may cause impact operations in downstream services.\r\n\r\nThe trigger of the incident was a bulk update of group memberships that expanded to an unexpectedly high number of modified permissions, which generated a large backlog of queued mutations to be applied in real-time. The processing of the backlog was degraded by a latent issue with the cache servers, which led to them running out of memory; this in turn resulted in requests to IAM timing out. The problem was temporarily exacerbated in various regions by emergency rollouts performed to mitigate the high memory usage. \r\n\r\n\r\n# REMEDIATION AND PREVENTION\r\n\r\nOnce the scope of the issue became clear at 2020-03-26 16:35 US/Pacific, Google engineers quickly began looking for viable mitigations. At 17:06, an offline job to build an updated cache was manually started. Additionally, at 17:34, cache servers were restarted with additional memory, along with a configuration change to allow temporarily serving stale data (a snapshot from before the problematic bulk update) while investigation continued; this mitigated the first impact window. A second window of impact began in other regions at 18:49. At 19:13, similar efforts to mitigate with additional memory began, which mitigated the second impact window by 19:42. Additional efforts to fix the stale data continued, and finally the latest offline backfill of IAM data was loaded into the cache servers. The remaining time was spent progressing through the backlog of changes, and live data was slowly re-enabled region-by-region to successfully mitigate the staleness globally at 2020-03-27 05:55. \r\n\r\nGoogle is committed to quickly and continually improving our technology and operations to both prevent service disruptions, and to mitigate them quickly when they occur. In addition to ensuring that the cache servers can handle bulk updates of the kind which triggered this incident, efforts are underway to optimize the memory usage and protections on the cache servers, and allow emergency configuration changes without requiring restarts. To allow us to mitigate data staleness issues more quickly in future, we will also be sharding out the database batch processing to allow for parallelization and more frequent runs. We understand how important regional reliability is for our users and apologize for this incident. \r\n\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\n\r\nOn Thursday 26 March, 2020 from 16:14 to Friday 27 March 2020, 06:20 US/Pacific, Cloud IAM experienced out of date (stale) data, which had varying degrees of impact as described in detail below. Additionally, multiple services experienced bursts of Cloud IAM errors. These spikes were clustered around 16:35 to 17:45, 18:45 to 19:00, and 19:20 to 19:40, however the precise timing for each Cloud region differed. Error rates reached up to 100% in the later two periods as mitigations propagated globally. As a result, many Cloud services experienced concurrent outages in multiple regions, and most regions experienced some impact. Even though error rates recovered after mitigations, Cloud IAM members from Google Groups [1] remained stale until the full incident had been resolved. The staleness varied in severity throughout the incident as new batch processes completed, with an approximate four hour delay at 16:14, up to a 9 hour delay at 21:13. Users directly granted IAM roles were not impacted by stale permissions.\r\n\r\n[1] https://cloud.google.com/iam/docs/overview#google_group \r\n\r\n## Cloud IAM\r\nExperienced delays mapping IAM roles from changes in Google Groups membership for users and Service Accounts, which resulted in serving stale permissions globally from 2020-03-26 16:15 to 2020-03-27 05:55. Permissions assigned to individual non-service account users were not affected.\r\n\r\n## App Engine (GAE)\r\nExperienced elevated rates of deployment failures and increased timeouts on serving for apps with access control [2] from 16:22 to 2020-03-27 05:48 in the following regions: asia-east2, asia-northeast1, asia-south1, europe-west1, europe-west2, europe-west3,australia-southeast1, northamerica-northeast1, us-central1, us-east1, us-east4, and us-west2. Public apps did not have HTTP serving affected. \r\n\r\n[2] https://cloud.google.com/appengine/docs/standard/python3/access-control\r\n\r\n## AI Platform Predictions\r\nExperienced elevated error rates from 16:50 to 19:54 in the following regions: europe-west1, asia-northeast1, us-east4. The average error rate was <1% with a peak of 2.2% during the impact window.\r\n\r\n## AI Platform Notebooks\r\nExperienced elevated error rates and failure creating new instances from 16:34 to 19:17 in the following regions: asia-east1, us-west1, us-east1.\r\n\r\n## Cloud Asset Inventory\r\nExperienced elevated error rates globally from 17:00 to 19:56. The average error rate during the first spike from 16:50 to 17:42 was 5%, and 40% during the second spike from 19:34 to 19:43, with a peak of 45%. \r\n\r\n## Cloud Composer\r\nExperienced elevated error rates for various API calls in all regions, with the following regions seeing up to a 100% error rate: asia-east2, europe-west1, us-west3. This primarily impacted environment creation, updates, and upgrades, and existing healthy environments should have been unaffected, \r\n\r\n## Cloud Console\r\nExperienced elevated error rates loading various pages globally from 16:40 to 20:00. 4.2% of page views experienced degraded performance , with a spike between 16:40 to 18:00, and 18:50 to 20:00. Some pages may have seen up to 100% degraded page views depending on the service requested. \r\n\r\n## Cloud Dataproc\r\nExperienced elevated cluster operation error rates from 16:30 to 19:45 in the following regions: asia-east, asia-east2, asia-northeast1, asia-northeast2, asia-northeast3, asia-south1, asia-southwest1, australia-southeast1, europe-north1, europe-west1, europe-west2, europe-west3, europe-west4, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east1, us-east4, us-west1, us-west2. The average and peak error rates were <1% in all regions. \r\n\r\n## Cloud Dataflow\r\nExperienced elevated error rates creating new jobs between 16:34 and 19:43 in the following regions: asia-east1, asia-northeast1, europe-west1, europe-west2, europe-west3, europe-west4, us-central1, us-east4, us-west1. The error rate varied by region over the course of the incident, averaging 70%, with peaks of up to 100%. Existing jobs may have seen temporarily increased latency. \r\n\r\n## Cloud Data Fusion\r\nExperienced elevated error rates creating new pipelines from 17:00 to 2020-03-27 07:00 in the following regions: asia-east1, asia-east2, asia-northeast1, asia-northeast2, asia-northeast3, asia-south1, asia-southeast1, australia-southeast1, europe-north1, europe-west1, europe-west2, europe -west3, europe-west4, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east1, us-east4, us-west1, and us-west2. 100% of create operations failed during the impact window.\r\n\r\n## Cloud Dialogflow\r\nExperienced elevated API errors from 16:36 to 17:43 and from 19:36 to 19:43 globally. The error rate averaged 2.6%, with peaks of up to 12% during the impact window. \r\n\r\n## Cloud Filestore\r\nExperienced elevated errors on instance operations from 16:44 to 17:53 in asia-east1, asia-east2, us-west1, from 18:45 to 19:10 in asia-northeast1, australia-southeast1, southamerica-east1, and from 19:30 to 19:45 in europe-west4, asia-east2, europe-north1, australia-southeast1, us-east4, and us-west1. Globally, projects which had recently activated the Filestore service were unable to create instances.\r\n\r\n## Cloud Firestore & Cloud Datastore\r\nExperienced elevated error rates and increased request latency between 16:41 and 20:14. From 16:41 to 17:45 only europe-west1 and asia-east2 were impacted. On average, the availability of Firestore was 99.75% with a low of 97.3% at 19:38. Datastore had an average <0.1% of errors, with a peak error rate of 1% at 19:40. From 18:45 to 19:06 the following regions were impacted: asia-east2, asia-northeast1, asia-northeast2, asia-northeast3, asia-south1, australia-southeast1, europe-west1, europe-west2, europe-west3, europe-west4, europe-west5, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east4, us-west2, us-west3, and us-west4. Finally, from 19:27 to 20:15 all regions were impacted. \r\n\r\n## Cloud Functions\r\nExperienced elevated rates of deployment failures and increased timeouts when serving functions with access control [3] from 16:22 to 20-03-27 05:48 in the following regions: asia-east2, europe-west1, europe-west2, europe-west3, asia-northeast1, europe-north1, and us-east4. Public services did not have HTTP serving affected. \r\n\r\n[3] https://cloud.google.com/functions/docs/concepts/iam\r\n\r\n## Cloud Healthcare API\r\nExperienced elevated error rates in the ‘us’ multi-region from 16:47 to 17:40, with a 12% average error rate, and a peak error rate of 25%. \r\n\r\n## Cloud KMS\r\nExperienced elevated error rates from 16:30 to 17:46 in the following regions: asia, asia-east1, asia-east2, europe, europe-west1, us-west1, southamerica-east1, europe-west3, europe-north1, europe-west4, and us-east4. The average error rate during the impact window was 26%, with a peak of 36%. \r\n\r\n## Cloud Memorystore\r\nExperienced failed instance operations from 16:44 to 17:53 in asia-east1, asia-east2, us-west1, from 18:45 to 19:10 in asia-northeast1, australia-southeast1, southamerica-east1, and from 19:30 to 19:45 in europe-west4, asia-east2, europe-north1, australia-southeast1, us-east4, us-west1. Globally, projects which had recently activated the Memorystore service were unable to create instances until 2020-03-27 06:00. \r\n\r\n## Cloud Monitoring\r\nExperienced elevated error rates for the Dashboards and Accounts API endpoints from 16:35 to 19:42 in the following regions: asia-west1, asia-east1, europe-west1, us-central1, us-west1. Rates fluctuated by region throughout the duration of the incident, with an average of 15% for the Accounts API, and 30% for the Dashboards API, and a peak of 26% and 80% respectively. The asia-east1 region had the most significant impact. \r\n\r\n## Cloud Pub/Sub\r\nExperienced elevated error rates in all regions from 16:30 to 19:46, with the most significant in europe-west1, asia-east1, asia-east2, and us-central1. Average error rates during each impact window was 30%, with a peak of 59% at 19:36. Operations had the following average error rates: Publish: 3.7%, StreamingPull: 1.9%, Pull: 1.4%.\r\n\r\n## Cloud Scheduler\r\nExperienced elevated error rates in all regions from 16:42 to 17:42, and 18:47 to 19:42 with the most significant in asia-east2, europe-west1, and us-central1. The error rates varied across regions during the impact window with peaks of up to 100%. \r\n\r\n## Cloud Storage (GCS)\r\nExperienced elevated error rates and timeouts for various API calls from 16:34 to 17:32 and 19:15 to 19:41. Per-region availability dropped as low as 91.4% for asia-east2, 98.55% for europe-west1, 99.04% for us-west1, 98.15% for the ‘eu’ multiregion, and 98.45% for the ‘asia’ multi-region. Additionally, errors in the Firebase Console were seen specifically for first-time Cloud Storage for Firebase users trying to create a project from 17:35 to 2020-03-27 08:18.\r\n\r\n## Cloud SQL\r\nExperienced errors creating new instances globally from 2020-03-26 16:22 to 2020-03-27 06:05.\r\n\r\n## Cloud Spanner\r\nCloud Spanner instances experienced failures when managing or accessing databases from 17:03 to 20:40 in the following regions: regional-us-west1, regional-asia-east1, regional-asia-east2, regional-europe-west1, regional-asia-east2, eur3. The average error rate was 2.6% for all regions, with a peak of 33.3% in asia-east2. \r\n\r\n## Cloud Tasks\r\nExperienced elevated error rates on new task creations in asia-east2, asia-northeast1, asia-northeast2, asia-northeast3, asia-south1, australia-southeast1, europe-west2, europe-west3, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east4, us-west2. Delivery of existing tasks were unaffected, but downstream services may have experienced other issues as documented. \r\n\r\n## Compute Engine (GCE)\r\nExperienced elevated error rates on API operations, and elevated latency for disk snapshot creation from 19:35 to 19:43 in all regions. The average and peak error rate was 40% throughout the impact window. \r\n\r\n## Container Registry\r\nExperienced elevated error rates on the Container Analysis API. Additionally, there was increased latency on Container Scanning and Continuous Analysis requests which took up to 1 hour. Continuous Analysis was also delayed. \r\n\r\n## Cloud Run\r\nExperienced elevated rates of deployment failures and increased timeouts serving deployed services with access control [4] from 16:22 to 2020-03-27 05:48 in the following regions: asia-east1, asia-northeast1, europe-north1, europe-west1, europe-west4, us-east4, us-west1. Public services did not have HTTP serving affected. Newly created Cloud projects (with new IAM permissions) weren't able to complete service deployments because of stale IAM reads on the service account's permissions.\r\n\r\n[4] https://cloud.google.com/run/docs/securing/managing-access\r\n\r\n## Data Catalog\r\nExperienced elevated error rates on read & write API’s in the following regions: ‘us’ multi-region, ‘eu’ multi-region, asia-east1, asia-east2, asia-south1, asia-southeast1, australia-southeast1, europe-west1, europe-west4, us-central1, us-west1, and us-west2. The exact error rate percentages varied by API method and region, but ranged from 0% to 8%. Errors began at 16:30, saw an initial recovery at 17:50, and were fully resolved by 19:42.\r\n\r\n## Firebase ML Kit\r\nExperienced elevated errors from 16:45 to 17:45 globally. The average error rate was 10% globally, with a peak of 14% globally. However, users located near the Pacific Northwest and Western Europe saw the most impact.  \r\n\r\n## Google BigQuery\r\nExperienced significantly elevated error rates across many API methods in all regions. The asia-east1 and asia-east2 regions were the most impacted with 100% of metadata dataset insertion operations failing. The following regions experienced multiple customers with error rates above 10%: asia-east1, asia-east2, asia-northeast1, australia-southeast1, ‘eu’ multi-region, europe-north1, europe-west2, europe-west3, us-east4, and us-west2. The first round of errors occurred between 16:42 and 17:42. The second round of errors occurred between 18:45 and 19:45 and experienced slightly higher average error rates than the first. The exact impact windows differed slightly between APIs.\r\n\r\n## Kubernetes Engine (GKE)\r\nExperienced elevated errors on GKE API from 16:35 - 17:40 and 19:35 - 19:40 in the following regions: asia-east1, asia-east2, us-west1, and europe-west1. This mainly affected cluster operations including creation, listing, upgrades and nodes changes. Existing healthy clusters remained unaffected.\r\n\r\n## Secret Manager\r\nExperienced elevated error rates from 16:44 to 17:43 on secrets stored globally, however the most impacted regions were in europe-west1, asia-east1, and us-west1, with an additional spike between 19:35 to 19:42. The average error rate was <1%, with a peak of 4.2%. \r\n\r\n\r\n# SLA CREDITS\r\n\r\nIf you believe your paid application experienced an SLA violation as a result of this incident, please populate the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\r\n\r\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/.\r\n\r\nFor G Suite, please request an SLA credit through one of the Support channels: https://support.google.com/a/answer/104721\r\n\r\nG Suite Service Level Agreement can be found at https://gsuite.google.com/intl/en/terms/sla.html",
      "when": "2020-04-02T00:15:20Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "high",
    "updates": [
      {
        "created": "2020-04-02T00:15:20Z",
        "modified": "2020-04-02T01:27:20Z",
        "text": "# ISSUE SUMMARY\r\n\r\nOn Thursday 26 March, 2020 at 16:14 US/Pacific, Cloud IAM experienced elevated error rates which caused disruption across many services for a duration of 3.5 hours, and stale data (resulting in continued disruption in administrative operations for a subset of services) for a duration of 14 hours. Google's commitment to user privacy and data security means that IAM is a common dependency across many GCP services. To our Cloud customers whose business was impacted during this disruption, we sincerely apologize – this is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability. We have conducted an internal investigation and are taking steps to improve the resiliency of our service. \r\n\r\n\r\n# ROOT CAUSE\r\n\r\nMany Cloud services depend on a distributed Access Control List (ACL) in Identity and Access Management (IAM) for validating permissions, activating new APIs, or creating new cloud resources. These permissions are stored in a distributed database and are heavily cached. Two processes keep the database up-to-date; one real-time, and one batch. However, if the real-time pipeline falls too far behind, stale data is served which may cause impact operations in downstream services.\r\n\r\nThe trigger of the incident was a bulk update of group memberships that expanded to an unexpectedly high number of modified permissions, which generated a large backlog of queued mutations to be applied in real-time. The processing of the backlog was degraded by a latent issue with the cache servers, which led to them running out of memory; this in turn resulted in requests to IAM timing out. The problem was temporarily exacerbated in various regions by emergency rollouts performed to mitigate the high memory usage. \r\n\r\n\r\n# REMEDIATION AND PREVENTION\r\n\r\nOnce the scope of the issue became clear at 2020-03-26 16:35 US/Pacific, Google engineers quickly began looking for viable mitigations. At 17:06, an offline job to build an updated cache was manually started. Additionally, at 17:34, cache servers were restarted with additional memory, along with a configuration change to allow temporarily serving stale data (a snapshot from before the problematic bulk update) while investigation continued; this mitigated the first impact window. A second window of impact began in other regions at 18:49. At 19:13, similar efforts to mitigate with additional memory began, which mitigated the second impact window by 19:42. Additional efforts to fix the stale data continued, and finally the latest offline backfill of IAM data was loaded into the cache servers. The remaining time was spent progressing through the backlog of changes, and live data was slowly re-enabled region-by-region to successfully mitigate the staleness globally at 2020-03-27 05:55. \r\n\r\nGoogle is committed to quickly and continually improving our technology and operations to both prevent service disruptions, and to mitigate them quickly when they occur. In addition to ensuring that the cache servers can handle bulk updates of the kind which triggered this incident, efforts are underway to optimize the memory usage and protections on the cache servers, and allow emergency configuration changes without requiring restarts. To allow us to mitigate data staleness issues more quickly in future, we will also be sharding out the database batch processing to allow for parallelization and more frequent runs. We understand how important regional reliability is for our users and apologize for this incident. \r\n\r\n\r\n# DETAILED DESCRIPTION OF IMPACT\r\n\r\nOn Thursday 26 March, 2020 from 16:14 to Friday 27 March 2020, 06:20 US/Pacific, Cloud IAM experienced out of date (stale) data, which had varying degrees of impact as described in detail below. Additionally, multiple services experienced bursts of Cloud IAM errors. These spikes were clustered around 16:35 to 17:45, 18:45 to 19:00, and 19:20 to 19:40, however the precise timing for each Cloud region differed. Error rates reached up to 100% in the later two periods as mitigations propagated globally. As a result, many Cloud services experienced concurrent outages in multiple regions, and most regions experienced some impact. Even though error rates recovered after mitigations, Cloud IAM members from Google Groups [1] remained stale until the full incident had been resolved. The staleness varied in severity throughout the incident as new batch processes completed, with an approximate four hour delay at 16:14, up to a 9 hour delay at 21:13. Users directly granted IAM roles were not impacted by stale permissions.\r\n\r\n[1] https://cloud.google.com/iam/docs/overview#google_group \r\n\r\n## Cloud IAM\r\nExperienced delays mapping IAM roles from changes in Google Groups membership for users and Service Accounts, which resulted in serving stale permissions globally from 2020-03-26 16:15 to 2020-03-27 05:55. Permissions assigned to individual non-service account users were not affected.\r\n\r\n## App Engine (GAE)\r\nExperienced elevated rates of deployment failures and increased timeouts on serving for apps with access control [2] from 16:22 to 2020-03-27 05:48 in the following regions: asia-east2, asia-northeast1, asia-south1, europe-west1, europe-west2, europe-west3,australia-southeast1, northamerica-northeast1, us-central1, us-east1, us-east4, and us-west2. Public apps did not have HTTP serving affected. \r\n\r\n[2] https://cloud.google.com/appengine/docs/standard/python3/access-control\r\n\r\n## AI Platform Predictions\r\nExperienced elevated error rates from 16:50 to 19:54 in the following regions: europe-west1, asia-northeast1, us-east4. The average error rate was <1% with a peak of 2.2% during the impact window.\r\n\r\n## AI Platform Notebooks\r\nExperienced elevated error rates and failure creating new instances from 16:34 to 19:17 in the following regions: asia-east1, us-west1, us-east1.\r\n\r\n## Cloud Asset Inventory\r\nExperienced elevated error rates globally from 17:00 to 19:56. The average error rate during the first spike from 16:50 to 17:42 was 5%, and 40% during the second spike from 19:34 to 19:43, with a peak of 45%. \r\n\r\n## Cloud Composer\r\nExperienced elevated error rates for various API calls in all regions, with the following regions seeing up to a 100% error rate: asia-east2, europe-west1, us-west3. This primarily impacted environment creation, updates, and upgrades, and existing healthy environments should have been unaffected, \r\n\r\n## Cloud Console\r\nExperienced elevated error rates loading various pages globally from 16:40 to 20:00. 4.2% of page views experienced degraded performance , with a spike between 16:40 to 18:00, and 18:50 to 20:00. Some pages may have seen up to 100% degraded page views depending on the service requested. \r\n\r\n## Cloud Dataproc\r\nExperienced elevated cluster operation error rates from 16:30 to 19:45 in the following regions: asia-east, asia-east2, asia-northeast1, asia-northeast2, asia-northeast3, asia-south1, asia-southwest1, australia-southeast1, europe-north1, europe-west1, europe-west2, europe-west3, europe-west4, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east1, us-east4, us-west1, us-west2. The average and peak error rates were <1% in all regions. \r\n\r\n## Cloud Dataflow\r\nExperienced elevated error rates creating new jobs between 16:34 and 19:43 in the following regions: asia-east1, asia-northeast1, europe-west1, europe-west2, europe-west3, europe-west4, us-central1, us-east4, us-west1. The error rate varied by region over the course of the incident, averaging 70%, with peaks of up to 100%. Existing jobs may have seen temporarily increased latency. \r\n\r\n## Cloud Data Fusion\r\nExperienced elevated error rates creating new pipelines from 17:00 to 2020-03-27 07:00 in the following regions: asia-east1, asia-east2, asia-northeast1, asia-northeast2, asia-northeast3, asia-south1, asia-southeast1, australia-southeast1, europe-north1, europe-west1, europe-west2, europe -west3, europe-west4, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east1, us-east4, us-west1, and us-west2. 100% of create operations failed during the impact window.\r\n\r\n## Cloud Dialogflow\r\nExperienced elevated API errors from 16:36 to 17:43 and from 19:36 to 19:43 globally. The error rate averaged 2.6%, with peaks of up to 12% during the impact window. \r\n\r\n## Cloud Filestore\r\nExperienced elevated errors on instance operations from 16:44 to 17:53 in asia-east1, asia-east2, us-west1, from 18:45 to 19:10 in asia-northeast1, australia-southeast1, southamerica-east1, and from 19:30 to 19:45 in europe-west4, asia-east2, europe-north1, australia-southeast1, us-east4, and us-west1. Globally, projects which had recently activated the Filestore service were unable to create instances.\r\n\r\n## Cloud Firestore & Cloud Datastore\r\nExperienced elevated error rates and increased request latency between 16:41 and 20:14. From 16:41 to 17:45 only europe-west1 and asia-east2 were impacted. On average, the availability of Firestore was 99.75% with a low of 97.3% at 19:38. Datastore had an average <0.1% of errors, with a peak error rate of 1% at 19:40. From 18:45 to 19:06 the following regions were impacted: asia-east2, asia-northeast1, asia-northeast2, asia-northeast3, asia-south1, australia-southeast1, europe-west1, europe-west2, europe-west3, europe-west4, europe-west5, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east4, us-west2, us-west3, and us-west4. Finally, from 19:27 to 20:15 all regions were impacted. \r\n\r\n## Cloud Functions\r\nExperienced elevated rates of deployment failures and increased timeouts when serving functions with access control [3] from 16:22 to 20-03-27 05:48 in the following regions: asia-east2, europe-west1, europe-west2, europe-west3, asia-northeast1, europe-north1, and us-east4. Public services did not have HTTP serving affected. \r\n\r\n[3] https://cloud.google.com/functions/docs/concepts/iam\r\n\r\n## Cloud Healthcare API\r\nExperienced elevated error rates in the ‘us’ multi-region from 16:47 to 17:40, with a 12% average error rate, and a peak error rate of 25%. \r\n\r\n## Cloud KMS\r\nExperienced elevated error rates from 16:30 to 17:46 in the following regions: asia, asia-east1, asia-east2, europe, europe-west1, us-west1, southamerica-east1, europe-west3, europe-north1, europe-west4, and us-east4. The average error rate during the impact window was 26%, with a peak of 36%. \r\n\r\n## Cloud Memorystore\r\nExperienced failed instance operations from 16:44 to 17:53 in asia-east1, asia-east2, us-west1, from 18:45 to 19:10 in asia-northeast1, australia-southeast1, southamerica-east1, and from 19:30 to 19:45 in europe-west4, asia-east2, europe-north1, australia-southeast1, us-east4, us-west1. Globally, projects which had recently activated the Memorystore service were unable to create instances until 2020-03-27 06:00. \r\n\r\n## Cloud Monitoring\r\nExperienced elevated error rates for the Dashboards and Accounts API endpoints from 16:35 to 19:42 in the following regions: asia-west1, asia-east1, europe-west1, us-central1, us-west1. Rates fluctuated by region throughout the duration of the incident, with an average of 15% for the Accounts API, and 30% for the Dashboards API, and a peak of 26% and 80% respectively. The asia-east1 region had the most significant impact. \r\n\r\n## Cloud Pub/Sub\r\nExperienced elevated error rates in all regions from 16:30 to 19:46, with the most significant in europe-west1, asia-east1, asia-east2, and us-central1. Average error rates during each impact window was 30%, with a peak of 59% at 19:36. Operations had the following average error rates: Publish: 3.7%, StreamingPull: 1.9%, Pull: 1.4%.\r\n\r\n## Cloud Scheduler\r\nExperienced elevated error rates in all regions from 16:42 to 17:42, and 18:47 to 19:42 with the most significant in asia-east2, europe-west1, and us-central1. The error rates varied across regions during the impact window with peaks of up to 100%. \r\n\r\n## Cloud Storage (GCS)\r\nExperienced elevated error rates and timeouts for various API calls from 16:34 to 17:32 and 19:15 to 19:41. Per-region availability dropped as low as 91.4% for asia-east2, 98.55% for europe-west1, 99.04% for us-west1, 98.15% for the ‘eu’ multiregion, and 98.45% for the ‘asia’ multi-region. Additionally, errors in the Firebase Console were seen specifically for first-time Cloud Storage for Firebase users trying to create a project from 17:35 to 2020-03-27 08:18.\r\n\r\n## Cloud SQL\r\nExperienced errors creating new instances globally from 2020-03-26 16:22 to 2020-03-27 06:05.\r\n\r\n## Cloud Spanner\r\nCloud Spanner instances experienced failures when managing or accessing databases from 17:03 to 20:40 in the following regions: regional-us-west1, regional-asia-east1, regional-asia-east2, regional-europe-west1, regional-asia-east2, eur3. The average error rate was 2.6% for all regions, with a peak of 33.3% in asia-east2. \r\n\r\n## Cloud Tasks\r\nExperienced elevated error rates on new task creations in asia-east2, asia-northeast1, asia-northeast2, asia-northeast3, asia-south1, australia-southeast1, europe-west2, europe-west3, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east4, us-west2. Delivery of existing tasks were unaffected, but downstream services may have experienced other issues as documented. \r\n\r\n## Compute Engine (GCE)\r\nExperienced elevated error rates on API operations, and elevated latency for disk snapshot creation from 19:35 to 19:43 in all regions. The average and peak error rate was 40% throughout the impact window. \r\n\r\n## Container Registry\r\nExperienced elevated error rates on the Container Analysis API. Additionally, there was increased latency on Container Scanning and Continuous Analysis requests which took up to 1 hour. Continuous Analysis was also delayed. \r\n\r\n## Cloud Run\r\nExperienced elevated rates of deployment failures and increased timeouts serving deployed services with access control [4] from 16:22 to 2020-03-27 05:48 in the following regions: asia-east1, asia-northeast1, europe-north1, europe-west1, europe-west4, us-east4, us-west1. Public services did not have HTTP serving affected. Newly created Cloud projects (with new IAM permissions) weren't able to complete service deployments because of stale IAM reads on the service account's permissions.\r\n\r\n[4] https://cloud.google.com/run/docs/securing/managing-access\r\n\r\n## Data Catalog\r\nExperienced elevated error rates on read & write API’s in the following regions: ‘us’ multi-region, ‘eu’ multi-region, asia-east1, asia-east2, asia-south1, asia-southeast1, australia-southeast1, europe-west1, europe-west4, us-central1, us-west1, and us-west2. The exact error rate percentages varied by API method and region, but ranged from 0% to 8%. Errors began at 16:30, saw an initial recovery at 17:50, and were fully resolved by 19:42.\r\n\r\n## Firebase ML Kit\r\nExperienced elevated errors from 16:45 to 17:45 globally. The average error rate was 10% globally, with a peak of 14% globally. However, users located near the Pacific Northwest and Western Europe saw the most impact.  \r\n\r\n## Google BigQuery\r\nExperienced significantly elevated error rates across many API methods in all regions. The asia-east1 and asia-east2 regions were the most impacted with 100% of metadata dataset insertion operations failing. The following regions experienced multiple customers with error rates above 10%: asia-east1, asia-east2, asia-northeast1, australia-southeast1, ‘eu’ multi-region, europe-north1, europe-west2, europe-west3, us-east4, and us-west2. The first round of errors occurred between 16:42 and 17:42. The second round of errors occurred between 18:45 and 19:45 and experienced slightly higher average error rates than the first. The exact impact windows differed slightly between APIs.\r\n\r\n## Kubernetes Engine (GKE)\r\nExperienced elevated errors on GKE API from 16:35 - 17:40 and 19:35 - 19:40 in the following regions: asia-east1, asia-east2, us-west1, and europe-west1. This mainly affected cluster operations including creation, listing, upgrades and nodes changes. Existing healthy clusters remained unaffected.\r\n\r\n## Secret Manager\r\nExperienced elevated error rates from 16:44 to 17:43 on secrets stored globally, however the most impacted regions were in europe-west1, asia-east1, and us-west1, with an additional spike between 19:35 to 19:42. The average error rate was <1%, with a peak of 4.2%. \r\n\r\n\r\n# SLA CREDITS\r\n\r\nIf you believe your paid application experienced an SLA violation as a result of this incident, please populate the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\r\n\r\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/.\r\n\r\nFor G Suite, please request an SLA credit through one of the Support channels: https://support.google.com/a/answer/104721\r\n\r\nG Suite Service Level Agreement can be found at https://gsuite.google.com/intl/en/terms/sla.html",
        "when": "2020-04-02T00:15:20Z"
      },
      {
        "created": "2020-03-27T13:54:01Z",
        "modified": "2020-03-27T13:54:01Z",
        "text": "The issue with Google Cloud infrastructure components has been resolved for all affected projects as of Friday, 2020-03-27 06:32 US/Pacific.\n\nWe will publish an analysis of this incident once we have completed our internal investigation.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-27T13:54:01Z"
      },
      {
        "created": "2020-03-27T12:58:20Z",
        "modified": "2020-03-27T12:58:20Z",
        "text": "Description: The engineering team has tested a fix, which is being gradually rolled out to the affected services. Current data indicates that the issue has been resolved for the majority of users and we expect full resolution within the next hour (by 2020-03-27 07:00 US/Pacific). The estimate is tentative and is subject to change.\n\nWe will provide an update by Friday, 2020-03-27 07:00 US/Pacific with current details.\n\n\nDiagnosis: Affected customers may experience delayed IAM modifications that surface across multiple Google Cloud Platform services. Currently known products that are impacted are: \nDataflow, BigTable, BigQuery, DialogFlow, Kubernetes Engine, Cloud Firestore, App Engine, Cloud Functions, Cloud Monitoring, Cloud Memorystore, Cloud Filestore, Cloud Spanner, Cloud Storage, Cloud Composer, Cloud Dataproc, Cloud KMS, Cloud Container Registry, Compute Engine, Cloud IAM, Cloud SQL, Firebase Storage, Cloud Healthcare API, Cloud AI, Firebase Machine Learning, Data Catalog, Data Fusion, and Cloud Console.\n\n\nWorkaround: Retry failed requests with exponential backoff.",
        "when": "2020-03-27T12:58:20Z"
      },
      {
        "created": "2020-03-27T10:44:38Z",
        "modified": "2020-03-27T10:44:38Z",
        "text": "Description: The engineering team has tested a fix, which is being gradually rolled out to the affected services. We expect full resolution within the next two hours (by 2020-03-27 06:00 US/Pacific). The estimate is tentative and is subject to change.\n\n\nWe will provide an update by Friday, 2020-03-27 06:00 US/Pacific with current details.\n\n\nDiagnosis: Affected customers may experience delayed IAM modifications that surface across multiple Google Cloud Platform services. Currently known products that are impacted are: \nDataflow, BigQuery, DialogFlow, Kubernetes Engine, Cloud Firestore, App Engine, Cloud Functions, Cloud Monitoring, Cloud Memorystore, Cloud Filestore, Cloud Spanner, Cloud Storage, Cloud Composer, Cloud Dataproc, Cloud KMS, Cloud Container Registry, Compute Engine, Cloud IAM, Cloud SQL, Firebase Storage, Cloud Healthcare API, Cloud AI, Firebase Machine Learning, Data Catalog, Data Fusion, and Cloud Console.\n\n\nWorkaround: Retry failed requests with exponential backoff.",
        "when": "2020-03-27T10:44:38Z"
      },
      {
        "created": "2020-03-27T08:38:17Z",
        "modified": "2020-03-27T08:38:17Z",
        "text": "Description: The engineering team has tested a fix, which is being gradually rolled out to the affected services. We expect full resolution within the next three hours (by 2020-03-27 05:00 US/Pacific). The estimate is tentative and is subject to change.\n\n\nWe will provide an update by Friday, 2020-03-27 05:00 US/Pacific with current details.\n\n\nDiagnosis: Affected customers may experience delayed IAM modifications that surface across multiple Google Cloud Platform services. Currently known products that are impacted are: \nDataflow, BigQuery, DialogFlow, Kubernetes Engine, Cloud Firestore, App Engine, Cloud Functions, Cloud Monitoring, Cloud Memorystore, Cloud Filestore, Cloud Spanner, Cloud Storage, Cloud Composer, Cloud Dataproc, Cloud KMS, Cloud Container Registry, Compute Engine, Cloud IAM, Cloud SQL, Firebase Storage, Cloud Healthcare API, Cloud AI, Firebase Machine Learning, Data Catalog, Data Fusion, and Cloud Console.\n\n\nWorkaround: Retry failed requests with exponential backoff.",
        "when": "2020-03-27T08:38:17Z"
      },
      {
        "created": "2020-03-27T06:55:55Z",
        "modified": "2020-03-27T06:55:55Z",
        "text": "Description: Mitigation work is still underway by our engineering team for a full resolution. The mitigation is expected to complete within the next few hours.\n\nWe will provide an update by Friday, 2020-03-27 02:00 US/Pacific with current details.\n\nDiagnosis: Affected customers may experience delayed IAM modifications that surface across multiple Google Cloud Platform services. Currently known products that are impacted are: \nDataflow, BigQuery, DialogFlow, Kubernetes Engine, Cloud Firestore, App Engine, Cloud Functions, Cloud Monitoring, Cloud Memorystore, Cloud Filestore, Cloud Spanner, Cloud Storage, Cloud Composer, Cloud Dataproc, Cloud KMS, Cloud Container Registry, Compute Engine, Cloud IAM, Cloud SQL, Firebase Storage, Cloud Healthcare API, Cloud AI, Firebase Machine Learning, Data Catalog, Data Fusion, and Cloud Console.\n\n\nWorkaround: Retry failed requests with exponential backoff.",
        "when": "2020-03-27T06:55:55Z"
      },
      {
        "created": "2020-03-27T05:58:28Z",
        "modified": "2020-03-27T05:58:28Z",
        "text": "Description: Mitigation work is still underway by our engineering team for a full resolution. \n\nWe will provide an update by Friday, 2020-03-27 00:00 US/Pacific with current details.\n\nDiagnosis: Affected customers may experience delayed IAM modifications that surface across multiple Google Cloud Platform services. Currently known products that are impacted are: \nDataflow, BigQuery, DialogFlow, Kubernetes Engine, Cloud Firestore, App Engine, Cloud Functions, Cloud Monitoring, Cloud Memorystore, Cloud Filestore, Cloud Spanner, Cloud Storage, Cloud Composer, Cloud Dataproc, Cloud KMS, Cloud Container Registry, Compute Engine, Cloud IAM, Cloud SQL, Firebase Storage, Cloud Healthcare API, Cloud AI, Firebase Machine Learning, Data Catalog, Data Fusion, and Cloud Console.\n\n\nWorkaround: Retry failed requests with exponential backoff.",
        "when": "2020-03-27T05:58:28Z"
      },
      {
        "created": "2020-03-27T05:01:49Z",
        "modified": "2020-03-27T05:01:49Z",
        "text": "Description: We believe the issue with Google Cloud infrastructure components is partially resolved. Restoration of IAM modifications to real-time is underway and Cloud IAM latency has decreased. \n\nWe will provide an update by Thursday, 2020-03-26 23:00 US/Pacific with current details.\n\nDiagnosis: Affected customers may experience delayed IAM modifications that surface across multiple Google Cloud Platform services. Currently known products that are impacted are: \nDataflow, BigQuery, DialogFlow, Kubernetes Engine, Cloud Firestore, App Engine, Cloud Functions, Cloud Monitoring, Cloud Memorystore, Cloud Filestore, Cloud Spanner, Cloud Storage, Cloud Composer, Cloud Dataproc, Cloud KMS, Cloud Container Registry, Compute Engine, Cloud IAM, Cloud SQL, Firebase Storage, Cloud Healthcare API, Cloud AI, Firebase Machine Learning, Data Catalog, Data Fusion, and Cloud Console.\n\n\nWorkaround: Retry failed requests with exponential backoff.",
        "when": "2020-03-27T05:01:49Z"
      },
      {
        "created": "2020-03-27T03:36:22Z",
        "modified": "2020-03-27T03:36:22Z",
        "text": "Description: We believe the issue with Google Cloud infrastructure components is partially resolved. The mitigations have been rolled out globally, and the errors should have subsided for all affected users as of 2020-03-26 20:15. There remains a backlog of Cloud IAM modifications, which may still have increased latency before taking effect. We are currently working through the backlog to restore IAM applications to real-time. \n\nWe will provide an update by Thursday, 2020-03-26 22:00 US/Pacific with current details.\n\nDiagnosis: Affected customers may experience elevated error rates that surface across multiple Google Cloud Platform services. Currently known products that are impacted are: \nDataflow, BigQuery, DialogFlow, Kubernetes Engine, Cloud Firestore, App Engine, Cloud Functions, Cloud Monitoring, Cloud MemoryStore, Cloud Spanner, Cloud Storage, Cloud Composer, Cloud Dataproc, Cloud KMS, Cloud Container Registry, Compute Engine, Cloud IAM, Cloud SQL, Firebase Storage, Cloud Healthcare API, Cloud AI, Firebase Machine Learning, Data Catalog, Data Fusion and Cloud Console.\n\nWorkaround: Retry failed requests with exponential backoff.",
        "when": "2020-03-27T03:36:22Z"
      },
      {
        "created": "2020-03-27T03:02:26Z",
        "modified": "2020-03-27T03:02:26Z",
        "text": "Description: Modifications to Cloud IAM permissions and service accounts may have significantly increased latency before taking effect. Existing permissions remain enforced. Mitigation work is still underway by our engineering team for the remaining services. Customers may experience intermittent spikes in errors while mitigations are pushed out globally. \n\nThe following services have recovered at this time: App Engine, Cloud Functions, Cloud Run, BigQuery, Dataflow, Dialogflow, Cloud Console, MemoryStore, Cloud Storage, Cloud Spanner,  Data Catalog, Cloud KMS, and Cloud Pub/Sub.\n\nLocations that saw the most impact were us-west1, europe-west1, asia-east1, and asia-east2. \n\nServices that may still be seeing impact include:\nCloud SQL - New instance creation failing\nCloud Composer - New Composer environments are failing to be created\nCloud IAM - Significantly increased latency for changes to take effect\n\nWe will provide an update by Thursday, 2020-03-26 21:00 US/Pacific with current details.\n\nDiagnosis: Affected customers may experience elevated error rates that surface across multiple Google Cloud Platform services. Currently known products that are impacted are: \nDataflow, BigQuery, DialogFlow, Kubernetes Engine, Cloud Firestore, App Engine, Cloud Functions, Cloud Monitoring, Cloud MemoryStore, Cloud Spanner, Cloud Storage, Cloud Composer, Cloud Dataproc, Cloud KMS, Cloud Container Registry, Compute Engine, Cloud IAM, Cloud SQL, Firebase Storage, Cloud Healthcare API, Cloud AI, Firebase Machine Learning, Data Catalog and Cloud Console.\n\nWorkaround: Retry failed requests with exponential backoff.",
        "when": "2020-03-27T03:02:26Z"
      },
      {
        "created": "2020-03-27T02:05:14Z",
        "modified": "2020-03-27T02:05:14Z",
        "text": "Description: We believe the issue with Google Cloud infrastructure components is partially resolved.\nThe following services have recovered at this time: App Engine, Cloud Functions, Cloud Run, BigQuery, Dataflow, Dialogflow, Cloud Console, MemoryStore, Cloud Storage, Cloud Spanner, Cloud KMS, and Cloud Pub/Sub.\n\nNew service accounts are failing to propagate which is manifesting as errors in downstream services.\n\nMitigation work is still underway by our engineering team for the remaining services.\n\nServices that may still be seeing impact include:\nCloud SQL - New instance creation failing\nCloud Composer - New Composer environments are failing to be created\n\nLocations that saw the most impact were us-west1, europe-west1, asia-east1, and asia-east2, asia-northeast1.\n\nWe will provide an update by Thursday, 2020-03-26 20:00 US/Pacific with current details.\n\nDiagnosis: Affected customers may experience elevated error rates that surface across multiple Google Cloud Platform services. Currently known products that are impacted are: \nDataflow, BigQuery, DialogFlow, Kubernetes Engine, Cloud Firestore, App Engine, Cloud Functions, Cloud Monitoring, Cloud MemoryStore, Cloud Spanner, Cloud Storage, Cloud Composer, Cloud Dataproc, Cloud KMS, Cloud Container Registry, Compute Engine, Cloud IAM, Cloud SQL, Firebase Storage, Cloud Healthcare, Cloud AI, Firebase Machine Learning and Cloud Console.\n\nWorkaround: Retry failed requests with exponential backoff.",
        "when": "2020-03-27T02:05:14Z"
      },
      {
        "created": "2020-03-27T01:18:35Z",
        "modified": "2020-03-27T01:18:35Z",
        "text": "Description: Impact is global for some services but is primarily located in the following regions: us-west1, europe-west1, asia-east1, and asia-east2. Mitigation work is still underway by our engineering team. Error rates have been decreasing starting on Thursday, 2020-03-26 17:40 US/Pacific. Many downstream services are beginning to recover. \n\nWe will provide an update by Thursday, 2020-03-26 19:00 US/Pacific with current details.\n\nDiagnosis: Affected customers may experience elevated error rates that surface across multiple Google Cloud Platform services. Currently known products that are impacted are: Dataflow, BigQuery, DialogFlow, Kubernetes Engine, Cloud Firestore, App Engine, Cloud Functions, Cloud Monitoring, Cloud MemoryStore, Cloud Spanner, Cloud Storage, Cloud Composer, Cloud Dataproc, Cloud KMS, Cloud Container Registry, Compute Engine, Cloud IAM, Cloud SQL, Firebase Storage, Cloud Healthcare, Cloud AI and Cloud Console.\n\nWorkaround: Retry failed requests with exponential backoff.",
        "when": "2020-03-27T01:18:35Z"
      },
      {
        "created": "2020-03-27T00:50:11Z",
        "modified": "2020-03-27T00:50:11Z",
        "text": "Description: Mitigation work is currently underway by our engineering team. We are beginning to see some services recover. \n\nWe do not have an ETA for mitigation at this point\n\nWe will provide more information by Thursday, 2020-03-26 19:00 US/Pacific.\n\nDiagnosis: Affected customers may experience elevated error rates that surface across multiple Google Cloud Platform services. Currently known products that are impacted are: Dataflow, BigQuery, DialogFlow, Kubernetes Engine, Cloud Firestore, App Engine, Cloud Functions, Cloud Monitoring, Cloud MemoryStore, Cloud Spanner, Cloud Storage, Cloud Composer, Cloud Dataproc, Cloud KMS, and Cloud Console.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T00:50:11Z"
      },
      {
        "created": "2020-03-27T00:23:36Z",
        "modified": "2020-03-27T00:23:36Z",
        "text": "Description: We are experiencing an intermittent issue with Google Cloud infrastructure components beginning on Thursday, 2020-03-26 16:50 US/Pacific.\n\nSymptoms: Affected customers may experience network connectivity issues, and elevated error rates across multiple Google Cloud Platform services. Currently known products that are impacted are: Dataflow, BigQuery, DialogFlow, Kubernetes Engine, Firestore, App Engine, Cloud Functions, Cloud Monitoring, and Cloud Dataproc.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-03-26 18:00 US/Pacific with current details.\n\n\nDiagnosis: Affected customers may experience network connectivity issues, and elevated error rates across multiple Google Cloud Platform services.\n\nWorkaround: None at this time.",
        "when": "2020-03-27T00:23:36Z"
      }
    ],
    "uri": "/incident/zall/20003"
  },
  {
    "begin": "2020-03-26T15:18:17Z",
    "created": "2020-03-26T16:08:20Z",
    "end": "2020-03-26T16:21:39Z",
    "external_desc": "We believe that the issue with Google Cloud infrastructure components has been mitigated. We are continuing to actively monitor the situation.",
    "modified": "2020-03-26T20:10:11Z",
    "most-recent-update": {
      "created": "2020-03-26T20:10:10Z",
      "modified": "2020-03-26T20:10:10Z",
      "text": "Some of our users experienced a service disruption today, as a result of a significant router failure at 08:18am Pacific in one of our data centers in Atlanta, causing network congestion. As a result, Google services running in that data center were directly impacted and were unavailable until our engineers rerouted the traffic and moved those services to alternate facilities. Users in the South Eastern US may also have seen temporary difficulties in accessing a wider range of Google services due to the network congestion.\r\n\r\nThe majority of directly impacted Google services were moved to alternative data centers by 08:50am Pacific, and networking impact was mitigated by 09:21am Pacific, with some services taking longer to recover.\r\n\r\nThe root cause of the problem was a failure of networking devices at our Atlanta datacenter site. We are working on mitigating the issue and taking steps to avoid a recurrence.",
      "when": "2020-03-26T20:10:10Z"
    },
    "number": 20002,
    "public": true,
    "service_key": "zall",
    "service_name": "Google Cloud Infrastructure Components",
    "severity": "high",
    "updates": [
      {
        "created": "2020-03-26T20:10:10Z",
        "modified": "2020-03-26T20:10:10Z",
        "text": "Some of our users experienced a service disruption today, as a result of a significant router failure at 08:18am Pacific in one of our data centers in Atlanta, causing network congestion. As a result, Google services running in that data center were directly impacted and were unavailable until our engineers rerouted the traffic and moved those services to alternate facilities. Users in the South Eastern US may also have seen temporary difficulties in accessing a wider range of Google services due to the network congestion.\r\n\r\nThe majority of directly impacted Google services were moved to alternative data centers by 08:50am Pacific, and networking impact was mitigated by 09:21am Pacific, with some services taking longer to recover.\r\n\r\nThe root cause of the problem was a failure of networking devices at our Atlanta datacenter site. We are working on mitigating the issue and taking steps to avoid a recurrence.",
        "when": "2020-03-26T20:10:10Z"
      },
      {
        "created": "2020-03-26T17:38:39Z",
        "modified": "2020-03-26T17:38:39Z",
        "text": "The issue with Google Cloud infrastructure components has been resolved for all affected users as of 09:21. Total time of impact was 08:18 to 09:21 US/Pacific, with the most severe impact at the start of the issue, tapering off as services routed traffic away from Atlanta.\n\nThe impact of this incident was concentrated in a region that is not a main GCP region and therefore there was no impact to services based on Google Compute Engine. Services that may have been impacted include External HTTP/S Load balancing requests and API requests that may have been served near the Atlanta metro.\n\nThe root cause was a set of router failures in Atlanta, which affected traffic routed through that region.",
        "when": "2020-03-26T17:38:39Z"
      },
      {
        "created": "2020-03-26T17:17:01Z",
        "modified": "2020-03-26T17:17:01Z",
        "text": "Description: We believe the issue with Google Cloud infrastructure components is mitigated, and we are continuing to actively monitor the situation.\n\nWe will provide an update by Thursday, 2020-03-26 12:00 US/Pacific with current details.\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-03-26T17:17:01Z"
      },
      {
        "created": "2020-03-26T16:38:30Z",
        "modified": "2020-03-26T16:38:30Z",
        "text": "Description: We believe the issue with Google Cloud infrastructure components is mitigated, and we are continuing to actively monitor the situation.\n\nWe will provide an update by Thursday, 2020-03-26 10:15 US/Pacific with current details.\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-03-26T16:38:30Z"
      },
      {
        "created": "2020-03-26T16:32:52Z",
        "modified": "2020-03-26T16:32:52Z",
        "text": "Description: We believe the issue with Google Cloud infrastructure components is partially resolved and recovery is beginning.\n\nWe do not have an ETA for full resolution at this point.\n\nWe will provide an update by Thursday, 2020-03-26 10:00 US/Pacific with current details.\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-03-26T16:32:52Z"
      },
      {
        "created": "2020-03-26T16:08:20Z",
        "modified": "2020-03-26T16:08:20Z",
        "text": "Description: We are experiencing an issue with Google Cloud infrastructure components.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-03-26 09:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\n\nDiagnosis: None at this time\n\nWorkaround: None at this time",
        "when": "2020-03-26T16:08:20Z"
      }
    ],
    "uri": "/incident/zall/20002"
  },
  {
    "begin": "2020-03-13T00:37:56Z",
    "created": "2020-03-13T00:54:40Z",
    "end": "2020-03-13T01:19:44Z",
    "external_desc": "Cloud AI Online Prediction requests failing.",
    "modified": "2020-03-13T01:19:44Z",
    "most-recent-update": {
      "created": "2020-03-13T01:19:44Z",
      "modified": "2020-03-13T01:19:44Z",
      "text": "The issue with Cloud AI has been resolved for all affected projects as of Thursday, 2020-03-12 18:19 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-03-13T01:19:44Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-ml",
    "service_name": "Cloud Machine Learning",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-13T01:19:44Z",
        "modified": "2020-03-13T01:19:44Z",
        "text": "The issue with Cloud AI has been resolved for all affected projects as of Thursday, 2020-03-12 18:19 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-03-13T01:19:44Z"
      },
      {
        "created": "2020-03-13T00:54:40Z",
        "modified": "2020-03-13T00:54:40Z",
        "text": "Description: We are experiencing an issue with Cloud AI. The Online Prediction requests failing.\n\nSymptoms: requests failing.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-03-12 19:00 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nWorkaround: None at this time.",
        "when": "2020-03-13T00:54:40Z"
      }
    ],
    "uri": "/incident/cloud-ml/20001"
  },
  {
    "begin": "2020-03-08T11:29:19Z",
    "created": "2020-03-08T12:33:34Z",
    "end": "2020-03-08T17:30:35Z",
    "external_desc": "BigQuery API requests return errors intermittently in europe-west2",
    "modified": "2020-03-08T19:48:17Z",
    "most-recent-update": {
      "created": "2020-03-08T19:40:35Z",
      "modified": "2020-03-08T19:47:40Z",
      "text": "The issue with Google BigQuery has been resolved for all affected projects as of Sunday, 2020-03-08 12:39 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.\r\n\r\nThis issue has been mitigated as of Sunday, 2020-03-08 10:30 US/Pacific and no further errors have been detected.\r\n\r\nPlease contact Google Cloud Support for further assistance.",
      "when": "2020-03-08T19:40:35Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "bigquery",
    "service_name": "Google BigQuery",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-03-08T19:40:35Z",
        "modified": "2020-03-08T19:47:40Z",
        "text": "The issue with Google BigQuery has been resolved for all affected projects as of Sunday, 2020-03-08 12:39 US/Pacific.\r\n\r\nWe thank you for your patience while we've worked on resolving the issue.\r\n\r\nThis issue has been mitigated as of Sunday, 2020-03-08 10:30 US/Pacific and no further errors have been detected.\r\n\r\nPlease contact Google Cloud Support for further assistance.",
        "when": "2020-03-08T19:40:35Z"
      },
      {
        "created": "2020-03-08T18:09:00Z",
        "modified": "2020-03-08T18:09:00Z",
        "text": "Description: We are experiencing an intermittent issue with Google BigQuery in europe-west2, beginning on Sunday, 2020-03-08 03:00 US/Pacific.\n\nSymptoms: Elevated errors are occurring intermittently across many BQ APIs, but most common in TableService, DatasetService, and JobService operations. to the BigQuery API in europe-west2.\n\nMitigation efforts are in place and we are seeing error rates return to normal levels starting 2020-03-08 10:30 PST.\n\nWe will provide an update by Sunday, 2020-03-08 14:30 US/Pacific with current details.\n\nDiagnosis: Customers may experience intermittent elevated errors from the BigQuery API in europe-west2, especially TableService, DatasetService, and JobService operations\n\nWorkaround: If possible, retry requests to the API.",
        "when": "2020-03-08T18:09:00Z"
      },
      {
        "created": "2020-03-08T17:07:20Z",
        "modified": "2020-03-08T17:07:20Z",
        "text": "Description: We are experiencing an intermittent issue with Google BigQuery, beginning on Sunday, 2020-03-08 03:00 US/Pacific.\n\nSymptoms: Elevated errors are occurring intermittently across many BQ APIs, but most common in TableService, DatasetService, and JobService operations. to the BigQuery API in europe-west2.\n\nWe are working towards identifying a root cause.\n\nWe will provide an update by Sunday, 2020-03-08 11:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Customers may experience intermittent elevated errors from the BigQuery API in europe-west2, especially TableService, DatasetService, and JobService operations\n\nWorkaround: If possible, retry requests to the API.",
        "when": "2020-03-08T17:07:20Z"
      },
      {
        "created": "2020-03-08T15:32:49Z",
        "modified": "2020-03-08T15:32:49Z",
        "text": "Description: We are experiencing an intermittent issue with Google BigQuery, beginning at Sunday, 2020-03-08 03:00 US/Pacific.\n\nSymptoms: Intermittent errors for requests to the BigQuery API in europe-west2.\n\nA possible root cause has been identified, and the engineering team is working on mitigating the issue.\n\nWe will provide an update by Sunday, 2020-03-08 10:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Customers may experience intermittent elevated errors from the BigQuery API in europe-west2.\n\nWorkaround: If possible, retry requests to the API.",
        "when": "2020-03-08T15:32:49Z"
      },
      {
        "created": "2020-03-08T13:35:11Z",
        "modified": "2020-03-08T13:35:11Z",
        "text": "Description: We are experiencing an intermittent issue with Google BigQuery, beginning at Sunday, 2020-03-08 03:00 US/Pacific.\n\nSymptoms: Intermittent errors for requests to the BigQuery API in europe-west2.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Sunday, 2020-03-08 08:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Customers may experience intermittent elevated errors from the BigQuery API in europe-west2.\n\nWorkaround: If possible, retry requests to the API.",
        "when": "2020-03-08T13:35:11Z"
      },
      {
        "created": "2020-03-08T12:33:34Z",
        "modified": "2020-03-08T12:33:34Z",
        "text": "Description: We are experiencing an intermittent issue with Google BigQuery, beginning at Sunday, 2020-03-08 03:00 US/Pacific.\n\nSymptoms: Intermittent errors for requests to the BigQuery API in europe-west2.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Sunday, 2020-03-08 06:30 US/Pacific with current details.\n\nWe apologize to all who are affected by the disruption.\n\nDiagnosis: Customers may experience intermittent elevated errors from the BigQuery API in europe-west2.\n\nWorkaround: None at this time",
        "when": "2020-03-08T12:33:34Z"
      }
    ],
    "uri": "/incident/bigquery/20001"
  },
  {
    "begin": "2020-02-27T23:05:25Z",
    "created": "2020-02-28T01:14:26Z",
    "end": "2020-02-28T02:06:13Z",
    "external_desc": "We are investigating an alerting issue in Stackdriver Monitoring",
    "modified": "2020-02-28T02:06:13Z",
    "most-recent-update": {
      "created": "2020-02-28T02:06:13Z",
      "modified": "2020-02-28T02:06:13Z",
      "text": "The issue with Stackdriver Monitoring has been resolved for all affected users as of Thursday, 2020-02-27 18:01 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-02-28T02:06:13Z"
    },
    "number": 20003,
    "public": true,
    "service_key": "google-stackdriver",
    "service_name": "Operations",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-02-28T02:06:13Z",
        "modified": "2020-02-28T02:06:13Z",
        "text": "The issue with Stackdriver Monitoring has been resolved for all affected users as of Thursday, 2020-02-27 18:01 US/Pacific.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-02-28T02:06:13Z"
      },
      {
        "created": "2020-02-28T01:36:42Z",
        "modified": "2020-02-28T01:36:42Z",
        "text": "Description: We are experiencing an issue with Stackdriver Monitoring.\n\nSymptoms: Some alerting policies are not being evaluated.\n\nOur engineering team continues to investigate the issue.\n\nWe will provide an update by Thursday, 2020-02-27 18:10 US/Pacific with current details.\n\nDiagnosis: Users with alerting policies that aggregate away all resource labels for certain resource types may be affected: gce_instance, gae_app, cloud_tasks_queue, cloudsql_database, gce_disk, vpn_gateway, pubsub_topic, pubsub_subscription, pubsub_snapshot.\n\nWorkaround: Adding a resource label, for instance project_id, to the Group By fields in the condition will enable the alerting policies to be evaluated.",
        "when": "2020-02-28T01:36:42Z"
      },
      {
        "created": "2020-02-28T01:14:26Z",
        "modified": "2020-02-28T01:14:26Z",
        "text": "Description: We are investigating a potential issue with Stackdriver Monitoring.\n\nWe will provide more information by Thursday, 2020-02-27 17:45 US/Pacific.",
        "when": "2020-02-28T01:14:26Z"
      }
    ],
    "uri": "/incident/google-stackdriver/20003"
  },
  {
    "begin": "2020-02-25T02:30:19Z",
    "created": "2020-02-25T04:45:03Z",
    "end": "2020-02-25T12:48:28Z",
    "external_desc": "Description: A small percentage of GKE private clusters are experiencing control plane unavailability after master re-creation is triggered.",
    "modified": "2020-02-25T12:48:29Z",
    "most-recent-update": {
      "created": "2020-02-25T12:48:29Z",
      "modified": "2020-02-25T12:48:29Z",
      "text": "The issue with Google Kubernetes Engine private clusters is believed to be affecting a very small number of projects and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nNo further updates will be provided here.",
      "when": "2020-02-25T12:48:28Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "container-engine",
    "service_name": "Google Kubernetes Engine",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-02-25T12:48:29Z",
        "modified": "2020-02-25T12:48:29Z",
        "text": "The issue with Google Kubernetes Engine private clusters is believed to be affecting a very small number of projects and our Engineering Team is working on it.\n\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\n\nNo further updates will be provided here.",
        "when": "2020-02-25T12:48:28Z"
      },
      {
        "created": "2020-02-25T09:07:02Z",
        "modified": "2020-02-25T12:09:59Z",
        "text": "Description: A small percentage of GKE private clusters are experiencing control plane unavailability after master re-creation is triggered.\r\n\r\nSymptoms: Customers may not be able to apply changes to their private clusters or workloads when upgrading the cluster master, updating addons or rotating master IPs.\r\n\r\nPlease avoid upgrading the master, updating addons or rotating master IPs for GKE private clusters.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Tuesday, 2020-02-25 05:00 US/Pacific with current details.\r\n\r\nDiagnosis: Customers may not be able to apply changes to private clusters or workloads if updating cluster masters, updating addons or rotating master IPs.\r\n\r\nWorkaround: None at this time.\r\n",
        "when": "2020-02-25T09:07:02Z"
      },
      {
        "created": "2020-02-25T05:27:56Z",
        "modified": "2020-02-25T12:10:27Z",
        "text": "Description: A small percentage of GKE private clusters are experiencing control plane unavailability after master re-creation is triggered.\r\n\r\nSymptoms: Customers may not be able to apply changes to their private clusters or workloads when upgrading the cluster master, updating addons or rotating master IPs.\r\n\r\nPlease avoid upgrading the master, updating addons or rotating master IPs for GKE private clusters.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Tuesday, 2020-02-25 01:30 US/Pacific with current details.\r\n\r\nDiagnosis: Customers may not be able to apply changes to private clusters or workloads if updating cluster masters, updating addons or rotating master IPs.\r\n\r\nWorkaround: None at this time.\r\n",
        "when": "2020-02-25T05:27:56Z"
      },
      {
        "created": "2020-02-25T04:45:04Z",
        "modified": "2020-02-25T12:10:47Z",
        "text": "Description: A small percentage of GKE private clusters are experiencing control plane unavailability after master re-creation is triggered.\r\n\r\nSymptoms: Customers may not be able to apply changes to their private clusters or workloads when upgrading the cluster master, updating addons or rotating master IPs.\r\n\r\nPlease avoid upgrading the master, updating addons or rotating master IPs for GKE private clusters.\r\n\r\nOur engineering team continues to investigate the issue.\r\n\r\nWe will provide an update by Tuesday, 2020-02-24 21:30 US/Pacific with current details.\r\n\r\nDiagnosis: Customers may not be able to apply changes to private clusters or workloads if updating cluster masters, updating addons or rotating master IPs.\r\n\r\nWorkaround: None at this time.\r\n",
        "when": "2020-02-25T04:45:04Z"
      }
    ],
    "uri": "/incident/container-engine/20001"
  },
  {
    "begin": "2020-02-22T21:25:51Z",
    "created": "2020-02-22T22:09:45Z",
    "end": "2020-02-23T01:25:48Z",
    "external_desc": "We are investigating an issue with Cloud Dataflow.",
    "modified": "2020-02-23T01:25:49Z",
    "most-recent-update": {
      "created": "2020-02-23T01:25:49Z",
      "modified": "2020-02-23T01:25:49Z",
      "text": "The issue with Cloud Dataflow has been resolved for all affected users as of Saturday, 2020-02-22 17:24 US/Pacific.\nIf you have a job in an unhealthy state, either failed or queued for more than 6 hours, please restart it so that it is executed correctly, or contact Support for more information.\n\nWe thank you for your patience while we've worked on resolving the issue.",
      "when": "2020-02-23T01:25:48Z"
    },
    "number": 20001,
    "public": true,
    "service_key": "cloud-dataflow",
    "service_name": "Google Cloud Dataflow",
    "severity": "medium",
    "updates": [
      {
        "created": "2020-02-23T01:25:49Z",
        "modified": "2020-02-23T01:25:49Z",
        "text": "The issue with Cloud Dataflow has been resolved for all affected users as of Saturday, 2020-02-22 17:24 US/Pacific.\nIf you have a job in an unhealthy state, either failed or queued for more than 6 hours, please restart it so that it is executed correctly, or contact Support for more information.\n\nWe thank you for your patience while we've worked on resolving the issue.",
        "when": "2020-02-23T01:25:48Z"
      },
      {
        "created": "2020-02-23T00:31:16Z",
        "modified": "2020-02-23T00:31:16Z",
        "text": "Description: We are investigating an issue with Cloud Dataflow.\nJobs using Dataflow Shuffle may fail or (when using Flexible Resource Scheduling) be queued indefinitely.\nMitigation work is still underway by our engineering team. At this time we don't have an ETA for a full recovery yet.\n\nWe will provide more information by Saturday, 2020-02-22 17:30 US/Pacific at the latest.\n\nWorkaround: Jobs that fail to run should be re-tried by canceling any pipelines affected by the incident and re-running them.",
        "when": "2020-02-23T00:31:16Z"
      },
      {
        "created": "2020-02-22T23:31:43Z",
        "modified": "2020-02-22T23:31:43Z",
        "text": "Description: We are investigating an issue with Cloud Dataflow.\nJobs using Dataflow Shuffle may fail or (when using Flexible Resource Scheduling) be queued indefinitely.\nMitigation work is still underway by our engineering team.\n\nWe will provide more information by Saturday, 2020-02-22 16:30 US/Pacific at the latest.\n\nWorkaround: Jobs that fail to run should be re-tried by canceling any pipelines affected by the incident and re-running them.",
        "when": "2020-02-22T23:31:43Z"
      },
      {
        "created": "2020-02-22T22:31:51Z",
        "modified": "2020-02-22T22:31:51Z",
        "text": "Description: We are investigating an issue with Cloud Dataflow.\nJobs using Dataflow Shuffle may fail or (when using Flexible Resource Scheduling) be queued indefinitely.\nMitigation work is still underway by our engineering team.\n\nWe will provide more information by Saturday, 2020-02-22 15:30 US/Pacific at the latest.\n\nWorkaround: Jobs that fail to run should be re-tried by canceling any pipelines affected by the incident and re-running them.",
        "when": "2020-02-22T22:31:51Z"
      },
      {
        "created": "2020-02-22T22:09:46Z",
        "modified": "2020-02-22T22:09:46Z",
        "text": "Description: We are investigating an issue with Cloud Dataflow.\nJobs using Dataflow Shuffle may fail or (when using Flexible Resource Scheduling) be queued indefinitely.\nMitigation work is currently underway by our engineering team.\n\nWe will provide more information by Saturday, 2020-02-22 14:30 US/Pacific.\n\nWorkaround: Jobs that fail to run should be re-tried by canceling any pipelines affected by the incident and re-running them.",
        "when": "2020-02-22T22:09:46Z"
      }
    ],
    "uri": "/incident/cloud-dataflow/20001"
  }
]
