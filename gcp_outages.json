[
  {
    "id": "AQ2XT5utr5zovdxoE64s",
    "number": "1346994744969028346",
    "begin": "2021-09-22T14:00:38+00:00",
    "created": "2021-09-22T14:43:18+00:00",
    "modified": "2021-09-23T16:38:52+00:00",
    "external_desc": "Google Engineers are investigating an Issue with Cloud Build",
    "updates": [
      {
        "created": "2021-09-23T16:38:52+00:00",
        "modified": "2021-09-23T16:38:53+00:00",
        "when": "2021-09-23T16:38:52+00:00",
        "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers.\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2021-09-23 14:45 US/Pacific.}\nWe will provide more information by Thursday, 2021-09-23 15:00 US/Pacific.\nDiagnosis: Users with write access to a repository via a team are no longer considered collaborators in the GitHub API. This affects customers with GitHub Pull Request comment control triggers as certain users will no longer be able to trigger builds.\nWorkaround: To workaround this, the users should be given the writer role to a repository directly.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-23T16:09:24+00:00",
        "modified": "2021-09-23T16:09:24+00:00",
        "when": "2021-09-23T16:09:24+00:00",
        "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers.\nDescription: Mitigation work is still currently underway by our engineering team.\nWe will provide more information by Thursday, 2021-09-23 10:00 US/Pacific.\nDiagnosis: Users with write access to a repository via a team are no longer considered collaborators in the GitHub API. This affects customers with GitHub Pull Request comment control triggers as certain users will no longer be able to trigger builds.\nWorkaround: To workaround this, the users should be given the writer role to a repository directly.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-23T15:30:04+00:00",
        "modified": "2021-09-23T15:30:06+00:00",
        "when": "2021-09-23T15:30:04+00:00",
        "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers.\nDescription: Mitigation work is currently underway by our engineering team.\nWe will provide more information by Thursday, 2021-09-23 09:00 US/Pacific.\nDiagnosis: Users with write access to a repository via a team are no longer considered collaborators in the GitHub API. This affects customers with GitHub Pull Request comment control triggers as certain users will no longer be able to trigger builds.\nWorkaround: To workaround this, the users should be given the writer role to a repository directly.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-23T15:11:52+00:00",
        "modified": "2021-09-23T15:11:53+00:00",
        "when": "2021-09-23T15:11:52+00:00",
        "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers.\nDescription: Mitigation work is currently underway by our engineering team.\nWe will provide more information by Thursday, 2021-09-23 08:30 US/Pacific.\nDiagnosis: Users with write access to a repository via a team are no longer considered collaborators in the GitHub API. This affects customers with GitHub Pull Request comment control triggers as certain users will no longer be able to trigger builds.\nWorkaround: To workaround this, the users should be given the writer role to a repository directly.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-23T03:53:40+00:00",
        "modified": "2021-09-23T03:53:40+00:00",
        "when": "2021-09-23T03:53:40+00:00",
        "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers.\nDescription: Mitigation work is currently underway by our engineering team.\nWe will provide more information by Thursday, 2021-09-23 07:00 US/Pacific.\nDiagnosis: Users with write access to a repository via a team are no longer considered collaborators in the GitHub API. This affects customers with GitHub Pull Request comment control triggers as certain users will no longer be able to trigger builds.\nWorkaround: To workaround this, the users should be given the writer role to a repository directly.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-23T01:04:20+00:00",
        "modified": "2021-09-23T01:04:20+00:00",
        "when": "2021-09-23T01:04:20+00:00",
        "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers.\nDescription: Mitigation work is currently underway by our engineering team.\nWe will provide more information by Wednesday, 2021-09-22 21:00 US/Pacific.\nDiagnosis: Users with write access to a repository via a team are no longer considered collaborators in the GitHub API. This affects customers with GitHub Pull Request comment control triggers as certain users will no longer be able to trigger builds.\nWorkaround: To workaround this, the users should be given the writer role to a repository directly.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-22T22:46:44+00:00",
        "modified": "2021-09-22T22:46:49+00:00",
        "when": "2021-09-22T22:46:44+00:00",
        "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers.\nDescription: We are continuing to make progress with partners on investigating this issue. Options for mitigation are being explored as well.\nWe will provide an update by Wednesday, 2021-09-22 18:00 US/Pacific with latest details.\nDiagnosis: Users with write access to a repository via a team are no longer considered collaborators in the GitHub API. This affects customers with GitHub Pull Request comment control triggers as certain users will no longer be able to trigger builds.\nWorkaround: To workaround this, the users should be given the writer role to a repository directly.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-22T20:45:54+00:00",
        "modified": "2021-09-22T20:45:54+00:00",
        "when": "2021-09-22T20:45:54+00:00",
        "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers\nDescription: We are continuing to work with our partner to investigate the issue, and exploring other options for mitigation.\nWe will provide an update by Wednesday, 2021-09-22 16:00 US/Pacific with current details.\nDiagnosis: Users with write access to a repository via a team are no longer considered collaborators in the GitHub API. This affects customers with GitHub Pull Request comment control triggers as certain users will no longer be able to trigger builds.\nWorkaround: To workaround this, the users should be given the writer role to a repository directly.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-22T18:40:07+00:00",
        "modified": "2021-09-22T18:40:07+00:00",
        "when": "2021-09-22T18:40:07+00:00",
        "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers\nDescription: We are continuing to work with our partner to investigate the issue.\nWe will provide an update by Wednesday, 2021-09-22 14:00 US/Pacific with current details.\nDiagnosis: Users with write access to a repository via a team are no longer considered collaborators in the GitHub API. This affects customers with GitHub Pull Request comment control triggers as certain users will no longer be able to trigger builds.\nWorkaround: To workaround this, the users should be given the writer role to a repository directly.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-22T17:14:19+00:00",
        "modified": "2021-09-22T17:14:19+00:00",
        "when": "2021-09-22T17:14:19+00:00",
        "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers\nDescription: We have attempted a rollback of the current release in an effort to mitigate the issue, but have not seen improvements in the situation. We are continuing to work with our partner to investigate the issue.\nWe will provide an update by Wednesday, 2021-09-22 12:00 US/Pacific with current details.\nDiagnosis: GitHub Pull Request Triggers with comment control enabled are not firing for customers with the \"writer\" role.\nWorkaround: A workaround is to use the \"collaborator\" role.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-22T16:28:45+00:00",
        "modified": "2021-09-22T16:28:51+00:00",
        "when": "2021-09-22T16:28:45+00:00",
        "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers\nDescription: We are experiencing an issue with Cloud Build related to Github Pull Request Triggers.\nOur engineering team continues to investigate this issue to identify a mitigation. We are also reaching out to our partner to assist with the investigation.\nWe will provide an update by Wednesday, 2021-09-22 10:30 US/Pacific with current details.\nDiagnosis: GitHub Pull Request Triggers with comment control enabled are not firing for customers with the \"writer\" role.\nWorkaround: A workaround is to use the \"collaborator\" role.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-22T15:51:07+00:00",
        "modified": "2021-09-22T15:51:07+00:00",
        "when": "2021-09-22T15:51:07+00:00",
        "text": "Summary: Google Engineers are investigating an Issue with Cloud Build\nDescription: We are experiencing an issue with Cloud Build related to Github Pull Request Triggers.\nOur engineering team continues to investigate this issue to identify a mitigation.\nWe will provide an update by Wednesday, 2021-09-22 09:35 US/Pacific with current details.\nDiagnosis: GitHub Pull Request Triggers with comment control enabled are not firing for customers with the \"writer\" role\nWorkaround: A workaround is to use the \"collaborator\" role.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-22T15:06:20+00:00",
        "modified": "2021-09-22T15:06:26+00:00",
        "when": "2021-09-22T15:06:20+00:00",
        "text": "Summary: Google Engineers are investigating an Issue with Cloud Build\nDescription: We are experiencing an issue with Cloud Build related to Github Pull Request Triggers\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-09-22 09:15 US/Pacific with current details.\nDiagnosis: GitHub Pull Request Triggers with comment control enabled are not firing for customers with the \"writer\" role\nWorkaround: A workaround is to use the \"collaborator\" role.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-22T14:43:09+00:00",
        "modified": "2021-09-22T14:43:18+00:00",
        "when": "2021-09-22T14:43:09+00:00",
        "text": "Summary: Google Engineers are investigating an Issue with Cloud Build\nDescription: We are experiencing an issue with Cloud Build related to Github Pull Request Triggers\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-09-22 09:15 US/Pacific with current details.\nDiagnosis: There is a regression for Github Pull Request Triggers with comment control enabled. Customers with the \"writer\" role may not be able to trigger builds\nWorkaround: A workaround is to use the \"collaborator\" role.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-23T16:38:52+00:00",
      "modified": "2021-09-23T16:38:53+00:00",
      "when": "2021-09-23T16:38:52+00:00",
      "text": "Summary: Google Engineers are investigating an issue with Cloud Build Github Pull Request Triggers.\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2021-09-23 14:45 US/Pacific.}\nWe will provide more information by Thursday, 2021-09-23 15:00 US/Pacific.\nDiagnosis: Users with write access to a repository via a team are no longer considered collaborators in the GitHub API. This affects customers with GitHub Pull Request comment control triggers as certain users will no longer be able to trigger builds.\nWorkaround: To workaround this, the users should be given the writer role to a repository directly.",
      "status": "SERVICE_DISRUPTION"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "BGJQ6jbGK4kUuBTQFZ1G",
    "service_name": "Cloud Developer Tools",
    "affected_products": [
      {
        "title": "Cloud Developer Tools",
        "id": "BGJQ6jbGK4kUuBTQFZ1G"
      }
    ],
    "uri": "incidents/AQ2XT5utr5zovdxoE64s"
  },
  {
    "id": "rjF86FbooET3FDpMV9w1",
    "number": "1694098087281257421",
    "begin": "2021-09-17T15:00:00+00:00",
    "created": "2021-09-17T14:39:52+00:00",
    "end": "2021-09-17T18:25:00+00:00",
    "modified": "2021-09-20T23:33:53+00:00",
    "external_desc": "Increased VM failure rates in a subset of Google Cloud zones",
    "updates": [
      {
        "created": "2021-09-20T23:33:50+00:00",
        "modified": "2021-09-20T23:33:50+00:00",
        "when": "2021-09-20T23:33:50+00:00",
        "text": "**Incident Start:** 17 September 2021 08:00\n**Incident End:** 17 September 2021 11:25\n**Duration:** 3 hours, 25 minutes\n**Affected Services and Features:**\nGoogle Compute Engine\n**Regions/Zones:** us-central1-f\n**Description:**\nGoogle Compute Engine reported elevated instance failures. From preliminary analysis an issue with a node software rollout was initially suspected, but subsequently ruled out. Due to the potential impact, we proactively notified customers on the Cloud Status Dashboard. However, further analysis concluded the error rates were negligible and not a cause for concern.\n**Customer Impact:**\nAfter analysis, it was determined this particular incident did not have any customer impact.\n**Additional details:**\nWe are continuing to enhance our detection mechanisms to avoid false positives.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-17T21:20:13+00:00",
        "modified": "2021-09-17T21:20:13+00:00",
        "when": "2021-09-17T21:20:13+00:00",
        "text": "The issue with Google Compute Engine is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-17T19:00:08+00:00",
        "modified": "2021-09-17T19:00:09+00:00",
        "when": "2021-09-17T19:00:08+00:00",
        "text": "Summary: Increased VM failure rates in a subset of Google Cloud zones\nDescription: Mitigation work is still underway with our engineering team.\nWe do not have an ETA for mitigation at this point.\nAs a workaround, customers can use alternative zones.\nWe will provide more information by Friday, 2021-09-17 14:15 US/Pacific.\nDiagnosis: Customers may be experiencing higher VM failure rates.\nWorkaround: Use alternative zones.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-17T17:18:19+00:00",
        "modified": "2021-09-17T17:18:19+00:00",
        "when": "2021-09-17T17:18:19+00:00",
        "text": "Summary: Increased VM failure rates in a subset of Google Cloud zones\nDescription: Mitigation work is still underway with our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-09-17 12:15 US/Pacific.\nDiagnosis: Customers may be experiencing higher VM failure rates.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-17T15:52:25+00:00",
        "modified": "2021-09-17T15:52:26+00:00",
        "when": "2021-09-17T15:52:25+00:00",
        "text": "Summary: Increased VM failure rates in a subset of Google Cloud zones\nDescription: Mitigation work is still underway with our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-09-17 10:15 US/Pacific.\nDiagnosis: Customers may be experiencing higher VM failure rates.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-17T15:06:50+00:00",
        "modified": "2021-09-17T15:06:52+00:00",
        "when": "2021-09-17T15:06:50+00:00",
        "text": "Summary: Increased VM failure rates in a subset of Google Cloud zones\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-09-17 09:00 US/Pacific.\nDiagnosis: Customers may be experiencing higher VM failure rates.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-17T14:39:44+00:00",
        "modified": "2021-09-17T14:39:53+00:00",
        "when": "2021-09-17T14:39:44+00:00",
        "text": "Summary: Increased VM failure rates in a subset of Google Cloud zones\nDescription: We are experiencing an intermittent issue with Google Compute Engine in the following zones:\nasia-east1-c\nasia-east2-c\nasia-northeast1-c\nasia-northeast2-c\nasia-northeast3-c\nasia-south1-c\nasia-south2-c\nasia-southeast1-c\nasia-southeast2-c\naustralia-southeast1-c\naustralia-southeast2-c\neurope-central2-c\neurope-north1-c\neurope-west1-c\neurope-west2-c\neurope-west3-c\neurope-west4-c\neurope-west6-c\nnorthamerica-northeast1-c\nnorthamerica-northeast2-c\nsouthamerica-east1-c\nus-central1-c\nus-central1-f\nus-east1-c\nus-east4-c\nus-west1-c\nus-west2-a\nus-west2-b\nus-west2-c\nus-west3-c\nus-west4-c\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-09-17 08:10 US/Pacific with current details.\nDiagnosis: Customers may be experiencing higher VM failure rates.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-20T23:33:50+00:00",
      "modified": "2021-09-20T23:33:50+00:00",
      "when": "2021-09-20T23:33:50+00:00",
      "text": "**Incident Start:** 17 September 2021 08:00\n**Incident End:** 17 September 2021 11:25\n**Duration:** 3 hours, 25 minutes\n**Affected Services and Features:**\nGoogle Compute Engine\n**Regions/Zones:** us-central1-f\n**Description:**\nGoogle Compute Engine reported elevated instance failures. From preliminary analysis an issue with a node software rollout was initially suspected, but subsequently ruled out. Due to the potential impact, we proactively notified customers on the Cloud Status Dashboard. However, further analysis concluded the error rates were negligible and not a cause for concern.\n**Customer Impact:**\nAfter analysis, it was determined this particular incident did not have any customer impact.\n**Additional details:**\nWe are continuing to enhance our detection mechanisms to avoid false positives.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/rjF86FbooET3FDpMV9w1"
  },
  {
    "id": "nkUtGfx3WQcAB1iLEtcd",
    "number": "17175204310165775620",
    "begin": "2021-09-13T17:20:00+00:00",
    "created": "2021-09-17T20:10:07+00:00",
    "end": "2021-09-18T08:27:00+00:00",
    "modified": "2021-09-20T19:27:09+00:00",
    "external_desc": "Global: Cloud Networking connectivity issues for customers using packet mirroring.",
    "updates": [
      {
        "created": "2021-09-20T19:25:32+00:00",
        "modified": "2021-09-20T19:25:32+00:00",
        "when": "2021-09-20T19:25:32+00:00",
        "text": "We apologize for the inconvenience this service outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 13 September 2021 10:20\n**Incident End:** 18 September 2021 01:27\n**Duration:** 4 days, 15 hours, 7 minutes\n**Affected Services and Features:**\n- Google Compute Engine – Access to Google Cloud services such as Google Cloud Storage, Cloud Bigtable, Cloud Spanner, and Google Container Registry were affected for Virtual Machine (VMs) with packet mirroring enabled.\n- Google Kubernetes Engine – Clusters with mirroring enabled had issues accessing Google endpoints including Google Container Registry and Google Cloud storage buckets.\n**Regions/Zones:** Global\n**Description:**\nGoogle Compute Engine (GCE) VM instances and Google Kubernetes Engine (GKE) instances were unable to access Google Cloud services if the packet mirroring feature was enabled.\nFrom preliminary analysis, the root cause was identified as an issue in the packet mirroring functionality that resulted in packet drops for VM to Google Cloud Services endpoint connections.\n**Customer Impact:**\n* GCE VMs with packet mirroring enabled were unable to access Google services. * Affected VMs were unable to retrieve Google Container Registry (GCR) images. * Affected VMs experienced timeouts when accessing Google Services.\n* GKE clusters with packet mirroring enabled were unable to access Google services.\n**Additional details:**\n* As a workaround, customers were informed to disable packet mirroring (if enabled) in order to reduce the impact on affected projects.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-18T09:47:54+00:00",
        "modified": "2021-09-18T10:01:57+00:00",
        "when": "2021-09-18T09:47:54+00:00",
        "text": "The issue with Cloud Networking has been mitigated for all affected projects and there is no customer impact as of Saturday, 2021-09-18 01:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-18T07:07:07+00:00",
        "modified": "2021-09-18T07:07:07+00:00",
        "when": "2021-09-18T07:07:07+00:00",
        "text": "Summary: Global: Cloud Networking connectivity issues for customers using packet mirroring.\nDescription: Engineering team is continuing to monitor the mitigation steps currently being rolled out and expect it to complete by Saturday, 2021-09-18 03:00 US/Pacific.\nCustomers can disable packet mirroring as a workaround.\nWe will provide more information by Saturday, 2021-09-18 03:00 US/Pacific.\nDiagnosis: Customers might experience connection failures or delays for connections from GCE VMs to Google endpoints including gcr.io and Google Cloud Storage buckets.\nWorkaround: Disable packet mirroring.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-18T05:43:16+00:00",
        "modified": "2021-09-18T05:43:22+00:00",
        "when": "2021-09-18T05:43:16+00:00",
        "text": "Summary: Global: Cloud Networking connectivity issues for customers using packet mirroring.\nDescription: Engineering team is continuing to monitor the mitigation steps currently being rolled out and expect it to complete by Saturday, 2021-09-18 01:00 US/Pacific.\nCustomers can disable packet mirroring as a workaround.\nWe will provide more information by Saturday, 2021-09-18 01:00 US/Pacific.\nDiagnosis: Customers might experience connection failures or delays for connections from GCE VMs to Google endpoints including gcr.io and Google Cloud Storage buckets.\nWorkaround: Disable packet mirroring.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-18T02:22:07+00:00",
        "modified": "2021-09-18T02:22:12+00:00",
        "when": "2021-09-18T02:22:07+00:00",
        "text": "Summary: Global: Cloud Networking connectivity issues for customers using packet mirroring.\nDescription: Mitigation work is underway by our engineering team. The mitigation is expected to complete by Friday, 2021-09-17 23:00 US/Pacific.\nCustomers can disable packet mirroring as a workaround.\nWe will provide more information by Friday, 2021-09-17 23:00 US/Pacific.\nDiagnosis: Customers might experience connection failures or delays for connections from GCE VMs to Google endpoints including gcr.io and Google Cloud Storage buckets.\nWorkaround: Disable packet mirroring.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-17T20:10:06+00:00",
        "modified": "2021-09-17T20:10:07+00:00",
        "when": "2021-09-17T20:10:06+00:00",
        "text": "Summary: Global: Cloud Networking connectivity issues for customers using packet mirroring.\nDescription: Mitigation work is underway by our engineering team. The mitigation is expected to complete by Friday, 2021-09-17 10:00 US/Pacific.\nCustomers can disable packet mirroring as a workaround.\nWe will provide more information by Friday, 2021-09-17 23:00 US/Pacific.\nDiagnosis: Customers might experience connection failures or delays for connections from GCE VMs to Google endpoints including gcr.io and Google Cloud Storage buckets.\nWorkaround: Disable packet mirroring.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-20T19:25:32+00:00",
      "modified": "2021-09-20T19:25:32+00:00",
      "when": "2021-09-20T19:25:32+00:00",
      "text": "We apologize for the inconvenience this service outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 13 September 2021 10:20\n**Incident End:** 18 September 2021 01:27\n**Duration:** 4 days, 15 hours, 7 minutes\n**Affected Services and Features:**\n- Google Compute Engine – Access to Google Cloud services such as Google Cloud Storage, Cloud Bigtable, Cloud Spanner, and Google Container Registry were affected for Virtual Machine (VMs) with packet mirroring enabled.\n- Google Kubernetes Engine – Clusters with mirroring enabled had issues accessing Google endpoints including Google Container Registry and Google Cloud storage buckets.\n**Regions/Zones:** Global\n**Description:**\nGoogle Compute Engine (GCE) VM instances and Google Kubernetes Engine (GKE) instances were unable to access Google Cloud services if the packet mirroring feature was enabled.\nFrom preliminary analysis, the root cause was identified as an issue in the packet mirroring functionality that resulted in packet drops for VM to Google Cloud Services endpoint connections.\n**Customer Impact:**\n* GCE VMs with packet mirroring enabled were unable to access Google services. * Affected VMs were unable to retrieve Google Container Registry (GCR) images. * Affected VMs experienced timeouts when accessing Google Services.\n* GKE clusters with packet mirroring enabled were unable to access Google services.\n**Additional details:**\n* As a workaround, customers were informed to disable packet mirroring (if enabled) in order to reduce the impact on affected projects.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/nkUtGfx3WQcAB1iLEtcd"
  },
  {
    "id": "SDkKgEgDZJCrvutAz3bn",
    "number": "3108142056827409484",
    "begin": "2021-09-09T19:06:03+00:00",
    "created": "2021-09-09T19:06:04+00:00",
    "end": "2021-09-09T19:54:38+00:00",
    "modified": "2021-09-09T22:25:23+00:00",
    "external_desc": "europe-central2, europe-west3: Elevated error rates for GKE control plane",
    "updates": [
      {
        "created": "2021-09-09T22:25:23+00:00",
        "modified": "2021-09-09T22:25:24+00:00",
        "when": "2021-09-09T22:25:23+00:00",
        "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 09 September 2021 10:46\n**Incident End:** 09 September 2021 12:44\n**Duration:** 1 hour, 58 minutes\n**Affected Services and Features:**\n- Google Kubernetes Engine (GKE) - Cluster operations\n**Regions/Zones:** europe-west3 , europe-central2\n**Description:**\nGoogle Kubernetes Engine (GKE) experienced elevated error rates intermittently in europe-west3 and europe-central2 for a duration of 1 hour, 58 minutes. From preliminary analysis, the issue was caused by an ongoing rollout in the backend authentication service. The backend authentication service was rolled back, ending impact at 12:44.\n**Customer Impact:**\n- Less than 0.5% of cluster operations that require an authentication token experienced elevated error rates.\n- Elevated error rates on GKE master pods that required authorization to change GCE resources.\n**Additional details:**\nA retry of the failed operation would have completed successfully.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-09T19:54:37+00:00",
        "modified": "2021-09-09T19:54:38+00:00",
        "when": "2021-09-09T19:54:37+00:00",
        "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Thursday, 2021-09-09 12:53 US/Pacific.\nThere is no further impact to our customers.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-09T19:48:23+00:00",
        "modified": "2021-09-09T19:48:23+00:00",
        "when": "2021-09-09T19:48:23+00:00",
        "text": "Summary: europe-central2, europe-west3: Elevated error rates for GKE control plane\nDescription: Our engineering team is currently working on the mitigation of the issue.\nThe affected locations have reduced and updated for the incident post.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2021-09-09 14:00 US/Pacific.\nDiagnosis: Customers may experience issue with cluster availability and errors with CreateToken. Service account may intermittently succeed or fail.\nWorkaround: Customers who experience failure can retry.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-09T19:29:36+00:00",
        "modified": "2021-09-09T19:29:36+00:00",
        "when": "2021-09-09T19:29:36+00:00",
        "text": "Summary: europe-central2, europe-west3, europe-west4, us-east4, asia-northeast1: Elevated error rates for GKE control plane\nDescription: We are experiencing an issue with Google Kubernetes Engine.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-09-09 14:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience issue with cluster availability and errors with CreateToken.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-09T19:18:18+00:00",
        "modified": "2021-09-09T19:18:18+00:00",
        "when": "2021-09-09T19:18:18+00:00",
        "text": "Summary: europe-central2, europe-west3, europe-west4, us-east4, asia-northeast1: Elevated error rates for GKE control plane\nDescription: We are investigating a potential issue with Google Kubernetes Engine.\nWe will provide more information by Thursday, 2021-09-09 12:35 US/Pacific.\nDiagnosis: We are currently investigating the impact of this incident.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-09T19:06:04+00:00",
        "modified": "2021-09-09T19:06:05+00:00",
        "when": "2021-09-09T19:06:04+00:00",
        "text": "Summary: europe-west3, europe-west4, us-east4, asia-northeast1: Elevated error rates for GKE control plane\nDescription: We are investigating a potential issue with Google Kubernetes Engine.\nWe will provide more information by Thursday, 2021-09-09 12:35 US/Pacific.\nDiagnosis: We are currently investigating the impact of this incident.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-09T22:25:23+00:00",
      "modified": "2021-09-09T22:25:24+00:00",
      "when": "2021-09-09T22:25:23+00:00",
      "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 09 September 2021 10:46\n**Incident End:** 09 September 2021 12:44\n**Duration:** 1 hour, 58 minutes\n**Affected Services and Features:**\n- Google Kubernetes Engine (GKE) - Cluster operations\n**Regions/Zones:** europe-west3 , europe-central2\n**Description:**\nGoogle Kubernetes Engine (GKE) experienced elevated error rates intermittently in europe-west3 and europe-central2 for a duration of 1 hour, 58 minutes. From preliminary analysis, the issue was caused by an ongoing rollout in the backend authentication service. The backend authentication service was rolled back, ending impact at 12:44.\n**Customer Impact:**\n- Less than 0.5% of cluster operations that require an authentication token experienced elevated error rates.\n- Elevated error rates on GKE master pods that required authorization to change GCE resources.\n**Additional details:**\nA retry of the failed operation would have completed successfully.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/SDkKgEgDZJCrvutAz3bn"
  },
  {
    "id": "mRTeQ94fZRLdx2Q7NLLX",
    "number": "6101118185948634658",
    "begin": "2021-09-07T22:04:00+00:00",
    "created": "2021-09-07T22:57:42+00:00",
    "end": "2021-09-07T22:45:00+00:00",
    "modified": "2021-09-08T17:26:25+00:00",
    "external_desc": "Regions: (Asia, Western US) <-> (Eastern US, Europe). Packet loss on inter region traffic.",
    "updates": [
      {
        "created": "2021-09-08T17:25:57+00:00",
        "modified": "2021-09-08T17:25:57+00:00",
        "when": "2021-09-08T17:25:57+00:00",
        "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 07 September 2021 15:04\n**Incident End:** 07 September 2021 15:45\n**Duration:** 41 minutes\n**Affected Services and Features:**\n- Google Cloud Networking - Cloud VPC, Cloud Interconnect.\n- Ingress and Egress traffic of any Google Cloud services to and from the affected regions.\n**Regions/Zones:**\nThe traffic between multiple regions (inter-region) was affected, while the traffic within each region (intra-region) remained unaffected. The regions asia-east, asia-northeast, asia-southeast, australia-southeast, us-west, and us-central had trouble connecting to the regions of us-east, northamerica-northeast, europe-central, europe-north, and europe-west, and vice-versa.\n**Description:**\nGoogle Cloud Networking experienced elevated packet loss for traffic between multiple regions for a duration of 41 minutes. Preliminary analysis indicates that during routine and typically non-disruptive router maintenance, a software issue occurred which unintentionally impacted packet forwarding.\n**Customer Impact:**\n- Google Cloud Networking - elevated packet loss\n- Other services using Cloud Networking - elevated latencies or other networking related delays.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-07T23:16:21+00:00",
        "modified": "2021-09-07T23:16:21+00:00",
        "when": "2021-09-07T23:16:21+00:00",
        "text": "The issue with Cloud Networking has been resolved for all affected projects as of Tuesday, 2021-09-07 15:45 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-07T23:07:09+00:00",
        "modified": "2021-09-07T23:07:14+00:00",
        "when": "2021-09-07T23:07:09+00:00",
        "text": "Summary: Regions: (Asia, Western US) <-> (Eastern US, Europe). Packet loss on inter region traffic. Mitigation completed.\nDescription: We believe the issue with Cloud Networking is mitigated starting 15:45 US/Pacific . Our engineering team continues to work towards full resolution of the issue.\nWe will provide an update by Tuesday, 2021-09-07 16:37 US/Pacific with current details.\nDiagnosis: Customer will see packet loss on traffic between regions in US and Asia\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-07T23:05:27+00:00",
        "modified": "2021-09-07T23:05:28+00:00",
        "when": "2021-09-07T23:05:27+00:00",
        "text": "Summary: Regions: (Asia, Western US) <-> (Eastern US, Europe). Packet loss on inter region traffic. Mitigation completed.\nDescription: We believe the issue with Cloud Networking is mitigated starting 15:45. Our engineering team continues to work towards full resolution of the issue.\nWe will provide an update by Tuesday, 2021-09-07 16:37 US/Pacific with current details.\nDiagnosis: Customer will see packet loss on traffic between regions in US and Asia\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-07T22:57:36+00:00",
        "modified": "2021-09-07T22:57:42+00:00",
        "when": "2021-09-07T22:57:36+00:00",
        "text": "Summary: Regions: US, Asia: Packet loss reported on GCE traffic between US and Asia\nDescription: We are experiencing an issue with Cloud Networking beginning at Tuesday, 2021-09-07 15:04 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-09-07 16:28 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customer will see packet loss on traffic between regions in US and Asia\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-08T17:25:57+00:00",
      "modified": "2021-09-08T17:25:57+00:00",
      "when": "2021-09-08T17:25:57+00:00",
      "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 07 September 2021 15:04\n**Incident End:** 07 September 2021 15:45\n**Duration:** 41 minutes\n**Affected Services and Features:**\n- Google Cloud Networking - Cloud VPC, Cloud Interconnect.\n- Ingress and Egress traffic of any Google Cloud services to and from the affected regions.\n**Regions/Zones:**\nThe traffic between multiple regions (inter-region) was affected, while the traffic within each region (intra-region) remained unaffected. The regions asia-east, asia-northeast, asia-southeast, australia-southeast, us-west, and us-central had trouble connecting to the regions of us-east, northamerica-northeast, europe-central, europe-north, and europe-west, and vice-versa.\n**Description:**\nGoogle Cloud Networking experienced elevated packet loss for traffic between multiple regions for a duration of 41 minutes. Preliminary analysis indicates that during routine and typically non-disruptive router maintenance, a software issue occurred which unintentionally impacted packet forwarding.\n**Customer Impact:**\n- Google Cloud Networking - elevated packet loss\n- Other services using Cloud Networking - elevated latencies or other networking related delays.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/mRTeQ94fZRLdx2Q7NLLX"
  },
  {
    "id": "16SSwVXrYSLjy8fEMvyZ",
    "number": "1280580001127136058",
    "begin": "2021-09-07T18:19:00+00:00",
    "created": "2021-09-08T19:17:06+00:00",
    "end": "2021-09-08T18:00:00+00:00",
    "modified": "2021-09-09T21:09:57+00:00",
    "external_desc": "us-central1: Cloud Functions experiencing increased latency and pending queue aborted error request rate.",
    "updates": [
      {
        "created": "2021-09-09T21:09:57+00:00",
        "modified": "2021-09-09T21:09:57+00:00",
        "when": "2021-09-09T21:09:57+00:00",
        "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 07 September 2021 11:19\n**Incident End:** 08 September 2021 11:00\n**Duration:** 23 hours, 41 minutes\n**Affected Services and Features:**\n- Google App Engine - Standard\n- Google Cloud Functions\n**Regions/Zones:** us-central1\n**Description:**\nGoogle App Engine and Google Cloud Functions experienced elevated latency on requests in us-central1 on a small number of projects for a duration of 23 hours, 41 minutes. From preliminary analysis, the root cause of the issue is due to a sudden increase in load within the region.\n**Customer Impact:**\n- Affected customers would have experienced elevated serving latency on apps and functions.\n- This may have manifested with http errors and corresponding cloud logging entries such as: “Request was aborted after waiting too long to attempt to service your request.”\n**Additional Details:**\n- Impact was mitigated by applying targeted throttling.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-08T19:28:29+00:00",
        "modified": "2021-09-08T19:28:29+00:00",
        "when": "2021-09-08T19:28:29+00:00",
        "text": "The issue with Google Cloud Functions has been resolved for all affected projects as of Wednesday, 2021-09-08 12:27 US/Pacific.\nPlease follow the link to status dashboard post with more details: https://status.cloud.google.com/incidents/uaRinwS8pu2yyjdYbDaM\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-08T19:16:59+00:00",
        "modified": "2021-09-08T19:17:06+00:00",
        "when": "2021-09-08T19:16:59+00:00",
        "text": "Summary: us-central1: Cloud Functions experiencing increased latency and pending queue aborted error request rate.\nDescription: Engineering team investigation has identified increased latency and an increase in pushbacks to requests (increase in pending queue aborted error request rate) for some customers.\nOur engineering team continues to work on the mitigation to reduce the pushback errors and reduce the latency observed.\nFor further updates please follow this link: https://status.cloud.google.com/incidents/uaRinwS8pu2yyjdYbDaM\nDiagnosis: Customer may observe increased latency and heightened pending queue aborted error request rate.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-09T21:09:57+00:00",
      "modified": "2021-09-09T21:09:57+00:00",
      "when": "2021-09-09T21:09:57+00:00",
      "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 07 September 2021 11:19\n**Incident End:** 08 September 2021 11:00\n**Duration:** 23 hours, 41 minutes\n**Affected Services and Features:**\n- Google App Engine - Standard\n- Google Cloud Functions\n**Regions/Zones:** us-central1\n**Description:**\nGoogle App Engine and Google Cloud Functions experienced elevated latency on requests in us-central1 on a small number of projects for a duration of 23 hours, 41 minutes. From preliminary analysis, the root cause of the issue is due to a sudden increase in load within the region.\n**Customer Impact:**\n- Affected customers would have experienced elevated serving latency on apps and functions.\n- This may have manifested with http errors and corresponding cloud logging entries such as: “Request was aborted after waiting too long to attempt to service your request.”\n**Additional Details:**\n- Impact was mitigated by applying targeted throttling.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "oW4vJ7VNqyxTWNzSHopX",
    "service_name": "Google Cloud Functions",
    "affected_products": [
      {
        "title": "Google Cloud Functions",
        "id": "oW4vJ7VNqyxTWNzSHopX"
      }
    ],
    "uri": "incidents/16SSwVXrYSLjy8fEMvyZ"
  },
  {
    "id": "uaRinwS8pu2yyjdYbDaM",
    "number": "13800817493833147491",
    "begin": "2021-09-07T18:19:00+00:00",
    "created": "2021-09-08T18:41:04+00:00",
    "end": "2021-09-08T18:00:00+00:00",
    "modified": "2021-09-09T21:09:56+00:00",
    "external_desc": "us-central1: Google App Engine Standard experiencing increased latency and pending queue aborted error request rate.",
    "updates": [
      {
        "created": "2021-09-09T21:09:56+00:00",
        "modified": "2021-09-09T21:09:56+00:00",
        "when": "2021-09-09T21:09:56+00:00",
        "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 07 September 2021 11:19\n**Incident End:** 08 September 2021 11:00\n**Duration:** 23 hours, 41 minutes\n**Affected Services and Features:**\n- Google App Engine - Standard\n- Google Cloud Functions\n**Regions/Zones:** us-central1\n**Description:**\nGoogle App Engine and Google Cloud Functions experienced elevated latency on requests in us-central1 on a small number of projects for a duration of 23 hours, 41 minutes. From preliminary analysis, the root cause of the issue is due to a sudden increase in load within the region.\n**Customer Impact:**\n- Affected customers would have experienced elevated serving latency on apps and functions.\n- This may have manifested with http errors and corresponding cloud logging entries such as: “Request was aborted after waiting too long to attempt to service your request.”\n**Additional Details:**\n- Impact was mitigated by applying targeted throttling.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-08T19:25:36+00:00",
        "modified": "2021-09-08T19:25:41+00:00",
        "when": "2021-09-08T19:25:36+00:00",
        "text": "The issue with Google App Engine and Cloud Functions has been resolved for all affected projects as of Wednesday, 2021-09-08 12:24 US/Pacific.\nThere is no further impact to our customers.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-08T18:40:57+00:00",
        "modified": "2021-09-08T18:41:05+00:00",
        "when": "2021-09-08T18:40:57+00:00",
        "text": "Summary: us-central1: Google App Engine Standard and Cloud Functions experiencing increased latency and pending queue aborted error request rate.\nDescription: Further investigation into the increased latency issue has confirmed that we are also observing an increase in pushbacks to requests (increase in pending queue aborted error request rate) for some customers.\nOur engineering team continues to work on the mitigation to reduce the pushback errors and reduce the latency observed.\nWe will provide more information by Wednesday, 2021-09-08 12:30 US/Pacific.\nDiagnosis: Customer may observe increased latency and heightened pending queue aborted error request rate.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-09T21:09:56+00:00",
      "modified": "2021-09-09T21:09:56+00:00",
      "when": "2021-09-09T21:09:56+00:00",
      "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 07 September 2021 11:19\n**Incident End:** 08 September 2021 11:00\n**Duration:** 23 hours, 41 minutes\n**Affected Services and Features:**\n- Google App Engine - Standard\n- Google Cloud Functions\n**Regions/Zones:** us-central1\n**Description:**\nGoogle App Engine and Google Cloud Functions experienced elevated latency on requests in us-central1 on a small number of projects for a duration of 23 hours, 41 minutes. From preliminary analysis, the root cause of the issue is due to a sudden increase in load within the region.\n**Customer Impact:**\n- Affected customers would have experienced elevated serving latency on apps and functions.\n- This may have manifested with http errors and corresponding cloud logging entries such as: “Request was aborted after waiting too long to attempt to service your request.”\n**Additional Details:**\n- Impact was mitigated by applying targeted throttling.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "kchyUtnkMHJWaAva8aYc",
    "service_name": "Google App Engine",
    "affected_products": [
      {
        "title": "Google App Engine",
        "id": "kchyUtnkMHJWaAva8aYc"
      }
    ],
    "uri": "incidents/uaRinwS8pu2yyjdYbDaM"
  },
  {
    "id": "WzDzgmTjQfAKPJha6Rbb",
    "number": "3409436363697907976",
    "begin": "2021-09-03T12:40:00+00:00",
    "created": "2021-09-03T13:39:38+00:00",
    "end": "2021-09-03T13:20:00+00:00",
    "modified": "2021-09-03T19:27:11+00:00",
    "external_desc": "europe-west2-c: Cloud networking is currently experiencing issues.",
    "updates": [
      {
        "created": "2021-09-03T19:27:00+00:00",
        "modified": "2021-09-03T19:27:00+00:00",
        "when": "2021-09-03T19:27:00+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 03 September 2021 05:40\n**Incident End:** 03 September 2021 06:20\n**Duration:** 40 minutes\n**Affected Services and Features:**\n- Cloud Networking\n- Compute Engine\n- Persistent Disk\n- Kubernetes Engine\n- App Engine\n- Cloud Run\n- Cloud Bigtable\n- Cloud Storage\n- Cloud Filestore\n- Cloud MemoryStore\n- Cloud Monitoring\n- Cloud VPN\n**Regions/Zones:** europe-west2-c\n**Description:**\nGoogle Cloud Networking experienced elevated packet loss and latency in europe-west2-c for a duration of 40 minutes. Additional Cloud services that use Cloud Networking experienced similar symptoms. From preliminary analysis, the root cause of the issue was a sudden redirection of traffic from a datacenter that was experiencing an issue.\n**Customer Impact:**\n- Affected customers may have experienced elevated packet loss and latency as their traffic was temporarily redirected.\n- Google Compute Engine instances experienced failed connectivity and packet loss on ingress, egress, and inter-zonal traffic. Autoscaling was also impacted and may have failed to make decisions.\n- Persistent Disk experienced elevated I/O latency on regional and zonal disks\n- Google Kubernetes Engine clusters experienced 30% of zonal and 5% of regional clusters reporting as unhealthy.\n- Google App Engine and Cloud Run served elevated 500 errors within europe-west2.\n- Cloud Bigtable experienced an elevated error rate and latency on operations within europe-west2.\n- Cloud SQL experienced issues connecting to instances in europe-west2. Affected instances may have lost telemetry data, and HA instances failed over if the primary was in the affected zone.\n- Google Cloud Storage experienced elevated read errors of up to 2.3% in europe-west2.\n- Cloud Filestore instances within europe-west2-c may have been unreachable.\n- Cloud MemoryStore instances within europe-west2 may have been unreachable.\n- Cloud Monitoring experienced delayed or missing metrics from resources in the zone.\n- Cloud VPN experienced a short duration where tunnels went down for a short time before being reestablished.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-03T14:17:31+00:00",
        "modified": "2021-09-03T14:17:32+00:00",
        "when": "2021-09-03T14:17:31+00:00",
        "text": "The issue with Cloud Networking has been resolved for all affected users as of Friday, 2021-09-03 06:20 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-03T14:06:16+00:00",
        "modified": "2021-09-03T14:06:16+00:00",
        "when": "2021-09-03T14:06:16+00:00",
        "text": "Summary: europe-west2-c: Cloud networking is currently experiencing issues.\nDescription: On further investigation we have confirmed the issue is affecting a single zone europe-west2-c.\nOur engineering team is currently investigating the issue and confirming the current impact to our users.\nWe will provide an update by Friday, 2021-09-03 07:30 US/Pacific with current details.\nDiagnosis: Customer may high latency and packet loss.\nWorkaround: Other Zone and region can be utilized for workaround.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-03T14:02:27+00:00",
        "modified": "2021-09-03T14:02:28+00:00",
        "when": "2021-09-03T14:02:27+00:00",
        "text": "Summary: europe-west2: Cloud networking is currently experiencing issues.\nDescription: We are experiencing an issue with Cloud Networking , beginning at Friday, 2021-09-03 0535 US/Pacific\nOur engineering team is currently investigating the issue and confirming the current impact to our users.\nWe will provide an update by Friday, 2021-09-03 07:30 US/Pacific with current details.\nDiagnosis: Customer may high latency and packet loss.\nWorkaround: Other Zone and region can be utilized for workaround.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-03T13:39:36+00:00",
        "modified": "2021-09-03T13:39:39+00:00",
        "when": "2021-09-03T13:39:36+00:00",
        "text": "Summary: Cloud networking issues being investigated impacting some user in eu-west2c\nDescription: We are experiencing an issue with Cloud Networking , beginning at Friday, 2021-09-03 0535 US/Pacific\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-09-03 06:59 US/Pacific with current details.\nDiagnosis: Customer may high latency and packet loss\nWorkaround: Other Zone and region are unaffected",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-03T19:27:00+00:00",
      "modified": "2021-09-03T19:27:00+00:00",
      "when": "2021-09-03T19:27:00+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 03 September 2021 05:40\n**Incident End:** 03 September 2021 06:20\n**Duration:** 40 minutes\n**Affected Services and Features:**\n- Cloud Networking\n- Compute Engine\n- Persistent Disk\n- Kubernetes Engine\n- App Engine\n- Cloud Run\n- Cloud Bigtable\n- Cloud Storage\n- Cloud Filestore\n- Cloud MemoryStore\n- Cloud Monitoring\n- Cloud VPN\n**Regions/Zones:** europe-west2-c\n**Description:**\nGoogle Cloud Networking experienced elevated packet loss and latency in europe-west2-c for a duration of 40 minutes. Additional Cloud services that use Cloud Networking experienced similar symptoms. From preliminary analysis, the root cause of the issue was a sudden redirection of traffic from a datacenter that was experiencing an issue.\n**Customer Impact:**\n- Affected customers may have experienced elevated packet loss and latency as their traffic was temporarily redirected.\n- Google Compute Engine instances experienced failed connectivity and packet loss on ingress, egress, and inter-zonal traffic. Autoscaling was also impacted and may have failed to make decisions.\n- Persistent Disk experienced elevated I/O latency on regional and zonal disks\n- Google Kubernetes Engine clusters experienced 30% of zonal and 5% of regional clusters reporting as unhealthy.\n- Google App Engine and Cloud Run served elevated 500 errors within europe-west2.\n- Cloud Bigtable experienced an elevated error rate and latency on operations within europe-west2.\n- Cloud SQL experienced issues connecting to instances in europe-west2. Affected instances may have lost telemetry data, and HA instances failed over if the primary was in the affected zone.\n- Google Cloud Storage experienced elevated read errors of up to 2.3% in europe-west2.\n- Cloud Filestore instances within europe-west2-c may have been unreachable.\n- Cloud MemoryStore instances within europe-west2 may have been unreachable.\n- Cloud Monitoring experienced delayed or missing metrics from resources in the zone.\n- Cloud VPN experienced a short duration where tunnels went down for a short time before being reestablished.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/WzDzgmTjQfAKPJha6Rbb"
  },
  {
    "id": "9dSqbyLnq9ALkVnD84eF",
    "number": "1544920841042535714",
    "begin": "2021-09-02T09:00:00+00:00",
    "created": "2021-09-02T15:25:22+00:00",
    "end": "2021-09-02T19:00:00+00:00",
    "modified": "2021-09-03T16:57:50+00:00",
    "external_desc": "Google Cloud Storage UI is experiencing some issues",
    "updates": [
      {
        "created": "2021-09-03T16:57:38+00:00",
        "modified": "2021-09-03T16:57:38+00:00",
        "when": "2021-09-03T16:57:38+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 02 Sep 2021 02:00\n**Incident End:** 02 Sep 2021 12:00\n**Duration:** 10 hours\n**Affected Services and Features:**\n- Google Cloud Storage - Cloud Console UI\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Storage (GCS) experienced up to an 85% failure rate globally when creating buckets from the GCS Console UI or other service UI’s which create buckets programmatically. From preliminary analysis, the increased failure rate was due to a GCS API rollout.\n**Customer Impact:**\n- Customers experienced errors including “RPO is not supported” when creating new GCS buckets using the Cloud Console UI.\n**Additional details:**\n- Customer workarounds included using the gcloud CLI (gsutil), or the API (such as via client libraries).\n- Retrying failed requests may have also succeeded\n- The GCS API rollout has been rolled back which fully restored the service.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-02T15:37:32+00:00",
        "modified": "2021-09-02T15:37:38+00:00",
        "when": "2021-09-02T15:37:32+00:00",
        "text": "The issue with Google Cloud Storage is believed to be affecting only the user interface and has a workaround to use gsutil on CLI. Our Engineering Team is currently working on the resolution.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-02T15:25:19+00:00",
        "modified": "2021-09-02T15:25:23+00:00",
        "when": "2021-09-02T15:25:19+00:00",
        "text": "Summary: Google Cloud Storage UI is experiencing some issues\nDescription: We are experiencing an issue with Google Cloud Storage beginning at Thursday, 2021-09-02 07:45:57 PDT US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-09-02 08:55 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users attempting to create gcs buckets in pantheon are getting errors\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-03T16:57:38+00:00",
      "modified": "2021-09-03T16:57:38+00:00",
      "when": "2021-09-03T16:57:38+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 02 Sep 2021 02:00\n**Incident End:** 02 Sep 2021 12:00\n**Duration:** 10 hours\n**Affected Services and Features:**\n- Google Cloud Storage - Cloud Console UI\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Storage (GCS) experienced up to an 85% failure rate globally when creating buckets from the GCS Console UI or other service UI’s which create buckets programmatically. From preliminary analysis, the increased failure rate was due to a GCS API rollout.\n**Customer Impact:**\n- Customers experienced errors including “RPO is not supported” when creating new GCS buckets using the Cloud Console UI.\n**Additional details:**\n- Customer workarounds included using the gcloud CLI (gsutil), or the API (such as via client libraries).\n- Retrying failed requests may have also succeeded\n- The GCS API rollout has been rolled back which fully restored the service.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "UwaYoXQ5bHYHG6EdiPB8",
    "service_name": "Google Cloud Storage",
    "affected_products": [
      {
        "title": "Google Cloud Storage",
        "id": "UwaYoXQ5bHYHG6EdiPB8"
      }
    ],
    "uri": "incidents/9dSqbyLnq9ALkVnD84eF"
  },
  {
    "id": "gwKjX9Lukav15SaFPbBF",
    "number": "1393196405563089999",
    "begin": "2021-09-01T02:35:00+00:00",
    "created": "2021-09-02T16:22:29+00:00",
    "end": "2021-09-03T03:55:00+00:00",
    "modified": "2021-09-07T21:39:46+00:00",
    "external_desc": "us-central1, europe-west1, us-west1, asia-east1: Issue with Local SSDs on Google Compute Engine.",
    "updates": [
      {
        "created": "2021-09-07T21:39:46+00:00",
        "modified": "2021-09-07T21:39:46+00:00",
        "when": "2021-09-07T21:39:46+00:00",
        "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 31 August 2021 19:35\n**Incident End:** 2 September 2021 20:55\n**Duration:** 2 days, 1 hours, 20 minutes\n**Affected Services and Features:**\n- Google Compute Engine - Local SSD\n**Regions/Zones:**\n- us-central1-{a|b|f}\n- europe-west1-b\n- us-west1-a\n- asia-east1-b\n**Description:**\nGoogle Compute Engine (GCE) experienced local solid-state drive (SSD) unavailability for new instances in select zones intermittently for a duration of 2 days, 1 hours, and 20 minutes. From preliminary analysis, the root cause is due to latent issues within the GCE capacity management system.\n**Customer Impact:**\n- Unable to add Local SSDs to existing/new instances.\n**Additional details:**\n- The asia-southeast1-b zone was not impacted despite previous communication that suggested it was.\n- Existing instances, or instances that rebooted, were not impacted.\n- Low priority maintenance events on host machines were paused to prevent further impact to customer instances.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-03T16:04:17+00:00",
        "modified": "2021-09-03T16:04:17+00:00",
        "when": "2021-09-03T16:04:17+00:00",
        "text": "The issue with VM maintenance on Google Compute Engine has been resolved for all affected users as of Friday, 2021-09-03 08:31 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-03T08:43:44+00:00",
        "modified": "2021-09-03T08:43:44+00:00",
        "when": "2021-09-03T08:43:44+00:00",
        "text": "Summary: us-central1, europe-west1, us-west1, asia-east1, asia-southeast1: Issue with VM maintenance on Google Compute Engine.\nDescription: Mitigation work is still underway by our engineering team. The engineering team has confirmed that pausing the VM maintenance has mitigated current customer impact.\nZones recovered: us-west1, asia-east1, and asia-southeast1\nZones recovering: us-central1, europe-west1\nSuspected Root cause: An internal maintenance operation incorrectly removed too many machines from the service.\nWe will provide more information by Friday, 2021-09-03 13:30 US/Pacific.\nDiagnosis: Customers may see on VM termination/maintenance, replacement VMs cannot acquire Local SSD in order to initialize and therefore VMs will not be able to restart.\nWorkaround: No workaround available at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-02T20:34:06+00:00",
        "modified": "2021-09-02T20:34:06+00:00",
        "when": "2021-09-02T20:34:06+00:00",
        "text": "Summary: us-central1, europe-west1, us-west1, asia-east1, asia-southeast1: Issue with VM maintenance on Google Compute Engine.\nDescription: Mitigation work is currently under progress. Engineering has confirmed that pausing the VM maintenance has mitigated current customer impact.\nCustomers may observe loss of local SSD on VM termination till the full resolution is deployed.\nWe will provide more information by Friday, 2021-09-03 13:30 US/Pacific.\nDiagnosis: Customers may see on VM termination/maintenance, replacement VMs cannot acquire Local SSD in order to initialize and therefore VMs will not be able to restart.\nWorkaround: No workaround available at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-02T19:03:24+00:00",
        "modified": "2021-09-02T19:03:24+00:00",
        "when": "2021-09-02T19:03:24+00:00",
        "text": "Summary: us-central1, europe-west1, us-west1, asia-east1, asia-southeast1: Issue with VM maintenance on Google Compute Engine.\nDescription: Mitigation work is currently under progress. Engineering team continues to pause the regular VM maintenance operations for SSD machines to mitigate the customer impact.\nWe do not have an ETA for completion of mitigation activities at this point.\nWe will provide more information by Thursday, 2021-09-02 13:30 US/Pacific.\nDiagnosis: Customers may see on VM termination/maintenance, replacement VMs cannot acquire Local SSD in order to initialize and therefore VMs will not be able to restart.\nWorkaround: No workaround available at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-02T18:00:11+00:00",
        "modified": "2021-09-02T18:00:11+00:00",
        "when": "2021-09-02T18:00:11+00:00",
        "text": "Summary: us-central1, europe-west1, us-west1, asia-east1, asia-southeast1: Issue with VM maintenance on Google Compute Engine.\nDescription: Engineering team has implemented a pause on regular VM maintenance operations for SSD machines to mitigate the customer impact.\nWe do not have an ETA for completion of mitigation activities at this point.\nWe will provide more information by Thursday, 2021-09-02 12:00 US/Pacific.\nDiagnosis: Customers may see on VM termination/maintenance, replacement VMs cannot acquire Local SSD in order to initialize and therefore VMs will not be able to restart.\nWorkaround: No workaround available at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-02T16:57:57+00:00",
        "modified": "2021-09-02T16:57:57+00:00",
        "when": "2021-09-02T16:57:57+00:00",
        "text": "Summary: us-central1, europe-west1, us-west1, asia-east1, asia-southeast1: Issue with VM maintenance on Google Compute Engine.\nDescription: Engineering team has started mitigation efforts to reduce customer impact.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2021-09-02 11:00 US/Pacific.\nDiagnosis: Customers may see on VM termination/maintenance, replacement VMs cannot acquire Local SSD in order to initialize and therefore VMs will not be able to restart.\nWorkaround: No workaround available at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-09-02T16:22:27+00:00",
        "modified": "2021-09-02T16:22:30+00:00",
        "when": "2021-09-02T16:22:27+00:00",
        "text": "Summary: us-central1, europe-west1, us-west1, asia-east1, asia-southeast1: Issue with VM maintenance on Google Compute Engine.\nDescription: Some customers are experiencing an issue performing VM maintenance activities on Google Compute Engine.\nOur engineering team is currently investigating the issue.\nWe will provide an update by Thursday, 2021-09-02 10:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may see on VM termination/maintenance, replacement VMs cannot acquire Local SSD in order to initialize and therefore VMs will not be able to restart.\nWorkaround: No workaround available at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-07T21:39:46+00:00",
      "modified": "2021-09-07T21:39:46+00:00",
      "when": "2021-09-07T21:39:46+00:00",
      "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 31 August 2021 19:35\n**Incident End:** 2 September 2021 20:55\n**Duration:** 2 days, 1 hours, 20 minutes\n**Affected Services and Features:**\n- Google Compute Engine - Local SSD\n**Regions/Zones:**\n- us-central1-{a|b|f}\n- europe-west1-b\n- us-west1-a\n- asia-east1-b\n**Description:**\nGoogle Compute Engine (GCE) experienced local solid-state drive (SSD) unavailability for new instances in select zones intermittently for a duration of 2 days, 1 hours, and 20 minutes. From preliminary analysis, the root cause is due to latent issues within the GCE capacity management system.\n**Customer Impact:**\n- Unable to add Local SSDs to existing/new instances.\n**Additional details:**\n- The asia-southeast1-b zone was not impacted despite previous communication that suggested it was.\n- Existing instances, or instances that rebooted, were not impacted.\n- Low priority maintenance events on host machines were paused to prevent further impact to customer instances.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/gwKjX9Lukav15SaFPbBF"
  },
  {
    "id": "5yL8cbrpS3ssbYjRZQJv",
    "number": "17020659156612080007",
    "begin": "2021-08-31T18:32:00+00:00",
    "created": "2021-08-31T19:58:35+00:00",
    "end": "2021-08-31T21:09:00+00:00",
    "modified": "2021-09-01T20:47:59+00:00",
    "external_desc": "Global: Cloud Pubsub experiencing elevated latencies and failures.",
    "updates": [
      {
        "created": "2021-09-01T20:44:36+00:00",
        "modified": "2021-09-01T20:44:36+00:00",
        "when": "2021-09-01T20:44:36+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 31 August 2021 11:32\n**Incident End:** 31 August 2021 14:09\n**Duration:** 2 hours, 37 minutes\n**Affected Services and Features:**\n- Google Cloud Pubsub - AdminOperation CreateSubscription, Backlog Stats Lookup (how many messages are in the queue to be received and acknowledged, how old is the oldest unacknowledged message)\n- Google Cloud Functions - Deployments\n- Google Cloud Dataflow - Jobs and Watermarks\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Pubsub experienced problems creating new subscriptions and viewing backlog statistics for a period of 2 hours and 37 minutes. The Pubsub issue also caused issues with Google Cloud Functions deployments and affected related Google Cloud Dataflow streaming jobs and watermarks. From preliminary analysis, the root cause of the issue was an unhealthy task in our Pubsub change notification system that created a feedback loop with increased errors on backlog stats which scaled up more tasks and put more load on our Pubsub change notification system. Google Cloud Dataflow Streaming jobs that interact with PubSub were stalled due to the dependency of those jobs on Backlog Stats which are required to calculate the watermark.\n**Customer Impact:**\n- Google Cloud Pubsub - Users experienced latencies creating subscriptions and viewing their backlog status data such as how many messages they have in the queue to be received and acknowledged and how old is the oldest unacknowledged message)\n- Google Cloud Functions - Users experienced issues with deployments.\n- Google Cloud Dataflow - Streaming jobs that interact with PubSub stalled and experienced lagging watermarks.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-31T21:17:17+00:00",
        "modified": "2021-08-31T21:17:17+00:00",
        "when": "2021-08-31T21:17:17+00:00",
        "text": "The issue with Cloud Pub/Sub, Cloud Functions, and Dataflow has been resolved for all affected projects as of Tuesday, 2021-08-31 14:09 US/Pacific, 13:02 US/Pacific, and 13:16 US/Pacific respectively.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-31T21:01:39+00:00",
        "modified": "2021-08-31T21:01:39+00:00",
        "when": "2021-08-31T21:01:39+00:00",
        "text": "Summary: Global: Cloud Pubsub experiencing elevated latencies and failures.\nDescription: The issue with Cloud Functions and Dataflow are now resolved and mitigation work is currently underway by our engineering team for Cloud Pub/Sub.\nThe mitigation is expected to complete by Tuesday, 2021-08-31 15:30 US/Pacific.\nCloud Pub/Sub:\n* Impact is ongoing\n* Customers may experience latencies creating subscriptions.\n* Customers are unavailable to lookup their backlog data.\nCloud Functions:\n* Impact resolved and customers should no longer experience errors with deployments\nDataflow:\n* Impact resolved and customers should no longer experience issues with jobs.\nIf you are still experiencing issues with Cloud Functions or Dataflow, please open a support case so we can work with you to resolve those issues.\nWe will provide more information by Tuesday, 2021-08-31 15:30 US/Pacific.\nDiagnosis: Customers could experience elevated latencies and failures for Cloud Pub/Sub\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-31T20:27:10+00:00",
        "modified": "2021-08-31T20:27:10+00:00",
        "when": "2021-08-31T20:27:10+00:00",
        "text": "Summary: Global: Cloud Pubsub, Cloud Functions and Cloud Dataflow experiencing elevated latencies and failures.\nDescription: The issue with Cloud Functions and Dataflow are now resolved and mitigation work is currently underway by our engineering team for Cloud Pub/Sub.\nWe do not have an ETA for Cloud Pub/Sub mitigation at this point.\nCloud Pub/Sub:\n* Impact is ongoing\n* Customers may experience latencies creating subscriptions.\n* Customers are unavailable to lookup their backlog data.\nCloud Functions:\n* Impact resolved and customers should no longer experience errors with deployments\nDataflow:\n* Impact resolved and customers should no longer experience issues with jobs.\nIf you are still experiencing issues with Cloud Functions or Dataflow, please open a support case so we can work with you to resolve those issues.\nWe will provide more information by Tuesday, 2021-08-31 14:30 US/Pacific.\nDiagnosis: Customers could experience elevated latencies and failures for Cloud Pub/Sub\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-31T19:58:35+00:00",
        "modified": "2021-08-31T19:58:35+00:00",
        "when": "2021-08-31T19:58:35+00:00",
        "text": "Summary: Global: Cloud Pubsub, Cloud Functions and Cloud Dataflow experiencing elevated latencies and failures.\nDescription: We are experiencing an issue with Cloud Pub/Sub, Cloud Functions and Cloud Dataflow beginning at Tuesday, 2021-08-31 11:30 US/Pacific.\nCloud Pub/Sub:\n* Customers may experience latencies creating subscriptions.\n* Customers are unavailable to lookup their backlog data.\nCloud Functions:\n* Users are experiencing errors with deployment\nDataflow:\n* Customers may experience lagging jobs/watermarks\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-08-31 13:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers could experience elevated latencies and failures for Cloud Pub/Sub, Cloud Functions and Dataflow jobs.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-01T20:44:36+00:00",
      "modified": "2021-09-01T20:44:36+00:00",
      "when": "2021-09-01T20:44:36+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 31 August 2021 11:32\n**Incident End:** 31 August 2021 14:09\n**Duration:** 2 hours, 37 minutes\n**Affected Services and Features:**\n- Google Cloud Pubsub - AdminOperation CreateSubscription, Backlog Stats Lookup (how many messages are in the queue to be received and acknowledged, how old is the oldest unacknowledged message)\n- Google Cloud Functions - Deployments\n- Google Cloud Dataflow - Jobs and Watermarks\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Pubsub experienced problems creating new subscriptions and viewing backlog statistics for a period of 2 hours and 37 minutes. The Pubsub issue also caused issues with Google Cloud Functions deployments and affected related Google Cloud Dataflow streaming jobs and watermarks. From preliminary analysis, the root cause of the issue was an unhealthy task in our Pubsub change notification system that created a feedback loop with increased errors on backlog stats which scaled up more tasks and put more load on our Pubsub change notification system. Google Cloud Dataflow Streaming jobs that interact with PubSub were stalled due to the dependency of those jobs on Backlog Stats which are required to calculate the watermark.\n**Customer Impact:**\n- Google Cloud Pubsub - Users experienced latencies creating subscriptions and viewing their backlog status data such as how many messages they have in the queue to be received and acknowledged and how old is the oldest unacknowledged message)\n- Google Cloud Functions - Users experienced issues with deployments.\n- Google Cloud Dataflow - Streaming jobs that interact with PubSub stalled and experienced lagging watermarks.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "dFjdLh2v6zuES6t9ADCB",
    "service_name": "Google Cloud Pub/Sub",
    "affected_products": [
      {
        "title": "Google Cloud Pub/Sub",
        "id": "dFjdLh2v6zuES6t9ADCB"
      }
    ],
    "uri": "incidents/5yL8cbrpS3ssbYjRZQJv"
  },
  {
    "id": "sBT6tcw8bxRArf6Jw19o",
    "number": "2852238876231482449",
    "begin": "2021-08-31T18:30:00+00:00",
    "created": "2021-09-01T00:16:58+00:00",
    "end": "2021-08-31T20:16:00+00:00",
    "modified": "2021-09-01T00:21:25+00:00",
    "external_desc": "Global: Dataflow Streaming jobs that interact with PubSub are experiencing failures.",
    "updates": [
      {
        "created": "2021-09-01T00:18:30+00:00",
        "modified": "2021-09-01T00:18:30+00:00",
        "when": "2021-09-01T00:18:30+00:00",
        "text": "Global: Dataflow Streaming jobs that interact with PubSub experienced failures.\nThe issue with Cloud Dataflow has been resolved for all affected users as of Tuesday, 2021-08-31 13:22 US/Pacific.\nFor more information, please follow: https://status.cloud.google.com/incidents/5yL8cbrpS3ssbYjRZQJv\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-09-01T00:16:59+00:00",
        "modified": "2021-09-01T00:16:59+00:00",
        "when": "2021-09-01T00:16:59+00:00",
        "text": "Summary: Global: Dataflow Streaming jobs that interact with PubSub are experiencing failures.\nDescription: We are experiencing an issue with Cloud Dataflow beginning at Tuesday, 2021-08-31 11:30 US/Pacific. Our engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/5yL8cbrpS3ssbYjRZQJv where we will provide the next update by Tuesday, 2021-08-31 13:30 US/Pacific.\nDiagnosis: Customers will experience lagging jobs/watermarks and failure in subscription creation.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-09-01T00:18:30+00:00",
      "modified": "2021-09-01T00:18:30+00:00",
      "when": "2021-09-01T00:18:30+00:00",
      "text": "Global: Dataflow Streaming jobs that interact with PubSub experienced failures.\nThe issue with Cloud Dataflow has been resolved for all affected users as of Tuesday, 2021-08-31 13:22 US/Pacific.\nFor more information, please follow: https://status.cloud.google.com/incidents/5yL8cbrpS3ssbYjRZQJv\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "T9bFoXPqG8w8g1YbWTKY",
    "service_name": "Google Cloud Dataflow",
    "affected_products": [
      {
        "title": "Google Cloud Dataflow",
        "id": "T9bFoXPqG8w8g1YbWTKY"
      }
    ],
    "uri": "incidents/sBT6tcw8bxRArf6Jw19o"
  },
  {
    "id": "XnB6ncPMYd3Tei7XcCE1",
    "number": "4559585505212123721",
    "begin": "2021-08-26T21:25:41+00:00",
    "created": "2021-08-26T21:25:44+00:00",
    "end": "2021-08-26T21:53:29+00:00",
    "modified": "2021-08-26T21:53:29+00:00",
    "external_desc": "Cloud Logging experiencing issue returning results for \"tail\" commands globally",
    "updates": [
      {
        "created": "2021-08-26T21:53:29+00:00",
        "modified": "2021-08-26T21:53:29+00:00",
        "when": "2021-08-26T21:53:29+00:00",
        "text": "The issue with Cloud Logging `gcloud alpha logging tail` command and any direct calls to the Tailing API is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-26T21:25:42+00:00",
        "modified": "2021-08-26T21:25:44+00:00",
        "when": "2021-08-26T21:25:42+00:00",
        "text": "Summary: Cloud Logging experiencing issue returning results for \"tail\" commands globally\nDescription: We are experiencing an issue with Cloud Logging.\nCustomers may not be able to look at live logs by running \"tail\" commands\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-08-26 14:55 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may not be able to look at live logs by running \"tail\" commands\nWorkaround: Normal log queries work fine and users can still use streaming in the UI.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-26T21:53:29+00:00",
      "modified": "2021-08-26T21:53:29+00:00",
      "when": "2021-08-26T21:53:29+00:00",
      "text": "The issue with Cloud Logging `gcloud alpha logging tail` command and any direct calls to the Tailing API is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/XnB6ncPMYd3Tei7XcCE1"
  },
  {
    "id": "A27EJTBQ6anaCdeNX6zp",
    "number": "4326509736320173557",
    "begin": "2021-08-26T13:49:00+00:00",
    "created": "2021-08-26T13:49:30+00:00",
    "end": "2021-08-27T01:06:48+00:00",
    "modified": "2021-09-02T21:21:06+00:00",
    "external_desc": "GKE service is unaffected. Mitigation for issue with Anthos On-Prem admin workstation access, is underway. See further details below.",
    "updates": [
      {
        "created": "2021-08-27T01:07:06+00:00",
        "modified": "2021-09-02T21:21:06+00:00",
        "when": "2021-08-27T01:07:06+00:00",
        "text": "GKE service is unaffected. Mitigation for issue with Anthos On-Prem admin workstation access, is underway.\nFix: - Release 1.8.2 with the fix delivered.\nETA for the hotfix releases: - Hotfix for 1.7.3 is expected to be released by Friday (9/03).\nFor workaround procedures, please refer to the previous notification down below.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here. We thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-26T21:15:54+00:00",
        "modified": "2021-08-26T21:15:54+00:00",
        "when": "2021-08-26T21:15:54+00:00",
        "text": "Summary: Anthos On-Prem customers unable to login to admin workstation (starting 2021-08-25 for customers using Anthos OP v1.7.2)\nDescription: Mitigation work is currently underway by our engineering team.\nETA for the releases: - Release 1.8.2 with the fix is expected to be next Monday (8/29). - And hotfix for 1.7.3 is expected to be next Thursday (9/02).\nWe will provide an update on Thursday 2021-09-02 by 17:00 US/Pacific.\nDiagnosis: Customers are unable to login to their admin workstation in both their prod and non-prod environments.\nWorkaround: Mitigation steps for the admin workstation:\nUse a temporary VM to perform the following steps. If you don’t have a VM, you can create an admin workstation at 1.7.1-gke.4 as the temporary VM.\n1)Ensure the VM and the problematic 1.7.2-gke.2 admin workstation are in power off state.\n2)Attach the boot disk of the problematic admin workstation to the VM. The boot disk is the one with the label Hard disk 1.\n3)Mount the boot disk inside the VM. sudo mkdir -p /mnt/boot-disk sudo mount /dev/sdc1 /mnt/boot-disk, assuming the boot disk is identified as dev/sdc1.\n4)Set the ubuntu user expiration date to unlimited. sudo chroot /mnt/boot-disk chage -M 99999 ubuntu\n5)Shutdown the temporary VM.\n6)Power on the admin workstation. You should be able to SSH to the admin workstation as usual.\n7)[Clean up] Delete the temporary VM.\nNote that this fix will break the CIS benchmark rule[1] 5.4.1.1 Ensure password expiration is 365 days or less.\n[1]https://cloud.google.com/anthos/clusters/docs/on-prem/1.7/concepts/cis-ubuntu-benchmark\nMitigation steps for non admin workstation nodes (including cluster nodes and Seesaw VM):\nLogin onto each node (or use SSH) to run the following command on the node sudo chroot /mnt/boot-disk chage -M 99999 ubuntu\nNote that if the non admin workstation nodes are not SSHable due to the error, you will have to use the mitigation step for admin workstation.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-26T14:12:47+00:00",
        "modified": "2021-08-26T14:12:54+00:00",
        "when": "2021-08-26T14:12:47+00:00",
        "text": "Summary: Anthos On-Prem customers unable to login to admin workstation (starting 2021-08-25 for customers using Anthos OP v1.7.2)\nDescription: Mitigation work is currently underway by our engineering team.\nETA for the releases: - Release 1.8.2 with the fix is aiming next Monday (8/29). - And hotfix for 1.7.3 is also aiming next week.\nWe will provide more information by Thursday, 2021-08-26 17:00 US/Pacific.\nDiagnosis: Customers are unable to login to their admin workstation in both their prod and non-prod environments.\nWorkaround: Mitigation steps for the admin workstation:\nUse a temporary VM to perform the following steps. If you don’t have a VM, you can create an admin workstation at 1.7.1-gke.4 as the temporary VM.\n1)Ensure the VM and the problematic 1.7.2-gke.2 admin workstation are in power off state.\n2)Attach the boot disk of the problematic admin workstation to the VM. The boot disk is the one with the label Hard disk 1.\n3)Mount the boot disk inside the VM. sudo mkdir -p /mnt/boot-disk sudo mount /dev/sdc1 /mnt/boot-disk, assuming the boot disk is identified as dev/sdc1.\n4)Set the ubuntu user expiration date to unlimited. sudo chroot /mnt/boot-disk chage -M 99999 ubuntu\n5)Shutdown the temporary VM.\n6)Power on the admin workstation. You should be able to SSH to the admin workstation as usual.\n7)[Clean up] Delete the temporary VM.\nNote that this fix will break the CIS benchmark rule[1] 5.4.1.1 Ensure password expiration is 365 days or less.\n[1]https://cloud.google.com/anthos/clusters/docs/on-prem/1.7/concepts/cis-ubuntu-benchmark\nMitigation steps for non admin workstation nodes (including cluster nodes and Seesaw VM):\nLogin onto each node (or use SSH) to run the following command on the node sudo chroot /mnt/boot-disk chage -M 99999 ubuntu\nNote that if the non admin workstation nodes are not SSHable due to the error, you will have to use the mitigation step for admin workstation.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-26T13:49:22+00:00",
        "modified": "2021-08-26T13:51:17+00:00",
        "when": "2021-08-26T13:49:22+00:00",
        "text": "Summary: Anthos On-Prem customers unable to login to admin workstation (starting 2021-08-25 for customers using Anthos OP v1.7.2)\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2021-08-26 07:25 US/Pacific.\nDiagnosis: Customers are unable to login to their admin workstation in both their prod and non-prod environments.\nWorkaround: Mitigation steps for the admin workstation:\nUse a temporary VM to perform the following steps. If you don’t have a VM, you can create an admin workstation at 1.7.1-gke.4 as the temporary VM.\n1)Ensure the VM and the problematic 1.7.2-gke.2 admin workstation are in power off state.\n2)Attach the boot disk of the problematic admin workstation to the VM. The boot disk is the one with the label Hard disk 1.\n3)Mount the boot disk inside the VM. sudo mkdir -p /mnt/boot-disk sudo mount /dev/sdc1 /mnt/boot-disk, assuming the boot disk is identified as dev/sdc1.\n4)Set the ubuntu user expiration date to unlimited. sudo chroot /mnt/boot-disk chage -M 99999 ubuntu\n5)Shutdown the temporary VM.\n6)Power on the admin workstation. You should be able to SSH to the admin workstation as usual.\n7)[Clean up] Delete the temporary VM.\nNote that this fix will break the CIS benchmark rule[1] 5.4.1.1 Ensure password expiration is 365 days or less.\n[1]https://cloud.google.com/anthos/clusters/docs/on-prem/1.7/concepts/cis-ubuntu-benchmark\nMitigation steps for non admin workstation nodes (including cluster nodes and Seesaw VM):\nLogin onto each node (or use SSH) to run the following command on the node sudo chroot /mnt/boot-disk chage -M 99999 ubuntu\nNote that if the non admin workstation nodes are not SSHable due to the error, you will have to use the mitigation step for admin workstation.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-27T01:07:06+00:00",
      "modified": "2021-09-02T21:21:06+00:00",
      "when": "2021-08-27T01:07:06+00:00",
      "text": "GKE service is unaffected. Mitigation for issue with Anthos On-Prem admin workstation access, is underway.\nFix: - Release 1.8.2 with the fix delivered.\nETA for the hotfix releases: - Hotfix for 1.7.3 is expected to be released by Friday (9/03).\nFor workaround procedures, please refer to the previous notification down below.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here. We thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/A27EJTBQ6anaCdeNX6zp"
  },
  {
    "id": "vcRkm91DVuWNGWMw9w84",
    "number": "1183468118352922339",
    "begin": "2021-08-25T08:37:00+00:00",
    "created": "2021-08-25T10:39:11+00:00",
    "end": "2021-08-25T11:14:00+00:00",
    "modified": "2021-08-25T18:20:08+00:00",
    "external_desc": "Google Cloud Dataflow elevated errors starting new or querying existing dataflow jobs in us-west1, asia-east1, asia-northeast1, and europe-west1.",
    "updates": [
      {
        "created": "2021-08-25T18:18:50+00:00",
        "modified": "2021-08-25T18:18:50+00:00",
        "when": "2021-08-25T18:18:50+00:00",
        "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 25 August 2021 01:37\n**Incident End:** 25 August 2021 04:14\n**Duration:** 2 hours, 37 minutes\n**Affected Services and Features:**\n- Google Cloud Dataflow\n- Dataproc Metastore\n**Regions/Zones:** us-west1, asia-east1, asia-northeast1, europe-west1\n**Description:**\nGoogle Cloud Dataflow experienced elevated errors starting new or querying existing dataflow jobs in us-west1, asia-east1, asia-northeast1, and europe-west1 for a duration of 2 hours and 37 minutes. From preliminary analysis, the root cause of the issue was a misconfiguration triggered by a rollout.\n**Customer Impact:**\n- 500 errors when launching new dataflow jobs.\n- 500 errors querying existing dataflow jobs.\n- The majority of the impact for customers was in us-west1, with 33% of job creation and query traffic reporting errors.\n- Dataproc Metastore uses underlying Dataflow jobs for some features, and thus experienced elevated errors of up to 100% on the following API’s in us-west1 from 01:27 to 03:53; Restore, Import (from SQL, Avro), and Export (to Avro).\n- There was a slight re-occurance in europe-west1 between 06:06 and 08:02 with a peak error rate of 3.5%.\n- Existing jobs continued to progress without issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-25T11:43:02+00:00",
        "modified": "2021-08-25T15:18:15+00:00",
        "when": "2021-08-25T11:43:02+00:00",
        "text": "The issue with Google Cloud Dataflow has been resolved for all affected projects as of Wednesday, 2021-08-25 04:42 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-25T11:30:24+00:00",
        "modified": "2021-08-25T15:22:33+00:00",
        "when": "2021-08-25T11:30:24+00:00",
        "text": "Summary: Dataflow job querying and creation impacted in us-west1\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Wednesday, 2021-08-25 06:00 US/Pacific.\nWe will provide more information by Wednesday, 2021-08-25 05:30 US/Pacific.\nDiagnosis: We believe starting a Dataflow job or querying existing Dataflow jobs may fail for the customers. However, existing Dataflow jobs should continue to progress as usual.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-25T10:39:11+00:00",
        "modified": "2021-08-25T15:22:26+00:00",
        "when": "2021-08-25T10:39:11+00:00",
        "text": "Summary: Dataflow job querying and creation impacted in us-west1\nDescription: We are experiencing an issue with Google Cloud Dataflow in us-west1 beginning at Wednesday, 2021-08-25 01:37 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-08-25 04:30 US/Pacific with current details. We apologize to all who are affected by the disruption.\nDiagnosis: We believe starting a Dataflow job or querying existing Dataflow jobs may fail for the customers. However, existing Dataflow jobs should continue to progress as usual.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-25T18:18:50+00:00",
      "modified": "2021-08-25T18:18:50+00:00",
      "when": "2021-08-25T18:18:50+00:00",
      "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 25 August 2021 01:37\n**Incident End:** 25 August 2021 04:14\n**Duration:** 2 hours, 37 minutes\n**Affected Services and Features:**\n- Google Cloud Dataflow\n- Dataproc Metastore\n**Regions/Zones:** us-west1, asia-east1, asia-northeast1, europe-west1\n**Description:**\nGoogle Cloud Dataflow experienced elevated errors starting new or querying existing dataflow jobs in us-west1, asia-east1, asia-northeast1, and europe-west1 for a duration of 2 hours and 37 minutes. From preliminary analysis, the root cause of the issue was a misconfiguration triggered by a rollout.\n**Customer Impact:**\n- 500 errors when launching new dataflow jobs.\n- 500 errors querying existing dataflow jobs.\n- The majority of the impact for customers was in us-west1, with 33% of job creation and query traffic reporting errors.\n- Dataproc Metastore uses underlying Dataflow jobs for some features, and thus experienced elevated errors of up to 100% on the following API’s in us-west1 from 01:27 to 03:53; Restore, Import (from SQL, Avro), and Export (to Avro).\n- There was a slight re-occurance in europe-west1 between 06:06 and 08:02 with a peak error rate of 3.5%.\n- Existing jobs continued to progress without issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "T9bFoXPqG8w8g1YbWTKY",
    "service_name": "Google Cloud Dataflow",
    "affected_products": [
      {
        "title": "Google Cloud Dataflow",
        "id": "T9bFoXPqG8w8g1YbWTKY"
      }
    ],
    "uri": "incidents/vcRkm91DVuWNGWMw9w84"
  },
  {
    "id": "TSaW8RCnLss2ob5fM2t5",
    "number": "16348501793535204061",
    "begin": "2021-08-24T04:12:02+00:00",
    "created": "2021-08-24T05:20:16+00:00",
    "end": "2021-08-24T05:31:46+00:00",
    "modified": "2021-08-24T05:31:46+00:00",
    "external_desc": "We are experiencing a connectivity issue affecting Google Cloud Storage in australia-southeast2",
    "updates": [
      {
        "created": "2021-08-24T05:31:45+00:00",
        "modified": "2021-08-24T05:31:46+00:00",
        "when": "2021-08-24T05:31:45+00:00",
        "text": "The issue with Google Cloud Storage has been resolved for all affected users as of Monday, 2021-08-23 22:27 US/Pacific. However most users should have seen the impact mitigated as of approximately 21:20 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T05:20:16+00:00",
        "modified": "2021-08-24T05:20:16+00:00",
        "when": "2021-08-24T05:20:16+00:00",
        "text": "Summary: We are experiencing a connectivity issue affecting Google Cloud Storage in australia-southeast2\nDescription: We are experiencing an issue impacting Google Cloud Storage in australia-southeast2 begining at 2021-08-23 19:52 US/Pacific. We believe this issue is linked to https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G\nOur engineering team continues to investigate the issue.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T05:31:45+00:00",
      "modified": "2021-08-24T05:31:46+00:00",
      "when": "2021-08-24T05:31:45+00:00",
      "text": "The issue with Google Cloud Storage has been resolved for all affected users as of Monday, 2021-08-23 22:27 US/Pacific. However most users should have seen the impact mitigated as of approximately 21:20 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "UwaYoXQ5bHYHG6EdiPB8",
    "service_name": "Google Cloud Storage",
    "affected_products": [
      {
        "title": "Google Cloud Storage",
        "id": "UwaYoXQ5bHYHG6EdiPB8"
      }
    ],
    "uri": "incidents/TSaW8RCnLss2ob5fM2t5"
  },
  {
    "id": "ZzoChnVNAqbWBKC4wcAP",
    "number": "14147611926594694208",
    "begin": "2021-08-24T03:24:37+00:00",
    "created": "2021-08-24T04:04:02+00:00",
    "end": "2021-08-24T04:40:28+00:00",
    "modified": "2021-08-24T04:40:28+00:00",
    "external_desc": "We are experiencing a connectivity issue affecting Cloud Bigtable in australia-southeast2",
    "updates": [
      {
        "created": "2021-08-24T04:40:28+00:00",
        "modified": "2021-08-24T04:40:28+00:00",
        "when": "2021-08-24T04:40:28+00:00",
        "text": "The issue with Cloud Bigtable has been resolved for all affected users as of Monday, 2021-08-23 21:36 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T04:04:02+00:00",
        "modified": "2021-08-24T04:04:02+00:00",
        "when": "2021-08-24T04:04:02+00:00",
        "text": "Summary: We are experiencing a connectivity issue affecting Cloud Bigtable in australia-southeast2\nDescription: We are experiencing an issue with Google Cloud infrastructure components at australia-southeast2\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T04:40:28+00:00",
      "modified": "2021-08-24T04:40:28+00:00",
      "when": "2021-08-24T04:40:28+00:00",
      "text": "The issue with Cloud Bigtable has been resolved for all affected users as of Monday, 2021-08-23 21:36 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LfZSuE3xdQU46YMFV5fy",
    "service_name": "Google Cloud Bigtable",
    "affected_products": [
      {
        "title": "Google Cloud Bigtable",
        "id": "LfZSuE3xdQU46YMFV5fy"
      }
    ],
    "uri": "incidents/ZzoChnVNAqbWBKC4wcAP"
  },
  {
    "id": "FWZV7AXUH99PsLc9Eywr",
    "number": "8604705649045314008",
    "begin": "2021-08-24T03:21:31+00:00",
    "created": "2021-08-24T04:02:17+00:00",
    "end": "2021-08-24T04:48:46+00:00",
    "modified": "2021-08-24T04:48:46+00:00",
    "external_desc": "We are experiencing a connectivity issue affecting Cloud Memorystore in australia-southeast2",
    "updates": [
      {
        "created": "2021-08-24T04:48:45+00:00",
        "modified": "2021-08-24T04:48:45+00:00",
        "when": "2021-08-24T04:48:45+00:00",
        "text": "The issue with Cloud Memorystore has been resolved for all affected users as of approximately Monday, 2021-08-23 20:03 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T04:02:12+00:00",
        "modified": "2021-08-24T04:02:18+00:00",
        "when": "2021-08-24T04:02:12+00:00",
        "text": "Summary: We are experiencing a connectivity issue affecting Cloud Memorystore in australia-southeast2\nDescription: We are experiencing an issue with Google Cloud infrastructure components at australia-southeast2\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T04:48:45+00:00",
      "modified": "2021-08-24T04:48:45+00:00",
      "when": "2021-08-24T04:48:45+00:00",
      "text": "The issue with Cloud Memorystore has been resolved for all affected users as of approximately Monday, 2021-08-23 20:03 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LGPLu3M5pcUAKU1z6eP3",
    "service_name": "Cloud Memorystore",
    "affected_products": [
      {
        "title": "Cloud Memorystore",
        "id": "LGPLu3M5pcUAKU1z6eP3"
      }
    ],
    "uri": "incidents/FWZV7AXUH99PsLc9Eywr"
  },
  {
    "id": "LccZqKpFkxnBijMvQFU3",
    "number": "7840853179390995303",
    "begin": "2021-08-24T03:20:24+00:00",
    "created": "2021-08-24T04:08:22+00:00",
    "end": "2021-08-24T05:41:36+00:00",
    "modified": "2021-08-24T05:41:36+00:00",
    "external_desc": "We are experiencing a connectivity issue affecting Cloud Pub/Sub in australia-southeast2",
    "updates": [
      {
        "created": "2021-08-24T05:41:36+00:00",
        "modified": "2021-08-24T05:41:36+00:00",
        "when": "2021-08-24T05:41:36+00:00",
        "text": "The issue with Cloud Pub/Sub has been resolved for all affected projects as of Monday, 2021-08-23 20:38 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T04:08:22+00:00",
        "modified": "2021-08-24T04:08:22+00:00",
        "when": "2021-08-24T04:08:22+00:00",
        "text": "Summary: We are experiencing a connectivity issue affecting Cloud Pub/Sub in australia-southeast2\nDescription: We are experiencing an issue with Google Cloud infrastructure components at australia-southeast2\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T05:41:36+00:00",
      "modified": "2021-08-24T05:41:36+00:00",
      "when": "2021-08-24T05:41:36+00:00",
      "text": "The issue with Cloud Pub/Sub has been resolved for all affected projects as of Monday, 2021-08-23 20:38 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "dFjdLh2v6zuES6t9ADCB",
    "service_name": "Google Cloud Pub/Sub",
    "affected_products": [
      {
        "title": "Google Cloud Pub/Sub",
        "id": "dFjdLh2v6zuES6t9ADCB"
      }
    ],
    "uri": "incidents/LccZqKpFkxnBijMvQFU3"
  },
  {
    "id": "pYnCSa67rJ3Q5FrXxPHg",
    "number": "7105084436743396399",
    "begin": "2021-08-24T03:19:54+00:00",
    "created": "2021-08-24T04:18:23+00:00",
    "end": "2021-08-24T04:37:49+00:00",
    "modified": "2021-08-24T04:37:49+00:00",
    "external_desc": "We are experiencing a connectivity issue affecting Cloud access policy in australia-southeast2",
    "updates": [
      {
        "created": "2021-08-24T04:37:49+00:00",
        "modified": "2021-08-24T04:37:49+00:00",
        "when": "2021-08-24T04:37:49+00:00",
        "text": "The issue with Cloud Identity & Security has been resolved for all affected users as of Monday, 2021-08-23 20:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T04:18:23+00:00",
        "modified": "2021-08-24T04:18:24+00:00",
        "when": "2021-08-24T04:18:23+00:00",
        "text": "Summary: We are experiencing a connectivity issue affecting Cloud access policy in australia-southeast2\nDescription: We are experiencing an issue with Google Cloud infrastructure components at australia-southeast2\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T04:37:49+00:00",
      "modified": "2021-08-24T04:37:49+00:00",
      "when": "2021-08-24T04:37:49+00:00",
      "text": "The issue with Cloud Identity & Security has been resolved for all affected users as of Monday, 2021-08-23 20:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "adnGEDEt9zWzs8uF1oKA",
    "service_name": "Identity and Access Management",
    "affected_products": [
      {
        "title": "Identity and Access Management",
        "id": "adnGEDEt9zWzs8uF1oKA"
      }
    ],
    "uri": "incidents/pYnCSa67rJ3Q5FrXxPHg"
  },
  {
    "id": "1LczkFcPKVVPUEw6XBf7",
    "number": "4310336585790370745",
    "begin": "2021-08-24T03:18:56+00:00",
    "created": "2021-08-24T04:18:41+00:00",
    "end": "2021-08-24T04:49:38+00:00",
    "modified": "2021-08-24T04:49:38+00:00",
    "external_desc": "We are experiencing a connectivity issue affecting Persistent Disk in australia-southeast2",
    "updates": [
      {
        "created": "2021-08-24T04:49:38+00:00",
        "modified": "2021-08-24T04:49:38+00:00",
        "when": "2021-08-24T04:49:38+00:00",
        "text": "The issue with Google Compute Engine Persistent Disk has been resolved for all affected users as of Monday, 2021-08-23 20:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T04:18:41+00:00",
        "modified": "2021-08-24T04:18:42+00:00",
        "when": "2021-08-24T04:18:41+00:00",
        "text": "Summary: We are experiencing a connectivity issue affecting Persistent Disk in australia-southeast2\nDescription: We are experiencing an issue with Google Cloud infrastructure components at australia-southeast2\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T04:49:38+00:00",
      "modified": "2021-08-24T04:49:38+00:00",
      "when": "2021-08-24T04:49:38+00:00",
      "text": "The issue with Google Compute Engine Persistent Disk has been resolved for all affected users as of Monday, 2021-08-23 20:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/1LczkFcPKVVPUEw6XBf7"
  },
  {
    "id": "8aPfN89nkeWJVui93StH",
    "number": "10408151242071435888",
    "begin": "2021-08-24T03:15:41+00:00",
    "created": "2021-08-24T04:06:17+00:00",
    "end": "2021-08-24T04:28:15+00:00",
    "modified": "2021-08-24T04:28:15+00:00",
    "external_desc": "We are experiencing a connectivity issue affecting Google Kubernetes Engine in australia-southeast2",
    "updates": [
      {
        "created": "2021-08-24T04:28:15+00:00",
        "modified": "2021-08-24T04:28:15+00:00",
        "when": "2021-08-24T04:28:15+00:00",
        "text": "The issue with Google Kubernetes Engine has been resolved for all affected users as of Monday, 2021-08-23 20:41 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T04:06:16+00:00",
        "modified": "2021-08-24T04:06:17+00:00",
        "when": "2021-08-24T04:06:16+00:00",
        "text": "Summary: We are experiencing a connectivity issue affecting Google Kubernetes Engine in australia-southeast2\nDescription: We are experiencing an issue with Google Cloud infrastructure components at australia-southeast2\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T04:28:15+00:00",
      "modified": "2021-08-24T04:28:15+00:00",
      "when": "2021-08-24T04:28:15+00:00",
      "text": "The issue with Google Kubernetes Engine has been resolved for all affected users as of Monday, 2021-08-23 20:41 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/8aPfN89nkeWJVui93StH"
  },
  {
    "id": "wNRZfELPApTbYeBrVTRy",
    "number": "17955589576369634627",
    "begin": "2021-08-24T03:14:48+00:00",
    "created": "2021-08-24T04:11:11+00:00",
    "end": "2021-08-24T05:35:31+00:00",
    "modified": "2021-08-24T05:35:31+00:00",
    "external_desc": "We are experiencing a connectivity issue affecting Cloud SQL in australia-southeast2",
    "updates": [
      {
        "created": "2021-08-24T05:35:31+00:00",
        "modified": "2021-08-24T05:35:31+00:00",
        "when": "2021-08-24T05:35:31+00:00",
        "text": "The issue with Cloud SQL has been resolved for all affected projects as of Monday, 2021-08-23 21:52 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T04:11:11+00:00",
        "modified": "2021-08-24T04:11:11+00:00",
        "when": "2021-08-24T04:11:11+00:00",
        "text": "Summary: We are experiencing a connectivity issue affecting Cloud SQL in australia-southeast2\nDescription: We are experiencing an issue with Google Cloud infrastructure components at australia-southeast2\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T05:35:31+00:00",
      "modified": "2021-08-24T05:35:31+00:00",
      "when": "2021-08-24T05:35:31+00:00",
      "text": "The issue with Cloud SQL has been resolved for all affected projects as of Monday, 2021-08-23 21:52 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "hV87iK5DcEXKgWU2kDri",
    "service_name": "Google Cloud SQL",
    "affected_products": [
      {
        "title": "Google Cloud SQL",
        "id": "hV87iK5DcEXKgWU2kDri"
      }
    ],
    "uri": "incidents/wNRZfELPApTbYeBrVTRy"
  },
  {
    "id": "RPBQJ6t6qkJGkKG21Quv",
    "number": "5727678322536895542",
    "begin": "2021-08-24T03:14:16+00:00",
    "created": "2021-08-24T04:09:37+00:00",
    "end": "2021-08-24T05:43:01+00:00",
    "modified": "2021-08-24T05:43:01+00:00",
    "external_desc": "We are experiencing a connectivity issue affecting Cloud Dataproc in australia-southeast2",
    "updates": [
      {
        "created": "2021-08-24T05:43:01+00:00",
        "modified": "2021-08-24T05:43:01+00:00",
        "when": "2021-08-24T05:43:01+00:00",
        "text": "The issue with Cloud Dataproc has been resolved for all affected projects as of Monday, 2021-08-23 21:50 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T04:09:37+00:00",
        "modified": "2021-08-24T04:09:37+00:00",
        "when": "2021-08-24T04:09:37+00:00",
        "text": "Summary: We are experiencing a connectivity issue affecting Cloud Dataproc in australia-southeast2\nDescription: We are experiencing an issue with Google Cloud infrastructure components at australia-southeast2\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T05:43:01+00:00",
      "modified": "2021-08-24T05:43:01+00:00",
      "when": "2021-08-24T05:43:01+00:00",
      "text": "The issue with Cloud Dataproc has been resolved for all affected projects as of Monday, 2021-08-23 21:50 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "yjXrEg3Yvy26BauMwr69",
    "service_name": "Google Cloud Dataproc",
    "affected_products": [
      {
        "title": "Google Cloud Dataproc",
        "id": "yjXrEg3Yvy26BauMwr69"
      }
    ],
    "uri": "incidents/RPBQJ6t6qkJGkKG21Quv"
  },
  {
    "id": "9FtLfPznLEsy2pwmzfYp",
    "number": "695108566094988677",
    "begin": "2021-08-24T03:14:00+00:00",
    "created": "2021-08-24T04:23:18+00:00",
    "end": "2021-08-24T04:21:00+00:00",
    "modified": "2021-08-24T05:48:33+00:00",
    "external_desc": "Connectivity issues affecting BigQuery in australia-southeast2.",
    "updates": [
      {
        "created": "2021-08-24T05:14:27+00:00",
        "modified": "2021-08-24T05:14:28+00:00",
        "when": "2021-08-24T05:14:27+00:00",
        "text": "The issue with BigQuery has been resolved for all affected users as of Monday, 2021-08-23 21:21 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T04:23:17+00:00",
        "modified": "2021-08-24T04:23:18+00:00",
        "when": "2021-08-24T04:23:17+00:00",
        "text": "Description: We are experiencing an issue with BigQuery at australia-southeast2\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G, no further updates will be provided here.\nWe apologise to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T05:14:27+00:00",
      "modified": "2021-08-24T05:14:28+00:00",
      "when": "2021-08-24T05:14:27+00:00",
      "text": "The issue with BigQuery has been resolved for all affected users as of Monday, 2021-08-23 21:21 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "9CcrhHUcFevXPSVaSxkf",
    "service_name": "Google BigQuery",
    "affected_products": [
      {
        "title": "Google BigQuery",
        "id": "9CcrhHUcFevXPSVaSxkf"
      }
    ],
    "uri": "incidents/9FtLfPznLEsy2pwmzfYp"
  },
  {
    "id": "NJJp8jkNzFStMyiJZWWD",
    "number": "16011761144916808084",
    "begin": "2021-08-24T03:14:00+00:00",
    "created": "2021-08-24T04:21:20+00:00",
    "end": "2021-08-24T03:41:13+00:00",
    "modified": "2021-08-24T05:48:13+00:00",
    "external_desc": "The issue with Cloud Networking has been resolved for all affected users as of Monday, 2021-08-23 20:41:13 PDT.\nWe thank you for your patience while we worked on resolving the issue.",
    "updates": [
      {
        "created": "2021-08-24T04:21:20+00:00",
        "modified": "2021-08-24T04:21:20+00:00",
        "when": "2021-08-24T04:21:20+00:00",
        "text": "Description: We are experiencing an issue with Cloud Networking at australia-southeast2\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T04:21:20+00:00",
      "modified": "2021-08-24T04:21:20+00:00",
      "when": "2021-08-24T04:21:20+00:00",
      "text": "Description: We are experiencing an issue with Cloud Networking at australia-southeast2\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/8DhiwfKvD987f5tJrj1G, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
      "status": "SERVICE_DISRUPTION"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/NJJp8jkNzFStMyiJZWWD"
  },
  {
    "id": "8DhiwfKvD987f5tJrj1G",
    "number": "13912371513886524933",
    "begin": "2021-08-24T02:50:00+00:00",
    "created": "2021-08-24T03:35:48+00:00",
    "end": "2021-08-24T04:20:00+00:00",
    "modified": "2021-08-24T23:09:25+00:00",
    "external_desc": "Google Cloud infrastructure components faced issues in australia-southeast2 starting 2021-08-23 19:50 PDT. Most of the services are fully restored by 2021-08-23 21:20 PDT.",
    "updates": [
      {
        "created": "2021-08-24T22:59:30+00:00",
        "modified": "2021-08-24T22:59:30+00:00",
        "when": "2021-08-24T22:59:30+00:00",
        "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 23 August 2021 19:50\n**Incident End:** 23 August 2021 21:20\n**Duration:** 1 hours, 30 minutes\n**Affected Services and Features:**\n- Cloud Networking\n- Cloud L7 and L4 Load balancers\n- Cloud Interconnect\n- Cloud NAT\n- Cloud VPN\n- Google Compute Engine\n- Google Kubernetes Engine\n- Cloud Persistent Disk\n- Cloud Cloud Storage\n- Cloud FileStore\n- Cloud Dataproc\n- Cloud Run\n- Cloud SQL\n- Cloud Spanner\n- Cloud Pub/Sub\n- Cloud Dataflow\n- Cloud Dataproc\n- Cloud Firestore\n- Cloud Bigtable\n- Cloud Logging\n- Cloud Monitoring\n- Cloud BigQuery\n- Cloud IAM\n**Regions/Zones:** australia-southeast2\n**Description:**\nGoogle Cloud Networking experienced intermittent connectivity issues with Google Cloud Services in australia-southeast2 for 1 hour and 30 minutes. The underlying Cloud Networking impact ended at 20:41, however, some Cloud Services took longer to recover - delaying the all clear until 21:20. Any service that uses Cloud Networking may have seen impact. We have included available details of service specific impact below; however, this may not be a comprehensive accounting of all downstream networking impact. From preliminary analysis, the root cause of the issue was transient voltage at the feeder to the network equipment, causing the equipment to reboot. In order to mitigate the issue, traffic within the australia-southeast2 region was redirected temporarily.\n**Customer Impact:**\n- Cloud Networking: Public IP traffic connectivity failed from 19:51 to 20:41.\n- Cloud L7 Load Balancers: Partial dataplane query loss and control plane operational delay for External load balancers from 19:50 - 20:12, and Internal load balancers from 19:50 - 20:18.\n- Cloud L4 Load Balancing Inbound public IP traffic was dropped from 19:51 to 20:41.\n- Cloud Interconnect: Up to 100% packet loss between 19:50 and 20:21.\n- Cloud NAT experienced control plane failures from 19:51 to 20:00.\n- Cloud VPN HA dropped up to 83% of traffic between 19:51 and 20:21, while Legacy VPN dropped ~100% of traffic between 19:51 and 20:41.\n- Cloud SQL: 100% error rate from 19:49 to 20:01.\n- Cloud Storage: 100% error rate through 21:20.\n- Cloud Functions:\n- Cloud Run: 100% error rate through 21:19.\n- Cloud Bigtable: 100% error rate from 19:49 to 20:01 and increased latency from 20:01 to 20:13.\n- Cloud Logging: Logs written within the region may have failed to be ingested from 20:07 to 21:18.\n- Cloud Monitoring: Customers may have experienced falsely firing alerts, missed alerts, missing metrics and failed writes from 19:50 to 20:15.\n- Google Compute Engine: Operations to create or modify instances failed from 19:52 to 20:12. Connectivity from instances to other GCP services may be affected until 20:26. Existing instances may have lost network connectivity. Additionally autoscaling had delays or errors collecting input data which may have impacted autoscaling decisions.\n- Google Kubernetes Engine: Control plane operations on regional clusters failed between 19:50 and 20:04. Increased latency from 20:05 to 20:41. 100% of requests to container.googleapis.com failed\n- Persistent Disk: Up to 100% device unavailability between 19:51 and 20:13.\n- Cloud Filestore: Up to 100% error rate from 19:50 to 20:03.\n- Cloud IAM: ~80% error rate from 19:52 to 20:10.\n- Cloud Spanner: 100% error rate between 19:53 and 20:09.\n- Cloud Pub/Sub: Increased error rate and latency of up to 95% between 19:50 and 20:12.\n- Cloud Dataflow: Increased errors starting jobs and making progress on existing jobs between 19:50 and 20:12.\n- Cloud Dataproc: New cluster creation failed from 20:09 until 21:20\n- Cloud Firestore: Control Plane saw ~90% error rates from 19:50 to 20:03. Data plane so no significant impact.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T05:27:39+00:00",
        "modified": "2021-08-24T05:34:21+00:00",
        "when": "2021-08-24T05:27:39+00:00",
        "text": "Google Cloud infrastructure components faced issues in australia-southeast2. Most of the services are now fully restored. The impact is believed to have started at 2021-08-23 19:50 PST.\nProducts impacted and current status:\n- Cloud FileStore - Service restored. 21:07 PST\n- Cloud Networking - Service restored. 20:41 PST\n- Cloud SQL - Customers might still see errors.\n- Cloud VPN - Service fully restored 20:41 PST\n- Cloud GKE - Service fully restored 20:41 PST\n- Cloud Storage - Service fully restored 22:27 PST\n- Cloud Dataproc - Service fully restored. 21:50:36 PST\n- Cloud Run - Service fully restored\n- Cloud Spanner - Service fully restored\n- Cloud Pub/Sub - Service restored. 20:38 PST\n- Cloud Dataflow - Services fully restored at 20:12 PST\n- Cloud Bigtable - Service restored. 21:36 PST\n- Cloud Memorystore - Service restored. 20:03 PST\n- Cloud Logging - Services fully restored - 21:18 PST\n- Cloud BigQuery - Services fully restored - 21:21 PST.\n- Cloud Identity & Security(Cloud Access Policy) - Service fully restored.\n- Cloud Load balancers- Fully restored- 21:47 PST\n- Cloud Persistent Disk - Service fully restored\nWe apologise for the service disruption caused by this issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-24T04:53:47+00:00",
        "modified": "2021-08-24T04:59:37+00:00",
        "when": "2021-08-24T04:53:47+00:00",
        "text": "We are experiencing an issue with Google Cloud infrastructure components at australia-southeast2. We have started seeing recovery with our services.\nProducts impacted and current status:\n- Cloud FileStore - Customers might see API errors.\n- Cloud Networking - Service restored. 20:41 PST\n- Cloud VPN\n- Cloud GKE - Service fully restored.\n- Cloud Storage - Service fully restored.\n- Cloud Dataproc\n- Cloud Run - Service fully restored\n- Cloud Spanner - Service fully restored\n- Cloud Pub/Sub\n- Cloud Dataflow\n- Cloud Bigtable - Service restored. 21:36 PST\n- Cloud Memorystore - Service restored. 20:03 PST\n- Cloud Logging\n- Cloud BigQuery\n- Cloud Identity & Security(Cloud Access Policy) - Service fully restored.\n- Cloud load balancers- Fully restored\n- Persistent Disk - Service fully restored\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-08-23 22:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis:\nCustomers impacted by this issue may see connectivity issues on Google Cloud Services.\nWorkaround:\nNone at this time…",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-24T03:35:42+00:00",
        "modified": "2021-08-24T04:52:47+00:00",
        "when": "2021-08-24T03:35:42+00:00",
        "text": "We are experiencing an issue with Google Cloud infrastructure components in australia-southeast2 starting 2021-08-23 19:50 PT.\nProducts impacted:\n- Google Cloud Load Balancers\n- Google Compute Engine - Customers might see failure for creating new VMs.\n- Cloud FileStore - Customers might see API errors.\n- Cloud VPN\n- Cloud GKE\n- Cloud PD\n- Cloud Storage\n- Cloud Dataproc\n- Cloud Run\n- Cloud Spanner\n- Cloud Pub/Sub\n- Cloud Dataflow\n- Cloud Bigtable\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-08-23 21:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis:\nCustomers impacted by this issue may see connectivity issues on Google Cloud Services.\nWorkaround:\nNone at this time",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-24T22:59:30+00:00",
      "modified": "2021-08-24T22:59:30+00:00",
      "when": "2021-08-24T22:59:30+00:00",
      "text": "We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 23 August 2021 19:50\n**Incident End:** 23 August 2021 21:20\n**Duration:** 1 hours, 30 minutes\n**Affected Services and Features:**\n- Cloud Networking\n- Cloud L7 and L4 Load balancers\n- Cloud Interconnect\n- Cloud NAT\n- Cloud VPN\n- Google Compute Engine\n- Google Kubernetes Engine\n- Cloud Persistent Disk\n- Cloud Cloud Storage\n- Cloud FileStore\n- Cloud Dataproc\n- Cloud Run\n- Cloud SQL\n- Cloud Spanner\n- Cloud Pub/Sub\n- Cloud Dataflow\n- Cloud Dataproc\n- Cloud Firestore\n- Cloud Bigtable\n- Cloud Logging\n- Cloud Monitoring\n- Cloud BigQuery\n- Cloud IAM\n**Regions/Zones:** australia-southeast2\n**Description:**\nGoogle Cloud Networking experienced intermittent connectivity issues with Google Cloud Services in australia-southeast2 for 1 hour and 30 minutes. The underlying Cloud Networking impact ended at 20:41, however, some Cloud Services took longer to recover - delaying the all clear until 21:20. Any service that uses Cloud Networking may have seen impact. We have included available details of service specific impact below; however, this may not be a comprehensive accounting of all downstream networking impact. From preliminary analysis, the root cause of the issue was transient voltage at the feeder to the network equipment, causing the equipment to reboot. In order to mitigate the issue, traffic within the australia-southeast2 region was redirected temporarily.\n**Customer Impact:**\n- Cloud Networking: Public IP traffic connectivity failed from 19:51 to 20:41.\n- Cloud L7 Load Balancers: Partial dataplane query loss and control plane operational delay for External load balancers from 19:50 - 20:12, and Internal load balancers from 19:50 - 20:18.\n- Cloud L4 Load Balancing Inbound public IP traffic was dropped from 19:51 to 20:41.\n- Cloud Interconnect: Up to 100% packet loss between 19:50 and 20:21.\n- Cloud NAT experienced control plane failures from 19:51 to 20:00.\n- Cloud VPN HA dropped up to 83% of traffic between 19:51 and 20:21, while Legacy VPN dropped ~100% of traffic between 19:51 and 20:41.\n- Cloud SQL: 100% error rate from 19:49 to 20:01.\n- Cloud Storage: 100% error rate through 21:20.\n- Cloud Functions:\n- Cloud Run: 100% error rate through 21:19.\n- Cloud Bigtable: 100% error rate from 19:49 to 20:01 and increased latency from 20:01 to 20:13.\n- Cloud Logging: Logs written within the region may have failed to be ingested from 20:07 to 21:18.\n- Cloud Monitoring: Customers may have experienced falsely firing alerts, missed alerts, missing metrics and failed writes from 19:50 to 20:15.\n- Google Compute Engine: Operations to create or modify instances failed from 19:52 to 20:12. Connectivity from instances to other GCP services may be affected until 20:26. Existing instances may have lost network connectivity. Additionally autoscaling had delays or errors collecting input data which may have impacted autoscaling decisions.\n- Google Kubernetes Engine: Control plane operations on regional clusters failed between 19:50 and 20:04. Increased latency from 20:05 to 20:41. 100% of requests to container.googleapis.com failed\n- Persistent Disk: Up to 100% device unavailability between 19:51 and 20:13.\n- Cloud Filestore: Up to 100% error rate from 19:50 to 20:03.\n- Cloud IAM: ~80% error rate from 19:52 to 20:10.\n- Cloud Spanner: 100% error rate between 19:53 and 20:09.\n- Cloud Pub/Sub: Increased error rate and latency of up to 95% between 19:50 and 20:12.\n- Cloud Dataflow: Increased errors starting jobs and making progress on existing jobs between 19:50 and 20:12.\n- Cloud Dataproc: New cluster creation failed from 20:09 until 21:20\n- Cloud Firestore: Control Plane saw ~90% error rates from 19:50 to 20:03. Data plane so no significant impact.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "uoypgc4GWUyzAKRHPjEv",
    "service_name": "Google Cloud Infrastructure Components",
    "affected_products": [
      {
        "title": "Google Cloud Infrastructure Components",
        "id": "uoypgc4GWUyzAKRHPjEv"
      }
    ],
    "uri": "incidents/8DhiwfKvD987f5tJrj1G"
  },
  {
    "id": "QEcZsLuW9bqYZggLZXgS",
    "number": "7343907517039605904",
    "begin": "2021-08-19T03:40:00+00:00",
    "created": "2021-08-19T09:02:38+00:00",
    "end": "2021-08-19T08:40:00+00:00",
    "modified": "2021-08-19T09:27:54+00:00",
    "external_desc": "We experienced performance issues with Cloud Dataflow between 2021-08-18 20:40 Pacific Time to 2021-08-19 01:40 Pacific Time.\nSome streaming jobs may have seen higher than usual watermark. Multiple regions affected eg: europe-west1, us-west2\nThe issue is fully resolved and service is restored.\nWe apologize to all who are affected by the disruption.",
    "updates": [
      {
        "created": "2021-08-19T09:02:38+00:00",
        "modified": "2021-08-19T09:02:39+00:00",
        "when": "2021-08-19T09:02:38+00:00",
        "text": "Performance degradation of Dataflow streaming jobs in multiple regions.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-19T09:02:38+00:00",
      "modified": "2021-08-19T09:02:39+00:00",
      "when": "2021-08-19T09:02:38+00:00",
      "text": "Performance degradation of Dataflow streaming jobs in multiple regions.",
      "status": "SERVICE_DISRUPTION"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "T9bFoXPqG8w8g1YbWTKY",
    "service_name": "Google Cloud Dataflow",
    "affected_products": [
      {
        "title": "Google Cloud Dataflow",
        "id": "T9bFoXPqG8w8g1YbWTKY"
      }
    ],
    "uri": "incidents/QEcZsLuW9bqYZggLZXgS"
  },
  {
    "id": "CWYZQhBtU4sf2cYJ8AAf",
    "number": "6700504986737780589",
    "begin": "2021-08-18T18:15:00+00:00",
    "created": "2021-08-18T20:42:34+00:00",
    "end": "2021-08-18T22:06:00+00:00",
    "modified": "2021-08-19T19:05:10+00:00",
    "external_desc": "The issue with Cloud Logging has been resolved for all affected projects.",
    "updates": [
      {
        "created": "2021-08-19T19:03:54+00:00",
        "modified": "2021-08-19T19:05:10+00:00",
        "when": "2021-08-19T19:03:54+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 18 August 2021 11:15\n**Incident End:** 18 August 2021 15:06\n**Duration:** 3 hours, 51 minutes\n**Affected Services and Features:** Cloud Logging\n**Regions/Zones:** Global\n**Description:**\nCloud Logging experienced increased read errors globally for 3 hours, 51 minutes. From preliminary analysis, the root cause of the issue was due to a large increase in work from an internal service which overwhelmed the available capacity on a backend database. Log ingestion was not impacted.\n**Customer Impact:**\n* Customers experienced elevated read failures when attempting to query logs.\n* Customers were unable to access logs in the Cloud Console due to query timeouts.\n**Additional details:**\nThe issue has been mitigated and the problematic service has been identified and canceled. Query operations have returned to normal.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-18T22:48:26+00:00",
        "modified": "2021-08-18T22:48:26+00:00",
        "when": "2021-08-18T22:48:26+00:00",
        "text": "The issue with Cloud Logging has been resolved for all affected projects as of Wednesday, 2021-08-18 15:30 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-18T21:51:35+00:00",
        "modified": "2021-08-18T21:51:35+00:00",
        "when": "2021-08-18T21:51:35+00:00",
        "text": "Summary: We are experiencing elevated read error rates with Cloud Logging in multiple regions.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Wednesday, 2021-08-18 16:00 US/Pacific.\nWe will provide more information by Wednesday, 2021-08-18 16:00 US/Pacific.\nDiagnosis: Some customers may be unable to view logging in the Cloud Console.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-18T21:38:15+00:00",
        "modified": "2021-08-18T21:38:15+00:00",
        "when": "2021-08-18T21:38:15+00:00",
        "text": "Summary: We are experiencing elevated read error rates with Cloud Logging in multiple regions.\nDescription: We are experiencing elevated read error rates with Cloud Logging in multiple regions beginning at Wednesday, 2021-08-18 11:15 US/Pacific.\nOur engineering team is working on mitigation options.\nWe will provide an update by Wednesday, 2021-08-18 15:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Some customers may be unable to view logging in the Cloud Console.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-18T21:14:56+00:00",
        "modified": "2021-08-18T21:14:56+00:00",
        "when": "2021-08-18T21:14:56+00:00",
        "text": "Summary: We are experiencing elevated read error rates with Cloud Logging in multiple regions.\nDescription: We are experiencing elevated read error rates with Cloud Logging in multiple regions beginning at Wednesday, 2021-08-18 11:15 US/Pacific.\nOur engineering team is exploring mitigation options.\nWe will provide an update by Wednesday, 2021-08-18 14:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Some customers may be unable to view logging in the Cloud Console.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-18T20:42:33+00:00",
        "modified": "2021-08-18T21:08:25+00:00",
        "when": "2021-08-18T20:42:33+00:00",
        "text": "Summary: We are experiencing elevated read error rates with Cloud Logging in multiple regions\nDescription: We are experiencing elevated read errors with Cloud Logging in multiple regions beginning at Wednesday, 2021-08-18 11:15 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-08-18 14:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may be unable to view logging in the Cloud Console.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-19T19:03:54+00:00",
      "modified": "2021-08-19T19:05:10+00:00",
      "when": "2021-08-19T19:03:54+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 18 August 2021 11:15\n**Incident End:** 18 August 2021 15:06\n**Duration:** 3 hours, 51 minutes\n**Affected Services and Features:** Cloud Logging\n**Regions/Zones:** Global\n**Description:**\nCloud Logging experienced increased read errors globally for 3 hours, 51 minutes. From preliminary analysis, the root cause of the issue was due to a large increase in work from an internal service which overwhelmed the available capacity on a backend database. Log ingestion was not impacted.\n**Customer Impact:**\n* Customers experienced elevated read failures when attempting to query logs.\n* Customers were unable to access logs in the Cloud Console due to query timeouts.\n**Additional details:**\nThe issue has been mitigated and the problematic service has been identified and canceled. Query operations have returned to normal.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/CWYZQhBtU4sf2cYJ8AAf"
  },
  {
    "id": "9hh2XPBVqqem4DxXZxui",
    "number": "271309249334889945",
    "begin": "2021-08-16T08:19:00+00:00",
    "created": "2021-08-17T15:17:36+00:00",
    "end": "2021-08-17T15:55:00+00:00",
    "modified": "2021-08-17T21:08:01+00:00",
    "external_desc": "Cloud Router creations are failing in southamerica-east1",
    "updates": [
      {
        "created": "2021-08-17T21:06:04+00:00",
        "modified": "2021-08-17T21:08:01+00:00",
        "when": "2021-08-17T21:06:04+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 16 August 2021 01:19\n**Incident End:** 17 August 2021 08:55\n**Duration:** 1 day, 7 hours, 36 minutes\n**Affected Services and Features:** Cloud Router\n**Regions/Zones:** southamerica-east1\n**Description:**\nGoogle Cloud Router experienced failures creating or modifying routers in southamerica-east1 for a duration of 1 day, 7 hours and 36 minutes. New Cloud router creations or modifications to existing Cloud Routers would have been impacted. From preliminary analysis, the root cause of the issue is related to a rollout within the virtual routing control plane for the region, which had a configuration mismatch as part of an ongoing migration.\n**Customer Impact:**\n- Customers were unable to create or modify existing Cloud Routers from 16 August 2021 01:19 to 17 August 2021 08:34.\n- Router status requests [1] which rely on the getRouterStatus [2] API may have also returned errors during the incident\n- All existing routers that had completed programming continued to work throughout the entire duration.\n- Dynamic routing functionality [3] using BGP routes continued to work as expected.\n**Additional details:**\n- In order to prevent a recurrence, we are fixing outdated automations used during migrations\n- In order to reduce detection delays, we are improving our control plane probers to ensure we are alerted promptly\n**Reference(s):**\n[1] https://cloud.google.com/network-connectivity/docs/router/how-to/viewing-router-details#viewing-router-status\n[2] https://cloud.google.com/compute/docs/reference/rest/v1/routers/getRouterStatus\n[3] https://cloud.google.com/vpc/docs/routes#dynamic_routes",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-17T17:14:20+00:00",
        "modified": "2021-08-17T17:14:21+00:00",
        "when": "2021-08-17T17:14:20+00:00",
        "text": "The issue with Cloud Router has been resolved for all affected projects as of Tuesday, 2021-08-17 10:00 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-17T16:08:17+00:00",
        "modified": "2021-08-17T16:08:18+00:00",
        "when": "2021-08-17T16:08:17+00:00",
        "text": "Summary: Cloud Router creations are failing in southamerica-east1\nDescription: We believe the issue with Cloud Router is partially resolved. Full resolution is expected to complete by Tuesday, 2021-08-17 10:15 US/Pacific. We will provide an update by Tuesday, 2021-08-17 10:15 US/Pacific with current details.\nDiagnosis: New Cloud Router creations should be failing in southamerica-east1. Status request operations may also fail.\nWorkaround: Avoid making changes to existing router within southamerica-east1.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-17T15:17:36+00:00",
        "modified": "2021-08-17T15:34:39+00:00",
        "when": "2021-08-17T15:17:36+00:00",
        "text": "Summary: Cloud Router creations are failing in southamerica-east1\nDescription: We are experiencing an issue with Cloud Router pertaining to creations within southamerica-east1. Our engineering team continues to investigate the issue. We will provide an update by Tuesday, 2021-08-17 09:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: New Cloud Router creations should be failing in southamerica-east1. Status request operations may also fail\nWorkaround: Avoid making changes to existing router within southamerica-east1.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-17T21:06:04+00:00",
      "modified": "2021-08-17T21:08:01+00:00",
      "when": "2021-08-17T21:06:04+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 16 August 2021 01:19\n**Incident End:** 17 August 2021 08:55\n**Duration:** 1 day, 7 hours, 36 minutes\n**Affected Services and Features:** Cloud Router\n**Regions/Zones:** southamerica-east1\n**Description:**\nGoogle Cloud Router experienced failures creating or modifying routers in southamerica-east1 for a duration of 1 day, 7 hours and 36 minutes. New Cloud router creations or modifications to existing Cloud Routers would have been impacted. From preliminary analysis, the root cause of the issue is related to a rollout within the virtual routing control plane for the region, which had a configuration mismatch as part of an ongoing migration.\n**Customer Impact:**\n- Customers were unable to create or modify existing Cloud Routers from 16 August 2021 01:19 to 17 August 2021 08:34.\n- Router status requests [1] which rely on the getRouterStatus [2] API may have also returned errors during the incident\n- All existing routers that had completed programming continued to work throughout the entire duration.\n- Dynamic routing functionality [3] using BGP routes continued to work as expected.\n**Additional details:**\n- In order to prevent a recurrence, we are fixing outdated automations used during migrations\n- In order to reduce detection delays, we are improving our control plane probers to ensure we are alerted promptly\n**Reference(s):**\n[1] https://cloud.google.com/network-connectivity/docs/router/how-to/viewing-router-details#viewing-router-status\n[2] https://cloud.google.com/compute/docs/reference/rest/v1/routers/getRouterStatus\n[3] https://cloud.google.com/vpc/docs/routes#dynamic_routes",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/9hh2XPBVqqem4DxXZxui"
  },
  {
    "id": "yC6jA5p6Taoij6pPgSSW",
    "number": "12084164814980114469",
    "begin": "2021-08-06T21:25:00+00:00",
    "created": "2021-08-06T22:11:39+00:00",
    "end": "2021-08-07T03:53:00+00:00",
    "modified": "2021-08-09T16:02:47+00:00",
    "external_desc": "Elevated error rate across all monitoring API endpoints globally",
    "updates": [
      {
        "created": "2021-08-09T16:02:22+00:00",
        "modified": "2021-08-09T16:02:22+00:00",
        "when": "2021-08-09T16:02:22+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 06 August 2021 14:25\n**Incident End:** 06 August 2021 20:53\n**Duration:** 6 hours, 28 minutes\n**Affected Services and Features:**\nGoogle Cloud Monitoring\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Monitoring experienced increased latency and error rates for monitoring endpoints globally for 6 hours, 28 minutes. From preliminary analysis, the root cause of the issue is an overload of a monitoring API dependency that serves metric and monitored resource descriptors.\n**Customer Impact:**\nRequests against the monitoring API would have seen increased timeouts, errors, and latency.\nCloud Monitoring dashboards would have failed to load due to timeout.\n**Additional details:**\nThis service disruption was mitigated by increasing the resources available to the affected dependency, and we are confident that there will not be a recurrence.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-07T04:32:21+00:00",
        "modified": "2021-08-07T04:32:21+00:00",
        "when": "2021-08-07T04:32:21+00:00",
        "text": "The issue with Cloud Monitoring has been resolved for all affected users as of Friday, 2021-08-06 20:53 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-07T00:51:30+00:00",
        "modified": "2021-08-07T00:51:30+00:00",
        "when": "2021-08-07T00:51:30+00:00",
        "text": "Summary: Elevated error rate across all monitoring API endpoints globally\nDescription: Mitigation work is still underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-08-06 21:29 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-08-06T23:56:27+00:00",
        "modified": "2021-08-06T23:56:28+00:00",
        "when": "2021-08-06T23:56:27+00:00",
        "text": "Summary: Elevated error rate across all monitoring API endpoints globally\nDescription: Mitigation work is still underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-08-06 17:59 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-08-06T22:58:23+00:00",
        "modified": "2021-08-06T22:58:23+00:00",
        "when": "2021-08-06T22:58:23+00:00",
        "text": "Summary: Elevated error rate across all monitoring API endpoints globally\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-08-06 16:59 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-08-06T22:25:19+00:00",
        "modified": "2021-08-06T22:25:25+00:00",
        "when": "2021-08-06T22:25:19+00:00",
        "text": "Summary: Elevated error rate across all monitoring API endpoints globally\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-08-06 15:59 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-08-06T22:11:39+00:00",
        "modified": "2021-08-06T22:11:40+00:00",
        "when": "2021-08-06T22:11:39+00:00",
        "text": "Summary: Elevated error rate across all monitoring API endpoints globally\nDescription: We are experiencing an issue with Cloud Monitoring beginning at Friday, 2021-08-06 14:25 US/Pacific US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide the next update by Friday, 2021-08-06 15:40 US/Pacific US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-09T16:02:22+00:00",
      "modified": "2021-08-09T16:02:22+00:00",
      "when": "2021-08-09T16:02:22+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 06 August 2021 14:25\n**Incident End:** 06 August 2021 20:53\n**Duration:** 6 hours, 28 minutes\n**Affected Services and Features:**\nGoogle Cloud Monitoring\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Monitoring experienced increased latency and error rates for monitoring endpoints globally for 6 hours, 28 minutes. From preliminary analysis, the root cause of the issue is an overload of a monitoring API dependency that serves metric and monitored resource descriptors.\n**Customer Impact:**\nRequests against the monitoring API would have seen increased timeouts, errors, and latency.\nCloud Monitoring dashboards would have failed to load due to timeout.\n**Additional details:**\nThis service disruption was mitigated by increasing the resources available to the affected dependency, and we are confident that there will not be a recurrence.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_OUTAGE",
    "severity": "high",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/yC6jA5p6Taoij6pPgSSW"
  },
  {
    "id": "f8NTn1ZFA4vXTd3CHQgw",
    "number": "11183604505216208942",
    "begin": "2021-08-06T09:38:09+00:00",
    "created": "2021-08-06T09:41:46+00:00",
    "end": "2021-08-06T10:38:22+00:00",
    "modified": "2021-08-06T10:38:22+00:00",
    "external_desc": "Significant packet loss on Cloud Interconnect in europe-west2 for some customers.",
    "updates": [
      {
        "created": "2021-08-06T10:38:20+00:00",
        "modified": "2021-08-06T10:38:21+00:00",
        "when": "2021-08-06T10:38:20+00:00",
        "text": "This incident with Cloud Networking was initially triggered by our internal monitoring systems.\nThere is a current incident running for this issue please ref:\nhttps://status.cloud.google.com/incidents/oNMgU4ZjJFCiFTfeMyDX",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-06T10:28:59+00:00",
        "modified": "2021-08-06T10:29:00+00:00",
        "when": "2021-08-06T10:28:59+00:00",
        "text": "Summary: Significant packet loss on Cloud Interconnect in europe-west2 for some customers.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-08-06 04:15 US/Pacific.\nDiagnosis: Visible, near 100% packet loss on Cloud Interconnect.\nWorkaround: Fail over to other Cloud regions.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-06T10:02:19+00:00",
        "modified": "2021-08-06T10:02:21+00:00",
        "when": "2021-08-06T10:02:19+00:00",
        "text": "Summary: Significant packet loss on Cloud Interconnect in europe-west2 for some customers.\nDescription: We believe the issue with Cloud Interconnect is partially resolved.\nWe will provide an update by Friday, 2021-08-06 03:45 US/Pacific with current details.\nDiagnosis: Visible, near 100% packet loss on Cloud Interconnect.\nWorkaround: Fail over to other Cloud regions.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-06T09:41:37+00:00",
        "modified": "2021-08-06T09:41:47+00:00",
        "when": "2021-08-06T09:41:37+00:00",
        "text": "Summary: Significant packet loss on Cloud Interconnect in europe-west2 for some customers.\nDescription: We are experiencing an issue with Cloud Interconnect beginning at Friday, 2021-08-06 01:55 US/Pacific.\nWe're seeing significant packet loss on Cloud Interconnect in europe-west2 for some customers.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-08-06 03:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Visible, near 100% packet loss on Cloud Interconnect.\nWorkaround: Fail over to other Cloud regions.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-06T10:38:20+00:00",
      "modified": "2021-08-06T10:38:21+00:00",
      "when": "2021-08-06T10:38:20+00:00",
      "text": "This incident with Cloud Networking was initially triggered by our internal monitoring systems.\nThere is a current incident running for this issue please ref:\nhttps://status.cloud.google.com/incidents/oNMgU4ZjJFCiFTfeMyDX",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/f8NTn1ZFA4vXTd3CHQgw"
  },
  {
    "id": "oNMgU4ZjJFCiFTfeMyDX",
    "number": "16825402852599713412",
    "begin": "2021-08-06T08:56:00+00:00",
    "created": "2021-08-06T10:00:16+00:00",
    "end": "2021-08-06T12:41:00+00:00",
    "modified": "2021-08-06T19:03:17+00:00",
    "external_desc": "We've been informed that Cloud Networking, and Load Balancer, are not functioning in europe-west2",
    "updates": [
      {
        "created": "2021-08-06T18:56:46+00:00",
        "modified": "2021-08-06T19:03:17+00:00",
        "when": "2021-08-06T18:56:46+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Timeline:**\n06 August 2021 01:56 - 03:23\n06 August 2021 05:27 - 05:41\n**Duration:** 1 hours, 41 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking, Cloud Load Balancing, Compute Engine, Cloud Spanner, Pub/Sub, Cloud Interconnect\n**Regions/Zones:** europe-west2-a\n**Description:**\nGoogle Cloud Networking and Google Cloud Load Balancing (GCLB) experienced elevated packet loss in europe-west2-a. From preliminary analysis, the root cause of the issue is a configuration change on a device that caused a permission issue with an automatic configuration deployment and failed to propagate. This resulted in a corrupted configuration which caused traffic to be dropped.\n**Customer Impact:**\nCustomers experienced elevated packet loss or connection terminations for connections in europe-west2-a.\nA small number of Compute Engine instances failed to start in europe-west2-a.\nCloud Interconnect in europe-west2 observed an increase in packet loss.\nCloud Spanner requests passing through europe-west2-a experienced increased error rates.\nCloud Pub/Sub may have experienced increased error rates when publishing to topics in europe-west2-a.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-06T11:31:04+00:00",
        "modified": "2021-08-06T11:31:08+00:00",
        "when": "2021-08-06T11:31:04+00:00",
        "text": "The issue with Cloud Networking / Load Balancing has been resolved for all affected users as of Friday, 2021-08-06 03:22 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-06T10:59:58+00:00",
        "modified": "2021-08-06T11:00:01+00:00",
        "when": "2021-08-06T10:59:58+00:00",
        "text": "Summary: We've been informed that Cloud Networking, and Load Balancer, are not functioning in europe-west2\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-08-06 04:36 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-06T10:00:13+00:00",
        "modified": "2021-08-06T10:00:17+00:00",
        "when": "2021-08-06T10:00:13+00:00",
        "text": "Summary: We've been informed that Cloud Networking, and Load Balancer, are not functioning in europe-west2\nDescription: We are investigating a potential issue with Cloud Networking and/or Load Balancing in europe-west2.\nWe will provide more information by Friday, 2021-08-06 04:00 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-06T18:56:46+00:00",
      "modified": "2021-08-06T19:03:17+00:00",
      "when": "2021-08-06T18:56:46+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Timeline:**\n06 August 2021 01:56 - 03:23\n06 August 2021 05:27 - 05:41\n**Duration:** 1 hours, 41 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking, Cloud Load Balancing, Compute Engine, Cloud Spanner, Pub/Sub, Cloud Interconnect\n**Regions/Zones:** europe-west2-a\n**Description:**\nGoogle Cloud Networking and Google Cloud Load Balancing (GCLB) experienced elevated packet loss in europe-west2-a. From preliminary analysis, the root cause of the issue is a configuration change on a device that caused a permission issue with an automatic configuration deployment and failed to propagate. This resulted in a corrupted configuration which caused traffic to be dropped.\n**Customer Impact:**\nCustomers experienced elevated packet loss or connection terminations for connections in europe-west2-a.\nA small number of Compute Engine instances failed to start in europe-west2-a.\nCloud Interconnect in europe-west2 observed an increase in packet loss.\nCloud Spanner requests passing through europe-west2-a experienced increased error rates.\nCloud Pub/Sub may have experienced increased error rates when publishing to topics in europe-west2-a.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/oNMgU4ZjJFCiFTfeMyDX"
  },
  {
    "id": "LGFBxyLwbh92E47fAzJ5",
    "number": "135405297875892189",
    "begin": "2021-08-01T07:00:00+00:00",
    "created": "2021-08-03T20:28:27+00:00",
    "end": "2021-08-04T23:18:00+00:00",
    "modified": "2021-08-05T17:35:12+00:00",
    "external_desc": "Mutliregional Price for E2 Free Tier core is set incorrectly",
    "updates": [
      {
        "created": "2021-08-05T17:34:33+00:00",
        "modified": "2021-08-05T17:34:34+00:00",
        "when": "2021-08-05T17:34:33+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 01 August 2021 00:00\n**Incident End:** 04 August 2021 16:18\n**Duration:** 3 days, 16 hours, 18 minutes\n**Affected Services and Features:**\nGoogle Compute Engine Billing\n**Regions/Zones:** us-west1, us-east1, us-central1\n**Description:**\nGoogle Compute Engine Billing experienced incorrect charges in us-west1, us-east1, and us-central1 for e2-micro VMs for 3 days, 16 hours, 18 minutes. From preliminary analysis, the root cause was an incorrect discount being applied to E2 core usage for e2-micro VMs due to a mismatch between metered usage and the discount for the E2 SKU.\n**Customer Impact:**\nCustomers may have seen incorrect charges for e2-micro VMs in us-west1, us-east1, and us-central1 regions during the duration of the incident.\n**Additional details:**\nThis issue has been fully resolved, and charges have been corrected for all affected projects. No action is required from customers regarding this issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-05T12:52:04+00:00",
        "modified": "2021-08-05T12:52:05+00:00",
        "when": "2021-08-05T12:52:04+00:00",
        "text": "The issue with Google Compute Engine has been resolved for all affected users as of Thursday, 2021-08-05 05:51 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-08-05T08:35:48+00:00",
        "modified": "2021-08-05T08:35:54+00:00",
        "when": "2021-08-05T08:35:48+00:00",
        "text": "Summary: Mutliregional Price for E2 Free Tier core is set incorrectly\nDescription: We believe the issue with Google Compute Engine pricing is partially resolved.\nWe are now confirming if the fix addresses all kinds of corner cases.\nWe will provide an update by Thursday, 2021-08-05 08:30 US/Pacific with current details.\nDiagnosis: Customers might see that they're being incorrectly charged for a general purpose e2-micro VMs.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-05T04:59:08+00:00",
        "modified": "2021-08-05T04:59:09+00:00",
        "when": "2021-08-05T04:59:08+00:00",
        "text": "Summary: Mutliregional Price for E2 Free Tier core is set incorrectly\nDescription: We believe the issue with Google Compute Engine pricing is partially resolved.\nWe are now confirming if the fix addresses all kinds of corner cases.\nWe will provide an update by Thursday, 2021-08-05 02:40 US/Pacific with current details.\nDiagnosis: Customers might see that they're being incorrectly charged for a general purpose e2-micro VMs.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-04T17:51:06+00:00",
        "modified": "2021-08-04T17:51:07+00:00",
        "when": "2021-08-04T17:51:06+00:00",
        "text": "Summary: Mutliregional Price for E2 Free Tier core is set incorrectly\nDescription: Mitigation work is still underway by our engineering teamMitigation work is still underway by our engineering team.\nThe full resolution is expected to completed by Wednesday, 2021-08-04 21:00 US/Pacific.\nWe will provide more information by Wednesday, 2021-08-04 22:00 US/Pacific.\nDiagnosis: Customers might see that they're being incorrectly charged for a general purpose e2-micro VMs.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-04T17:33:57+00:00",
        "modified": "2021-08-04T17:34:00+00:00",
        "when": "2021-08-04T17:33:57+00:00",
        "text": "Summary: Mutliregional Price for E2 Free Tier core is set incorrectly\nDescription: Mitigation work is still underway by our engineering team.\nValidation in the testing environment has been completed.\nThe full mitigation is expected to complete by Wednesday, 2021-08-04 21:00 US/Pacific.\nWe will provide more information by Wednesday, 2021-08-04 13:15 US/Pacific.\nDiagnosis: Customers might see that they're being incorrectly charged for a general purpose e2-micro VMs.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-04T16:45:00+00:00",
        "modified": "2021-08-04T16:45:02+00:00",
        "when": "2021-08-04T16:45:00+00:00",
        "text": "Summary: Mutliregional Price for E2 Free Tier core is set incorrectly\nDescription: Our engineering team have a mitigation underway.\nWe are finalizing the validation of the fix in our testing environment, we will provide an update on the production rollout as soon as that is complete.\nWe will provide more information by Wednesday, 2021-08-04 12:00 US/Pacific.\nDiagnosis: Customers might see that they're being incorrectly charged for a general purpose e2-micro VMs.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-04T11:42:17+00:00",
        "modified": "2021-08-04T11:42:19+00:00",
        "when": "2021-08-04T11:42:17+00:00",
        "text": "Summary: Mutliregional Price for E2 Free Tier core is set incorrectly\nDescription: Customers in us-west1 and central1 creating E2-micro VMs are being incorrectly charged. Our engineering team have a mitigation underway.\nThe mitigation is expected to complete by Wednesday, 2021-08-04 end of day US/Pacific.\nWe will provide more information by Wednesday, 2021-08-04 10:00 US/Pacific.\nDiagnosis: Customers might see that they're being incorrectly charged for a general purpose e2-micro VMs.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-04T00:31:55+00:00",
        "modified": "2021-08-04T00:31:56+00:00",
        "when": "2021-08-04T00:31:55+00:00",
        "text": "Summary: Mutliregional Price for E2 Free Tier core is set incorrectly\nDescription: Customers in us-west1 and central1 creating E2-micro VMs are being incorrectly charged. Our engineering team have a mitigation underway.\nThe mitigation is expected to complete by Wednesday, 2021-08-04 EOD US/Pacific.\nWe will provide more information by Wednesday, 2021-08-04 06:00 US/Pacific.\nDiagnosis: Customers might see that they're being incorrectly charged for a general purpose e2-micro VMs.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-03T22:31:53+00:00",
        "modified": "2021-08-03T22:31:56+00:00",
        "when": "2021-08-03T22:31:53+00:00",
        "text": "Summary: Mutliregional Price for E2 Free Tier core is set incorrectly\nDescription: Customers in us-west1 and central1 creating E2-micro VMs are being incorrectly charged. Our engineering team have a mitigation underway.\nMitigation progress is expected by Tuesday, 2021-08-03 17:30 US/Pacific.\nWe will provide more information by Tuesday, 2021-08-03 17:30 US/Pacific.\nDiagnosis: Customers might see that they're being incorrectly charged for a general purpose e2-micro VMs.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-03T21:24:47+00:00",
        "modified": "2021-08-03T21:24:47+00:00",
        "when": "2021-08-03T21:24:47+00:00",
        "text": "Summary: Price for E2 Free Tier core is set incorrectly\nDescription: We are experiencing an issue with Google Cloud Billing related to general purpose e2-micro VMs., beginning at Sunday, 2021-08-01 00:00 US/Pacific}.\nCustomers creating E2-micro VMs are being incorrectly charged. Our engineering team have a mitigation underway.\nWe will provide an update by Tuesday, 2021-08-03 15:25 US/Pacific with current details.\nDiagnosis: Customers might see that they're being incorrectly charged for a general purpose e2-micro VMs.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-08-03T20:28:26+00:00",
        "modified": "2021-08-03T20:28:27+00:00",
        "when": "2021-08-03T20:28:26+00:00",
        "text": "Summary: Price for E2 Free Tier core is set incorrectly\nDescription: We are experiencing an issue with Google Cloud Billing related to general purpose e2-micro VMs., beginning at Sunday, 2021-08-01 00:00 US/Pacific}.\nCustomers creating E2-micro VMs are being incorrectly charged. Our engineering team have a mitigation underway.\nWe will provide an update by Tuesday, 2021-08-03 14:25 US/Pacific with current details.\nDiagnosis: Customers might see that they're being incorrectly charged for a general purpose e2-micro VMs.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-05T17:34:33+00:00",
      "modified": "2021-08-05T17:34:34+00:00",
      "when": "2021-08-05T17:34:33+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 01 August 2021 00:00\n**Incident End:** 04 August 2021 16:18\n**Duration:** 3 days, 16 hours, 18 minutes\n**Affected Services and Features:**\nGoogle Compute Engine Billing\n**Regions/Zones:** us-west1, us-east1, us-central1\n**Description:**\nGoogle Compute Engine Billing experienced incorrect charges in us-west1, us-east1, and us-central1 for e2-micro VMs for 3 days, 16 hours, 18 minutes. From preliminary analysis, the root cause was an incorrect discount being applied to E2 core usage for e2-micro VMs due to a mismatch between metered usage and the discount for the E2 SKU.\n**Customer Impact:**\nCustomers may have seen incorrect charges for e2-micro VMs in us-west1, us-east1, and us-central1 regions during the duration of the incident.\n**Additional details:**\nThis issue has been fully resolved, and charges have been corrected for all affected projects. No action is required from customers regarding this issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/LGFBxyLwbh92E47fAzJ5"
  },
  {
    "id": "ZJoBx7kocBokFxS1ZN5p",
    "number": "7204119448599013942",
    "begin": "2021-07-29T02:24:00+00:00",
    "created": "2021-07-30T15:27:02+00:00",
    "end": "2021-07-31T01:52:00+00:00",
    "modified": "2021-08-02T18:46:57+00:00",
    "external_desc": "Multi-region: Accessing Component Gateway fails with 400 (Bad Request). Unable to access clusters details page after cluster creation.",
    "updates": [
      {
        "created": "2021-08-02T18:45:48+00:00",
        "modified": "2021-08-02T18:46:57+00:00",
        "when": "2021-08-02T18:45:48+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 28 July 2021 19:24\n**Incident End:** 30 July 2021 18:52\n**Duration:** 1 day, 23 hours and 28 minutes\n**Affected Services and Features:**\nGoogle Cloud Dataproc - Ability to view and access Component Gateway URLs [1]\n**Regions/Zones:**\nasia-east1, asia-east2, asia-northeast1, asia-northeast3, asia-south1, asia-southeast1, asia-southeast2, australia-southeast1, europe-north1, europe-west1, europe-west2, europe-west4, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east1, us-east4, us-west1\n**Description:**\nGoogle Cloud Dataproc experienced elevated 400 errors indicating “Bad Requests” when accessing the component gateway URLs[1] for a duration of around 2 days. From preliminary analysis, the root cause of the issue was a rollout that started on 28 July 2021 at 12:45. The rollout was paused preventing further regions from being affected and a rollback started on 30 July 2021 at 9:18 to mitigate the issue in affected regions . During the incident, a workaround was provided which was to use the SSH SOCKS proxy as described in doc [2] to access the component gateway URLs.\n**Customer Impact:**\nGoogle Cloud Dataproc- Accessing component gateway URLs failed with 400 errors.\n**References:**\n[1] https://cloud.google.com/dataproc/docs/concepts/accessing/dataproc-gateways#viewing_and_accessing_component_gateway_urls\n[2] https://cloud.google.com/dataproc/docs/concepts/accessing/cluster-web-interfaces",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-31T02:04:20+00:00",
        "modified": "2021-07-31T02:04:20+00:00",
        "when": "2021-07-31T02:04:20+00:00",
        "text": "The issue with Cloud Dataproc has been resolved for all affected projects as of Friday, 2021-07-30 19:03 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-31T01:18:39+00:00",
        "modified": "2021-07-31T01:18:39+00:00",
        "when": "2021-07-31T01:18:39+00:00",
        "text": "Summary: Multi-region: Accessing Component Gateway fails with 400 (Bad Request). Unable to access clusters details page after cluster creation.\nDescription: We have observed reduction in the error rate and the issue is currently intermittent.\nEngineering team continues to work on the mitigation. The mitigation is in progress and estimated to complete by Friday, 2021-07-30 19:00 US/Pacific.\nAction: Utilize the SOCKS proxy to access their UIs as a workaround. Please refer to workaround section for more details.\nWe will provide more information by Friday, 2021-07-30 19:00 US/Pacific.\nDiagnosis: Unable to access the cluster details page after cluster creation.\nWorkaround: Customers can use the SOCKS proxy to access their UIs while component gateway is not working.\nPlease refer to the link for more details: https://cloud.google.com/dataproc/docs/concepts/accessing/cluster-web-interfaces",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-30T22:59:37+00:00",
        "modified": "2021-07-30T22:59:37+00:00",
        "when": "2021-07-30T22:59:37+00:00",
        "text": "Summary: Multi-region: Accessing Component Gateway fails with 400 (Bad Request). Unable to access clusters details page after cluster creation.\nDescription: We have observed reduction in the error rate and the issue is currently intermittent.\nEngineering team continues to work on the mitigation. The mitigation is estimated to complete by Friday, 2021-07-30 18:00 US/Pacific.\nAction: Utilize the SOCKS proxy to access their UIs as a workaround. Please refer to workaround section for more details.\nWe will provide more information by Friday, 2021-07-30 18:00 US/Pacific.\nDiagnosis: Unable to access the cluster details page after cluster creation.\nWorkaround: Customers can use the SOCKS proxy to access their UIs while component gateway is not working.\nPlease refer to the link for more details: https://cloud.google.com/dataproc/docs/concepts/accessing/cluster-web-interfaces",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-30T22:59:13+00:00",
        "modified": "2021-07-30T22:59:14+00:00",
        "when": "2021-07-30T22:59:13+00:00",
        "text": "Summary: Multi-region: Accessing Component Gateway fails with 400 (Bad Request). Unable to access clusters details page after cluster creation.\nDescription: We have observed reduction in the error rate and the issue is currently intermittent.\nEngineering team continues to work on the mitigation. The mitigation is estimated to complete by Friday, 2021-07-30 16:00 US/Pacific.\nAction: Utilize the SOCKS proxy to access their UIs as a workaround. Please refer to workaround section for more details.\nWe will provide more information by Friday, 2021-07-30 18:00 US/Pacific.\nDiagnosis: Unable to access the cluster details page after cluster creation.\nWorkaround: Customers can use the SOCKS proxy to access their UIs while component gateway is not working.\nPlease refer to the link for more details: https://cloud.google.com/dataproc/docs/concepts/accessing/cluster-web-interfaces",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-30T20:17:43+00:00",
        "modified": "2021-07-30T20:17:44+00:00",
        "when": "2021-07-30T20:17:43+00:00",
        "text": "Summary: Multi-region: Accessing Component Gateway fails with 400 (Bad Request). Unable to access clusters details page after cluster creation.\nDescription: We have observed reduction in the error rate and the issue is currently intermittent.\nEngineering team continues to work on the mitigation. The mitigation is estimated to complete by Friday, 2021-07-30 16:00 US/Pacific.\nAction: Utilize socks proxy to access their UIs as a workaround. Please refer to workaround section for more details.\nWe will provide more information by Friday, 2021-07-30 16:00 US/Pacific.\nDiagnosis: Unable to access the cluster details page after cluster creation.\nWorkaround: Customers can use the socks proxy to access their UIs while component gateway is not working.\nPlease refer to the link for more details: https://cloud.google.com/dataproc/docs/concepts/accessing/cluster-web-interfaces",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-30T19:27:43+00:00",
        "modified": "2021-07-30T19:27:43+00:00",
        "when": "2021-07-30T19:27:43+00:00",
        "text": "Summary: Multi-region: Accessing Component Gateway fails with 400 (Bad Request). Unable to access clusters details page after cluster creation.\nDescription: Mitigation work is still underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nAction: Utilize socks proxy to access their UIs as a workaround. Please refer to workaround section for more details.\nWe will provide more information by Friday, 2021-07-30 13:30 US/Pacific.\nDiagnosis: Unable to access the cluster details page after cluster creation.\nWorkaround: Customers can use the socks proxy to access their UIs while component gateway is not working.\nPlease refer to the link for more details: https://cloud.google.com/dataproc/docs/concepts/accessing/cluster-web-interfaces",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-30T18:07:47+00:00",
        "modified": "2021-07-30T18:07:47+00:00",
        "when": "2021-07-30T18:07:47+00:00",
        "text": "Summary: Multi-region: Accessing Component Gateway fails with 400 (Bad Request). Unable to access clusters details page after cluster creation.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nAction: Utilize socks proxy to access their UIs as a workaround. Please refer to workaround section for more details.\nWe will provide more information by Friday, 2021-07-30 12:30 US/Pacific.\nDiagnosis: Unable to access the cluster details page after cluster creation.\nWorkaround: Customers can use the socks proxy to access their UIs while component gateway is not working.\nPlease refer to the link for more details: https://cloud.google.com/dataproc/docs/concepts/accessing/cluster-web-interfaces",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-30T17:12:20+00:00",
        "modified": "2021-07-30T17:12:23+00:00",
        "when": "2021-07-30T17:12:20+00:00",
        "text": "Summary: Multi-region: Accessing Component Gateway fails with 400 (Bad Request). Unable to access clusters details page after cluster creation.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-07-30 11:30 US/Pacific.\nDiagnosis: Unable to access the cluster details page after cluster creation.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-30T16:47:10+00:00",
        "modified": "2021-07-30T16:47:10+00:00",
        "when": "2021-07-30T16:47:10+00:00",
        "text": "Summary: Multi-region: Accessing Component Gateway fails with 400 (Bad Request)\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-07-30 11:00 US/Pacific.\nDiagnosis: Increased failures with 400 bad request error\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-30T16:27:42+00:00",
        "modified": "2021-07-30T16:27:48+00:00",
        "when": "2021-07-30T16:27:42+00:00",
        "text": "Summary: Multi-region: Accessing Component Gateway fails with 400 (Bad Request)\nDescription: We are experiencing an issue with Cloud Dataproc.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-07-30 10:16 US/Pacific with current details.\nDiagnosis: Increased failures with 400 bad request error\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-30T15:56:51+00:00",
        "modified": "2021-07-30T15:56:56+00:00",
        "when": "2021-07-30T15:56:51+00:00",
        "text": "Summary: Multi-region: Accessing Component Gateway fails with 400 (Bad Request)\nDescription: We are experiencing an issue with Cloud Dataproc.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-07-30 09:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Increased failures with 400 bad request error\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-30T15:26:54+00:00",
        "modified": "2021-07-30T15:27:03+00:00",
        "when": "2021-07-30T15:26:54+00:00",
        "text": "Summary: Accessing Component Gateway fails with 400 (Bad Request)\nDescription: We are experiencing an issue with Cloud Dataproc.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-07-30 09:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Increased failures with 400 bad request error\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-08-02T18:45:48+00:00",
      "modified": "2021-08-02T18:46:57+00:00",
      "when": "2021-08-02T18:45:48+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 28 July 2021 19:24\n**Incident End:** 30 July 2021 18:52\n**Duration:** 1 day, 23 hours and 28 minutes\n**Affected Services and Features:**\nGoogle Cloud Dataproc - Ability to view and access Component Gateway URLs [1]\n**Regions/Zones:**\nasia-east1, asia-east2, asia-northeast1, asia-northeast3, asia-south1, asia-southeast1, asia-southeast2, australia-southeast1, europe-north1, europe-west1, europe-west2, europe-west4, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-east1, us-east4, us-west1\n**Description:**\nGoogle Cloud Dataproc experienced elevated 400 errors indicating “Bad Requests” when accessing the component gateway URLs[1] for a duration of around 2 days. From preliminary analysis, the root cause of the issue was a rollout that started on 28 July 2021 at 12:45. The rollout was paused preventing further regions from being affected and a rollback started on 30 July 2021 at 9:18 to mitigate the issue in affected regions . During the incident, a workaround was provided which was to use the SSH SOCKS proxy as described in doc [2] to access the component gateway URLs.\n**Customer Impact:**\nGoogle Cloud Dataproc- Accessing component gateway URLs failed with 400 errors.\n**References:**\n[1] https://cloud.google.com/dataproc/docs/concepts/accessing/dataproc-gateways#viewing_and_accessing_component_gateway_urls\n[2] https://cloud.google.com/dataproc/docs/concepts/accessing/cluster-web-interfaces",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "yjXrEg3Yvy26BauMwr69",
    "service_name": "Google Cloud Dataproc",
    "affected_products": [
      {
        "title": "Google Cloud Dataproc",
        "id": "yjXrEg3Yvy26BauMwr69"
      }
    ],
    "uri": "incidents/ZJoBx7kocBokFxS1ZN5p"
  },
  {
    "id": "MfiGCW4E26MPGRnCJ8by",
    "number": "13858523345881857527",
    "begin": "2021-07-27T17:35:27+00:00",
    "created": "2021-07-27T18:00:25+00:00",
    "end": "2021-07-27T23:15:35+00:00",
    "modified": "2021-07-27T23:15:35+00:00",
    "external_desc": "us-central1: GCS is returning stale version of object for bucket",
    "updates": [
      {
        "created": "2021-07-27T23:15:28+00:00",
        "modified": "2021-07-27T23:15:34+00:00",
        "when": "2021-07-27T23:15:28+00:00",
        "text": "The issue with Google Cloud Storage is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-27T22:07:26+00:00",
        "modified": "2021-07-27T22:07:31+00:00",
        "when": "2021-07-27T22:07:26+00:00",
        "text": "Summary: us-central1: GCS is returning stale version of object for bucket\nDescription: We believe the issue with Google Cloud Storage is partially resolved.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-07-27 15:56 US/Pacific with current details.\nDiagnosis: GCS is intermittently serving older deleted versions of objects, or not serving 404 for deleted objects.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T20:26:21+00:00",
        "modified": "2021-07-27T20:26:25+00:00",
        "when": "2021-07-27T20:26:21+00:00",
        "text": "Summary: us-central1: GCS is returning stale version of object for bucket\nDescription: Our engineering team is currently investigating the issue.\nThis issue affects get object requests that hit the us-central1 region and us multi region buckets.\nWe will provide an update by Tuesday, 2021-07-27 15:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: GCS is intermittently serving older deleted versions of objects, or not serving 404 for deleted objects.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T19:37:37+00:00",
        "modified": "2021-07-27T19:37:37+00:00",
        "when": "2021-07-27T19:37:37+00:00",
        "text": "Summary: us-central1: GCS is returning stale version of object for bucket\nDescription: Our engineering team is currently investigating the issue.\nThis issue affects get object requests that hit the us-central1 region and us multi region buckets.\nWe will provide an update by Tuesday, 2021-07-27 13:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: GCS is intermittently serving older deleted versions of objects, or not serving 404 for deleted objects.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T19:01:22+00:00",
        "modified": "2021-07-27T19:01:22+00:00",
        "when": "2021-07-27T19:01:22+00:00",
        "text": "Summary: us-central1: GCS is returning stale version of object for bucket\nDescription: Our engineering team continues to investigate the issue.\nThis issue affects get object requests that hit the us-central1 region and us multi region buckets.\nWe will provide an update by Tuesday, 2021-07-27 13:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: GCS is intermittently serving older deleted versions of objects, or not serving 404 for deleted objects.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T18:00:24+00:00",
        "modified": "2021-07-27T18:00:25+00:00",
        "when": "2021-07-27T18:00:24+00:00",
        "text": "Summary: GCS is returning stale version of object for bucket in us-central1\nDescription: We are experiencing an intermittent issue with Google Cloud Storage.\nThis issue affects us-central1 and multi-region buckets in US where resources are located in us-central1.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-07-27 12:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: GCS is intermittently serving older deleted versions of objects, or not serving 404 for deleted objects.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-07-27T23:15:28+00:00",
      "modified": "2021-07-27T23:15:34+00:00",
      "when": "2021-07-27T23:15:28+00:00",
      "text": "The issue with Google Cloud Storage is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "UwaYoXQ5bHYHG6EdiPB8",
    "service_name": "Google Cloud Storage",
    "affected_products": [
      {
        "title": "Google Cloud Storage",
        "id": "UwaYoXQ5bHYHG6EdiPB8"
      }
    ],
    "uri": "incidents/MfiGCW4E26MPGRnCJ8by"
  },
  {
    "id": "txaxJMs7eNMV5cHwgfRP",
    "number": "1839278878480132730",
    "begin": "2021-07-27T16:02:00+00:00",
    "created": "2021-07-27T18:53:54+00:00",
    "end": "2021-07-27T20:14:00+00:00",
    "modified": "2021-07-29T00:30:56+00:00",
    "external_desc": "Global: Cloud Logging Query timing out",
    "updates": [
      {
        "created": "2021-07-28T16:47:26+00:00",
        "modified": "2021-07-29T00:30:56+00:00",
        "when": "2021-07-28T16:47:26+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 27 July 2021 09:02\n**Incident End:** 27 July 2021 13:14\n**Duration:** 4 hours, 12 minutes\n**Affected Services and Features:**\nCloud Logging\n**Regions/Zones:** Global\n**Description:**\nCloud Logging experienced query timeouts globally for a duration of 4 hours, 12 minutes. From preliminary analysis, the root cause of the issue is a configuration change in the backend component used for indexing and cataloging the logs.\n**Customer Impact:**\n* Cloud Logging - Query timeouts\n* Cloud Console - Elevated errors for Activity Stream due to Cloud Logging query timeouts.\n* Kubernetes, Cloud Run- Elevated logging errors due to Cloud Logging query timeouts.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-27T21:48:09+00:00",
        "modified": "2021-07-27T21:48:15+00:00",
        "when": "2021-07-27T21:48:09+00:00",
        "text": "The issue with Cloud Logging has been resolved for all affected projects as of Tuesday, 2021-07-27 14:46 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-27T20:59:54+00:00",
        "modified": "2021-07-27T20:59:54+00:00",
        "when": "2021-07-27T20:59:54+00:00",
        "text": "Summary: Global: Cloud Logging Query timing out\nDescription: We believe the issue with Cloud Logging is partially resolved and there is no further impact observed.\nThe ETA for full resolution is end of week July 30th.\nWe will provide an update by Friday, July 30th with current details.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T19:58:38+00:00",
        "modified": "2021-07-27T19:58:38+00:00",
        "when": "2021-07-27T19:58:38+00:00",
        "text": "Summary: Global: Cloud Logging Query timing out\nDescription: We believe the issue with Cloud Logging is partially resolved and there is no further impact observed.\nThe ETA for full resolution is unknown at this time.\nWe will provide an update by Tuesday, 2021-07-27 14:00 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T19:22:33+00:00",
        "modified": "2021-07-27T19:22:34+00:00",
        "when": "2021-07-27T19:22:33+00:00",
        "text": "Summary: Global: Cloud Logging Query timing out\nDescription: We believe the issue with Cloud Logging is partially resolved and there is no further impact observed.\nWe will provide an update by Tuesday, 2021-07-27 13:00 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T18:53:54+00:00",
        "modified": "2021-07-27T18:53:55+00:00",
        "when": "2021-07-27T18:53:54+00:00",
        "text": "Summary: Global: Cloud Logging Query timing out\nDescription: We are investigating a potential issue with Cloud Logging.\nWe will provide more information by Tuesday, 2021-07-27 12:25 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-07-28T16:47:26+00:00",
      "modified": "2021-07-29T00:30:56+00:00",
      "when": "2021-07-28T16:47:26+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 27 July 2021 09:02\n**Incident End:** 27 July 2021 13:14\n**Duration:** 4 hours, 12 minutes\n**Affected Services and Features:**\nCloud Logging\n**Regions/Zones:** Global\n**Description:**\nCloud Logging experienced query timeouts globally for a duration of 4 hours, 12 minutes. From preliminary analysis, the root cause of the issue is a configuration change in the backend component used for indexing and cataloging the logs.\n**Customer Impact:**\n* Cloud Logging - Query timeouts\n* Cloud Console - Elevated errors for Activity Stream due to Cloud Logging query timeouts.\n* Kubernetes, Cloud Run- Elevated logging errors due to Cloud Logging query timeouts.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/txaxJMs7eNMV5cHwgfRP"
  },
  {
    "id": "eJ8bnwiB1kQXo8fet4Zg",
    "number": "2129730558922264261",
    "begin": "2021-07-27T15:29:00+00:00",
    "created": "2021-07-27T15:29:36+00:00",
    "end": "2021-07-27T16:00:00+00:00",
    "modified": "2021-07-28T20:45:04+00:00",
    "external_desc": "Global: Cloud Scheduler Pub/Sub jobs fail with permission denied",
    "updates": [
      {
        "created": "2021-07-28T20:45:04+00:00",
        "modified": "2021-07-28T20:45:04+00:00",
        "when": "2021-07-28T20:45:04+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident here: https://status.cloud.google.com/incidents/fEXXEicMtx5SaVZz2Gt7.\nPlease note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-27T16:00:01+00:00",
        "modified": "2021-07-27T16:05:13+00:00",
        "when": "2021-07-27T16:00:01+00:00",
        "text": "The issue with Cloud Scheduler has been resolved for some projects as of Tuesday, 2021-07-27 08:59 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-27T15:56:01+00:00",
        "modified": "2021-07-27T15:56:07+00:00",
        "when": "2021-07-27T15:56:01+00:00",
        "text": "Summary: Global: Cloud Scheduler Pub/Sub jobs fail with permission denied\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2021-07-27 09:37 US/Pacific.\nDiagnosis: Receiving Cloud Scheduler PERMISSION_DENIED\nWorkaround: Add publisher role to Cloud Scheduler service account. The service account has the form service-PROJECT_NUMBER@gcp-sa-cloudscheduler.iam.gserviceaccount.com",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T15:29:34+00:00",
        "modified": "2021-07-27T15:29:37+00:00",
        "when": "2021-07-27T15:29:34+00:00",
        "text": "Summary: Some Cloud Scheduler Pub/Sub jobs fail with permission denied\nDescription: We are experiencing an issue with Cloud Scheduler\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-07-27 09:00 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-07-28T20:45:04+00:00",
      "modified": "2021-07-28T20:45:04+00:00",
      "when": "2021-07-28T20:45:04+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident here: https://status.cloud.google.com/incidents/fEXXEicMtx5SaVZz2Gt7.\nPlease note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "Y9fKAQ6BVTQUYomrNN9A",
    "service_name": "Google Cloud Scheduler",
    "affected_products": [
      {
        "title": "Google Cloud Scheduler",
        "id": "Y9fKAQ6BVTQUYomrNN9A"
      }
    ],
    "uri": "incidents/eJ8bnwiB1kQXo8fet4Zg"
  },
  {
    "id": "FB2c3B9EAS7JA1mHgth1",
    "number": "15430518859596137620",
    "begin": "2021-07-27T12:50:34+00:00",
    "created": "2021-07-27T12:50:45+00:00",
    "end": "2021-07-27T12:54:57+00:00",
    "modified": "2021-07-27T12:54:58+00:00",
    "external_desc": "HTTP load balancing returning error for some user in Europe.",
    "updates": [
      {
        "created": "2021-07-27T12:54:50+00:00",
        "modified": "2021-07-27T12:54:57+00:00",
        "when": "2021-07-27T12:54:50+00:00",
        "text": "The issue with Cloud Load Balancing has been resolved for all affected users as of Tuesday, 2021-07-27 05:33 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-27T12:50:37+00:00",
        "modified": "2021-07-27T12:50:46+00:00",
        "when": "2021-07-27T12:50:37+00:00",
        "text": "Summary: HTTP load balancing returning error for some user in Europe.\nDescription: We are experiencing an issue with Cloud Load Balancing beginning at Tuesday, 2021-07-27 04:31 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-07-27 06:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-07-27T12:54:50+00:00",
      "modified": "2021-07-27T12:54:57+00:00",
      "when": "2021-07-27T12:54:50+00:00",
      "text": "The issue with Cloud Load Balancing has been resolved for all affected users as of Tuesday, 2021-07-27 05:33 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/FB2c3B9EAS7JA1mHgth1"
  },
  {
    "id": "UPG5wxRnLGjqqVFMW7Kq",
    "number": "17548538680718969456",
    "begin": "2021-07-27T11:15:00+00:00",
    "created": "2021-07-27T14:51:10+00:00",
    "end": "2021-07-28T04:05:00+00:00",
    "modified": "2021-07-29T00:32:15+00:00",
    "external_desc": "Issue resolved: HTTP load balancing returning error for some users in Europe.",
    "updates": [
      {
        "created": "2021-07-28T15:12:57+00:00",
        "modified": "2021-07-29T00:32:15+00:00",
        "when": "2021-07-28T15:12:57+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Timeline:**\n27 June 2021 04:15 - 05:33\n27 June 2021 06:56 - 07:41\n**Total Duration:**\n2 hours 3 minutes\n**Affected Services and Features:**\nGoogle Cloud Load Balancing\n**Regions/Zones:**\nWestern Europe\n**Description:**\nGoogle Cloud Load Balancing (GCLB) experienced increased TLS handshake errors or connection terminations for HTTPS traffic served from load balancers in Western Europe for a duration of 2 hours, 3 minutes. From preliminary analysis, the root cause of the issue is a configuration change that resulted in an overload of an internal component responsible for handling part of the traffic requests.\n**Customer Impact:**\nIncreased TLS handshake errors or connection terminations for GCLB traffic served from HTTPS load balancers in Western Europe.\n**Additional details:**\nThe issue was fully resolved on 27 June 2021 21:05 US/Pacific, and we are confident that there will not be a recurrence.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-28T04:05:23+00:00",
        "modified": "2021-07-28T04:05:24+00:00",
        "when": "2021-07-28T04:05:23+00:00",
        "text": "The issue with HTTP load balancing has been resolved for all affected users in Europe as of Tuesday, 2021-07-27 19:02 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-27T16:27:14+00:00",
        "modified": "2021-07-27T16:27:14+00:00",
        "when": "2021-07-27T16:27:14+00:00",
        "text": "Summary: HTTP load balancing returning error for some user in Europe.\nDescription: We believe the issue with Cloud Networking is resolved and there is no further impact.\nEngineering team has mitigated the current impact and expect the full resolution to be rolled out within next 12 hours.\nWe will provide an update by Tuesday, 2021-07-27 21:30 US/Pacific with current details.\nDiagnosis: None at this time\nWorkaround: None at this time",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T15:24:44+00:00",
        "modified": "2021-07-27T15:24:45+00:00",
        "when": "2021-07-27T15:24:44+00:00",
        "text": "Summary: HTTP load balancing returning error for some user in Europe.\nDescription: We believe the issue with Cloud Networking is resolved.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-07-27 15:30 US/Pacific with current details.\nDiagnosis: none at this time\nWorkaround: none at this time",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T15:22:20+00:00",
        "modified": "2021-07-27T15:22:21+00:00",
        "when": "2021-07-27T15:22:20+00:00",
        "text": "Summary: HTTP load balancing returning error for some user in Europe.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2021-07-27 09:57 US/Pacific.\nDiagnosis: none at this time\nWorkaround: none at this time",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T14:51:08+00:00",
        "modified": "2021-07-27T14:51:11+00:00",
        "when": "2021-07-27T14:51:08+00:00",
        "text": "Summary: HTTP load balancing returning error for some user in Europe.\nDescription: We are experiencing an intermittent issue with Cloud Networking beginning at Tuesday, 2021-07-27 06:56:46 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-07-27 08:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: none at this time\nWorkaround: none at this time",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-07-28T15:12:57+00:00",
      "modified": "2021-07-29T00:32:15+00:00",
      "when": "2021-07-28T15:12:57+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Timeline:**\n27 June 2021 04:15 - 05:33\n27 June 2021 06:56 - 07:41\n**Total Duration:**\n2 hours 3 minutes\n**Affected Services and Features:**\nGoogle Cloud Load Balancing\n**Regions/Zones:**\nWestern Europe\n**Description:**\nGoogle Cloud Load Balancing (GCLB) experienced increased TLS handshake errors or connection terminations for HTTPS traffic served from load balancers in Western Europe for a duration of 2 hours, 3 minutes. From preliminary analysis, the root cause of the issue is a configuration change that resulted in an overload of an internal component responsible for handling part of the traffic requests.\n**Customer Impact:**\nIncreased TLS handshake errors or connection terminations for GCLB traffic served from HTTPS load balancers in Western Europe.\n**Additional details:**\nThe issue was fully resolved on 27 June 2021 21:05 US/Pacific, and we are confident that there will not be a recurrence.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/UPG5wxRnLGjqqVFMW7Kq"
  },
  {
    "id": "fEXXEicMtx5SaVZz2Gt7",
    "number": "8304108178110052490",
    "begin": "2021-07-22T02:22:00+00:00",
    "created": "2021-07-27T16:10:36+00:00",
    "end": "2021-07-27T22:28:00+00:00",
    "modified": "2021-07-29T00:29:58+00:00",
    "external_desc": "Global: Cloud Scheduler Pub/Sub jobs fail with permission denied",
    "updates": [
      {
        "created": "2021-07-28T20:32:51+00:00",
        "modified": "2021-07-29T00:29:58+00:00",
        "when": "2021-07-28T20:32:51+00:00",
        "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 21 July 2021 19:22\n**Incident End:** 27 July 2021 15:28\n**Duration:** 5 days, 20 hours, 6 minutes\n**Affected Services and Features:**\nGoogle Cloud Scheduler Pub/Sub\n**Regions/Zones:** All Regions\n**Description:**\nGoogle Cloud Scheduler jobs experienced increased errors globally when publishing messages to Pub/Sub topics for a duration of 5 days, 20 hours, 6 minutes. From preliminary analysis, the root cause of the issue is due to a configuration change that updated the service agent used when publishing to Pub/Sub. Projects using the new service agent without the correct permissions resulted in PERMISSION_DENIED errors for tasks that required publishing to Pub/Sub.\n**Customer Impact:**\nAll customers with Cloud Scheduler jobs with a Pub/Sub topic as a target that did not grant the Cloud Scheduler Google-managed service account access to that Pub/Sub topic saw PERMISSION_DENIED errors.\n**Additional details:**\nThe issue was fully resolved on 27 July 2021 at 15:28 US/Pacific after a rollback of the change was completed.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-27T22:46:11+00:00",
        "modified": "2021-07-27T22:46:11+00:00",
        "when": "2021-07-27T22:46:11+00:00",
        "text": "The issue with Cloud Scheduler has been resolved for all affected projects as of Tuesday, 2021-07-27 15:43 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-27T22:23:54+00:00",
        "modified": "2021-07-27T22:23:55+00:00",
        "when": "2021-07-27T22:23:54+00:00",
        "text": "Summary: Global: Cloud Scheduler Pub/Sub jobs fail with permission denied\nDescription: We believe the issue with Cloud Scheduler is partially resolved.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-07-27 16:01 US/Pacific with current details.\nDiagnosis: Receiving Cloud Scheduler PERMISSION_DENIED\nWorkaround: Add the permission pubsub.topics.publish to Cloud Scheduler service account (service-PROJECT_NUMBER@gcp-sa-cloudscheduler.iam.gserviceaccount.com).",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T20:20:24+00:00",
        "modified": "2021-07-27T20:20:24+00:00",
        "when": "2021-07-27T20:20:24+00:00",
        "text": "Summary: Global: Cloud Scheduler Pub/Sub jobs fail with permission denied\nDescription: We believe the issue with Cloud Scheduler is partially resolved and there is no further impact observed.\nAction:\n- Customers should utilize the Cloud Services Robot account for authentication.\nWe will provide an update by Tuesday, 2021-07-27 15:30 US/Pacific with current details.\nDiagnosis: Receiving Cloud Scheduler PERMISSION_DENIED\nWorkaround: Add the permission pubsub.topics.publish to Cloud Scheduler service account (service-PROJECT_NUMBER@gcp-sa-cloudscheduler.iam.gserviceaccount.com).",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T19:28:06+00:00",
        "modified": "2021-07-27T19:28:06+00:00",
        "when": "2021-07-27T19:28:06+00:00",
        "text": "Summary: Global: Cloud Scheduler Pub/Sub jobs fail with permission denied\nDescription: We believe the issue with Cloud Scheduler is partially resolved and there is no further impact observed.\nAction:\n- Customers should utilize the Cloud Services Robot account for authentication.\nWe will provide an update by Tuesday, 2021-07-27 13:30 US/Pacific with current details.\nDiagnosis: Receiving Cloud Scheduler PERMISSION_DENIED\nWorkaround: Add the permission pubsub.topics.publish to Cloud Scheduler service account (service-PROJECT_NUMBER@gcp-sa-cloudscheduler.iam.gserviceaccount.com).",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T18:03:31+00:00",
        "modified": "2021-07-27T18:03:31+00:00",
        "when": "2021-07-27T18:03:31+00:00",
        "text": "Summary: Global: Cloud Scheduler Pub/Sub jobs fail with permission denied\nDescription: Mitigation work is still underway by our engineering team.\nThe rollback activity is currently 50% complete and ongoing.\nWe will provide more information by Tuesday, 2021-07-27 13:00 US/Pacific.\nDiagnosis: Receiving Cloud Scheduler PERMISSION_DENIED\nWorkaround: Add publisher role to Cloud Scheduler service account. The service account has the form service-PROJECT_NUMBER@gcp-sa-cloudscheduler.iam.gserviceaccount.com",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-07-27T16:10:35+00:00",
        "modified": "2021-07-27T16:10:37+00:00",
        "when": "2021-07-27T16:10:35+00:00",
        "text": "Summary: Global: Cloud Scheduler Pub/Sub jobs fail with permission denied\nDescription: This is a continuation of the previous post for incident \"Global: Cloud Scheduler Pub/Sub jobs fail with permission denied\" that was closed as resolved.\nWe have received updates from our engineering team that the Mitigation work is still underway for some regions and are currently waiting for an ETA.\nWe will provide more information by Tuesday, 2021-07-27 11:00 US/Pacific.\nDiagnosis: Receiving Cloud Scheduler PERMISSION_DENIED\nWorkaround: Add publisher role to Cloud Scheduler service account. The service account has the form service-PROJECT_NUMBER@gcp-sa-cloudscheduler.iam.gserviceaccount.com",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-07-28T20:32:51+00:00",
      "modified": "2021-07-29T00:29:58+00:00",
      "when": "2021-07-28T20:32:51+00:00",
      "text": "We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 21 July 2021 19:22\n**Incident End:** 27 July 2021 15:28\n**Duration:** 5 days, 20 hours, 6 minutes\n**Affected Services and Features:**\nGoogle Cloud Scheduler Pub/Sub\n**Regions/Zones:** All Regions\n**Description:**\nGoogle Cloud Scheduler jobs experienced increased errors globally when publishing messages to Pub/Sub topics for a duration of 5 days, 20 hours, 6 minutes. From preliminary analysis, the root cause of the issue is due to a configuration change that updated the service agent used when publishing to Pub/Sub. Projects using the new service agent without the correct permissions resulted in PERMISSION_DENIED errors for tasks that required publishing to Pub/Sub.\n**Customer Impact:**\nAll customers with Cloud Scheduler jobs with a Pub/Sub topic as a target that did not grant the Cloud Scheduler Google-managed service account access to that Pub/Sub topic saw PERMISSION_DENIED errors.\n**Additional details:**\nThe issue was fully resolved on 27 July 2021 at 15:28 US/Pacific after a rollback of the change was completed.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "Y9fKAQ6BVTQUYomrNN9A",
    "service_name": "Google Cloud Scheduler",
    "affected_products": [
      {
        "title": "Google Cloud Scheduler",
        "id": "Y9fKAQ6BVTQUYomrNN9A"
      }
    ],
    "uri": "incidents/fEXXEicMtx5SaVZz2Gt7"
  },
  {
    "id": "WXwFb7tx1XvHyGaxwdYs",
    "number": "14920841997106925105",
    "begin": "2021-07-07T21:25:00+00:00",
    "created": "2021-07-07T22:45:04+00:00",
    "end": "2021-07-07T23:40:00+00:00",
    "modified": "2021-07-16T22:59:00+00:00",
    "external_desc": "Increased latency in North America Regions for Cloud Datastore queries. Previous posts mention Google Cloud Firestore, upon further analysis we believe this is incorrect. We have moved the incident to Cloud Datastore to correctly reflect impact.",
    "updates": [
      {
        "created": "2021-07-08T20:29:10+00:00",
        "modified": "2021-07-16T22:59:00+00:00",
        "when": "2021-07-08T20:29:10+00:00",
        "text": "Mini Incident Report\n(All Times US/Pacific)\n**Incident Start:** 07 July 2021 14:25\n**Incident End:** 07 July 2021 16:40\n**Duration:** 2 hours, 15 minutes\n**Affected Services and Features:**\nGoogle Cloud Datastore\n**Regions/Zones:** NAM5 Multi-Region\n**Description:**\nGoogle Cloud Datastore queries experienced increased latency for a period of 2 hours and 15 minutes due to an unexpected spike in traffic.\n**Customer Impact:**\nAffected customers would have experienced increased latency when querying or writing to Cloud Datastore.\n**Additional details:**\nGoogle has addressed future unexpected traffic spikes of this nature by increasing Datastore capacity.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-07T23:58:17+00:00",
        "modified": "2021-07-07T23:58:17+00:00",
        "when": "2021-07-07T23:58:17+00:00",
        "text": "The issue with Cloud Firestore has been resolved for all affected projects as of Wednesday, 2021-07-07 16:40 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-07-07T23:28:51+00:00",
        "modified": "2021-07-07T23:28:51+00:00",
        "when": "2021-07-07T23:28:51+00:00",
        "text": "Summary: Increased latency in North America Regions for Cloud Firestore queries\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2021-07-07 17:30 US/Pacific.\nDiagnosis: Impacted customers may see increased latency when querying or writing to Cloud Firestore.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-07-07T22:52:54+00:00",
        "modified": "2021-07-07T22:52:54+00:00",
        "when": "2021-07-07T22:52:54+00:00",
        "text": "Summary: Increased latency in North America Regions for Cloud Firestore queries\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2021-07-07 16:30 US/Pacific.\nDiagnosis: Impacted customers may see increased latency when querying or writing to Cloud Firestore.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-07-07T22:45:03+00:00",
        "modified": "2021-07-07T22:45:04+00:00",
        "when": "2021-07-07T22:45:03+00:00",
        "text": "Summary: Increased latency in North America Regions for Cloud Firestore queries\nDescription: We are experiencing an issue with Cloud Firestore beginning at Wednesday, 2021-07-07 14:25 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-07-07 16:30 US/Pacific with current details. We apologize to all who are affected by the disruption.\nDiagnosis: Impacted customers may see increased latency when querying or writing to Cloud Firestore.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-07-08T20:29:10+00:00",
      "modified": "2021-07-16T22:59:00+00:00",
      "when": "2021-07-08T20:29:10+00:00",
      "text": "Mini Incident Report\n(All Times US/Pacific)\n**Incident Start:** 07 July 2021 14:25\n**Incident End:** 07 July 2021 16:40\n**Duration:** 2 hours, 15 minutes\n**Affected Services and Features:**\nGoogle Cloud Datastore\n**Regions/Zones:** NAM5 Multi-Region\n**Description:**\nGoogle Cloud Datastore queries experienced increased latency for a period of 2 hours and 15 minutes due to an unexpected spike in traffic.\n**Customer Impact:**\nAffected customers would have experienced increased latency when querying or writing to Cloud Datastore.\n**Additional details:**\nGoogle has addressed future unexpected traffic spikes of this nature by increasing Datastore capacity.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_OUTAGE",
    "severity": "high",
    "service_key": "MaS3dKoqp1oqkea4qB9U",
    "service_name": "Google Cloud Datastore",
    "affected_products": [
      {
        "title": "Google Cloud Datastore",
        "id": "MaS3dKoqp1oqkea4qB9U"
      }
    ],
    "uri": "incidents/WXwFb7tx1XvHyGaxwdYs"
  },
  {
    "id": "bqmX2EZrwgkPwZxutSk6",
    "number": "7467022363546712602",
    "begin": "2021-06-23T02:38:00+00:00",
    "created": "2021-06-23T03:45:31+00:00",
    "end": "2021-06-23T03:51:00+00:00",
    "modified": "2021-06-23T21:41:47+00:00",
    "external_desc": "High latency and increased error rates in northamerica multi-region.",
    "updates": [
      {
        "created": "2021-06-23T21:40:42+00:00",
        "modified": "2021-06-23T21:41:47+00:00",
        "when": "2021-06-23T21:40:42+00:00",
        "text": "**Incident Start:** 22 June 2021 19:38\n**Incident End:** 22 June 2021 20:51\n**Duration:** 1 hours, 13 minutes\n**Affected Services and Features:**\nGoogle Cloud Firestore\n**Regions/Zones:** nam5 multi-region\n**Description:**\nGoogle Cloud Firestore experienced elevated latency and error rates on up top 50% of projects in the nam5 multi-region for a duration of 1 hour and 13 minutes. The root cause of the issue was a traffic spike from an internal daily batch job which performs quota adjustments. This caused lock contention on the backend databases which, in conjunction with poor traffic distribution and misdirected traffic, ultimately overloaded the service.\n**Customer Impact:**\n- Affected customers may see “Deadline Exceeded” errors and degraded performance.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-06-23T04:53:55+00:00",
        "modified": "2021-06-23T04:53:55+00:00",
        "when": "2021-06-23T04:53:55+00:00",
        "text": "The issue with Cloud Firestore has been resolved for all affected users as of Tuesday, 2021-06-22 21:53 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-06-23T04:26:27+00:00",
        "modified": "2021-06-23T04:26:31+00:00",
        "when": "2021-06-23T04:26:27+00:00",
        "text": "Summary: High latency and increased error rates in northamerica multi-region.\nDescription: We are experiencing an intermittent issue with Cloud Firestore beginning at Tuesday, 2021-06-22 19:38 US/Pacific.\nAt the moment we see performance improvements and error rate is back to its original state.\nOur engineering team continues to monitor the situation.\nWe will provide an update by Tuesday, 2021-06-22 22:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers might see 'Deadline Exceeded' errors and degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-23T03:45:30+00:00",
        "modified": "2021-06-23T03:45:31+00:00",
        "when": "2021-06-23T03:45:30+00:00",
        "text": "Summary: High latency and increased error rates in northamerica multi-region.\nDescription: We are experiencing an intermittent issue with Cloud Firestore beginning at Tuesday, 2021-06-22 19:38 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-06-22 21:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers might see 'Deadline Exceeded' errors and degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-06-23T21:40:42+00:00",
      "modified": "2021-06-23T21:41:47+00:00",
      "when": "2021-06-23T21:40:42+00:00",
      "text": "**Incident Start:** 22 June 2021 19:38\n**Incident End:** 22 June 2021 20:51\n**Duration:** 1 hours, 13 minutes\n**Affected Services and Features:**\nGoogle Cloud Firestore\n**Regions/Zones:** nam5 multi-region\n**Description:**\nGoogle Cloud Firestore experienced elevated latency and error rates on up top 50% of projects in the nam5 multi-region for a duration of 1 hour and 13 minutes. The root cause of the issue was a traffic spike from an internal daily batch job which performs quota adjustments. This caused lock contention on the backend databases which, in conjunction with poor traffic distribution and misdirected traffic, ultimately overloaded the service.\n**Customer Impact:**\n- Affected customers may see “Deadline Exceeded” errors and degraded performance.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "CETSkT92V21G6A1x28me",
    "service_name": "Cloud Firestore",
    "affected_products": [
      {
        "title": "Cloud Firestore",
        "id": "CETSkT92V21G6A1x28me"
      }
    ],
    "uri": "incidents/bqmX2EZrwgkPwZxutSk6"
  },
  {
    "id": "N6EJou2rCwoEt8nowd2o",
    "number": "10748825742161305679",
    "begin": "2021-06-21T19:21:00+00:00",
    "created": "2021-06-22T03:26:34+00:00",
    "end": "2021-06-22T04:55:00+00:00",
    "modified": "2021-06-23T15:04:44+00:00",
    "external_desc": "We are experiencing an issue with Cloud Monitoring beginning at Monday, 2021-06-21 00:00 US/Pacific.",
    "updates": [
      {
        "created": "2021-06-22T22:02:10+00:00",
        "modified": "2021-06-23T15:04:44+00:00",
        "when": "2021-06-22T22:02:10+00:00",
        "text": "**Incident Start:** 21 June 2021 12:01\n**Incident End:** 21 June 2021 21:55\n**Duration:** 9 hours, 54 minutes\n**Affected Services and Features:**\nGoogle Cloud Monitoring, Cloud EKM\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Monitoring experienced intermittent API errors with a gradually increasing error rate on a limited set of internal endpoints for 9 hours and 54 minutes. The Cloud Monitoring section in the Cloud Console experienced intermittent errors when loading pages due to the underlying API errors. This included the following pages; Monitoring Homepage, Dashboard Builder, GKE Dashboard, Metrics Explorer, Network Topology, Uptime Checks Service. Additionally, attempting to create the first Cloud EKM key [1] in a project would fail during this period. If a project already has (or at some point had) Cloud EKM keys, they can continue to create keys in those projects and use them. The root cause of the issue is suspected to be the rollout of a permission change which incorrectly restricted access to the underlying database which stores metadata information about the affected APIs.\n**Customer Impact:**\n- Cloud Console errors on up to 10% of the listed page loads or equivalent API’s.\n**Additional details:**\n- Workaround: Retrying failed requests with exponential backoff returned successful results for some customers.\n- Workaround: Before attempting to create the first Cloud EKM key, running gcloud beta services identity create --service=cloudkms.googleapis.com --project $KEY_PROJECT_ID” prevented the failure.\n**Reference(s):**\n[1] https://cloud.google.com/service-usage/docs/reference/rest/v1beta1/services/generateServiceIdentity",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-06-22T04:46:17+00:00",
        "modified": "2021-06-22T04:46:17+00:00",
        "when": "2021-06-22T04:46:17+00:00",
        "text": "The issue with Cloud Monitoring has been resolved for all affected projects as of Monday, 2021-06-21 21:46 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-06-22T04:29:01+00:00",
        "modified": "2021-06-22T04:29:01+00:00",
        "when": "2021-06-22T04:29:01+00:00",
        "text": "Summary: We are experiencing an issue with Cloud Monitoring beginning at Monday, 2021-06-21 00:00 US/Pacific.\nDescription: We are experiencing an issue with Cloud Monitoring beginning at Monday, 2021-06-21 00:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-06-21 23:00 US/Pacific with current details.\nDiagnosis: You should be able to see an API error about \"method not available\" in the Network Tab in your browser's developer console.\nWorkaround: Trying to refresh or re-issue the query might help.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T03:26:32+00:00",
        "modified": "2021-06-22T03:26:34+00:00",
        "when": "2021-06-22T03:26:32+00:00",
        "text": "Summary: We are experiencing an issue with Cloud Monitoring beginning at Monday, 2021-06-21 00:00 US/Pacific.\nDescription: We are experiencing an issue with Cloud Monitoring beginning at Monday, 2021-06-21 00:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-06-21 21:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: You should be able to see an API error about \"method not available\" in the Network Tab in your browser's developer console.\nWorkaround: Trying to refresh or re-issue the query might help.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-06-22T22:02:10+00:00",
      "modified": "2021-06-23T15:04:44+00:00",
      "when": "2021-06-22T22:02:10+00:00",
      "text": "**Incident Start:** 21 June 2021 12:01\n**Incident End:** 21 June 2021 21:55\n**Duration:** 9 hours, 54 minutes\n**Affected Services and Features:**\nGoogle Cloud Monitoring, Cloud EKM\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Monitoring experienced intermittent API errors with a gradually increasing error rate on a limited set of internal endpoints for 9 hours and 54 minutes. The Cloud Monitoring section in the Cloud Console experienced intermittent errors when loading pages due to the underlying API errors. This included the following pages; Monitoring Homepage, Dashboard Builder, GKE Dashboard, Metrics Explorer, Network Topology, Uptime Checks Service. Additionally, attempting to create the first Cloud EKM key [1] in a project would fail during this period. If a project already has (or at some point had) Cloud EKM keys, they can continue to create keys in those projects and use them. The root cause of the issue is suspected to be the rollout of a permission change which incorrectly restricted access to the underlying database which stores metadata information about the affected APIs.\n**Customer Impact:**\n- Cloud Console errors on up to 10% of the listed page loads or equivalent API’s.\n**Additional details:**\n- Workaround: Retrying failed requests with exponential backoff returned successful results for some customers.\n- Workaround: Before attempting to create the first Cloud EKM key, running gcloud beta services identity create --service=cloudkms.googleapis.com --project $KEY_PROJECT_ID” prevented the failure.\n**Reference(s):**\n[1] https://cloud.google.com/service-usage/docs/reference/rest/v1beta1/services/generateServiceIdentity",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/N6EJou2rCwoEt8nowd2o"
  },
  {
    "id": "YtfZu9rttTf5zDYGe57n",
    "number": "11674600762170121866",
    "begin": "2021-06-20T06:00:00+00:00",
    "created": "2021-06-21T23:32:25+00:00",
    "end": "2021-06-23T16:06:00+00:00",
    "modified": "2021-06-24T18:16:34+00:00",
    "external_desc": "Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc, and Apigee X in those same regions",
    "updates": [
      {
        "created": "2021-06-24T18:10:58+00:00",
        "modified": "2021-06-24T18:16:34+00:00",
        "when": "2021-06-24T18:10:58+00:00",
        "text": "(All Times US/Pacific)\n**Incident Start:** 19 June 2021 23:00\n**Incident End:** 23 June 2021 09:06\n**Duration:** 3 days, 10 hours, 6 minutes\n**Affected Services and Features:**\n* Google Compute Engine (GCE) - New Virtual Machine (VM) creations using PD SSD.\n* Google Kubernetes Engine (GKE) - New cluster creations, node pools creation, scaling GKE node pools\n* Cloud Composer - Composer environment creations\n* Cloud SQL - Cluster creations\n* Dataproc - Cluster creations\n* Dataflow - Job creations\n* Cloud Build - Builds using custom size VMs or workerpools\n* Persistent Disk (PD) - New PD-SSD device creation\n**Regions/Zones:** us-east1-{a,b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a\n**Description:**\nMultiple Google Cloud services experienced intermittent problems with creating new Persistent Disk Solid-State Drive (PD-SSD) devices. This issue impacted creation of resources that depend on PD-SSD. The root cause of the issue was an unexpected increase in utilization of PD-SSD, which led to unavailability of SSD capacity for some users in the impacted zones.\n**Customer Impact:**\n* Google Compute Engine (GCE) : * Issues with new VM creations as boot disk creations failed. * Auto-scaling of VMs was impacted due to failure with new VM creations. * Intermittent reduction in write throughput. * Issues with expanding SSD-backed device sizes.\n* Cloud Composer: * Failed Cloud Composer environment creations.\n* Cloud SQL: * Intermittent create operation failures. * PD-SSD disk size increases failures.\n* Cloud Build: * Cloud Builds using custom size VMs or using workerpools experienced failures.\n* Google Kubernetes Engine: * Intermittent issues with cluster creation. * Intermittent issues with creation and scaling of node pools with PD-SSD nodes.\n* Dataproc/Dataflow: * Dataproc cluster creation and Dataflow jobs may have failed due to underlying errors regarding disk creation failures.\n**Additional details:**\nTo prevent unexpected spike in utilization from impacting PD-SSD capacity availability, the following actions and safety measures were implemented:\n* Engineering team has identified and throttled the source of the unexpected spike in PD-SSD utilization.\n* Additional SSD capacity added for higher tolerance to spikes in utilization.\n* Increased rebalancing to make additional SSD capacity available.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-06-24T00:06:43+00:00",
        "modified": "2021-06-24T00:06:44+00:00",
        "when": "2021-06-24T00:06:43+00:00",
        "text": "This issue has been fully mitigated by our product team. For any ongoing issues, please open a Support case for further troubleshooting.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-06-23T17:18:44+00:00",
        "modified": "2021-06-23T17:18:45+00:00",
        "when": "2021-06-23T17:18:44+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc, and Apigee X in those same regions\nDescription: The issue with creating SSD PDs is now mitigated in all affected zones for all affected customers.\nWe are currently monitoring the environment performance and will provide a final status update by Wednesday, 2021-06-23 17:00 US/Pacific.\nDiagnosis: Affected users might be unable to create new VMs in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Compute Engine, such as Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc and Apigee X in those regions.\nWorkaround: Customers may attempt to create resources in unaffected zones or regions.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-23T10:59:29+00:00",
        "modified": "2021-06-23T10:59:30+00:00",
        "when": "2021-06-23T10:59:29+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc, and Apigee X in those same regions\nDescription: The issue with creating SSD PDs is now mitigated in all affected zones for most affected customers. Some customers are still unable to create VMs in affected zones.\nWe are still working to fully mitigate this issue for all customers, and estimate this to be complete around Wednesday, 2021-06-23 12:00 US/Pacific.\nWe will provide more information by Wednesday, 2021-06-23 13:00 US/Pacific.\nDiagnosis: Affected users might be unable to create new VMs in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Compute Engine, such as Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc and Apigee X in those regions.\nWorkaround: Customers may attempt to create resources in unaffected zones or regions.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-23T09:30:21+00:00",
        "modified": "2021-06-23T09:30:23+00:00",
        "when": "2021-06-23T09:30:21+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc, and Apigee X in those same regions\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-{b,c}. In those zone the issue is resolved for the most of customers and we are still working to mitigate the rest of the impact, ETA for full resolution is for by end of day 2021-06-23 US/Pacific hours.\nWe will provide more information by Wednesday, 2021-06-23 04:00 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,}. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc, and Apigee X in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-23T06:25:21+00:00",
        "modified": "2021-06-23T06:25:21+00:00",
        "when": "2021-06-23T06:25:21+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc, and Apigee X in those same regions\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-{b,c}. In those zone the issue is resolved for the most of customers and we are still working to mitigate the rest of the impact, ETA for full resolution is for by end of day 2021-06-23 US/Pacific hours.\nWe will provide more information by Wednesday, 2021-06-23 02:30 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,}. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc, and Apigee X in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-23T03:27:29+00:00",
        "modified": "2021-06-23T03:27:29+00:00",
        "when": "2021-06-23T03:27:29+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc, and Apigee X in those same regions\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-{b,c}. We are still working to mitigate impact in these two remaining zones, ETA by end of day 2021-06-22 US/Pacific hours.\nWe will provide more information by Tuesday, 2021-06-22 23:30 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,}. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc, and Apigee X in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-23T00:43:46+00:00",
        "modified": "2021-06-23T00:43:46+00:00",
        "when": "2021-06-23T00:43:46+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc, and Apigee X in those same regions\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-{b,c}. We are still working to mitigate impact in these two remaining zones, ETA by end of day 2021-06-22 US/Pacific hours.\nWe will provide more information by Tuesday, 2021-06-22 20:30 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,}. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL, Cloud Dataproc, and Apigee X in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-23T00:26:34+00:00",
        "modified": "2021-06-23T00:26:34+00:00",
        "when": "2021-06-23T00:26:34+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-{b,c}. We are still working to mitigate impact in these two remaining zones, ETA by end of day 2021-06-22 US/Pacific hours.\nWe will provide more information by Tuesday, 2021-06-22 20:30 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,}. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T23:01:08+00:00",
        "modified": "2021-06-22T23:01:08+00:00",
        "when": "2021-06-22T23:01:08+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-{b,c}. We are still working to mitigate impact in these two remaining zones, ETA by end of day 2021-06-22 US/Pacific hours.\nWe will provide more information by Tuesday, 2021-06-22 17:30 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,}. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T22:57:39+00:00",
        "modified": "2021-06-22T22:57:39+00:00",
        "when": "2021-06-22T22:57:39+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-{b,c}. We are still working to mitigate impact in these two remaining zones, ETA by end of day 2021-06-22 US/Pacific hours.\nWe will provide more information by Tuesday, 2021-06-22 17:30 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T21:57:25+00:00",
        "modified": "2021-06-22T21:57:26+00:00",
        "when": "2021-06-22T21:57:25+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-{b,c}, us-east4-a. We are still working to mitigate impact in these three remaining zones, ETA by end of day 2021-06-22 US/Pacific hours.\nWe will provide more information by Tuesday, 2021-06-22 16:00 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T19:57:24+00:00",
        "modified": "2021-06-22T19:57:24+00:00",
        "when": "2021-06-22T19:57:24+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-{b,c}, us-east4-a. We are still working to mitigate impact in these three remaining zones, ETA by end of day 2021-06-22 US/Pacific hours.\nWe will provide more information by Tuesday, 2021-06-22 15:00 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T17:57:41+00:00",
        "modified": "2021-06-22T17:57:41+00:00",
        "when": "2021-06-22T17:57:41+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-{b,c}, us-east4-a. We are still working to mitigate impact in these three remaining zones, ETA by end of day 2021-06-22 US/Pacific hours.\nWe will provide more information by Tuesday, 2021-06-22 13:00 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T15:59:27+00:00",
        "modified": "2021-06-22T15:59:27+00:00",
        "when": "2021-06-22T15:59:27+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-{b,c}, us-east4-a. We are still working to mitigate impact in these three remaining zones.\nWe will provide more information by Tuesday, 2021-06-22 11:00 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T13:57:01+00:00",
        "modified": "2021-06-22T13:57:02+00:00",
        "when": "2021-06-22T13:57:01+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-b and us-east4-a. We are still working to mitigate impact in these two remaining zones.\nWe will provide more information by Tuesday, 2021-06-22 09:00 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T11:58:52+00:00",
        "modified": "2021-06-22T11:58:55+00:00",
        "when": "2021-06-22T11:58:52+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-b and us-east4-a. We are still working to mitigate impact in these two remaining zones.\nWe will provide more information by Tuesday, 2021-06-22 07:00 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T10:29:44+00:00",
        "modified": "2021-06-22T10:29:51+00:00",
        "when": "2021-06-22T10:29:44+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-b and us-east4-a. We are still working to mitigate impact in these two remaining zones.\nWe will provide more information by Tuesday, 2021-06-22 05:00 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T09:30:21+00:00",
        "modified": "2021-06-22T09:30:29+00:00",
        "when": "2021-06-22T09:30:21+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation is mitigated for all affected zones except us-east1-b and us-east4-a. We are still working to mitigate impact in these two remaining zones.\nWe will provide more information by Tuesday, 2021-06-22 03:30 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T08:30:56+00:00",
        "modified": "2021-06-22T08:31:03+00:00",
        "when": "2021-06-22T08:30:56+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: Mitigation work is still underway by our engineering team.\nPD creation should be working currently in us-east1-c and us-west1-c. We are working on mitigating impact in other affected zones.\nWe will provide more information by Tuesday, 2021-06-22 02:30 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T05:28:33+00:00",
        "modified": "2021-06-22T05:28:33+00:00",
        "when": "2021-06-22T05:28:33+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: A partial mitigation has been identified by the engineering team and is currently underway. We do not have an ETA for the partial mitigation at this point.\nWe will provide more information by Tuesday, 2021-06-22 01:30 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nAffected users may experience errors when attempting to create a new GKE Clusters or Node pools in us-east1.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.\nFor Users experiencing errors when attempting to create a new GKE Clusters or Node pools\n-Creating a node pool or cluster should be successful in other zones or regions may help.\n-Using Standard PDD or Local SSD should be successful.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T03:27:06+00:00",
        "modified": "2021-06-22T03:27:06+00:00",
        "when": "2021-06-22T03:27:06+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: A partial mitigation has been identified by the engineering team and is currently underway. We do not have an ETA for the partial mitigation at this point.\nWe will provide more information by Monday, 2021-06-21 22:30 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T02:00:39+00:00",
        "modified": "2021-06-22T02:00:39+00:00",
        "when": "2021-06-22T02:00:39+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: A partial mitigation has been identified by the engineering team and is currently underway. We do not have an ETA for the partial mitigation at this point.\nWe will provide more information by Monday, 2021-06-21 20:30 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-22T01:22:40+00:00",
        "modified": "2021-06-22T01:22:40+00:00",
        "when": "2021-06-22T01:22:40+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: A partial mitigation is identified by the engineering team and is currently underway. We do not have an ETA for the same at this point.\nWe will provide more information by Monday, 2021-06-21 20:00 US/Pacific.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-21T23:32:24+00:00",
        "modified": "2021-06-21T23:32:25+00:00",
        "when": "2021-06-21T23:32:24+00:00",
        "text": "Summary: Persistent Disk SSD creation is failing in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nDescription: We are still experiencing an issue with Google Compute Engine Persistent Disk SSD creation in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a beginning on Monday, 2021-06-20 20:00 US/Pacific. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-06-21 18:30 US/Pacific with current details.\nDiagnosis: Affected users might be unable to create new Persistent Disks (SSD) in us-east1-{b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a. This may impact creation of resources which depend on Persistent Disk SSD such as Google Compute Engine, Google Kubernetes Engine, Cloud Composer, Cloud SQL and Cloud Dataproc in those same regions.\nWorkaround: Standard Persistent Disks are not impacted, if workloads are not disk dependent, creating or scaling them with Standard PD may unblock workloads currently using PD backed by SSD. Creation of new Persistent Disks (SSD) in other regions are unaffected.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-06-24T18:10:58+00:00",
      "modified": "2021-06-24T18:16:34+00:00",
      "when": "2021-06-24T18:10:58+00:00",
      "text": "(All Times US/Pacific)\n**Incident Start:** 19 June 2021 23:00\n**Incident End:** 23 June 2021 09:06\n**Duration:** 3 days, 10 hours, 6 minutes\n**Affected Services and Features:**\n* Google Compute Engine (GCE) - New Virtual Machine (VM) creations using PD SSD.\n* Google Kubernetes Engine (GKE) - New cluster creations, node pools creation, scaling GKE node pools\n* Cloud Composer - Composer environment creations\n* Cloud SQL - Cluster creations\n* Dataproc - Cluster creations\n* Dataflow - Job creations\n* Cloud Build - Builds using custom size VMs or workerpools\n* Persistent Disk (PD) - New PD-SSD device creation\n**Regions/Zones:** us-east1-{a,b,c,d}, us-east4-{a,b}, us-west1-c and us-west4-a\n**Description:**\nMultiple Google Cloud services experienced intermittent problems with creating new Persistent Disk Solid-State Drive (PD-SSD) devices. This issue impacted creation of resources that depend on PD-SSD. The root cause of the issue was an unexpected increase in utilization of PD-SSD, which led to unavailability of SSD capacity for some users in the impacted zones.\n**Customer Impact:**\n* Google Compute Engine (GCE) : * Issues with new VM creations as boot disk creations failed. * Auto-scaling of VMs was impacted due to failure with new VM creations. * Intermittent reduction in write throughput. * Issues with expanding SSD-backed device sizes.\n* Cloud Composer: * Failed Cloud Composer environment creations.\n* Cloud SQL: * Intermittent create operation failures. * PD-SSD disk size increases failures.\n* Cloud Build: * Cloud Builds using custom size VMs or using workerpools experienced failures.\n* Google Kubernetes Engine: * Intermittent issues with cluster creation. * Intermittent issues with creation and scaling of node pools with PD-SSD nodes.\n* Dataproc/Dataflow: * Dataproc cluster creation and Dataflow jobs may have failed due to underlying errors regarding disk creation failures.\n**Additional details:**\nTo prevent unexpected spike in utilization from impacting PD-SSD capacity availability, the following actions and safety measures were implemented:\n* Engineering team has identified and throttled the source of the unexpected spike in PD-SSD utilization.\n* Additional SSD capacity added for higher tolerance to spikes in utilization.\n* Increased rebalancing to make additional SSD capacity available.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/YtfZu9rttTf5zDYGe57n"
  },
  {
    "id": "WiE4YhHnn4BQx5kveiUp",
    "number": "1599301179727112223",
    "begin": "2021-06-17T19:25:09+00:00",
    "created": "2021-06-17T19:25:10+00:00",
    "end": "2021-06-17T19:44:08+00:00",
    "modified": "2021-06-17T19:44:08+00:00",
    "external_desc": "Cloud Alerting users cannot receive notifications via Vespa, Webhook, Slack, or Pagerduty",
    "updates": [
      {
        "created": "2021-06-17T19:44:07+00:00",
        "modified": "2021-06-17T19:44:07+00:00",
        "when": "2021-06-17T19:44:07+00:00",
        "text": "The issue with Cloud Monitoring sending alerts via Vespa, Webhooks, Slack or Pagerduty\nhas been resolved for all affected users as of Thursday, 2021-06-17 12:43 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-06-17T19:25:10+00:00",
        "modified": "2021-06-17T19:25:10+00:00",
        "when": "2021-06-17T19:25:10+00:00",
        "text": "Summary: Cloud Alerting users cannot receive notifications via Vespa, Webhook, Slack, or Pagerduty\nDescription: We are experiencing an issue with Cloud Monitoring sending alerts via Vespa, Webhooks, Slack or Pagerduty.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-06-17 12:54 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: Notifications via email are working normally at this point.",
        "status": "SERVICE_OUTAGE"
      }
    ],
    "most_recent_update": {
      "created": "2021-06-17T19:44:07+00:00",
      "modified": "2021-06-17T19:44:07+00:00",
      "when": "2021-06-17T19:44:07+00:00",
      "text": "The issue with Cloud Monitoring sending alerts via Vespa, Webhooks, Slack or Pagerduty\nhas been resolved for all affected users as of Thursday, 2021-06-17 12:43 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_OUTAGE",
    "severity": "high",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/WiE4YhHnn4BQx5kveiUp"
  },
  {
    "id": "ysdpNCkMDUgpG41cxBSD",
    "number": "10141672634385226653",
    "begin": "2021-06-11T10:34:18+00:00",
    "created": "2021-06-11T10:34:23+00:00",
    "end": "2021-06-15T23:06:23+00:00",
    "modified": "2021-06-15T23:06:24+00:00",
    "external_desc": "Some BigQuery queries fail with RESOURCE_EXCEEDED errors",
    "updates": [
      {
        "created": "2021-06-15T23:06:23+00:00",
        "modified": "2021-06-15T23:06:23+00:00",
        "when": "2021-06-15T23:06:23+00:00",
        "text": "Upon further investigation, our engineering teams believe that the scope of the BigQuery issue is now limited to a small number of projects.\nIf you have questions or feel that you may be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. No further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-06-15T16:14:24+00:00",
        "modified": "2021-06-15T16:14:24+00:00",
        "when": "2021-06-15T16:14:24+00:00",
        "text": "Summary: Some BigQuery queries fail with RESOURCE_EXCEEDED errors\nDescription: We believe the issue with Google BigQuery is partially resolved. We are evaluating the projects impacted by this issue and performing mitigation as needed. We do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-06-15 16:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: No workarounds. Retries may eventually succeed as the issue seems to be intermittent",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-15T16:13:04+00:00",
        "modified": "2021-06-15T16:13:05+00:00",
        "when": "2021-06-15T16:13:04+00:00",
        "text": "Summary: Some BigQuery queries fail with RESOURCE_EXCEEDED errors\nDescription: We believe the issue with Google BigQuery is partially resolved. We are evaluating the projects impacted by this issue and performing mitigation as needed. We do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-06-15 16:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: No workarounds. Retries may eventually succeed as the issue seems to be intermittent",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-15T12:06:29+00:00",
        "modified": "2021-06-15T12:06:36+00:00",
        "when": "2021-06-15T12:06:29+00:00",
        "text": "Summary: Some BigQuery queries fail with RESOURCE_EXCEEDED errors\nDescription: We believe the issue with Google BigQuery is partially resolved. We are evaluating the projects impacted by this issue and performing mitigation as needed. We do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-06-15 10:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: No workarounds. Retries may eventually succeed as the issue seems to be intermittent",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-15T12:01:01+00:00",
        "modified": "2021-06-15T12:01:08+00:00",
        "when": "2021-06-15T12:01:01+00:00",
        "text": "Summary: Some BigQuery queries fail with RESOURCE_EXCEEDED errors\nDescription: We believe the issue with Google BigQuery is partially resolved. We are evaluating the projects impacted by this issue and performing mitigation as needed. We do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-06-15 10:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: No workarounds. Retries may eventually succeed as the issue seems to be intermittent",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-15T09:02:26+00:00",
        "modified": "2021-06-15T09:02:33+00:00",
        "when": "2021-06-15T09:02:26+00:00",
        "text": "Summary: Some BigQuery queries fail with RESOURCE_EXCEEDED errors\nDescription: We believe the issue with Google BigQuery is partially resolved. We are evaluating the projects impacted by this issue and performing mitigation as needed. We do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-06-15 05:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: No workarounds. Retries may eventually succeed as the issue seems to be intermittent",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-15T03:56:41+00:00",
        "modified": "2021-06-15T03:56:41+00:00",
        "when": "2021-06-15T03:56:41+00:00",
        "text": "Summary: Some BigQuery queries fail with RESOURCE_EXCEEDED errors\nDescription: We believe the issue with Google BigQuery is partially resolved. We are evaluating the projects impacted by this issue and performing mitigation as needed. We do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-06-15 02:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: No workarounds. Retries may eventually succeed as the issue seems to be intermittent",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-15T03:55:57+00:00",
        "modified": "2021-06-15T03:55:57+00:00",
        "when": "2021-06-15T03:55:57+00:00",
        "text": "Summary: Some BigQuery queries fail with RESOURCE_EXCEEDED errors\nDescription: We believe the issue with Google BigQuery is partially resolved. We are evaluating the projects impacted by this issue and performing mitigation as needed. We do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-06-15 02:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: No workarounds. Retries may eventually succeed as the issue seems to be intermittent",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-14T23:03:32+00:00",
        "modified": "2021-06-14T23:03:32+00:00",
        "when": "2021-06-14T23:03:32+00:00",
        "text": "Summary: Some BigQuery queries fail with RESOURCE_EXCEEDED errors\nDescription: We believe the issue with Google BigQuery is partially resolved. We are evaluating the projects impacted by this issue and performing mitigation as needed. We do not have an ETA for full resolution at this point.\nWe will provide an update by Monday, 2021-06-14 21:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: No workarounds. Retries may eventually succeed as the issue seems to be intermittent",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-14T16:57:11+00:00",
        "modified": "2021-06-14T16:57:11+00:00",
        "when": "2021-06-14T16:57:11+00:00",
        "text": "Summary: Some BigQuery queries fail with RESOURCE_EXCEEDED errors\nDescription: We believe the issue with Google BigQuery is partially resolved. However, mitigation work is still underway by our engineering team. We do not have an ETA for full resolution at this point.\nWe will provide an update by Monday, 2021-06-14 16:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: No workarounds. Retries may eventually succeed as the issue seems to be intermittent",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-13T01:14:36+00:00",
        "modified": "2021-06-13T01:14:36+00:00",
        "when": "2021-06-13T01:14:36+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: Summary:\nSome BigQuery Queries will fail with RESOURCE_EXCEEDED message:\nWe believe the issue with Google BigQuery is partially resolved. However mitigation is still underway for a viable mitigation for now. We do not have an ETA for full resolution at this point.\nWe will provide an update by Monday, 2021-06-14 11:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: No workarounds. Retries may eventually succeed as the issue seems to be intermittently affected.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-11T23:41:09+00:00",
        "modified": "2021-06-11T23:41:09+00:00",
        "when": "2021-06-11T23:41:09+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: Summary:\n* Some BigQuery Queries will fail with RESOURCE_EXCEEDED message:\nAn example message would be:\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\nWe believe the issue with Google BigQuery is partially resolved. However mitigation is still underway for a viable mitigation for now. We do not have an ETA for full resolution at this point.\nWe will provide an update by Saturday, 2021-06-12 13:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: No workarounds. Retries may eventually succeed as the issue seems to be intermittently affected.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-11T21:07:02+00:00",
        "modified": "2021-06-11T21:07:02+00:00",
        "when": "2021-06-11T21:07:02+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: We believe the issue with Google BigQuery is partially resolved.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Friday, 2021-06-11 16:30 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: Retrying the job may help but not necessarily immediately.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-11T21:04:54+00:00",
        "modified": "2021-06-11T21:04:54+00:00",
        "when": "2021-06-11T21:04:54+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: We believe the issue with Google BigQuery is partially resolved.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Friday, 2021-06-11 16:30 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: Retrying the job may help but not necessarily immediately.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-11T20:58:30+00:00",
        "modified": "2021-06-11T20:58:30+00:00",
        "when": "2021-06-11T20:58:30+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: We believe the issue with Google BigQuery is partially resolved.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Friday, 2021-06-11 16:30 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: Retrying the job may help but not necessarily immediately.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-11T20:06:36+00:00",
        "modified": "2021-06-11T20:06:36+00:00",
        "when": "2021-06-11T20:06:36+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: We believe the issue with Google BigQuery is partially resolved.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Friday, 2021-06-11 14:00 US/Pacific with current details.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: Retrying the job may help but not necessarily immediately.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-11T18:58:35+00:00",
        "modified": "2021-06-11T18:58:36+00:00",
        "when": "2021-06-11T18:58:35+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-06-11 13:06 US/Pacific.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: Retrying the job may help but not necessarily immediately.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-11T13:35:40+00:00",
        "modified": "2021-06-11T13:35:42+00:00",
        "when": "2021-06-11T13:35:40+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-06-11 12:06 US/Pacific.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: Retrying the job may help but not necessarily immediately.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-11T13:30:18+00:00",
        "modified": "2021-06-11T13:30:19+00:00",
        "when": "2021-06-11T13:30:18+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-06-11 12:06 US/Pacific.\nDiagnosis: The users will see an error message similar to:\n```\n[RESOURCES_UNAVAILABLE], Reason: code=RESOURCES_UNAVAILABLE message=RESOURCES_EXCEEDED_WITH_CONTEXT: [The query could not be executed in the allotted memory. Peak usage: 101% of limit.\\nTop memory consumer(s):\\n query parsing and optimization: 12%\\n table/storage metadata: 6%\\n other/unattributed: 82%\\n]\n```\nWorkaround: Retrying the job may help but not necessarily immediately.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-11T12:35:09+00:00",
        "modified": "2021-06-11T12:35:10+00:00",
        "when": "2021-06-11T12:35:09+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: We are experiencing an intermittent issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-06-11 06:35 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: Retrying the job may help but not necessarily immediately.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-06-11T10:34:21+00:00",
        "modified": "2021-06-11T10:34:23+00:00",
        "when": "2021-06-11T10:34:21+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: We are experiencing an intermittent issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-06-11 05:35 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-06-15T23:06:23+00:00",
      "modified": "2021-06-15T23:06:23+00:00",
      "when": "2021-06-15T23:06:23+00:00",
      "text": "Upon further investigation, our engineering teams believe that the scope of the BigQuery issue is now limited to a small number of projects.\nIf you have questions or feel that you may be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. No further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "9CcrhHUcFevXPSVaSxkf",
    "service_name": "Google BigQuery",
    "affected_products": [
      {
        "title": "Google BigQuery",
        "id": "9CcrhHUcFevXPSVaSxkf"
      }
    ],
    "uri": "incidents/ysdpNCkMDUgpG41cxBSD"
  },
  {
    "id": "EdoHcVkqXbPQmz3qYtqb",
    "number": "13724640166122167773",
    "begin": "2021-06-11T09:51:00+00:00",
    "created": "2021-06-11T10:11:23+00:00",
    "end": "2021-06-15T23:09:00+00:00",
    "modified": "2021-06-18T15:38:27+00:00",
    "external_desc": "Queries fail with RESOURCE_EXCEEDED",
    "updates": [
      {
        "created": "2021-06-11T10:11:15+00:00",
        "modified": "2021-06-11T10:11:24+00:00",
        "when": "2021-06-11T10:11:15+00:00",
        "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: We are experiencing an intermittent issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-06-11 05:41 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-06-11T10:11:15+00:00",
      "modified": "2021-06-11T10:11:24+00:00",
      "when": "2021-06-11T10:11:15+00:00",
      "text": "Summary: Queries fail with RESOURCE_EXCEEDED\nDescription: We are experiencing an intermittent issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-06-11 05:41 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
      "status": "SERVICE_DISRUPTION"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "9CcrhHUcFevXPSVaSxkf",
    "service_name": "Google BigQuery",
    "affected_products": [
      {
        "title": "Google BigQuery",
        "id": "9CcrhHUcFevXPSVaSxkf"
      }
    ],
    "uri": "incidents/EdoHcVkqXbPQmz3qYtqb"
  },
  {
    "id": "BDp83RWqaNczjhf2XcTF",
    "number": "1102199508564152239",
    "begin": "2021-06-11T09:37:39+00:00",
    "created": "2021-06-11T09:37:49+00:00",
    "end": "2021-06-11T10:30:31+00:00",
    "modified": "2021-06-11T10:30:31+00:00",
    "external_desc": "Talent solutions view is unavailable in Cloud Console",
    "updates": [
      {
        "created": "2021-06-11T10:30:29+00:00",
        "modified": "2021-06-11T10:30:30+00:00",
        "when": "2021-06-11T10:30:29+00:00",
        "text": "The issue with Cloud Talent Solution - Job Search has been resolved for all affected projects as of Friday, 2021-06-11 03:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-06-11T09:37:41+00:00",
        "modified": "2021-06-11T09:37:50+00:00",
        "when": "2021-06-11T09:37:41+00:00",
        "text": "Summary: Talent solutions view is unavailable in Cloud Console\nDescription: Beginning at Friday, 2021-06-10 21:00 US/PacificWe are experiencing an issue with Cloud Talent Solution - Job Search.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-06-11 05:11 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-06-11T10:30:29+00:00",
      "modified": "2021-06-11T10:30:30+00:00",
      "when": "2021-06-11T10:30:29+00:00",
      "text": "The issue with Cloud Talent Solution - Job Search has been resolved for all affected projects as of Friday, 2021-06-11 03:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VXydUfMqEtvZxXJFm56a",
    "service_name": "Cloud Talent Solution - Job Search",
    "affected_products": [
      {
        "title": "Cloud Talent Solution - Job Search",
        "id": "VXydUfMqEtvZxXJFm56a"
      }
    ],
    "uri": "incidents/BDp83RWqaNczjhf2XcTF"
  },
  {
    "id": "en1JzQ5fFdXvJBidW8D6",
    "number": "9708208911776657262",
    "begin": "2021-06-08T05:57:51+00:00",
    "created": "2021-06-08T05:57:57+00:00",
    "end": "2021-06-08T06:29:10+00:00",
    "modified": "2021-06-08T06:29:10+00:00",
    "external_desc": "We are experiencing an issue with Cloud Firestore beginning at Monday, 2021-06-07 22:04 US/Pacific.",
    "updates": [
      {
        "created": "2021-06-08T06:29:04+00:00",
        "modified": "2021-06-08T06:29:09+00:00",
        "when": "2021-06-08T06:29:04+00:00",
        "text": "The issue with Cloud Firestore has been resolved for all affected projects as of Monday, 2021-06-07 23:28 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-06-08T05:57:52+00:00",
        "modified": "2021-06-08T05:57:58+00:00",
        "when": "2021-06-08T05:57:52+00:00",
        "text": "Summary: We are experiencing an issue with Cloud Firestore beginning at Monday, 2021-06-07 22:04 US/Pacific.\nDescription: We are experiencing an issue with Cloud Firestore beginning at Monday, 2021-06-07 22:04 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-06-07 23:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-06-08T06:29:04+00:00",
      "modified": "2021-06-08T06:29:09+00:00",
      "when": "2021-06-08T06:29:04+00:00",
      "text": "The issue with Cloud Firestore has been resolved for all affected projects as of Monday, 2021-06-07 23:28 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "CETSkT92V21G6A1x28me",
    "service_name": "Cloud Firestore",
    "affected_products": [
      {
        "title": "Cloud Firestore",
        "id": "CETSkT92V21G6A1x28me"
      }
    ],
    "uri": "incidents/en1JzQ5fFdXvJBidW8D6"
  },
  {
    "id": "HU4hHMTWVXLBpo8gJL21",
    "number": "5011395758070801843",
    "begin": "2021-05-21T03:42:00+00:00",
    "created": "2021-05-21T10:27:47+00:00",
    "end": "2021-05-21T09:42:00+00:00",
    "modified": "2021-05-21T10:31:18+00:00",
    "external_desc": "Unavailability of streamed data in Google BigQuery in europe-west2.",
    "updates": [
      {
        "created": "2021-05-21T10:30:15+00:00",
        "modified": "2021-05-21T10:30:16+00:00",
        "when": "2021-05-21T10:30:15+00:00",
        "text": "We experienced an issue with Google BigQuery beginning at Friday, 2021-05-20 20:42 US/Pacific.\nSelf-diagnosis: Queries over recently streamed data in europe-west2 might have failed or returned incomplete results due to the streaming data being temporarily unavailable.\nThe issue has been resolved for all affected users as of Friday, 2021-05-21 02:42 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-21T10:27:43+00:00",
        "modified": "2021-05-21T10:27:48+00:00",
        "when": "2021-05-21T10:27:43+00:00",
        "text": "Summary: Unavailability of streamed data in Google BigQuery\nDescription: We are investigating a potential issue with Google BigQuery.\nDiagnosis: Queries over recently streamed data in europe-west2 might fail or return partial results.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-21T10:30:15+00:00",
      "modified": "2021-05-21T10:30:16+00:00",
      "when": "2021-05-21T10:30:15+00:00",
      "text": "We experienced an issue with Google BigQuery beginning at Friday, 2021-05-20 20:42 US/Pacific.\nSelf-diagnosis: Queries over recently streamed data in europe-west2 might have failed or returned incomplete results due to the streaming data being temporarily unavailable.\nThe issue has been resolved for all affected users as of Friday, 2021-05-21 02:42 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "9CcrhHUcFevXPSVaSxkf",
    "service_name": "Google BigQuery",
    "affected_products": [
      {
        "title": "Google BigQuery",
        "id": "9CcrhHUcFevXPSVaSxkf"
      }
    ],
    "uri": "incidents/HU4hHMTWVXLBpo8gJL21"
  },
  {
    "id": "B7cMek751d8KtnSn9gdZ",
    "number": "5169355527023825286",
    "begin": "2021-05-20T13:10:13+00:00",
    "created": "2021-05-20T13:41:00+00:00",
    "end": "2021-05-20T14:40:23+00:00",
    "modified": "2021-05-20T14:40:23+00:00",
    "external_desc": "External HTTP Load Balancer and Cloud Armor configuration changes are being delayed",
    "updates": [
      {
        "created": "2021-05-20T14:40:20+00:00",
        "modified": "2021-05-20T14:40:22+00:00",
        "when": "2021-05-20T14:40:20+00:00",
        "text": "This incident with Cloud Networking was found to be a direct cause of another incident causing issues with multiple products.\nThat incident is tracked at: https://status.cloud.google.com/incidents/bhMb6ab2NNyBPFCaUhgV",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-20T13:56:35+00:00",
        "modified": "2021-05-20T13:56:38+00:00",
        "when": "2021-05-20T13:56:35+00:00",
        "text": "Summary: External HTTP Load Balancer and Cloud Armor configuration changes are being delayed\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2021-05-20 07:30 US/Pacific.\nDiagnosis: External HTTP Load Balancer and Cloud Armor configuration changes are not going in effect timely.\nWorkaround: The configuration changes will eventually be propagated.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-20T13:40:47+00:00",
        "modified": "2021-05-20T13:41:00+00:00",
        "when": "2021-05-20T13:40:47+00:00",
        "text": "Summary: External HTTP Load Balancer configuration changes are being delayed\nDescription: We are experiencing an issue with External HTTP Load Balancing beginning at Thursday, 2021-05-20 06:01 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-05-20 07:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: HTTP Load Balancer configuration changes are not going in effect timely.\nWorkaround: The configuration changes will eventually be propagated.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-20T14:40:20+00:00",
      "modified": "2021-05-20T14:40:22+00:00",
      "when": "2021-05-20T14:40:20+00:00",
      "text": "This incident with Cloud Networking was found to be a direct cause of another incident causing issues with multiple products.\nThat incident is tracked at: https://status.cloud.google.com/incidents/bhMb6ab2NNyBPFCaUhgV",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/B7cMek751d8KtnSn9gdZ"
  },
  {
    "id": "bhMb6ab2NNyBPFCaUhgV",
    "number": "8021841938161207797",
    "begin": "2021-05-20T12:25:00+00:00",
    "created": "2021-05-20T14:29:22+00:00",
    "end": "2021-05-20T23:10:00+00:00",
    "modified": "2021-06-03T16:00:13+00:00",
    "external_desc": "Issue with multiple Google Cloud infrastructure components.",
    "updates": [
      {
        "created": "2021-06-02T20:25:33+00:00",
        "modified": "2021-06-03T16:00:13+00:00",
        "when": "2021-06-02T20:25:33+00:00",
        "text": "INCIDENT REPORT\n**Summary:**\nOn Thursday, May 20, 2021 at 05:25 US/Pacific, Google Cloud products experienced elevated latency and/or errors due to an issue with Access Control Lists (ACLs) intermittently for a duration of 10 hours and 45 minutes. The affected ACLs in this instance were internal that are used to define permissions for Google’s internal production resources. This prevented some internal service accounts from accessing various production jobs, which led to the downstream service impact. We apologize to our Cloud customers whose businesses were impacted during this disruption, and we are taking immediate action to improve the resiliency, performance, and availability of our services to avoid a recurrence.\n**Root Cause:**\nGoogle’s datacenters rely on Access Control Lists (ACLs) stored in a highly available lock service to perform operations, including validating permissions, activating new APIs, or creating new cloud resources. The access distribution manager, which maintains ACLs across Google production, encompasses both the control plane systems that allow for users to edit groups and the jobs which write the intended current state into the data plane, which is stored in a lock service as a set of signed ACL files.\nThe incident was triggered by a latent concurrency issue in a component of the production ACL system combined with a missing safety check, which led to truncation of ACLs across a subset of production. The safety mechanism for the legacy ACL components was inadvertently disabled by a change to update to the latest version in a subset of datacenters. The disabled safety checks in the legacy ACL component jobs allowed the invalid ACLs to be processed. The ACL component identified membership removals in the data snapshot and proceeded to remove ACL files from a backend locking service and passed the invalid ACLs to the backend stack, which correctly failed the safety checks.\n**Remediation and Prevention:**\nGoogle engineers were alerted to the issue by automated alerting on 20 May 2021 at 05:55 US/Pacific and immediately started an investigation. At 06:07, engineers identified an incomplete data snapshot being written, and a safety check mechanism was unexpectedly removing group memberships. At 06:21, engineers began mitigation efforts to terminate ACL component jobs globally to prevent further impact. To identify the root cause, engineers compared jobs serving affected datacenters and verified they were served by legacy ACL components, while those which were not affected were served using the latest version of safety check flags. The next phase of the mitigation strategy was to restore most critical group memberships that were removed. Simultaneously, the failing ACL component jobs were being configured to apply the correct safety checks and prepared to restart to restore healthy memberships. By 07:32, engineers worked to repair and restore the legacy stack jobs to write the correct ACLs in impacted datacenters. By 07:44, we began manually restoring critical ACLs.\nBy 15:09, most of the production fleet was mitigated and engineers continued to restore the remaining ACLs. At 16:10, the ACL issues across production were fully mitigated.\nWe apologize for the length and severity of this incident. We are taking immediate steps to prevent a recurrence and improve reliability in the future.\n**Detailed Description of Impact:**\nOn Thursday, May 20, 2021 from 05:25 to 16:10 US/Pacific, Google Cloud Infrastructure components experienced a service disruption which had varying degrees of impact to downstream services as described in detail below:\n**BigQuery**\nExperienced elevated error rates running queries and streaming in europe-west2. Around 5% of projects in the region were impacted with 0.63% failed query jobs and 3% of failed requests for streaming inserts from 06:10 to 07:30 PT.\n**Cloud Data Catalog**\nExperienced elevated error rates (30-40%) with permissions when reading backend databases in europe-west2 from 10:15 PT to 11:35 PT.\n**Cloud Logging**\nExperienced delayed logs in Google Cloud Storage (GCS) export pipeline in europe-west2 from 07:45 to 11:31 PT.\n**Cloud SQL**\nExperienced elevated error rates and latency on Admin APIs in the following regions from 06:51 to 09:44 PT: asia-south2, asia-southeast1, australia-southeast1, europe-north1, europe-west2, europe-west4, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-central2, us-east1, us-east4, us-west1 and europe-west1. Among most impacted operations, instance creation (instances.insert) had an error ratio of 69%. Additionally, 10% of successful responses to instance.insert later experienced downstream creation failures. Changes to instance configs (instances.update and instances.patch) had 96% and 87% error rates respectively. Existing instances had no significant connectivity impact. Customers using gcloud sql to connect from new IP addresses that had not yet been added to the ACL, would have been unable to connect.\n**Cloud Bigtable**\nData API experienced elevated latency and error rates up to 10% in europe-west2 from 06:30 to 09:33 PT.\n**Cloud Dataproc**\nExperienced elevated latency of 95% with cluster creation and deletion in europe-west2.\n**Cloud Vertex AI**\nExperienced service degradation in europe-west2 which caused 15% of API requests to fail from 06:57 to 10:28 PT.\n**Cloud AI Platform**\nExperienced up to 100% widespread backend error rates in europe-west2 from 06:15 to 12:40 PT.\n**Cloud Dataflow**\nExperienced jobs stuck in a pending state; jobs were unable to be terminated or cancelled; jobs were unable to migrate backends which resulted in stuck progress; and streaming jobs experienced delays in europe-west2. 35% of projects were impacted in the region from 06:06 to 12:37 PT.\n**Cloud Data Loss Prevention (DLP)**\nUp to 75% of DLP worker tasks were down in europe-west2. 25% error rate averaged across all method types from 10:28 to 11:36 PT.\n**Google Compute Engine (GCE)**\nSome GCE APIs experienced degraded availability and elevated error rates up to 40% in europe-west2 and europe-west3. Customers also experienced delays in VM creation and deletion operations in us-west2-a from 06:50 to 11:48 PT.\n**Cloud Composer**\nExperienced composer environment creation and update operation failures up to 80% globally from 06:08 to 11:07 PT. Existing environments may have experienced service errors.\n**AppEngine Flexible**\nExperienced deployment failures with timeouts or reporting success globally. Approximately 21% of affected projects experienced 503 errors after deploying a new version, and approximately 79% of affected projects experienced deployment deadline exceeded errors from 05:45 to 09:30 PT.\n**Cloud Networking**\nCustomer initiated control plane config changes related to load balancing products were delayed globally from 05:28 PT to 09:15 PT. Creation or changes to existing Network Load Balancers were delayed in europe-west2 (from 06:20 to 10:05 PT) and europe-west3 (from 07:19 to 10:05 PT). Customers who didn't command config changes during the incident were not affected.\n**Cloud Armor**\nNew Cloud Armor configs were delayed globally from 05:35 to 09:15 PT.\n**Cloud Console**\nExperienced elevated error rates up to 100% while accessing some pages of the console. 2.82% of users were impacted globally from 07:03 to 10:00 PT.\n**Artifact Registry**\nExperienced errors for several HTTP-Maven/Docker and ScottyAgent requests in europe-west1 and australia-southeast1 from 06:20 - 09:45 PT.\n**Google Cloud Storage (GCS)**\nExperienced elevated “400” errors up to 95% which were mostly deadline exceeded errors for 3 hours in europe-west2 from 07:25 to 10:22 PT.\n**Google Kubernetes Engine (GKE)**\nCustomers were unable to create new clusters for around 2 hours in europe-west2 and europe-west3 from 08:20 to 10:10 PT.\n**Identity and Access Management (IAM)**\nEurope-west2: Checkpolicy <0.01% error rate (2-3 qps) from 6:02 to 11:33 PT\nGlobalization Expand RPC served elevated latency everywhere from 6:47 to 10:02 PT.\n**Persistent Disk (PD)**\nUp to 40% of device creation operations failed in us-west2, while approximately 1% of snapshot operations were delayed or failed in us-central1, us-east1, us-west-1, and northamerica-northeast2. Existing Persistent Disk devices were not impacted.\nIn addition to fixing the underlying cause, we will be implementing changes to prevent, reduce the impact of, and better communicate about this type of failure in several ways:\n- Enhancing safety checks of our underlying systems.\n- Adding additional mechanisms that allow Google engineers to rapidly determine and fix the root cause of the service disruption.\n- Improve regression testing for ACL components for error conditions.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-21T19:32:06+00:00",
        "modified": "2021-06-02T20:27:14+00:00",
        "when": "2021-05-21T19:32:06+00:00",
        "text": "Mini Incident Report while full Incident Report is prepared\n(All Times US/Pacific)\n**Incident Start:** 20 May 2021 05:25\n**Incident End:** 20 May 2021 16:10\n**Duration:** 10 hours, 45 minutes\n**Affected Services and Features:**\nGoogle Compute Engine - VM creations and deletions\nPersistent Disk - Lifecycle Operations\nGoogle Cloud Networking - Load Balancers\nCloud Armor - New configs\nCloud Bigtable - Data API\nCloud SQL - Instance creation, gcloud sql connect\nAppEngine Flexible - Deployments\nDataproc - Cluster Creation and Deletion\nBigQuery, Cloud Vertex AI, Cloud AI Platform , IAM , Cloud Console, Artifact Registry, Google Cloud Storage, Cloud Logs, Dataflow, Chemist, Cloud Composer, Cloud Data Catalog, Cloud DLP\n**Regions/Zones:** Multi-Region\n**Description:**\nMultiple Google Cloud Products experienced elevated latencies and/or errors due to an issue with Access Control Lists (ACLs) intermittently for a duration of 10 hours and 45 minutes. Preliminary analysis revealed the cause was related to an issue impacting how ACLs are propagated. The issue was mitigated by correcting the behavior of the system responsible for distributing ACLs.\n**Customer Impact:**\n**europe-west2:**\nBigQuery- Streaming and Query fully stuck primarily in europe-west2.\nCloud Data Catalog - Permission errors when reading from backend databases.\nCloud Logs - Delays in exporting log data.\nCloud SQL - SQL operations like Instance creations, gcloud sql connect commands either failed or experienced delays.\nCloud Bigtable - Data API experienced elevated latencies and error rates\nDataproc- Increased cluster creation and deletion latencies in europe-west2.\nCloud Vertex AI - Service availability degraded for around 10 minutes in europe-west2\nCloud AI Platform - Widespread backend errors in europe-west2.\nDataflow- Jobs were stuck in pending state. Customers were unable to cancel or terminate jobs. Jobs unable to migrate backends which resulted in stuck progress. Streaming Jobs experienced delays.\nCloud DLP - Some DLP worker tasks were down.\n**us-west2-a:**\nGoogle Compute Engine - Some GCE APIs experienced degraded availability. Delays in VM creation and deletion operations.\n**Multi-Region:**\nCloud Composer - Composer environment creation and update operations failed. Existing environments may have experienced service errors.\nAppEngine Flexible - “major version\" (the usual way to deploy, \"not in place\") deployments failed with timeouts or reporting success then the deployed version served 503 errors.\nCloud Networking - Any customer initiated config change during the outage that is related to load balancing products were delayed over 3 hours. Customers that did not initiate config changes during the outage period were not affected.\nCloud Armor - New Cloud Armor configs were delayed.\nPersistent Disk - Lifecycle operations such as device creations, snapshot creations etc. experienced delays or failures. No impact to live Persistent Disk devices.\nCloud Console - Customers may have experienced errors while accessing some pages on the console.\nArtifact Registry - Errors for several HTTP-Maven/Docker and ScottyAgent requests for a little over 3 hours.\nGoogle Cloud Storage - Elevated 400 errors among which most are deadline exceeded errors.\nGoogle Kubernetes Engine - Customers were unable to create new clusters for 2 hours.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-21T00:34:56+00:00",
        "modified": "2021-05-21T00:34:56+00:00",
        "when": "2021-05-21T00:34:56+00:00",
        "text": "The issue with Google Cloud infrastructure components is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-21T00:00:52+00:00",
        "modified": "2021-05-21T00:00:52+00:00",
        "when": "2021-05-21T00:00:52+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: The issue with BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services, GCE APIs, PD Lifecycle Operations, AppEngine Flexible Deployments, Cloud Logs, Cloud DLP, CMLE, Cloud SQL,Cloud Console, Artifact Registry, Dataflow, Cloud Composer, Dataproc, Cloud Data Catalog have been partially resolved.\nFull resolution is expected to complete by Thursday, 2021-05-20 17:30 US/Pacific.\nWe will provide more information by Thursday, 2021-05-20 17:30 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-20T23:34:18+00:00",
        "modified": "2021-05-20T23:34:18+00:00",
        "when": "2021-05-20T23:34:18+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: The issue with BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services, GCE APIs, PD Lifecycle Operations, AppEngine Flexible Deployments, Cloud Logs, Cloud DLP, CMLE, Cloud SQL,Cloud Console, Artifact Registry, Dataflow, Cloud Composer, Dataproc, Cloud Data Catalog have been partially resolved.\nWe will provide more information by Thursday, 2021-05-20 17:00 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-20T23:02:14+00:00",
        "modified": "2021-05-20T23:02:14+00:00",
        "when": "2021-05-20T23:02:14+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services, GCE APIs, PD Lifecycle Operations, AppEngine Flexible Deployments, Cloud Logs, Cloud DLP, CMLE, Cloud SQL,Cloud Console, Artifact Registry, Dataflow, Cloud Composer, Dataproc, Cloud Data Catalog have been mitigated.\nThere could be some minor residual impacts pending to be resolved.\nThe Full resolution is still expected to complete by Thursday, 2021-05-20 16:30 US/Pacific\nWe will provide more information by Thursday, 2021-05-20 16:30 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-20T22:31:59+00:00",
        "modified": "2021-05-20T22:31:59+00:00",
        "when": "2021-05-20T22:31:59+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services, GCE APIs, PD Lifecycle Operations, AppEngine Flexible Deployments, Cloud Logs, Cloud DLP, CMLE, Cloud SQL,Cloud Console, Artifact Registry, Dataflow, Cloud Composer, Dataproc, Cloud Data Catalog have been mitigated.\nThere could be some minor residual impacts pending to be resolved.\nThe Full resolution is expected to complete by Thursday, 2021-05-20 16:30 US/Pacific\nWe will provide more information by Thursday, 2021-05-20 16:00 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-20T21:58:10+00:00",
        "modified": "2021-05-20T21:58:10+00:00",
        "when": "2021-05-20T21:58:10+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services, GCE APIs, PD Lifecycle Operations, AppEngine Flexible Deployments, Cloud Logs, Cloud DLP have been restored.\nCurrently known affected products: CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, Artifact Registry (europe-west1, australia-southest1), Dataflow (europe-west2), Cloud Composer, Dataproc (europe-west2), Cloud Data Catalog (europe-west2)\nThe mitigation is expected to complete by Thursday, 2021-05-20 15:30 US/Pacific\nWe will provide more information by Thursday, 2021-05-20 15:30 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T21:45:31+00:00",
        "modified": "2021-05-20T21:45:31+00:00",
        "when": "2021-05-20T21:45:31+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services, GCE APIs have been restored.\nCurrently known affected products: PD Lifecycle Operations, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry (europe-west1, australia-southest1), Cloud Logs (GCS Exports in europe-west2), Dataflow (europe-west2), Cloud Composer, Dataproc (europe-west2), Cloud Data Catalog (europe-west2), Cloud DLP (europe-west2)\nThe mitigation is expected to complete by Thursday, 2021-05-20 15:00 US/Pacific\nWe will provide more information by Thursday, 2021-05-20 15:15 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T21:13:01+00:00",
        "modified": "2021-05-20T21:13:01+00:00",
        "when": "2021-05-20T21:13:01+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services, GCE APIs have been restored.\nCurrently known affected products: PD Lifecycle Operations, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry (europe-west1, australia-southest1), Cloud Logs (GCS Exports in europe-west2), Dataflow (europe-west2), Cloud Composer, Dataproc (europe-west2), Cloud Data Catalog (europe-west2), Cloud DLP (europe-west2)\nThe mitigation is expected to complete by Thursday, 2021-05-20 15:00 US/Pacific\nWe will provide more information by Thursday, 2021-05-20 14:45 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T20:49:52+00:00",
        "modified": "2021-05-20T20:49:56+00:00",
        "when": "2021-05-20T20:49:52+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services, GCE APIs have been restored.\nCurrently known affected products: PD Lifecycle Operations, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry (europe-west1, australia-southest1), Cloud Logs (GCS Exports in europe-west2), Dataflow (europe-west2), Cloud Composer, Dataproc (europe-west2), Cloud Data Catalog (europe-west2), Cloud DLP (europe-west2)\nThe mitigation is expected to complete by Thursday, 2021-05-20 15:00 US/Pacific\nWe will provide more information by Thursday, 2021-05-20 14:15 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T20:44:38+00:00",
        "modified": "2021-05-20T20:44:48+00:00",
        "when": "2021-05-20T20:44:38+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services, GCE APIs have been restored.\nCurrently known affected products: PD Lifecycle Operations, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry (europe-west1, australia-southest1), Cloud Logs (GCS Exports in europe-west2), Dataflow (europe-west2), Cloud Composer, Dataproc (europe-west2), Cloud Data Catalog (europe-west2), Cloud DLP (europe-west2)\nThe mitigation is expected to complete by Thursday, 2021-05-20 14:00 US/Pacific\nWe will provide more information by Thursday, 2021-05-20 14:15 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T20:14:52+00:00",
        "modified": "2021-05-20T20:14:52+00:00",
        "when": "2021-05-20T20:14:52+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services, GCE APIs have been restored.\nCurrently known affected products: PD Lifecycle Operations, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry (europe-west1, australia-southest1), Cloud Logs (GCS Exports in europe-west2), Dataflow (europe-west2), Cloud Composer, Dataproc (europe-west2), Cloud Data Catalog (europe-west2), Cloud DLP (europe-west2)\nThe mitigation is expected to complete by Thursday, 2021-05-20 14:00 US/Pacific\nWe will provide more information by Thursday, 2021-05-20 13:45 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T19:47:45+00:00",
        "modified": "2021-05-20T19:47:45+00:00",
        "when": "2021-05-20T19:47:45+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services have been restored.\nCurrently known affected products: GCE APIs (including VM creation and deletion in us-west2-a and slow VM deletion in europe-west2, europe-west3), PD Lifecycle Operations, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry (europe-west1, australia-southest1), Cloud Logs (GCS Exports in europe-west2), Dataflow (europe-west2), Cloud Composer, Dataproc (europe-west2), Cloud Data Catalog (europe-west2), Cloud DLP (europe-west2)\nThe mitigation is expected to complete by Thursday, 2021-05-20 14:00 US/Pacific\nWe will provide more information by Thursday, 2021-05-20 13:15 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T19:16:18+00:00",
        "modified": "2021-05-20T19:16:18+00:00",
        "when": "2021-05-20T19:16:18+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services have been restored.\nCurrently known affected products: GCE APIs (including VM creation and deletion in us-west2-a and slow VM deletion in europe-west2, europe-west3), PD Lifecycle Operations, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry (europe-west1, australia-southest1), Cloud Logs (GCS Exports in europe-west2), Dataflow (europe-west2), Cloud Composer, Dataproc (europe-west2), Cloud Data Catalog (europe-west2), Cloud DLP (europe-west2)\nWe will provide more information by Thursday, 2021-05-20 12:45 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T18:48:28+00:00",
        "modified": "2021-05-20T18:48:28+00:00",
        "when": "2021-05-20T18:48:28+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner, Bigtable, Blobstore, Spanner services have been restored.\nCurrently known affected products: GCE APIs (including VM creation and deletion in us-west2-a and slow VM deletion in europe-west2, europe-west3), PD Lifecycle Operations, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry (europe-west1, australia-southest1), Cloud Logs (GCS Exports in europe-west2), Dataflow (europe-west2), Cloud Composer, Dataproc (europe-west2), Cloud Data Catalog (europe-west2)\nWe will provide more information by Thursday, 2021-05-20 12:15 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T18:14:48+00:00",
        "modified": "2021-05-20T18:14:48+00:00",
        "when": "2021-05-20T18:14:48+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM, Spanner services have been restored. Engineering team is currently obtaining confirmation on Cloud Composer and Dataproc service status post mitigation steps.\nCurrently known affected products: GCE APIs (including VM creation and deletion in us-west2-a and slow VM deletion in europe-west2, europe-west3), PD Lifecycle Operations, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry (europe-west1, australia-southest1), Cloud Logs (GCS Exports in europe-west2), Dataflow (europe-west2), Cloud Composer, Dataproc (europe-west2), Ads, Bigtable (largely recovered), Blobstore (mitigated), Colossus (mostly restored)\nWe will provide more information by Thursday, 2021-05-20 11:45 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T17:43:42+00:00",
        "modified": "2021-05-20T17:43:42+00:00",
        "when": "2021-05-20T17:43:42+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM services have been restored. Engineering team is currently obtaining confirmation on Cloud Composer and Dataproc service status post mitigation steps.\nCurrently known affected products: GCE APIs (including VM creation), PD Lifecycle Operations, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry, Cloud Logs Exports, Dataflow (europe-west2), Cloud Composer, Dataproc, Ads, Bigtable, Blobstore, Colossus, Spanner\nWe will provide more information by Thursday, 2021-05-20 11:15 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T17:15:30+00:00",
        "modified": "2021-05-20T17:15:30+00:00",
        "when": "2021-05-20T17:15:30+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. BigQuery, Cloud Networking, Cloud Armor, IAM services have been restored. Engineering team is currently obtaining confirmation on Cloud Composer and Dataproc service status post mitigation steps.\nCurrently known affected products: GCE APIs (including VM creation), PD Lifecycle Operations, Cloud Bigtable, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry, Cloud Logs Exports, Dataflow (europe-west2), Ads, Bigtable, Blobstore, Colossus, Spanner.\nWe will provide more information by Thursday, 2021-05-20 10:45 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T17:08:53+00:00",
        "modified": "2021-05-20T17:08:54+00:00",
        "when": "2021-05-20T17:08:53+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. IAM service has been recovered globally. Engineering team is currently working on rolling out the potential fix through the ACL manager and will confirm the results on completion. ETA for resolution for other affected services is unknown at this time.\nCurrently known affected products: GCE APIs (including VM creation), PD Lifecycle Operations, Cloud Bigtable, CMLE (europe-west2), Cloud SQL (instance creations), Cloud Console, AppEngine Flexible Deployments, Artifact Registry, Cloud Logs Exports, Dataflow (europe-west2), Ads, Bigtable, Blobstore, Colossus, Spanner.\nWe will provide more information by Thursday, 2021-05-20 10:15 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T16:44:19+00:00",
        "modified": "2021-05-20T17:31:36+00:00",
        "when": "2021-05-20T16:44:19+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. IAM service has been recovered globally. Engineering team is currently working on rolling out the potential fix through the ACL manager and will confirm the results on completion. ETA for resolution for other affected services is unknown at this time.\nCurrently known affected products: Bigtable, Cloud networking, Ads, Persistent Disk, Blobstore, BigQuery, GCE APIs, Cloud Composer, Cloud Console, Dataflow, Dataproc, App Engine, Control Plane.\nWe will provide more information by Thursday, 2021-05-20 10:15 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T16:15:09+00:00",
        "modified": "2021-05-20T16:15:10+00:00",
        "when": "2021-05-20T16:15:09+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Mitigation work is currently underway by our engineering team. Permissions that allow services in the cloud to communicate to other cloud services have apparently been removed.\nCurrently known affected products: Bigtable, Cloud networking, Ads, Persistent Disk, Blobstore, BigQuery, GCE APIs, Cloud Composer, IAM, Cloud Console, Dataflow, Dataproc, App Engine, Control Plane.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2021-05-20 09:45 US/Pacific.\nDiagnosis: Specific Cloud console pages are currently inaccessible for some customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T15:44:18+00:00",
        "modified": "2021-05-20T15:44:19+00:00",
        "when": "2021-05-20T15:44:18+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Permissions that allow services in the cloud to communicate to other cloud services have apparently been removed.\nCurrently known affected products: Bigtable, Cloud networking, Ads, Persistent Disk, Blobstore, BigQuery, GCE APIs, Cloud Composer, IAM, Cloud Console, Dataflow, Dataproc, App Engine, Control Plane.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-05-20 09:15 US/Pacific with current details.\nDiagnosis: Cloud console is currently inaccessible for all customers. Customers may experience issues with creating new backend services and observe latency in Cloud admin operations. Control plane operations may fail or have degraded performance.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T15:16:39+00:00",
        "modified": "2021-05-20T15:16:45+00:00",
        "when": "2021-05-20T15:16:39+00:00",
        "text": "Summary: Issue with multiple Google Cloud infrastructure components.\nDescription: Permissions that allow services in the cloud to communicate to other cloud services have apparently been removed.\nCurrently known affected products: Spanner, Bigtable, IAM, Networking, GFE, Compute Engine, Big Query\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-05-20 08:45 US/Pacific with current details.\nDiagnosis: Increased error rates and delayed operations.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-05-20T14:29:16+00:00",
        "modified": "2021-05-20T14:29:22+00:00",
        "when": "2021-05-20T14:29:16+00:00",
        "text": "Summary: We are experiencing elevated error rates and delayed operations\nDescription: We are experiencing an issue with Google Cloud infrastructure components. You will see elevated error rates and delayed operations across multiple products.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-05-20 08:00 US/Pacific with current details.\nDiagnosis: Increased error rates and delayed operations.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      }
    ],
    "most_recent_update": {
      "created": "2021-06-02T20:25:33+00:00",
      "modified": "2021-06-03T16:00:13+00:00",
      "when": "2021-06-02T20:25:33+00:00",
      "text": "INCIDENT REPORT\n**Summary:**\nOn Thursday, May 20, 2021 at 05:25 US/Pacific, Google Cloud products experienced elevated latency and/or errors due to an issue with Access Control Lists (ACLs) intermittently for a duration of 10 hours and 45 minutes. The affected ACLs in this instance were internal that are used to define permissions for Google’s internal production resources. This prevented some internal service accounts from accessing various production jobs, which led to the downstream service impact. We apologize to our Cloud customers whose businesses were impacted during this disruption, and we are taking immediate action to improve the resiliency, performance, and availability of our services to avoid a recurrence.\n**Root Cause:**\nGoogle’s datacenters rely on Access Control Lists (ACLs) stored in a highly available lock service to perform operations, including validating permissions, activating new APIs, or creating new cloud resources. The access distribution manager, which maintains ACLs across Google production, encompasses both the control plane systems that allow for users to edit groups and the jobs which write the intended current state into the data plane, which is stored in a lock service as a set of signed ACL files.\nThe incident was triggered by a latent concurrency issue in a component of the production ACL system combined with a missing safety check, which led to truncation of ACLs across a subset of production. The safety mechanism for the legacy ACL components was inadvertently disabled by a change to update to the latest version in a subset of datacenters. The disabled safety checks in the legacy ACL component jobs allowed the invalid ACLs to be processed. The ACL component identified membership removals in the data snapshot and proceeded to remove ACL files from a backend locking service and passed the invalid ACLs to the backend stack, which correctly failed the safety checks.\n**Remediation and Prevention:**\nGoogle engineers were alerted to the issue by automated alerting on 20 May 2021 at 05:55 US/Pacific and immediately started an investigation. At 06:07, engineers identified an incomplete data snapshot being written, and a safety check mechanism was unexpectedly removing group memberships. At 06:21, engineers began mitigation efforts to terminate ACL component jobs globally to prevent further impact. To identify the root cause, engineers compared jobs serving affected datacenters and verified they were served by legacy ACL components, while those which were not affected were served using the latest version of safety check flags. The next phase of the mitigation strategy was to restore most critical group memberships that were removed. Simultaneously, the failing ACL component jobs were being configured to apply the correct safety checks and prepared to restart to restore healthy memberships. By 07:32, engineers worked to repair and restore the legacy stack jobs to write the correct ACLs in impacted datacenters. By 07:44, we began manually restoring critical ACLs.\nBy 15:09, most of the production fleet was mitigated and engineers continued to restore the remaining ACLs. At 16:10, the ACL issues across production were fully mitigated.\nWe apologize for the length and severity of this incident. We are taking immediate steps to prevent a recurrence and improve reliability in the future.\n**Detailed Description of Impact:**\nOn Thursday, May 20, 2021 from 05:25 to 16:10 US/Pacific, Google Cloud Infrastructure components experienced a service disruption which had varying degrees of impact to downstream services as described in detail below:\n**BigQuery**\nExperienced elevated error rates running queries and streaming in europe-west2. Around 5% of projects in the region were impacted with 0.63% failed query jobs and 3% of failed requests for streaming inserts from 06:10 to 07:30 PT.\n**Cloud Data Catalog**\nExperienced elevated error rates (30-40%) with permissions when reading backend databases in europe-west2 from 10:15 PT to 11:35 PT.\n**Cloud Logging**\nExperienced delayed logs in Google Cloud Storage (GCS) export pipeline in europe-west2 from 07:45 to 11:31 PT.\n**Cloud SQL**\nExperienced elevated error rates and latency on Admin APIs in the following regions from 06:51 to 09:44 PT: asia-south2, asia-southeast1, australia-southeast1, europe-north1, europe-west2, europe-west4, europe-west6, northamerica-northeast1, southamerica-east1, us-central1, us-central2, us-east1, us-east4, us-west1 and europe-west1. Among most impacted operations, instance creation (instances.insert) had an error ratio of 69%. Additionally, 10% of successful responses to instance.insert later experienced downstream creation failures. Changes to instance configs (instances.update and instances.patch) had 96% and 87% error rates respectively. Existing instances had no significant connectivity impact. Customers using gcloud sql to connect from new IP addresses that had not yet been added to the ACL, would have been unable to connect.\n**Cloud Bigtable**\nData API experienced elevated latency and error rates up to 10% in europe-west2 from 06:30 to 09:33 PT.\n**Cloud Dataproc**\nExperienced elevated latency of 95% with cluster creation and deletion in europe-west2.\n**Cloud Vertex AI**\nExperienced service degradation in europe-west2 which caused 15% of API requests to fail from 06:57 to 10:28 PT.\n**Cloud AI Platform**\nExperienced up to 100% widespread backend error rates in europe-west2 from 06:15 to 12:40 PT.\n**Cloud Dataflow**\nExperienced jobs stuck in a pending state; jobs were unable to be terminated or cancelled; jobs were unable to migrate backends which resulted in stuck progress; and streaming jobs experienced delays in europe-west2. 35% of projects were impacted in the region from 06:06 to 12:37 PT.\n**Cloud Data Loss Prevention (DLP)**\nUp to 75% of DLP worker tasks were down in europe-west2. 25% error rate averaged across all method types from 10:28 to 11:36 PT.\n**Google Compute Engine (GCE)**\nSome GCE APIs experienced degraded availability and elevated error rates up to 40% in europe-west2 and europe-west3. Customers also experienced delays in VM creation and deletion operations in us-west2-a from 06:50 to 11:48 PT.\n**Cloud Composer**\nExperienced composer environment creation and update operation failures up to 80% globally from 06:08 to 11:07 PT. Existing environments may have experienced service errors.\n**AppEngine Flexible**\nExperienced deployment failures with timeouts or reporting success globally. Approximately 21% of affected projects experienced 503 errors after deploying a new version, and approximately 79% of affected projects experienced deployment deadline exceeded errors from 05:45 to 09:30 PT.\n**Cloud Networking**\nCustomer initiated control plane config changes related to load balancing products were delayed globally from 05:28 PT to 09:15 PT. Creation or changes to existing Network Load Balancers were delayed in europe-west2 (from 06:20 to 10:05 PT) and europe-west3 (from 07:19 to 10:05 PT). Customers who didn't command config changes during the incident were not affected.\n**Cloud Armor**\nNew Cloud Armor configs were delayed globally from 05:35 to 09:15 PT.\n**Cloud Console**\nExperienced elevated error rates up to 100% while accessing some pages of the console. 2.82% of users were impacted globally from 07:03 to 10:00 PT.\n**Artifact Registry**\nExperienced errors for several HTTP-Maven/Docker and ScottyAgent requests in europe-west1 and australia-southeast1 from 06:20 - 09:45 PT.\n**Google Cloud Storage (GCS)**\nExperienced elevated “400” errors up to 95% which were mostly deadline exceeded errors for 3 hours in europe-west2 from 07:25 to 10:22 PT.\n**Google Kubernetes Engine (GKE)**\nCustomers were unable to create new clusters for around 2 hours in europe-west2 and europe-west3 from 08:20 to 10:10 PT.\n**Identity and Access Management (IAM)**\nEurope-west2: Checkpolicy <0.01% error rate (2-3 qps) from 6:02 to 11:33 PT\nGlobalization Expand RPC served elevated latency everywhere from 6:47 to 10:02 PT.\n**Persistent Disk (PD)**\nUp to 40% of device creation operations failed in us-west2, while approximately 1% of snapshot operations were delayed or failed in us-central1, us-east1, us-west-1, and northamerica-northeast2. Existing Persistent Disk devices were not impacted.\nIn addition to fixing the underlying cause, we will be implementing changes to prevent, reduce the impact of, and better communicate about this type of failure in several ways:\n- Enhancing safety checks of our underlying systems.\n- Adding additional mechanisms that allow Google engineers to rapidly determine and fix the root cause of the service disruption.\n- Improve regression testing for ACL components for error conditions.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_OUTAGE",
    "severity": "high",
    "service_key": "uoypgc4GWUyzAKRHPjEv",
    "service_name": "Google Cloud Infrastructure Components",
    "affected_products": [
      {
        "title": "Google Cloud Infrastructure Components",
        "id": "uoypgc4GWUyzAKRHPjEv"
      }
    ],
    "uri": "incidents/bhMb6ab2NNyBPFCaUhgV"
  },
  {
    "id": "sqeWSRmcrJZyE2zSrJ74",
    "number": "5903222543441541849",
    "begin": "2021-05-17T13:51:36+00:00",
    "created": "2021-05-17T14:24:37+00:00",
    "end": "2021-05-17T15:45:34+00:00",
    "modified": "2021-05-17T15:45:34+00:00",
    "external_desc": "We are experiencing a global issue with creation and upgrades of GKE Clusters",
    "updates": [
      {
        "created": "2021-05-17T15:45:33+00:00",
        "modified": "2021-05-17T15:45:33+00:00",
        "when": "2021-05-17T15:45:33+00:00",
        "text": "The issue with Google Kubernetes Engine Cluster Creation is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-17T15:23:21+00:00",
        "modified": "2021-05-17T15:23:26+00:00",
        "when": "2021-05-17T15:23:21+00:00",
        "text": "Summary: We are experiencing a global issue with creation and upgrades of GKE Clusters\nDescription: We are experiencing global issue with creation and upgrades of Google Kubernetes Engine, beginning at Monday, 2021-05-17 06:51 US/Pacific.\nWe recommend customers do not Delete Clusters or initiate Cluster upgrades until further notice.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-05-17 09:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Creating GKE cluster operation failing with error message `GCE_PERMISSION_DENIED: Google Compute Engine: Required 'compute.images.useReadOnly' permission`\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-17T14:52:01+00:00",
        "modified": "2021-05-17T14:52:01+00:00",
        "when": "2021-05-17T14:52:01+00:00",
        "text": "Summary: We are experiencing a global issue with creation and upgrades of GKE Clusters\nDescription: We are experiencing global issue with creation and upgrades of Google Kubernetes Engine, beginning at Monday, 2021-05-17 06:51 US/Pacific.\nWe recommend customers do not Delete Clusters or initiate Cluster upgrades until further notice.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-05-17 08:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Creating GKE cluster operation failing with error message `GCE_PERMISSION_DENIED: Google Compute Engine: Required 'compute.images.useReadOnly' permission`\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-17T14:47:00+00:00",
        "modified": "2021-05-17T14:47:00+00:00",
        "when": "2021-05-17T14:47:00+00:00",
        "text": "Summary: We are experiencing a global issue with creation and upgrades of GKE Clusters\nDescription: We are experiencing global issue with creation and upgrades of Google Kubernetes Engine, beginning at Monday, 2021-05-17 06:51 US/Pacific.\nWe recommend customers do not initiate Cluster upgrades until further notice.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-05-17 08:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Creating GKE cluster operation failing with error message `GCE_PERMISSION_DENIED: Google Compute Engine: Required 'compute.images.useReadOnly' permission`\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-17T14:24:34+00:00",
        "modified": "2021-05-17T14:24:37+00:00",
        "when": "2021-05-17T14:24:34+00:00",
        "text": "Summary: We are experiencing a global issue with creating GKE Clusters\nDescription: We are experiencing global issue with creation of new Google Kubernetes Engine, beginning at Monday, 2021-05-17 06:51 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-05-17 07:55 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Creating GKE cluster operation failing with error message `GCE_PERMISSION_DENIED: Google Compute Engine: Required 'compute.images.useReadOnly' permission`\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-17T15:45:33+00:00",
      "modified": "2021-05-17T15:45:33+00:00",
      "when": "2021-05-17T15:45:33+00:00",
      "text": "The issue with Google Kubernetes Engine Cluster Creation is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/sqeWSRmcrJZyE2zSrJ74"
  },
  {
    "id": "hoW7kWQnQ6jK9E3sBAg5",
    "number": "9816977690929525237",
    "begin": "2021-05-16T11:24:58+00:00",
    "created": "2021-05-16T11:43:12+00:00",
    "end": "2021-05-16T17:20:54+00:00",
    "modified": "2021-05-16T17:20:54+00:00",
    "external_desc": "Cloud Build: builds fail trying to fetch git repositories from GitHub",
    "updates": [
      {
        "created": "2021-05-16T17:20:53+00:00",
        "modified": "2021-05-16T17:20:53+00:00",
        "when": "2021-05-16T17:20:53+00:00",
        "text": "The issue with Cloud Build has been resolved for all affected users as of Sunday, 2021-05-16 09:00 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-16T15:44:48+00:00",
        "modified": "2021-05-16T15:44:49+00:00",
        "when": "2021-05-16T15:44:48+00:00",
        "text": "Summary: Cloud Build: builds fail trying to fetch git repositories from GitHub\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Sunday, 2021-05-16 10:48 US/Pacific.\nDiagnosis: The problem is limited to GitHub only. The product team is now cooperating with GitHub to troubleshoot the issue on their side.\nWorkaround: Authenticating the repository using GitHub (Legacy) is reported to throw a warning but still complete the builds.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-16T13:42:53+00:00",
        "modified": "2021-05-16T13:42:54+00:00",
        "when": "2021-05-16T13:42:53+00:00",
        "text": "Summary: Cloud Build: builds fail trying to fetch git repos\nDescription: We are experiencing an issue with Cloud Build beginning at Sunday, 2021-05-16 03:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2021-05-16 08:45 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: Authenticating the repository using GitHub (Legacy) is reported to throw a warning but still complete the builds.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-16T12:36:12+00:00",
        "modified": "2021-05-16T12:36:14+00:00",
        "when": "2021-05-16T12:36:12+00:00",
        "text": "Summary: Cloud Build: builds fail trying to fetch git repos\nDescription: We are experiencing an issue with Cloud Build beginning at Sunday, 2021-05-16 03:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2021-05-16 06:45 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: Authenticating the repository using GitHub (Legacy) is reported to throw a warning but still complete the builds.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-16T11:43:10+00:00",
        "modified": "2021-05-16T11:43:13+00:00",
        "when": "2021-05-16T11:43:10+00:00",
        "text": "Summary: Cloud Build: builds fail trying to fetch git repos\nDescription: We are experiencing an issue with Cloud Build beginning at Sunday, 2021-05-16 03:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2021-05-16 05:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: Authenticating the repository using GitHub (Legacy) is reported to throw a warning but still complete the builds.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-16T17:20:53+00:00",
      "modified": "2021-05-16T17:20:53+00:00",
      "when": "2021-05-16T17:20:53+00:00",
      "text": "The issue with Cloud Build has been resolved for all affected users as of Sunday, 2021-05-16 09:00 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "BGJQ6jbGK4kUuBTQFZ1G",
    "service_name": "Cloud Developer Tools",
    "affected_products": [
      {
        "title": "Cloud Developer Tools",
        "id": "BGJQ6jbGK4kUuBTQFZ1G"
      }
    ],
    "uri": "incidents/hoW7kWQnQ6jK9E3sBAg5"
  },
  {
    "id": "T7DBhv3wmrXMKVfTnkDB",
    "number": "3002626837020940545",
    "begin": "2021-05-13T01:45:03+00:00",
    "created": "2021-05-13T02:08:00+00:00",
    "end": "2021-05-13T02:28:04+00:00",
    "modified": "2021-05-13T02:28:04+00:00",
    "external_desc": "Composer environment creation fails in all regions",
    "updates": [
      {
        "created": "2021-05-13T02:28:04+00:00",
        "modified": "2021-05-13T02:28:04+00:00",
        "when": "2021-05-13T02:28:04+00:00",
        "text": "The issue with Cloud Composer is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-13T02:07:59+00:00",
        "modified": "2021-05-13T02:08:00+00:00",
        "when": "2021-05-13T02:07:59+00:00",
        "text": "Summary: Composer environment creation fails in all regions\nDescription: We are experiencing an intermittent issue with Composer beginning on Wednesday, 2021-05-12 16:40 US/Pacific.\nFrom 16:40 US/Pacific, customers may see excessive delays or failure errors when attempting to create Composer Environments. This issue is linked to the ongoing Cloud Load Balancing issue.\nWe apologize to all who are affected by the disruption.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/1Mp2HBfzu8gjVw8BEXGH where we will provide the next update by Wednesday, 2021-05-12 22:00 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-13T02:28:04+00:00",
      "modified": "2021-05-13T02:28:04+00:00",
      "when": "2021-05-13T02:28:04+00:00",
      "text": "The issue with Cloud Composer is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "YxkG5FfcC42cQmvBCk4j",
    "service_name": "Google Cloud Composer",
    "affected_products": [
      {
        "title": "Google Cloud Composer",
        "id": "YxkG5FfcC42cQmvBCk4j"
      }
    ],
    "uri": "incidents/T7DBhv3wmrXMKVfTnkDB"
  },
  {
    "id": "7HGDRYTQ2qmB14Bmp41A",
    "number": "5430007717827966408",
    "begin": "2021-05-13T01:03:16+00:00",
    "created": "2021-05-13T01:55:54+00:00",
    "end": "2021-05-13T02:31:21+00:00",
    "modified": "2021-05-13T02:31:21+00:00",
    "external_desc": "Customers may see excessive delays or errors when attempting to deploy App Engine Flex instances globally",
    "updates": [
      {
        "created": "2021-05-13T02:31:21+00:00",
        "modified": "2021-05-13T02:31:21+00:00",
        "when": "2021-05-13T02:31:21+00:00",
        "text": "The issue affecting changes to Cloud Load Balancers has been resolved for all affected users as of Wednesday, 2021-05-12 19:08 US/Pacific.\nHowever, some affected products may still see impact until approximately 19:25 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-13T01:55:53+00:00",
        "modified": "2021-05-13T01:55:54+00:00",
        "when": "2021-05-13T01:55:53+00:00",
        "text": "Summary: Customers may see excessive delays or errors when attempting to deploy App Engine Flex instances globally\nDescription: We are experiencing an intermittent issue with Google App Engine Flex beginning at Wednesday, 2021-05-12 16:40 US/Pacific.\nFrom 16:40 US/Pacific, customers may see excessive delays or failure errors when attempting to deploy a App Engine Flex instance. This issue is linked to the ongoing Cloud Load Balancing issue.\nWe apologize to all who are affected by the disruption.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/1Mp2HBfzu8gjVw8BEXGH where we will provide the next update by Wednesday, 2021-05-12 22:00 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-13T02:31:21+00:00",
      "modified": "2021-05-13T02:31:21+00:00",
      "when": "2021-05-13T02:31:21+00:00",
      "text": "The issue affecting changes to Cloud Load Balancers has been resolved for all affected users as of Wednesday, 2021-05-12 19:08 US/Pacific.\nHowever, some affected products may still see impact until approximately 19:25 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "kchyUtnkMHJWaAva8aYc",
    "service_name": "Google App Engine",
    "affected_products": [
      {
        "title": "Google App Engine",
        "id": "kchyUtnkMHJWaAva8aYc"
      }
    ],
    "uri": "incidents/7HGDRYTQ2qmB14Bmp41A"
  },
  {
    "id": "1Mp2HBfzu8gjVw8BEXGH",
    "number": "17139372249929570277",
    "begin": "2021-05-13T01:02:47+00:00",
    "created": "2021-05-13T01:52:08+00:00",
    "end": "2021-05-13T02:29:39+00:00",
    "modified": "2021-05-13T02:29:39+00:00",
    "external_desc": "Deplyoing or updating Cloud Load Balancers may be slow globally",
    "updates": [
      {
        "created": "2021-05-13T02:29:38+00:00",
        "modified": "2021-05-13T02:29:39+00:00",
        "when": "2021-05-13T02:29:38+00:00",
        "text": "The issue affecting changes to Cloud Load Balancers has been resolved for all affected users as of Wednesday, 2021-05-12 19:08 US/Pacific.\nHowever, some affected products may still see impact until approximately 19:25 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-13T01:52:01+00:00",
        "modified": "2021-05-13T01:52:08+00:00",
        "when": "2021-05-13T01:52:01+00:00",
        "text": "Summary: Deplyoing or updating Cloud Load Balancers may be slow globally\nDescription: We are experiencing an issue affecting Cloud Load Balancing beginning at Wednesday, 2021-05-12 16:40 US/Pacific.\nStarting from 16:40 US/Pacific time, users attempting to update or deploy Cloud Load Balancers may experience delays or failures.\nProducts also utilising Cloud Load balancers may also be impacted.\nAs of 17:30 US/Pacific time, a mitigation has been put in place, however some users may continue to expirence delays, a full mitigation for impacted users is underway by our engineering team.\nWe will provide an update by Wednesday, 2021-05-12 22:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-13T02:29:38+00:00",
      "modified": "2021-05-13T02:29:39+00:00",
      "when": "2021-05-13T02:29:38+00:00",
      "text": "The issue affecting changes to Cloud Load Balancers has been resolved for all affected users as of Wednesday, 2021-05-12 19:08 US/Pacific.\nHowever, some affected products may still see impact until approximately 19:25 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/1Mp2HBfzu8gjVw8BEXGH"
  },
  {
    "id": "VVJnin9xh36NeBQ7Ut3c",
    "number": "13632501304152957407",
    "begin": "2021-05-11T22:18:16+00:00",
    "created": "2021-05-11T22:31:28+00:00",
    "end": "2021-05-12T03:43:39+00:00",
    "modified": "2021-05-12T03:43:39+00:00",
    "external_desc": "[Fully Resolved] We are investigating an issue with Google Cloud Support case creation and email notifications for new case comments",
    "updates": [
      {
        "created": "2021-05-12T03:43:39+00:00",
        "modified": "2021-05-12T03:43:39+00:00",
        "when": "2021-05-12T03:43:39+00:00",
        "text": "The issue with Google Cloud Support Case creation has been resolved for all affected users as of Tuesday, 2021-05-11 20:23 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-12T02:54:12+00:00",
        "modified": "2021-05-12T02:54:12+00:00",
        "when": "2021-05-12T02:54:12+00:00",
        "text": "Summary: [Partially Resolved] We are investigating an issue with Google Cloud Support case creation and email notifications for new case comments\nDescription: We believe the issue with Google Cloud Support case creation is partially resolved.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-05-11 21:00 US/Pacific with current details.\nDiagnosis: Customers may be unable to open new cases using chat or phone, cases created using the support portals are not impacted. Existing cases can continue to receive support via phone and support portal.\nCustomers may not receive email notifications for updates to their cases. In order to see if a case has been updated, the support portal needs to be reviewed manually.\nWorkaround: Customers with technical questions can engage Support via support portal. Customers needing to contact Billing Support should use the phone option.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-12T01:45:39+00:00",
        "modified": "2021-05-12T01:45:39+00:00",
        "when": "2021-05-12T01:45:39+00:00",
        "text": "Summary: We are investigating an issue with Google Cloud Support case creation and email notifications for new case comments\nDescription: We believe the issue with Google Cloud Support is partially resolved.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-05-11 20:00 US/Pacific with current details.\nDiagnosis: Customers may be unable to open new cases using chat or phone, cases created using the support portals are not impacted. Existing cases can continue to receive support via phone and support portal.\nCustomers may not receive email notifications for updates to their cases. In order to see if a case has been updated, the support portal needs to be reviewed manually.\nWorkaround: Customers with technical questions can engage Support via support portal. Customers needing to contact Billing Support should use the phone option.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-12T00:38:55+00:00",
        "modified": "2021-05-12T00:38:56+00:00",
        "when": "2021-05-12T00:38:55+00:00",
        "text": "Summary: We are investigating an issue with Google Cloud Support case creation and email notifications for new case comments\nDescription: We are investigating an intermittent issue with Google Cloud Support; customers may have issues creating new cases via chat. Customers with existing cases may not receive email notifications for case updates. Customers can reach support using phone support. Existing cases can continue to be investigated.\nWe are experiencing an intermittent issue with Google Cloud Support beginning on Tuesday, 2021-05-11 14:19 US/Pacific.\nOur engineering team is in the process of mitigating the issue.\nWe will provide an update by Tuesday, 2021-05-11 18:45 US/Pacific with current details.\nDiagnosis: Customers may be unable to open new cases using chat or phone, cases created using the support portals are not impacted. Existing cases can continue to receive support via phone and support portal.\nCustomers may not receive email notifications for updates to their cases. In order to see if a case has been updated, the support portal needs to be reviewed manually.\nWorkaround: Customers with technical questions can engage Support via support portal. Customers needing to contact Billing Support should use the phone option.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-12T00:12:24+00:00",
        "modified": "2021-05-12T00:12:24+00:00",
        "when": "2021-05-12T00:12:24+00:00",
        "text": "Summary: We are investigating an issue with Google Cloud Support case creation and email notifications for new case comments\nDescription: We are investigating an intermittent issue with Google Cloud Support; customers may have issues creating new cases via chat. Customers with existing cases may not receive email notifications for case updates. Customers can reach support using phone support. Existing cases can continue to be investigated.\nWe are experiencing an intermittent issue with Google Cloud Support beginning on Tuesday, 2021-05-11 14:19 US/Pacific.\nOur engineering team is in the process of mitigating the issue.\nWe will provide an update by Tuesday, 2021-05-11 17:45 US/Pacific with current details.\nDiagnosis: Customers may be unable to open new cases using chat or phone, cases created using the support portals are not impacted. Existing cases can continue to receive support via phone and support portal.\nCustomers may not receive email notifications for updates to their cases. In order to see if a case has been updated, the support portal needs to be reviewed manually.\nWorkaround: Customers with technical questions can engage Support via support portal. Customers needing to contact Billing Support should use the phone option.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-11T23:44:52+00:00",
        "modified": "2021-05-11T23:44:53+00:00",
        "when": "2021-05-11T23:44:52+00:00",
        "text": "Summary: We are investigating an issue with Google Cloud Support case creation and email notifications for new case comments\nDescription: We are investigating an issue with Google Cloud Support; customers may have issues creating new cases via chat. Customers with existing cases may not receive email notifications for case updates. Customers can reach support using phone support. Existing cases can continue to be investigated.\nWe are experiencing an intermittent issue with Google Cloud Support beginning on Tuesday, 2021-05-11 14:19 US/Pacific.\nOur engineering team is investigating the issue.\nWe will provide an update by Tuesday, 2021-05-11 17:15 US/Pacific with current details.\nDiagnosis: Customers may be unable to open new cases using chat or phone, cases created using the support portals are not impacted. Existing cases can continue to receive support via phone and support portal.\nCustomers may not receive email notifications for updates to their cases. In order to see if a case has been updated, the support portal needs to be reviewed manually.\nWorkaround: Customers with technical questions can engage Support via support portal. Customers needing to contact Billing Support should use the phone option.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-11T23:09:46+00:00",
        "modified": "2021-05-11T23:09:46+00:00",
        "when": "2021-05-11T23:09:46+00:00",
        "text": "Summary: We are investigating an issue with Google Cloud Support case creation and email notifications for new case comments\nDescription: We are investigating an issue with Google Cloud Support; customers may have issues creating new cases via chat. Customers with existing cases may not receive email notifications for case updates. Customers can reach support using phone support. Existing cases can continue to be investigated.\nWe are experiencing an intermittent issue with Google Cloud Support beginning on Tuesday, 2021-05-11 14:19 US/Pacific.\nOur engineering team is investigating the issue.\nWe will provide an update by Tuesday, 2021-05-11 16:45 US/Pacific with current details.\nDiagnosis: Customers may be unable to open new cases using chat or phone, cases created using the support portals are not impacted. Existing cases can continue to receive support via phone and support portal.\nCustomers may not receive email notifications for updates to their cases. In order to see if a case has been updated, the support portal needs to be reviewed manually.\nWorkaround: Customers can engage Support via support portal. Customers needing to contact Billing Support should use the phone option if they do not have a support subscription.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-11T22:49:11+00:00",
        "modified": "2021-05-11T22:49:16+00:00",
        "when": "2021-05-11T22:49:11+00:00",
        "text": "Summary: We are investigating an issue with Google Cloud Support case creation\nDescription: We are investigating an issue with Google Cloud Support; customers may have issues creating new cases via chat and phone and may not receive email notifications for case updates. Customers can reach support using phone support, but the agent's ability to create a case is impacted by the issue. Existing cases can continue to be investigated.\nWe are experiencing an intermittent issue with Google Cloud Support beginning at Tuesday, 2021-05-11 14:19 US/Pacific.\nOur engineering team is investigating the issue.\nWe will provide an update by Tuesday, 2021-05-11 16:15 US/Pacific with current details.\nDiagnosis: Customers may be unable to open new cases using chat or phone, cases created using the support portals are not impacted. Existing cases can continue to receive support via phone and support portal.\nCustomers may not receive email notifications for updates to their cases. In order to see if a case has been updated, the support portal needs to be reviewed manually.\nWorkaround: Customers can engage Support via support portals.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-11T22:31:22+00:00",
        "modified": "2021-05-11T22:31:29+00:00",
        "when": "2021-05-11T22:31:22+00:00",
        "text": "Summary: We are investigating an issue with Google Cloud Support case creation\nDescription: We are investigating an issue with Google Cloud Support; customers may have issues creating new cases via chat and phone. Customers can reach support using phone, but the agent's ability to create a case is impacted by the issue. Existing cases can continue to be investigated.\nWe are experiencing an intermittent issue with Google Cloud Support beginning at Tuesday, 2021-05-11 14:19 US/Pacific.\nOur engineering team is investigating the issue.\nWe will provide an update by Tuesday, 2021-05-11 16:00 US/Pacific with current details.\nDiagnosis: Customers may be unable to open new cases using chat or phone. Existing cases can continue to receive support via phone and support portal.\nWorkaround: Customers can engage Support via email and support portals.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-12T03:43:39+00:00",
      "modified": "2021-05-12T03:43:39+00:00",
      "when": "2021-05-12T03:43:39+00:00",
      "text": "The issue with Google Cloud Support Case creation has been resolved for all affected users as of Tuesday, 2021-05-11 20:23 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "bGThzF7oEGP5jcuDdMuk",
    "service_name": "Google Cloud Support",
    "affected_products": [
      {
        "title": "Google Cloud Support",
        "id": "bGThzF7oEGP5jcuDdMuk"
      }
    ],
    "uri": "incidents/VVJnin9xh36NeBQ7Ut3c"
  },
  {
    "id": "DtJPnaHo1ivRDnCCAqKU",
    "number": "17117631814963942329",
    "begin": "2021-05-05T02:26:24+00:00",
    "created": "2021-05-05T02:26:26+00:00",
    "end": "2021-05-05T04:57:04+00:00",
    "modified": "2021-05-05T04:57:04+00:00",
    "external_desc": "Cloud VPN gateways located in us-west2 may be unreachable and experience high traffic loss",
    "updates": [
      {
        "created": "2021-05-05T04:57:04+00:00",
        "modified": "2021-05-05T04:57:04+00:00",
        "when": "2021-05-05T04:57:04+00:00",
        "text": "The issue with Cloud VPN has been resolved for all affected users as of approximately Tuesday, 2021-05-04 21:15 US/Pacific.\nPlease follow https://status.cloud.google.com/incidents/eCPQKkKcFy6NYXExnPXL for additional details.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-05T02:26:25+00:00",
        "modified": "2021-05-05T02:26:26+00:00",
        "when": "2021-05-05T02:26:25+00:00",
        "text": "Summary: Cloud VPN gateways located in us-west2 may be unreachable and experience high traffic loss\nDescription: We are experiencing an intermittent issue with Cloud VPN affecting through gateway in us-west2 beginning at Tuesday, 2021-05-04 17:37 US/Pacific US/Pacific.\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/eCPQKkKcFy6NYXExnPXL CSD External Incident link for Parent OMG where we will provide the next update by Tuesday, 2021-05-04 20:30 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-05T04:57:04+00:00",
      "modified": "2021-05-05T04:57:04+00:00",
      "when": "2021-05-05T04:57:04+00:00",
      "text": "The issue with Cloud VPN has been resolved for all affected users as of approximately Tuesday, 2021-05-04 21:15 US/Pacific.\nPlease follow https://status.cloud.google.com/incidents/eCPQKkKcFy6NYXExnPXL for additional details.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/DtJPnaHo1ivRDnCCAqKU"
  },
  {
    "id": "pfqhuuw5jMhMkPfqd5WC",
    "number": "17515693120098385331",
    "begin": "2021-05-05T02:25:17+00:00",
    "created": "2021-05-05T02:25:19+00:00",
    "end": "2021-05-05T04:55:24+00:00",
    "modified": "2021-05-05T04:55:24+00:00",
    "external_desc": "Requests to and from Google Kubernetes Engine Instances in us-west2 may see increase traffic loss when using the instance's public IP",
    "updates": [
      {
        "created": "2021-05-05T04:55:21+00:00",
        "modified": "2021-05-05T04:55:23+00:00",
        "when": "2021-05-05T04:55:21+00:00",
        "text": "The issue with Google Kubernetes Engine has been resolved for all affected users as of approximately Tuesday, 2021-05-04 21:15 US/Pacific.\nPlease follow https://status.cloud.google.com/incidents/eCPQKkKcFy6NYXExnPXL for additional details.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-05T02:25:19+00:00",
        "modified": "2021-05-05T02:25:20+00:00",
        "when": "2021-05-05T02:25:19+00:00",
        "text": "Summary: Requests to and from Google Kubernetes Engine Instances in us-west2 may see increase traffic loss when using the instance's public IP\nDescription: We are experiencing an intermittent issue with Google Kubernetes Engine affecting traffic to and from instances in us-west2 when using their public IP, beginning at Tuesday, 2021-05-04 17:37 US/Pacific US/Pacific.\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/eCPQKkKcFy6NYXExnPXL where we will provide the next update by Tuesday, 2021-05-04 20:30 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-05T04:55:21+00:00",
      "modified": "2021-05-05T04:55:23+00:00",
      "when": "2021-05-05T04:55:21+00:00",
      "text": "The issue with Google Kubernetes Engine has been resolved for all affected users as of approximately Tuesday, 2021-05-04 21:15 US/Pacific.\nPlease follow https://status.cloud.google.com/incidents/eCPQKkKcFy6NYXExnPXL for additional details.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/pfqhuuw5jMhMkPfqd5WC"
  },
  {
    "id": "pxD6QciVMd9gLQGcREbV",
    "number": "11502608644097085691",
    "begin": "2021-05-05T02:11:10+00:00",
    "created": "2021-05-05T02:11:12+00:00",
    "end": "2021-05-05T04:54:57+00:00",
    "modified": "2021-05-05T04:54:57+00:00",
    "external_desc": "Requests to and from Google Compute Instances in us-west2 may see increase traffic loss when using the instance's public IP",
    "updates": [
      {
        "created": "2021-05-05T04:54:57+00:00",
        "modified": "2021-05-05T04:54:57+00:00",
        "when": "2021-05-05T04:54:57+00:00",
        "text": "The issue with Google Compute Engine has been resolved for all affected users as of approximately Tuesday, 2021-05-04 21:15 US/Pacific.\nPlease follow https://status.cloud.google.com/incidents/eCPQKkKcFy6NYXExnPXL for additional details.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-05T02:11:11+00:00",
        "modified": "2021-05-05T02:11:12+00:00",
        "when": "2021-05-05T02:11:11+00:00",
        "text": "Summary: Requests to and from Google Compute Instances in us-west2 may see increase traffic loss when using the instance's public IP\nDescription: We are experiencing an intermittent issue with Google Compute Engine affecting traffic to and from instances in us-west2 when using their public IP, beginning at Tuesday, 2021-05-04 17:37 US/Pacific US/Pacific.\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/eCPQKkKcFy6NYXExnPXL where we will provide the next update by Tuesday, 2021-05-04 20:30 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-05T04:54:57+00:00",
      "modified": "2021-05-05T04:54:57+00:00",
      "when": "2021-05-05T04:54:57+00:00",
      "text": "The issue with Google Compute Engine has been resolved for all affected users as of approximately Tuesday, 2021-05-04 21:15 US/Pacific.\nPlease follow https://status.cloud.google.com/incidents/eCPQKkKcFy6NYXExnPXL for additional details.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/pxD6QciVMd9gLQGcREbV"
  },
  {
    "id": "eCPQKkKcFy6NYXExnPXL",
    "number": "6904062435741399537",
    "begin": "2021-05-04T22:35:00+00:00",
    "created": "2021-05-05T02:03:46+00:00",
    "end": "2021-05-05T04:08:00+00:00",
    "modified": "2021-05-12T16:51:59+00:00",
    "external_desc": "Customers may experience traffic loss across multiple products with requests destined to and from us-west2",
    "updates": [
      {
        "created": "2021-05-06T19:12:31+00:00",
        "modified": "2021-05-12T16:51:40+00:00",
        "when": "2021-05-06T19:12:31+00:00",
        "text": "Following is the Incident Report for the networking outage occurred on May 4th 2021.\n(All Times US/Pacific)\n**Incident Start:** 2021-05-04 15:35\n**Incident End:** 2021-05-04 21:08\n**Duration:**. 5 hours, 33 minutes\n**Affected Services:** Google Cloud Networking, Google Compute Engine (GCE), Google Cloud VMWare Engine, Cloud SQL and Google Kubernetes Engine (GKE)\n**Features:** Cloud VPN, Cloud Interconnect, Google Private Access\n**Regions/Zones:** us-west2\n**Description:**\nGoogle Cloud Platform experienced an outage affecting network traffic in region us-west2 for a duration of 5 hours and 33 minutes. This impacted Internet and Cloud Interconnect connectivity to/from us-west2, including traffic between GCE VMs in the region and Internet endpoints, VM-to-VM traffic over Public IPs, External Network Load Balancing, Cloud VPN Classic (non-HA), and Cloud Interconnect. Cloud VPN HA was not impacted.\n**Root cause and mitigation:**\nThe root cause was a rollout that changed some internal network settings on machines which handle internet routing to Cloud Services. Machines which received the change were unable to receive network programming information. The change caused new TCP connections to establish successfully, but dropped some packets sent between the Control and Data plane (Maglev[1]). Maglevs route traffic from public IPs and interconnects to various endpoints such as Cloud VPN tasks, individual instances, and groups of instances. When a Maglev task first starts, it must be programmed in order to start routing traffic. As independent Maglev Control and Dataplane rollouts restarted tasks, their long-standing TCP connections were reset, and the newly established connections were unable to exchange programming messages. This was mitigated by rolling back the configuration change once the root cause was identified.\n[1] https://research.google/pubs/pub44824\n**Customer Impact:**\n* There were two impact windows, with minor impact from 15:35 to 17:50, and major impact from 17:50 to 21:08.\n* GCE and GKE experienced up to 50% egress and ingress traffic loss in us-west2 for traffic over public IP. Internal IP traffic was not affected.\n* Cloud VPN Classic gateways experienced failure of up to 50% of tunnels.\n* Cloud HA VPN experienced no loss of connectivity for customers with properly configured redundant interfaces.\nInterface 0 of HA VPN gateways experienced up to 70% tunnel failure. Interface 1 was unaffected.\n* Cloud Interconnect experienced ~50% loss.\n* Google Cloud VMWare Engine was impacted where control plane services in the us-west2 region were not reachable by customers. In addition some customers whose VMWare Private Clouds were in the region may have experienced issues with some VMWare services not connecting to their cloud / on-premise networks and/or services.\n* Google services accessed over Interconnect or VPN (e.g. Google Private Access) would have experienced similar loss.\n* Customers using CloudSQL instances in us-west2 may have experienced failed queries or failed connection attempts during the outage.\n**Additional Details:**\n* The issue was mitigated by performing a full rollback of the changes.\n* We are working on improving the testbeds for this type of changes, as well as improvements of our monitoring and visibility for this type of interactions",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-05T04:50:59+00:00",
        "modified": "2021-05-06T19:57:46+00:00",
        "when": "2021-05-05T04:50:59+00:00",
        "text": "The issue with Cloud Networking has been resolved for all affected users as of approximately Tuesday, 2021-05-04 21:15 US/Pacific.\nCustomers affected by this issue observed traffic loss and were unable to reach VPN or Interconnect gateways from and to resources in us-west2 between 2021-05-04 17:37 to 21:15 US/Pacific.\nThe following products were impacted:\nGoogle Compute Engine/Google Kubernetes Engine (Any resources/products using these products may also be impacted):\nMay experience high traffic loss and connections errors from and to us-west2 over public IP. Internal IP traffic should continue work as normal.\nCloud Interconnect/Cloud VPN:\nMay be unable to reach the gateway and high traffic loss.\nGoogle Private Access:\nMay see high packet loss.\nGoogle Compute VMWare Engine\nSome instances may have entered a 'down' state.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-05T03:36:37+00:00",
        "modified": "2021-05-05T03:36:43+00:00",
        "when": "2021-05-05T03:36:37+00:00",
        "text": "Summary: Customers may experience traffic loss across multiple products with requests destined to and from us-west2\nDescription: Our engineering team continues their investigation into this issue.\nAffected customers will see traffic loss and may be unable to reach VPN or Interconnect gateways from and to resources in us-west2 beginning at, Tuesday, 2021-05-04 17:37 US/Pacific.\nThe following products are currently impacted:\nGoogle Compute Engine/Google Kubernetes Engine - May see errors with connections to and from us-west2 over public IP. Internal IP traffic should continue work as normal.\nCloud Interconnect/Cloud VPN - May see some session disconnects and high traffic loss and Google Private Access - May see high packet loss.\nWe will provide an update by Tuesday, 2021-05-04 23:30 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-05-05T02:03:37+00:00",
        "modified": "2021-05-05T02:03:46+00:00",
        "when": "2021-05-05T02:03:37+00:00",
        "text": "Summary: Customers may experience traffic loss across multiple products with requests destined to and from us-west2\nDescription: We are experiencing an intermittent issue with Cloud Networking beginning at Tuesday, 2021-05-04 17:37 US/Pacific.\nThe following products are currently impacted:\nGoogle Compute Engine may see errors with connections to and from us-west2 over public IP. Internal IP traffic should continue work as normal.\nCloud Interconnect - May see some session disconnects\nCloud VPN - May see some session disconnects.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-05-04 20:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-06T19:12:31+00:00",
      "modified": "2021-05-12T16:51:40+00:00",
      "when": "2021-05-06T19:12:31+00:00",
      "text": "Following is the Incident Report for the networking outage occurred on May 4th 2021.\n(All Times US/Pacific)\n**Incident Start:** 2021-05-04 15:35\n**Incident End:** 2021-05-04 21:08\n**Duration:**. 5 hours, 33 minutes\n**Affected Services:** Google Cloud Networking, Google Compute Engine (GCE), Google Cloud VMWare Engine, Cloud SQL and Google Kubernetes Engine (GKE)\n**Features:** Cloud VPN, Cloud Interconnect, Google Private Access\n**Regions/Zones:** us-west2\n**Description:**\nGoogle Cloud Platform experienced an outage affecting network traffic in region us-west2 for a duration of 5 hours and 33 minutes. This impacted Internet and Cloud Interconnect connectivity to/from us-west2, including traffic between GCE VMs in the region and Internet endpoints, VM-to-VM traffic over Public IPs, External Network Load Balancing, Cloud VPN Classic (non-HA), and Cloud Interconnect. Cloud VPN HA was not impacted.\n**Root cause and mitigation:**\nThe root cause was a rollout that changed some internal network settings on machines which handle internet routing to Cloud Services. Machines which received the change were unable to receive network programming information. The change caused new TCP connections to establish successfully, but dropped some packets sent between the Control and Data plane (Maglev[1]). Maglevs route traffic from public IPs and interconnects to various endpoints such as Cloud VPN tasks, individual instances, and groups of instances. When a Maglev task first starts, it must be programmed in order to start routing traffic. As independent Maglev Control and Dataplane rollouts restarted tasks, their long-standing TCP connections were reset, and the newly established connections were unable to exchange programming messages. This was mitigated by rolling back the configuration change once the root cause was identified.\n[1] https://research.google/pubs/pub44824\n**Customer Impact:**\n* There were two impact windows, with minor impact from 15:35 to 17:50, and major impact from 17:50 to 21:08.\n* GCE and GKE experienced up to 50% egress and ingress traffic loss in us-west2 for traffic over public IP. Internal IP traffic was not affected.\n* Cloud VPN Classic gateways experienced failure of up to 50% of tunnels.\n* Cloud HA VPN experienced no loss of connectivity for customers with properly configured redundant interfaces.\nInterface 0 of HA VPN gateways experienced up to 70% tunnel failure. Interface 1 was unaffected.\n* Cloud Interconnect experienced ~50% loss.\n* Google Cloud VMWare Engine was impacted where control plane services in the us-west2 region were not reachable by customers. In addition some customers whose VMWare Private Clouds were in the region may have experienced issues with some VMWare services not connecting to their cloud / on-premise networks and/or services.\n* Google services accessed over Interconnect or VPN (e.g. Google Private Access) would have experienced similar loss.\n* Customers using CloudSQL instances in us-west2 may have experienced failed queries or failed connection attempts during the outage.\n**Additional Details:**\n* The issue was mitigated by performing a full rollback of the changes.\n* We are working on improving the testbeds for this type of changes, as well as improvements of our monitoring and visibility for this type of interactions",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/eCPQKkKcFy6NYXExnPXL"
  },
  {
    "id": "Fmkbw7dfD3MQBbAcFXJu",
    "number": "16818308943050716097",
    "begin": "2021-05-04T08:41:31+00:00",
    "created": "2021-05-04T08:45:54+00:00",
    "end": "2021-05-04T09:00:30+00:00",
    "modified": "2021-05-04T09:00:30+00:00",
    "external_desc": "We are experiencing an issue with Cloud Shell",
    "updates": [
      {
        "created": "2021-05-04T09:00:29+00:00",
        "modified": "2021-05-04T09:00:30+00:00",
        "when": "2021-05-04T09:00:29+00:00",
        "text": "We experienced an issue with Cloud Shell beginning at Tuesday, 2021-05-04 00:51:36 US/Pacific. US/Pacific.\nThe issue has been resolved for all affected projects as of Tuesday, 2021-05-04 01:59 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-05-04T08:45:46+00:00",
        "modified": "2021-05-04T08:45:55+00:00",
        "when": "2021-05-04T08:45:46+00:00",
        "text": "Summary: We are experiencing an issue with Cloud Shell\nDescription: We are experiencing an issue with Cloud Shell in asia-southeast1 beginning at Tuesday, 2021-05-03 03:47 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-05-04 03:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Unable to use Cloud Shell in asia-southeast1.\nWorkaround: Use the shell in a different region.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-05-04T09:00:29+00:00",
      "modified": "2021-05-04T09:00:30+00:00",
      "when": "2021-05-04T09:00:29+00:00",
      "text": "We experienced an issue with Cloud Shell beginning at Tuesday, 2021-05-04 00:51:36 US/Pacific. US/Pacific.\nThe issue has been resolved for all affected projects as of Tuesday, 2021-05-04 01:59 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "Wdsr1n5vyDvCt78qEifm",
    "service_name": "Google Cloud Console",
    "affected_products": [
      {
        "title": "Google Cloud Console",
        "id": "Wdsr1n5vyDvCt78qEifm"
      }
    ],
    "uri": "incidents/Fmkbw7dfD3MQBbAcFXJu"
  },
  {
    "id": "6wryTfuzefvshsv4Pdkn",
    "number": "6412233364700928934",
    "begin": "2021-03-24T22:50:34+00:00",
    "created": "2021-03-24T22:50:39+00:00",
    "end": "2021-03-25T01:10:59+00:00",
    "modified": "2021-03-25T01:10:59+00:00",
    "external_desc": "Customers may experience increased failures when executing Cloud Tasks scheduler jobs in us-central1.",
    "updates": [
      {
        "created": "2021-03-25T01:10:59+00:00",
        "modified": "2021-03-25T01:10:59+00:00",
        "when": "2021-03-25T01:10:59+00:00",
        "text": "The issue affecting job execution for Cloud Tasks. Cloud Scheduler, Appengine Queue and AppEngine Cron should be resolved for all affected users as of Wednesday, 2021-03-24 17:40 US/Pacific.\nJobs impacted by this issue between 13:40 and 17:40 US/Pacific time will need to be manually retried. Jobs scheduled after 17:40 US/Pacific time should not be affected by this issue.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-03-25T00:23:59+00:00",
        "modified": "2021-03-25T00:23:59+00:00",
        "when": "2021-03-25T00:23:59+00:00",
        "text": "Description: We are experiencing an intermittent issue affecting the execution of Cloud Tasks scheduler jobs in us-central1 beginning on Wednesday, 2021-03-24 13:40 US/Pacific.\nMitigation work currently underway by our engineering team.\nThe mitigation is expected to complete by Wednesday, 2021-03-24 18:15 US/Pacific.\nWe will provide more information by Wednesday, 2021-03-24 18:30 US/Pacific.\nDiagnosis: Customers impacted by this issue may see cloud scheduler jobs and App Engine Task Queues not being able to be executed.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-24T23:34:35+00:00",
        "modified": "2021-03-24T23:34:35+00:00",
        "when": "2021-03-24T23:34:35+00:00",
        "text": "Description: We are experiencing an intermittent issue with Cloud Tasks beginning at Wednesday, 2021-03-24 13:40 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-03-24 17:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers impacted by this issue may see cloud scheduler jobs and App Engine Task Queues not being able to be executed.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-24T22:50:39+00:00",
        "modified": "2021-03-24T22:50:39+00:00",
        "when": "2021-03-24T22:50:39+00:00",
        "text": "Description: We are experiencing an intermittent issue with Cloud Tasks beginning at Wednesday, 2021-03-24 14:40 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-03-24 16:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-03-25T01:10:59+00:00",
      "modified": "2021-03-25T01:10:59+00:00",
      "when": "2021-03-25T01:10:59+00:00",
      "text": "The issue affecting job execution for Cloud Tasks. Cloud Scheduler, Appengine Queue and AppEngine Cron should be resolved for all affected users as of Wednesday, 2021-03-24 17:40 US/Pacific.\nJobs impacted by this issue between 13:40 and 17:40 US/Pacific time will need to be manually retried. Jobs scheduled after 17:40 US/Pacific time should not be affected by this issue.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "tMWyzhyKK4rAzAf7x62h",
    "service_name": "Google Cloud Tasks",
    "affected_products": [
      {
        "title": "Google Cloud Tasks",
        "id": "tMWyzhyKK4rAzAf7x62h"
      }
    ],
    "uri": "incidents/6wryTfuzefvshsv4Pdkn"
  },
  {
    "id": "RD6r1QSBrxeKUW58g4pC",
    "number": "17705311542344215847",
    "begin": "2021-03-23T17:09:00+00:00",
    "created": "2021-03-23T20:14:19+00:00",
    "end": "2021-03-24T01:14:19+00:00",
    "modified": "2021-03-24T01:14:19+00:00",
    "external_desc": "Cloud Logging Ingestion delay, causing logs to be delayed.",
    "updates": [
      {
        "created": "2021-03-24T01:14:19+00:00",
        "modified": "2021-03-24T01:14:19+00:00",
        "when": "2021-03-24T01:14:19+00:00",
        "text": "The issue with Cloud Logging has been resolved for all affected projects as of Tuesday, 2021-03-23 18:14 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-03-23T23:25:08+00:00",
        "modified": "2021-03-23T23:25:08+00:00",
        "when": "2021-03-23T23:25:08+00:00",
        "text": "Description: We are still seeing delays decreasing.\nWe estimate that we are down to 25% of projects using the global region impacted. We are still waiting for the backlog in us-west1 to clear.\nWe will provide more information by Tuesday, 2021-03-23 18:00 US/Pacific.\nDiagnosis: Logs may be delayed. Current estimated delays in the following region: 2.2h us-west1\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-23T22:35:48+00:00",
        "modified": "2021-03-23T22:35:48+00:00",
        "when": "2021-03-23T22:35:48+00:00",
        "text": "Description: We are still seeing some recovery and latencies decreasing.\nThe backlog in us-east1 has now cleared and we are estimating the backlog for us-west1 to clear in about 2 hours.\nWe will provide more information by Tuesday, 2021-03-23 16:30 US/Pacific.\nDiagnosis: Logs may be delayed. Current estimated delays in the following region: 2.3h us-west1\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-23T21:48:09+00:00",
        "modified": "2021-03-23T21:48:09+00:00",
        "when": "2021-03-23T21:48:09+00:00",
        "text": "Description: Mitigation work continues by our engineering team. We are starting to see some recovery and latencies decreasing.\nCurrent data indicates that approximately 75% of projects in the global region and about 90% of projects in us-east1 and us-west1 are affected by this issue.\nWe will provide more information by Tuesday, 2021-03-23 15:45 US/Pacific.\nDiagnosis: Logs may be delayed. Current estimated delays in the following regions: 2.5h us-west1, 0.8h us-east1.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-23T21:00:49+00:00",
        "modified": "2021-03-23T21:00:49+00:00",
        "when": "2021-03-23T21:00:49+00:00",
        "text": "Description: Mitigation work continues by our engineering team.\nCurrent data indicates that approximately 75% of projects in multiple regions are affected by this issue.\nThe mitigation is now expected to in place by Tuesday, 2021-03-23 14:30 US/Pacific. However it may take some additional time for the backlog to catch up.\nWe will provide more information by Tuesday, 2021-03-23 14:45 US/Pacific.\nDiagnosis: Logs may be delayed. Current estimated delays in the following regions: 2.3h us-west1, 1.8h us-east1. us-central1 should not be impacted.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-23T20:14:20+00:00",
        "modified": "2021-03-23T20:14:20+00:00",
        "when": "2021-03-23T20:14:20+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team.\nCurrent data indicates that approximately 75% of projects in multiple regions are affected by this issue.\nThe mitigation is expected to in place by Tuesday, 2021-03-23 13:30 US/Pacific. However it may take some additional time for the backlog to catch up.\nWe will provide more information by Tuesday, 2021-03-23 14:00 US/Pacific.\nDiagnosis: Logs appear delayed.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-03-24T01:14:19+00:00",
      "modified": "2021-03-24T01:14:19+00:00",
      "when": "2021-03-24T01:14:19+00:00",
      "text": "The issue with Cloud Logging has been resolved for all affected projects as of Tuesday, 2021-03-23 18:14 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/RD6r1QSBrxeKUW58g4pC"
  },
  {
    "id": "X3wpirSoeRTxHzn3nHFC",
    "number": "924704402691538624",
    "begin": "2021-03-17T15:20:15+00:00",
    "created": "2021-03-17T16:23:50+00:00",
    "end": "2021-03-17T19:50:28+00:00",
    "modified": "2021-03-23T16:38:33+00:00",
    "external_desc": "Increased latency and packet loss",
    "updates": [
      {
        "created": "2021-03-23T16:38:33+00:00",
        "modified": "2021-03-23T16:38:33+00:00",
        "when": "2021-03-23T16:38:33+00:00",
        "text": "# ISSUE SUMMARY\nOn Wednesday 17 March 2021, Google Cloud Networking and Cloud Services that depend on Google's backbone network experienced a service disruption that resulted in increased latency, packet loss, and service unavailable errors for some services for a duration of 3 hours, 39 minutes. Cloud Interconnect had an extended impact duration of 4 hours, 30 minutes. We understand that this issue has impacted our valued customers and users, and we apologize to those who were affected.\n# ROOT CAUSE\nGoogle Cloud datacenters connect to Google’s global Backbone network through a datacenter edge networking stack that uses routers to bridge a region’s network with the global Backbone network. There are multiple roles that routers in Google networks have; some routers are dedicated to providing connectivity to the Google Backbone network, others are dedicated to providing aggregation for customer and peering routes. Google utilizes routers from multiple vendors to provide defense in depth in order to reduce impact for issues that affect a specific router vendor.\nThe trigger for this service disruption was a new set of routers being connected to Google’s backbone network as part of the normal router build process. The routers were part of a new network topology, this topology changed routes that some router roles received. This change in topology inadvertently caused the associated routes to be communicated to routers responsible for providing connectivity to the Google backbone, as well as aggregation routers. This triggered a defect in routers of a specific model, causing their routing process to fail. We previously communicated this defect was unknown; this is incorrect, as after further investigation we found that this defect was previously known, however it was not known to affect routers in these roles. During a routing failure these routers are configured to automatically redirect traffic away to minimize congestion and traffic loss, however, this results in some packet loss while the network reconverges onto new paths. This behavior worked as intended to reduce the potential impact of the issue, as repeated widespread routing process failures have the potential to create cascade failures in the backbone network.\n# REMEDIATION AND PREVENTION\nOnce the nature and scope of the problem became clear, Google engineers isolated the new set of routers from the network to prevent invalid routes being sent to the backbone routers. Once it was confirmed that affected routers were healthy and no longer had invalid routes, and impact for most services had ended, engineers began work to return traffic back to the routers that had rebooted. During this mitigation work to return traffic to a large number of routers, congestion caused a temporary period of increased loss and latency. Once the rebooted routers were back in the traffic path and the network had reconverged, the incident was considered mitigated.\nIn addition to fixing the underlying cause that resulted in invalid routes to trigger routing process failures on specific routers and repairing the bug in the vendor OS, we will be implementing changes to prevent and reduce the impact of this type of failure in several ways:\n1\\. Improve internal tooling for redirecting traffic from routers to reduce time to mitigation for issues with widespread network impact.\n2\\. Improve testing and release process of new router builds to ensure that topology changes for router roles are identified prior to being connected to the backbone network.\nIn addition to these changes, we are also working on long term architectural changes to help prevent issues of this type in the future. These changes will create well defined functional domains in the backbone network to allow for more consistent enforcement of route policies, limiting the scale of potential impact. These policies would provide better systematic protection against routes propagated through the network.\n# DETAILED DESCRIPTION OF IMPACT\nOn Wednesday 17 March 2021 from 08:20 to 12:50 US/Pacific, Google Cloud Networking increased latency, packet loss, and service unavailable errors for traffic between regions and from Google to external endpoints including on-premises environments and the public internet. The issue was mitigated when the source of the invalid routes was isolated by 11:00, and work to redirect traffic back to the affected routers began. During this time, the manual one-time mitigation to return traffic to a large number of routers caused a temporary period of congestion, leading to increased loss and latency between 11:13 and 11:24. Additionally, a set of faulty routers in us-east4 incorrectly had traffic routed to them as part of this mitigation work, which resulted in further impact to the network in that region between 11:08 and 11:59. Finally, Cloud Interconnect had extended impact until 12:50 due to a lack of router vendor redundancy in some interconnect locations.\n#### Compute Engine\nVM to VM inter-regional traffic via public IP’s experienced intermittent packet loss with peaks of up to 42.6%. VM to VM inter-regional traffic via private IP’s experienced intermittent packet loss with peaks of up to 15.6%. Connectivity within a zone was not impacted. The period of impact was between 08:20 and 11:59.\n#### Cloud Load Balancing\nRequests to Cloud load balancers and Cloud CDN experienced increased timeouts, errors of up to 25%, and additional latency between 08:20 and 10:43.\n#### Cloud Interconnect\nCloud interconnect experienced intermittent packet loss for interconnects, with peaks of up to 100% loss lasting several minutes between 08:20 and 12:50. Some interconnect locations did not have sufficient vendor redundancy for routers, resulting in a longer period of impact during traffic redirection.\n#### Cloud VPN\nUp to 13.5% of Cloud VPN tunnels experienced intermittent connectivity loss between 08:29 and 10:46.\n#### Kubernetes Engine\nZonal clusters were impacted due to the impact to Cloud Networking and Compute Engine and experienced increased latency, errors, and packet loss for requests to the Kubernetes control plane. Regional clusters were unaffected due to master node redundancy.\n#### App Engine Flex\nSome App Engine Flex traffic experienced increased latency during the incident.\n#### Cloud Spanner\nCloud Spanner experienced increased latency and increased DEADLINE_EXCEEDED errors in us-central1, us-east1, and europe-west1 from 08:50 to 11:45.\n# ADDITIONAL DETAILS\nThe end time used in the preliminary incident statement was incorrect, as some services had lingering impact after the issue was mitigated. The corrected details for impact times are contained in the above report.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-03-17T21:25:16+00:00",
        "modified": "2021-03-17T21:25:16+00:00",
        "when": "2021-03-17T21:25:16+00:00",
        "text": "Preliminary Incident Statement while full Incident Report is prepared.\n(All Times US/Pacific)\nIncident Start: 2021-03-17 08:26\nIncident End: 2021-03-17 11:00\nDuration: 2 hours, 34 minutes;\n### Affected:\n- Services: Cloud Networking and Cloud Services that depend on Google's backbone network including: Firebase, GCP (Cloud Interconnect, Cloud Partner Interconnect, Cloud VPN, Cloud CDN, Cloud Load Balancers, App Engine, etc.)\n- Features: Network Connectivity\n- Regions/Zones: Multi-region\n### Description:\nGoogle Cloud Platform experienced a multi-region service disruption resulting in intermittent connectivity issues. The root cause was an invalid route that triggered a previously unknown defect in routers of a specific vendor in Google's backbone network causing some to reboot. We have mitigated the issue by isolating the origin of the invalid route and have observed networks stabilize.\n### Customer Impact:\nGoogle Cloud Networking experienced increased latency, packet loss, and service unavailable errors for traffic between regions and from Google to external endpoints including on-premises environments and the internet. Connectivity within a zone was not impacted.\n### Additional Details:\nWe communicated during the disruption that Google Workspace was impacted, however upon further analysis, we have determined that the impact to Google Workspace was negligible.\nGoogle systems are built with a defense in depth strategy in mind. In this disruption, a diverse set of router vendors in our network helped reduce the length and severity of this issue. We will publish an analysis of this incident once we have completed our internal investigation.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-03-17T18:16:28+00:00",
        "modified": "2021-03-17T18:16:28+00:00",
        "when": "2021-03-17T18:16:28+00:00",
        "text": "Our engineering team has implemented a mitigation and is now confident that the issue will not recur.\nImpact to Cloud Networking started improving starting at 10:45 US/Pacific with complete resolution for all users by 11:00 US/Pacific. We will publish an analysis of this incident once we have completed our internal investigation.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-03-17T17:55:26+00:00",
        "modified": "2021-03-17T17:55:26+00:00",
        "when": "2021-03-17T17:55:26+00:00",
        "text": "Description: We are experiencing an intermittent issue with Google Cloud Networking impacting traffic between regions and Google from/to the internet. The issue started occurring intermittently at 08:26 US/Pacific. The issue is impacting Google’s Backbone network and may impact various services when accessing them from a different region or from the internet. Impacted services include Cloud Services (Workspace, Firebase, GCP) as well as other Google properties.\nConnectivity within a zone should not be impacted.\nOur engineering team has implemented a mitigation and is now monitoring the effectiveness of the change.\nWe will provide an update by Wednesday, 2021-03-17 11:30 US/Pacific with current details.\nDiagnosis: Customers impacted by this issue may see high latency, packet loss, and service unavailable errors. The issue manifests itself intermittently and different regions and locations may experience the issue at different times.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-03-17T17:14:21+00:00",
        "modified": "2021-03-17T17:17:17+00:00",
        "when": "2021-03-17T17:14:21+00:00",
        "text": "Description: We are experiencing an intermittent issue with Google Cloud Networking impacting traffic between regions and from Google to the internet. The issue started occurring intermittently at 08:26 US/Pacific. The issue is impacting Google’s Backbone network and may impact various services when accessing them from a different region or from the internet.\nConnectivity within a region should not be impacted.\nThe symptom is understood and our engineering team continues to investigate the issue to find triggers and mitigation.\nWe will provide an update by Wednesday, 2021-03-17 11:00 US/Pacific with current details.\nDiagnosis: Customers impacted by this issue may see high latency, packet loss, and service unavailable errors. The issue manifests itself intermittently and different regions and locations may experience the issue at different times.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-03-17T16:23:51+00:00",
        "modified": "2021-03-17T16:23:51+00:00",
        "when": "2021-03-17T16:23:51+00:00",
        "text": "Description: We are experiencing an intermittent intermittent issue with Cloud Networking.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-03-17 11:00 US/Pacific with current details.\nDiagnosis: High latency, packet loss, and service unavailable.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      }
    ],
    "most_recent_update": {
      "created": "2021-03-23T16:38:33+00:00",
      "modified": "2021-03-23T16:38:33+00:00",
      "when": "2021-03-23T16:38:33+00:00",
      "text": "# ISSUE SUMMARY\nOn Wednesday 17 March 2021, Google Cloud Networking and Cloud Services that depend on Google's backbone network experienced a service disruption that resulted in increased latency, packet loss, and service unavailable errors for some services for a duration of 3 hours, 39 minutes. Cloud Interconnect had an extended impact duration of 4 hours, 30 minutes. We understand that this issue has impacted our valued customers and users, and we apologize to those who were affected.\n# ROOT CAUSE\nGoogle Cloud datacenters connect to Google’s global Backbone network through a datacenter edge networking stack that uses routers to bridge a region’s network with the global Backbone network. There are multiple roles that routers in Google networks have; some routers are dedicated to providing connectivity to the Google Backbone network, others are dedicated to providing aggregation for customer and peering routes. Google utilizes routers from multiple vendors to provide defense in depth in order to reduce impact for issues that affect a specific router vendor.\nThe trigger for this service disruption was a new set of routers being connected to Google’s backbone network as part of the normal router build process. The routers were part of a new network topology, this topology changed routes that some router roles received. This change in topology inadvertently caused the associated routes to be communicated to routers responsible for providing connectivity to the Google backbone, as well as aggregation routers. This triggered a defect in routers of a specific model, causing their routing process to fail. We previously communicated this defect was unknown; this is incorrect, as after further investigation we found that this defect was previously known, however it was not known to affect routers in these roles. During a routing failure these routers are configured to automatically redirect traffic away to minimize congestion and traffic loss, however, this results in some packet loss while the network reconverges onto new paths. This behavior worked as intended to reduce the potential impact of the issue, as repeated widespread routing process failures have the potential to create cascade failures in the backbone network.\n# REMEDIATION AND PREVENTION\nOnce the nature and scope of the problem became clear, Google engineers isolated the new set of routers from the network to prevent invalid routes being sent to the backbone routers. Once it was confirmed that affected routers were healthy and no longer had invalid routes, and impact for most services had ended, engineers began work to return traffic back to the routers that had rebooted. During this mitigation work to return traffic to a large number of routers, congestion caused a temporary period of increased loss and latency. Once the rebooted routers were back in the traffic path and the network had reconverged, the incident was considered mitigated.\nIn addition to fixing the underlying cause that resulted in invalid routes to trigger routing process failures on specific routers and repairing the bug in the vendor OS, we will be implementing changes to prevent and reduce the impact of this type of failure in several ways:\n1\\. Improve internal tooling for redirecting traffic from routers to reduce time to mitigation for issues with widespread network impact.\n2\\. Improve testing and release process of new router builds to ensure that topology changes for router roles are identified prior to being connected to the backbone network.\nIn addition to these changes, we are also working on long term architectural changes to help prevent issues of this type in the future. These changes will create well defined functional domains in the backbone network to allow for more consistent enforcement of route policies, limiting the scale of potential impact. These policies would provide better systematic protection against routes propagated through the network.\n# DETAILED DESCRIPTION OF IMPACT\nOn Wednesday 17 March 2021 from 08:20 to 12:50 US/Pacific, Google Cloud Networking increased latency, packet loss, and service unavailable errors for traffic between regions and from Google to external endpoints including on-premises environments and the public internet. The issue was mitigated when the source of the invalid routes was isolated by 11:00, and work to redirect traffic back to the affected routers began. During this time, the manual one-time mitigation to return traffic to a large number of routers caused a temporary period of congestion, leading to increased loss and latency between 11:13 and 11:24. Additionally, a set of faulty routers in us-east4 incorrectly had traffic routed to them as part of this mitigation work, which resulted in further impact to the network in that region between 11:08 and 11:59. Finally, Cloud Interconnect had extended impact until 12:50 due to a lack of router vendor redundancy in some interconnect locations.\n#### Compute Engine\nVM to VM inter-regional traffic via public IP’s experienced intermittent packet loss with peaks of up to 42.6%. VM to VM inter-regional traffic via private IP’s experienced intermittent packet loss with peaks of up to 15.6%. Connectivity within a zone was not impacted. The period of impact was between 08:20 and 11:59.\n#### Cloud Load Balancing\nRequests to Cloud load balancers and Cloud CDN experienced increased timeouts, errors of up to 25%, and additional latency between 08:20 and 10:43.\n#### Cloud Interconnect\nCloud interconnect experienced intermittent packet loss for interconnects, with peaks of up to 100% loss lasting several minutes between 08:20 and 12:50. Some interconnect locations did not have sufficient vendor redundancy for routers, resulting in a longer period of impact during traffic redirection.\n#### Cloud VPN\nUp to 13.5% of Cloud VPN tunnels experienced intermittent connectivity loss between 08:29 and 10:46.\n#### Kubernetes Engine\nZonal clusters were impacted due to the impact to Cloud Networking and Compute Engine and experienced increased latency, errors, and packet loss for requests to the Kubernetes control plane. Regional clusters were unaffected due to master node redundancy.\n#### App Engine Flex\nSome App Engine Flex traffic experienced increased latency during the incident.\n#### Cloud Spanner\nCloud Spanner experienced increased latency and increased DEADLINE_EXCEEDED errors in us-central1, us-east1, and europe-west1 from 08:50 to 11:45.\n# ADDITIONAL DETAILS\nThe end time used in the preliminary incident statement was incorrect, as some services had lingering impact after the issue was mitigated. The corrected details for impact times are contained in the above report.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_OUTAGE",
    "severity": "high",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/X3wpirSoeRTxHzn3nHFC"
  },
  {
    "id": "DowHEw8KSxHtUD64kPZD",
    "number": "17601965626328413737",
    "begin": "2021-03-08T20:01:54+00:00",
    "created": "2021-03-08T20:01:55+00:00",
    "end": "2021-03-08T20:55:11+00:00",
    "modified": "2021-03-08T20:55:12+00:00",
    "external_desc": "We are investigating a potential issue with Cloud Shell",
    "updates": [
      {
        "created": "2021-03-08T20:55:12+00:00",
        "modified": "2021-03-08T20:55:12+00:00",
        "when": "2021-03-08T20:55:12+00:00",
        "text": "The issue with Google Cloud Shell has been resolved for all affected users as of Monday, 2021-03-08 12:54 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-03-08T20:35:40+00:00",
        "modified": "2021-03-08T20:35:40+00:00",
        "when": "2021-03-08T20:35:40+00:00",
        "text": "Description: We are experiencing an issue with Google Cloud Shell beginning at Monday, 2021-03-08 11:15 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-03-08 13:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Unable to connect to Cloud Shell\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-08T20:01:56+00:00",
        "modified": "2021-03-08T20:01:56+00:00",
        "when": "2021-03-08T20:01:56+00:00",
        "text": "Description: We are investigating a potential issue with Cloud Shell.\nWe will provide more information by Monday, 2021-03-08 12:40 US/Pacific.\nDiagnosis: Unable to connect to Cloud Shell globally\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-03-08T20:55:12+00:00",
      "modified": "2021-03-08T20:55:12+00:00",
      "when": "2021-03-08T20:55:12+00:00",
      "text": "The issue with Google Cloud Shell has been resolved for all affected users as of Monday, 2021-03-08 12:54 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "uoypgc4GWUyzAKRHPjEv",
    "service_name": "Google Cloud Infrastructure Components",
    "affected_products": [
      {
        "title": "Google Cloud Infrastructure Components",
        "id": "uoypgc4GWUyzAKRHPjEv"
      }
    ],
    "uri": "incidents/DowHEw8KSxHtUD64kPZD"
  },
  {
    "id": "kkASrXRsPs9HS1SuiT4J",
    "number": "2698140191854402168",
    "begin": "2021-03-08T18:50:02+00:00",
    "created": "2021-03-08T18:57:23+00:00",
    "end": "2021-03-08T19:24:46+00:00",
    "modified": "2021-03-08T19:24:46+00:00",
    "external_desc": "We are investigating an issue with Cloud Networking",
    "updates": [
      {
        "created": "2021-03-08T19:24:46+00:00",
        "modified": "2021-03-08T19:24:46+00:00",
        "when": "2021-03-08T19:24:46+00:00",
        "text": "The issue with Cloud Networking has been resolved for all affected users as of Monday, 2021-03-08 11:24 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-03-08T19:21:40+00:00",
        "modified": "2021-03-08T19:21:40+00:00",
        "when": "2021-03-08T19:21:40+00:00",
        "text": "Description: We believe the issue with Cloud Networking is partially resolved.\nFull resolution is expected to complete by Monday, 2021-03-08 12:30 US/Pacific.\nWe will provide an update by Monday, 2021-03-08 12:56 US/Pacific with current details.\nDiagnosis: Updates to L7 Load Balancers may not be possible\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-08T18:57:25+00:00",
        "modified": "2021-03-08T18:57:25+00:00",
        "when": "2021-03-08T18:57:25+00:00",
        "text": "Description: We are experiencing an issue with Cloud Networking beginning at Monday,\n2021-03-08 10:28:18 PST US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-03-08 12:42 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Updates to L7 Load Balancers may not be possible\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-03-08T19:24:46+00:00",
      "modified": "2021-03-08T19:24:46+00:00",
      "when": "2021-03-08T19:24:46+00:00",
      "text": "The issue with Cloud Networking has been resolved for all affected users as of Monday, 2021-03-08 11:24 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/kkASrXRsPs9HS1SuiT4J"
  },
  {
    "id": "LxxBg5BwMtL5e53jD3JC",
    "number": "168666198758907770",
    "begin": "2021-03-04T18:15:07+00:00",
    "created": "2021-03-04T18:37:57+00:00",
    "end": "2021-03-05T02:27:55+00:00",
    "modified": "2021-03-05T02:27:55+00:00",
    "external_desc": "Increased latency and possible partial results when listing Cloud SQL instances in us-central1 and us-east1",
    "updates": [
      {
        "created": "2021-03-05T02:27:55+00:00",
        "modified": "2021-03-05T02:27:55+00:00",
        "when": "2021-03-05T02:27:55+00:00",
        "text": "The issue with Cloud SQL is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-03-05T01:15:39+00:00",
        "modified": "2021-03-05T01:15:39+00:00",
        "when": "2021-03-05T01:15:39+00:00",
        "text": "Description: We believe the issue with Cloud SQL list operations is mitigated and we are monitoring for any reoccurrences.\nWe will provide an update by Thursday, 2021-03-04 18:30 US/Pacific with current details.\nDiagnosis: Increased latency when listing Cloud SQL instances and/or a warning error \"REGION_UNREACHABLE\" with partial results.\nWorkaround: None at this time",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-05T00:37:46+00:00",
        "modified": "2021-03-05T00:37:46+00:00",
        "when": "2021-03-05T00:37:46+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team.\nOur engineering believes to have identified the root cause and is applying a fix. We are monitoring for recovery after fix is applied.\nWe will provide more information by Thursday, 2021-03-04 17:15 US/Pacific.\nDiagnosis: Increased latency when listing Cloud SQL instances and/or a warning error \"REGION_UNREACHABLE\" with partial results.\nWorkaround: None at this time",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-04T23:01:27+00:00",
        "modified": "2021-03-04T23:01:27+00:00",
        "when": "2021-03-04T23:01:27+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team. We are continuing to monitor to verify is this helps decrease latency.\nWe will provide more information by Thursday, 2021-03-04 16:30 US/Pacific.\nDiagnosis: Increased latency when listing Cloud SQL instances and/or a warning error \"REGION_UNREACHABLE\" with partial results.\nWorkaround: None at this time",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-04T21:38:09+00:00",
        "modified": "2021-03-04T21:38:09+00:00",
        "when": "2021-03-04T21:38:09+00:00",
        "text": "Description: We are experiencing an issue with Cloud SQL beginning at Tuesday, 2021-03-02 05:30:00 US/Pacific.\nListing Cloud SQL instances in regions us-central1 and us-east1 may experience latency and/or a warning error \"REGION_UNREACHABLE\" with partial results.\nOther operations that do not rely on .List will continue to work.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-03-04 15:00 US/Pacific with current details.\nDiagnosis: Increased latency when listing Cloud SQL instances and/or a warning error \"REGION_UNREACHABLE\" with partial results.\nWorkaround: None at this time",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-04T19:27:15+00:00",
        "modified": "2021-03-04T19:27:15+00:00",
        "when": "2021-03-04T19:27:15+00:00",
        "text": "Description: We are experiencing an issue with Cloud SQL beginning at Tuesday, 2021-03-02 05:30:00 US/Pacific.\nListing Cloud SQL instances in regions us-central1 and us-east1 may experience latency and/or a warning error \"REGION_UNREACHABLE\" with partial results.\nrr\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-03-04 13:30 US/Pacific with current details.\nDiagnosis: Increased latency when listing Cloud SQL instances and/or a warning error \"REGION_UNREACHABLE\" with partial results.\nWorkaround: None at this time",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-03-04T18:37:58+00:00",
        "modified": "2021-03-04T18:37:58+00:00",
        "when": "2021-03-04T18:37:58+00:00",
        "text": "Description: We are experiencing an issue with Cloud SQL beginning at Tuesday, 2021-03-02 05:30:00 US/Pacific.\nListing Cloud SQL instances in regions us-central1 and us-east1 may experience latency and/or a warning error \"REGION_UNREACHABLE\" with partial results.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-03-04 11:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Increased latency when listing Cloud SQL instances and/or a warning error \"REGION_UNREACHABLE\" with partial results.\nWorkaround: None at this time",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-03-05T02:27:55+00:00",
      "modified": "2021-03-05T02:27:55+00:00",
      "when": "2021-03-05T02:27:55+00:00",
      "text": "The issue with Cloud SQL is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "hV87iK5DcEXKgWU2kDri",
    "service_name": "Google Cloud SQL",
    "affected_products": [
      {
        "title": "Google Cloud SQL",
        "id": "hV87iK5DcEXKgWU2kDri"
      }
    ],
    "uri": "incidents/LxxBg5BwMtL5e53jD3JC"
  },
  {
    "id": "jhaWLwL7NZzmvYvdxCYE",
    "number": "9813666090899715275",
    "begin": "2021-02-24T17:04:24+00:00",
    "created": "2021-02-24T17:10:12+00:00",
    "end": "2021-02-24T17:21:14+00:00",
    "modified": "2021-02-24T17:21:14+00:00",
    "external_desc": "Cloud Armor Configuration Updates Are Delayed",
    "updates": [
      {
        "created": "2021-02-24T17:21:14+00:00",
        "modified": "2021-02-24T17:21:14+00:00",
        "when": "2021-02-24T17:21:14+00:00",
        "text": "The issue with Cloud Armor has been resolved for all affected projects as of Wednesday, 2021-02-24 09:20 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-24T17:10:13+00:00",
        "modified": "2021-02-24T17:10:13+00:00",
        "when": "2021-02-24T17:10:13+00:00",
        "text": "Description: We are experiencing an issue with Cloud Armor where configuration updates are delayed beginning at Wednesday, 2021-02-24 08:21 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-02-24 10:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Configuration updates done in Cloud Armor might fail or be delayed.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-24T17:21:14+00:00",
      "modified": "2021-02-24T17:21:14+00:00",
      "when": "2021-02-24T17:21:14+00:00",
      "text": "The issue with Cloud Armor has been resolved for all affected projects as of Wednesday, 2021-02-24 09:20 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/jhaWLwL7NZzmvYvdxCYE"
  },
  {
    "id": "WeoK9qvwzGUoTWHMgYUk",
    "number": "11994537788280801310",
    "begin": "2021-02-24T16:32:46+00:00",
    "created": "2021-02-24T16:32:51+00:00",
    "end": "2021-02-24T17:19:30+00:00",
    "modified": "2021-02-24T17:19:30+00:00",
    "external_desc": "External HTTP(S) Load Balancers can't be created, updated, and deleted.",
    "updates": [
      {
        "created": "2021-02-24T17:19:30+00:00",
        "modified": "2021-02-24T17:19:30+00:00",
        "when": "2021-02-24T17:19:30+00:00",
        "text": "The issue with External HTTP(S) Load Balancers regarding creation, updates and deletions, has been resolved for all affected users as of Wednesday, 2021-02-24 08:55 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-24T17:03:16+00:00",
        "modified": "2021-02-24T17:03:16+00:00",
        "when": "2021-02-24T17:03:16+00:00",
        "text": "Description: We are experiencing an issue with External HTTP(S) Load Balancers beginning at Wednesday, 2021-02-24 07:54 US/Pacific. Existing configurations and Load Balancers are not affected.\nMitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point. However current signs show improvements.\nWe will provide more information by Wednesday, 2021-02-24 09:45 US/Pacific.\nDiagnosis: Any change applied to an External HTTP(S) Load Balancer gets stuck.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-24T16:38:16+00:00",
        "modified": "2021-02-24T16:38:16+00:00",
        "when": "2021-02-24T16:38:16+00:00",
        "text": "Description: We are experiencing an issue with External HTTP(S) Load Balancers beginning at Wednesday, 2021-02-24 07:54 US/Pacific. Existing configurations and Load Balancers are not affected.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-02-24 09:30 US/Pacific with current details. We apologize to all who are affected by the disruption.\nDiagnosis: Any change applied to an External HTTP(S) Load Balancer gets stuck.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-24T16:32:52+00:00",
        "modified": "2021-02-24T16:32:52+00:00",
        "when": "2021-02-24T16:32:52+00:00",
        "text": "Description: We are experiencing an issue with External HTTP(S) Load Balancers beginning at Wednesday, 2021-02-24 07:54 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-02-24 09:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Any change applied to an External HTTP(S) Load Balancer gets stuck.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-24T17:19:30+00:00",
      "modified": "2021-02-24T17:19:30+00:00",
      "when": "2021-02-24T17:19:30+00:00",
      "text": "The issue with External HTTP(S) Load Balancers regarding creation, updates and deletions, has been resolved for all affected users as of Wednesday, 2021-02-24 08:55 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/WeoK9qvwzGUoTWHMgYUk"
  },
  {
    "id": "oAcLVpmWPCrxm3enrP4A",
    "number": "16409202756305816639",
    "begin": "2021-02-24T16:09:33+00:00",
    "created": "2021-02-24T16:39:30+00:00",
    "end": "2021-02-24T17:24:50+00:00",
    "modified": "2021-02-24T17:24:50+00:00",
    "external_desc": "Newly ingested logs may be delayed before being accessible in Cloud Logging",
    "updates": [
      {
        "created": "2021-02-24T17:24:50+00:00",
        "modified": "2021-02-24T17:24:50+00:00",
        "when": "2021-02-24T17:24:50+00:00",
        "text": "The issue with Cloud Logging has been resolved for all affected projects as of Wednesday, 2021-02-24 09:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-24T16:39:30+00:00",
        "modified": "2021-02-24T16:39:30+00:00",
        "when": "2021-02-24T16:39:30+00:00",
        "text": "Description: We are experiencing an issue with Cloud Logging where newly ingested logs may be delayed before being accessible beginning at Wednesday, 2021-02-24 07:45 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2021-02-24 10:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-24T17:24:50+00:00",
      "modified": "2021-02-24T17:24:50+00:00",
      "when": "2021-02-24T17:24:50+00:00",
      "text": "The issue with Cloud Logging has been resolved for all affected projects as of Wednesday, 2021-02-24 09:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/oAcLVpmWPCrxm3enrP4A"
  },
  {
    "id": "QAxXBHLQZey4U51kfV7m",
    "number": "15730199639336203793",
    "begin": "2021-02-19T13:47:53+00:00",
    "created": "2021-02-19T13:50:30+00:00",
    "end": "2021-02-19T22:54:24+00:00",
    "modified": "2021-02-19T22:54:24+00:00",
    "external_desc": "We are experiencing an intermittent issue with Google Kubernetes Engine creation",
    "updates": [
      {
        "created": "2021-02-19T22:54:24+00:00",
        "modified": "2021-02-19T22:54:24+00:00",
        "when": "2021-02-19T22:54:24+00:00",
        "text": "The issue with Google Kubernetes Engine cluster creation is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-19T21:19:29+00:00",
        "modified": "2021-02-19T21:19:29+00:00",
        "when": "2021-02-19T21:19:29+00:00",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine creation.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-02-19 15:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: intermittent issue with GKE cluster creation\nWorkaround: Retry the creation process",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-19T19:17:24+00:00",
        "modified": "2021-02-19T19:17:24+00:00",
        "when": "2021-02-19T19:17:24+00:00",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine creation.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-02-19 13:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: intermittent issue with GKE cluster creation\nWorkaround: Retry the creation process",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-19T18:27:06+00:00",
        "modified": "2021-02-19T18:27:06+00:00",
        "when": "2021-02-19T18:27:06+00:00",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine creation.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-02-19 11:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: intermittent issue with GKE cluster creation\nWorkaround: Retry the creation process",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-19T17:29:51+00:00",
        "modified": "2021-02-19T17:29:51+00:00",
        "when": "2021-02-19T17:29:51+00:00",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine creation.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-02-19 10:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: intermittent issue with GKE cluster creation\nWorkaround: Retry the creation process",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-19T16:05:41+00:00",
        "modified": "2021-02-19T16:05:41+00:00",
        "when": "2021-02-19T16:05:41+00:00",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine creation.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-02-19 09:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: intermittent issue with GKE cluster creation\nWorkaround: Retry the creation process",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-19T13:50:31+00:00",
        "modified": "2021-02-19T13:50:31+00:00",
        "when": "2021-02-19T13:50:31+00:00",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine creation.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-02-19 08:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: intermittent issue with GKE cluster creation\nWorkaround: Retry the creation process",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-19T22:54:24+00:00",
      "modified": "2021-02-19T22:54:24+00:00",
      "when": "2021-02-19T22:54:24+00:00",
      "text": "The issue with Google Kubernetes Engine cluster creation is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/QAxXBHLQZey4U51kfV7m"
  },
  {
    "id": "WxVPiSW1m63mFsYSv2LW",
    "number": "527006311494215468",
    "begin": "2021-02-18T22:31:23+00:00",
    "created": "2021-02-18T22:46:21+00:00",
    "end": "2021-02-19T00:11:05+00:00",
    "modified": "2021-02-19T00:11:06+00:00",
    "external_desc": "Google App Engine Flex deployments are seeing increased errors in us-central1, us-east1 and us-east4, us-west3, europe-west6",
    "updates": [
      {
        "created": "2021-02-19T00:11:05+00:00",
        "modified": "2021-02-19T00:11:05+00:00",
        "when": "2021-02-19T00:11:05+00:00",
        "text": "The issue with Google App Engine Flex deployments seeing increased errors in us-central1, us-east1 and us-east4, us-west3, europe-west6 has been resolved for all affected users as of Thursday, 2021-02-18 15:00 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-18T23:48:23+00:00",
        "modified": "2021-02-18T23:48:23+00:00",
        "when": "2021-02-18T23:48:23+00:00",
        "text": "Description: We believe the issue with Google App Engine deployments in us-central1, us-east1 and us-east4, us-west3, europe-west6 is partially resolved and error rates are improving.\nWe do not have an ETA for full resolution at this point, but are monitoring for full recovery.\nWe will provide an update by Thursday, 2021-02-18 16:30 US/Pacific with current details.\nDiagnosis: Customers impacted by this issue may see an increase in errors when deploying new versions of App Engine Flex applications.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-18T23:12:01+00:00",
        "modified": "2021-02-18T23:12:01+00:00",
        "when": "2021-02-18T23:12:01+00:00",
        "text": "Description: We've received a report of an issue with Google App Engine Flex deployments in us-central1, us-east1 and us-east4, us-west3, europe-west6 as of Thursday, 2021-02-18 12:54 US/Pacific. Mitigation appears to be effective and error rates are decreasing. We are working to speed up a full recovery and continuing to monitor the situation.\nExisting deployments are not impacted.\nWe will provide more information by Thursday, 2021-02-18 15:45 US/Pacific.\nLocations:\n* us-east1\n* europe-west6\n* us-east4\n* us-central1\n* us-west3\nDiagnosis: Customers impacted by this issue may see an increase in errors when deploying new versions of App Engine Flex applications.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-18T22:46:21+00:00",
        "modified": "2021-02-18T22:46:21+00:00",
        "when": "2021-02-18T22:46:21+00:00",
        "text": "Description: We've received a report of an issue with Google App Engine Flex deployments in us-central1, us-east1 and us-east4, us-west3, europe-west6 as of Thursday, 2021-02-18 12:54 US/Pacific. A mitigation is being deployed and we are monitoring the situation. Existing deployments are not impacted.\nWe will provide more information by Thursday, 2021-02-18 15:30 US/Pacific.\nLocations:\n* us-east1\n* europe-west6\n* us-east4\n* us-central1\n* us-west3\nDiagnosis: Customers impacted by this issue may see an increase in errors when deploying new versions of App Engine Flex applications.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-19T00:11:05+00:00",
      "modified": "2021-02-19T00:11:05+00:00",
      "when": "2021-02-19T00:11:05+00:00",
      "text": "The issue with Google App Engine Flex deployments seeing increased errors in us-central1, us-east1 and us-east4, us-west3, europe-west6 has been resolved for all affected users as of Thursday, 2021-02-18 15:00 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "kchyUtnkMHJWaAva8aYc",
    "service_name": "Google App Engine",
    "affected_products": [
      {
        "title": "Google App Engine",
        "id": "kchyUtnkMHJWaAva8aYc"
      }
    ],
    "uri": "incidents/WxVPiSW1m63mFsYSv2LW"
  },
  {
    "id": "rf3TWPFD9xQxK7eXZX2K",
    "number": "9206866244601068394",
    "begin": "2021-02-18T21:43:44+00:00",
    "created": "2021-02-18T22:42:00+00:00",
    "end": "2021-02-18T23:43:06+00:00",
    "modified": "2021-02-18T23:43:07+00:00",
    "external_desc": "Cloud Function deployments are seeing increased errors in us-central1, us-east1 and us-east4",
    "updates": [
      {
        "created": "2021-02-18T23:43:07+00:00",
        "modified": "2021-02-18T23:43:07+00:00",
        "when": "2021-02-18T23:43:07+00:00",
        "text": "The issue with Google Cloud Functions deployments experiencing increased errors in us-central1, us-east1 and us-east4 has been resolved for all affected users as of Thursday, 2021-02-18 15:42 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-18T23:11:33+00:00",
        "modified": "2021-02-18T23:11:33+00:00",
        "when": "2021-02-18T23:11:33+00:00",
        "text": "Description: We've received a report of an issue with Google Cloud Functions deployments in us-central1, us-east1, and us-east4 as of Thursday, 2021-02-18 12:54 US/Pacific. Mitigation appears to be effective and error rates are decreasing. We are working to speed up a full recovery and continuing to monitor the situation.\nWe will provide more information by Thursday, 2021-02-18 15:45 US/Pacific.\nLocations:\n* us-central1\n* us-east1\n* us-east4\nDiagnosis: Customers impacted by this issue may see increased errors deploying new versions of cloud functions in the impacted regions.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-18T22:42:01+00:00",
        "modified": "2021-02-18T22:42:01+00:00",
        "when": "2021-02-18T22:42:01+00:00",
        "text": "Description: We've received a report of an issue with Google Cloud Functions deployments in us-central1, us-east1, and us-east4 as of Thursday, 2021-02-18 12:54 US/Pacific. A mitigation is being deployed and we are monitoring the situation. Existing deployments are not impacted.\nWe will provide more information by Thursday, 2021-02-18 15:30 US/Pacific.\nLocations:\n* us-central1\n* us-east1\n* us-east4\nDiagnosis: Customers impacted by this issue may see increased errors deploying new versions of cloud functions in the impacted regions.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-18T23:43:07+00:00",
      "modified": "2021-02-18T23:43:07+00:00",
      "when": "2021-02-18T23:43:07+00:00",
      "text": "The issue with Google Cloud Functions deployments experiencing increased errors in us-central1, us-east1 and us-east4 has been resolved for all affected users as of Thursday, 2021-02-18 15:42 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "oW4vJ7VNqyxTWNzSHopX",
    "service_name": "Google Cloud Functions",
    "affected_products": [
      {
        "title": "Google Cloud Functions",
        "id": "oW4vJ7VNqyxTWNzSHopX"
      }
    ],
    "uri": "incidents/rf3TWPFD9xQxK7eXZX2K"
  },
  {
    "id": "8PE2WjKBY7g4bVzMQfab",
    "number": "8876775928510522122",
    "begin": "2021-02-18T21:18:09+00:00",
    "created": "2021-02-18T22:17:54+00:00",
    "end": "2021-02-19T00:59:43+00:00",
    "modified": "2021-02-19T00:59:44+00:00",
    "external_desc": "The issue with Google Compute Engine VM instance creation and deletion is partially resolved as of 15:14 US/Pacific.",
    "updates": [
      {
        "created": "2021-02-19T00:59:44+00:00",
        "modified": "2021-02-19T00:59:44+00:00",
        "when": "2021-02-19T00:59:44+00:00",
        "text": "The issue with Google Compute Engine VM creation and deletion has been resolved for all affected projects as of Thursday, 2021-02-18 16:56 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-19T00:45:17+00:00",
        "modified": "2021-02-19T00:45:17+00:00",
        "when": "2021-02-19T00:45:17+00:00",
        "text": "Description: The issue with Google Compute Engine VM instance creation and deletion is partially resolved. New VM instance creation and deletion requests as of 15:14 US/Pacific should succeed.\nWe are working through a backlog of creation and deletion requests that should complete in the next few hours and users may continue to see issues while we process this backlog.\nWe will provide an update by Thursday, 2021-02-18 18:00 US/Pacific with current details.\nDiagnosis: Users impacted by this may have been unable to create new instances in us-central1, any products that rely on creating GCE instances in us-central1 as part of a workflow may also have seen an increase in errors. Delete operations may also have experienced latency.\nWorkaround: Retrying operations may succeed.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-18T23:54:35+00:00",
        "modified": "2021-02-18T23:54:35+00:00",
        "when": "2021-02-18T23:54:35+00:00",
        "text": "Description: We believe the issue with Google Compute Engine VM instance creation and deletion is partially resolved. New VM instance creation requests as of 15:14 US/Pacific should succeed. We are working through a backlog of creation requests that should complete in the next few hours.\nCurrent list of known impacted products in us-central1:\nCompute Engine\nKubernetes Engine\nCloud AI\nCloud SQL\nCloud Dataproc\nWe will provide an update by Thursday, 2021-02-18 16:30 US/Pacific with current details.\nDiagnosis: Users impacted by this may have been unable to create new instances in us-central1, any products that rely on creating GCE instances in us-central1 as part of a workflow may also have seen an increase in errors. Delete operations may also have experienced latency.\nWorkaround: Retrying operations may succeed.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-18T23:11:33+00:00",
        "modified": "2021-02-18T23:11:33+00:00",
        "when": "2021-02-18T23:11:33+00:00",
        "text": "Description: We are beginning to see recovery from applying the mitigation. We are continuing to monitor and exploring methods of increasing the rate of recovery.\nCurrent list of known impacted products in us-central1:\nCompute Engine\nKubernetes Engine\nApp Engine Flex\nCloud Functions\nCloud AI\nCloud SQL\nCloud Memorystore\nCloud Filestore\nCloud Dataproc\nCloud Dataflow\nWe will provide an update by Thursday, 2021-02-18 15:45 US/Pacific with current details.\nDiagnosis: Users may be unable to create new instances in us-central1, any products that rely on creating GCE instances in us-central1 as part of a workflow may also see an increase in errors. Delete operations may also experience latency.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-18T22:51:52+00:00",
        "modified": "2021-02-18T22:51:52+00:00",
        "when": "2021-02-18T22:51:52+00:00",
        "text": "Description: We are experiencing an issue with Google Compute Engine VM Instance creation in us-central1 beginning at Thursday, 2021-02-18 12:13 US/Pacific. We have begun rolling out a mitigation for the issue and are continuing to monitor.\nCurrent list of known impacted products:\nCompute Engine\nKubernetes Engine\nApp Engine Flex\nCloud Functions\nCloud AI\nWe will provide an update by Thursday, 2021-02-18 15:15 US/Pacific with current details.\nDiagnosis: Users may be unable to create new VMs in us-central1, any products that rely on creating GCE instances in us-central1 as part of a workflow may also see an increase in errors.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-18T22:17:56+00:00",
        "modified": "2021-02-18T22:17:56+00:00",
        "when": "2021-02-18T22:17:56+00:00",
        "text": "Description: We are experiencing an issue with Google Compute Engine VM Instance creation in us-central1 beginning at Thursday, 2021-02-18 12:13 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2021-02-18 14:45 US/Pacific with current details.\nDiagnosis: Users may be unable to create new VMs in us-central1, any products that rely on GCE will be impacted by this.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-19T00:59:44+00:00",
      "modified": "2021-02-19T00:59:44+00:00",
      "when": "2021-02-19T00:59:44+00:00",
      "text": "The issue with Google Compute Engine VM creation and deletion has been resolved for all affected projects as of Thursday, 2021-02-18 16:56 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/8PE2WjKBY7g4bVzMQfab"
  },
  {
    "id": "HQ2CbcaHVXG6HHCnAchB",
    "number": "10292813218239098276",
    "begin": "2021-02-18T20:13:00+00:00",
    "created": "2021-02-18T23:06:39+00:00",
    "end": "2021-02-19T00:13:25+00:00",
    "modified": "2021-02-19T00:13:26+00:00",
    "external_desc": "We are experiencing an issue with Cloud SQL instances in us-central1 starting at 12:13 US/Pacific.",
    "updates": [
      {
        "created": "2021-02-19T00:13:25+00:00",
        "modified": "2021-02-19T00:13:25+00:00",
        "when": "2021-02-19T00:13:25+00:00",
        "text": "Our engineers have determined this issue was mitigated at 15:46 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-18T23:06:39+00:00",
        "modified": "2021-02-18T23:06:39+00:00",
        "when": "2021-02-18T23:06:39+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-19T00:13:25+00:00",
      "modified": "2021-02-19T00:13:25+00:00",
      "when": "2021-02-19T00:13:25+00:00",
      "text": "Our engineers have determined this issue was mitigated at 15:46 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "hV87iK5DcEXKgWU2kDri",
    "service_name": "Google Cloud SQL",
    "affected_products": [
      {
        "title": "Google Cloud SQL",
        "id": "hV87iK5DcEXKgWU2kDri"
      }
    ],
    "uri": "incidents/HQ2CbcaHVXG6HHCnAchB"
  },
  {
    "id": "dTWWxQj3YWmTvK1X8hE3",
    "number": "2079265032955529488",
    "begin": "2021-02-18T20:13:00+00:00",
    "created": "2021-02-18T23:21:40+00:00",
    "end": "2021-02-19T00:47:04+00:00",
    "modified": "2021-02-19T00:47:05+00:00",
    "external_desc": "We are experiencing an issue with Cloud Dataproc in us-central1 starting at 12:13 US/Pacific.",
    "updates": [
      {
        "created": "2021-02-19T00:47:05+00:00",
        "modified": "2021-02-19T00:47:05+00:00",
        "when": "2021-02-19T00:47:05+00:00",
        "text": "Our engineers have determined this issue was mitigated at 16:14 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-18T23:21:40+00:00",
        "modified": "2021-02-18T23:21:40+00:00",
        "when": "2021-02-18T23:21:40+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-19T00:47:05+00:00",
      "modified": "2021-02-19T00:47:05+00:00",
      "when": "2021-02-19T00:47:05+00:00",
      "text": "Our engineers have determined this issue was mitigated at 16:14 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "yjXrEg3Yvy26BauMwr69",
    "service_name": "Google Cloud Dataproc",
    "affected_products": [
      {
        "title": "Google Cloud Dataproc",
        "id": "yjXrEg3Yvy26BauMwr69"
      }
    ],
    "uri": "incidents/dTWWxQj3YWmTvK1X8hE3"
  },
  {
    "id": "hY79QaoMeJj48m2SXvmB",
    "number": "6726739196998586419",
    "begin": "2021-02-18T20:13:00+00:00",
    "created": "2021-02-18T22:44:37+00:00",
    "end": "2021-02-19T00:15:35+00:00",
    "modified": "2021-02-19T00:15:35+00:00",
    "external_desc": "We are experiencing an issue with Google Kubernetes Engine in us-central1 starting at 12:13 US/Pacific.",
    "updates": [
      {
        "created": "2021-02-19T00:15:35+00:00",
        "modified": "2021-02-19T00:15:35+00:00",
        "when": "2021-02-19T00:15:35+00:00",
        "text": "Our engineers have determined this issue was mitigated at 16:05 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-18T22:44:37+00:00",
        "modified": "2021-02-18T22:44:37+00:00",
        "when": "2021-02-18T22:44:37+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-19T00:15:35+00:00",
      "modified": "2021-02-19T00:15:35+00:00",
      "when": "2021-02-19T00:15:35+00:00",
      "text": "Our engineers have determined this issue was mitigated at 16:05 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/hY79QaoMeJj48m2SXvmB"
  },
  {
    "id": "N6p8aF8qA3xcehTB6pPZ",
    "number": "10889676128060988366",
    "begin": "2021-02-18T20:13:00+00:00",
    "created": "2021-02-18T23:20:01+00:00",
    "end": "2021-02-18T23:58:49+00:00",
    "modified": "2021-02-18T23:58:49+00:00",
    "external_desc": "We are experiencing an issue with Cloud Filestore in us-central1 starting at 12:13 US/Pacific.",
    "updates": [
      {
        "created": "2021-02-18T23:58:49+00:00",
        "modified": "2021-02-18T23:58:49+00:00",
        "when": "2021-02-18T23:58:49+00:00",
        "text": "Our engineers have determined this issue was mitigated at 15:28 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-18T23:20:01+00:00",
        "modified": "2021-02-18T23:20:01+00:00",
        "when": "2021-02-18T23:20:01+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-18T23:58:49+00:00",
      "modified": "2021-02-18T23:58:49+00:00",
      "when": "2021-02-18T23:58:49+00:00",
      "text": "Our engineers have determined this issue was mitigated at 15:28 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "jog4nyYkquiLeSK5s26q",
    "service_name": "Cloud Filestore",
    "affected_products": [
      {
        "title": "Cloud Filestore",
        "id": "jog4nyYkquiLeSK5s26q"
      }
    ],
    "uri": "incidents/N6p8aF8qA3xcehTB6pPZ"
  },
  {
    "id": "bWW1KUmjBhZWnE9cHWfV",
    "number": "17891349094795474682",
    "begin": "2021-02-18T20:13:00+00:00",
    "created": "2021-02-18T23:17:02+00:00",
    "end": "2021-02-18T23:59:42+00:00",
    "modified": "2021-02-18T23:59:43+00:00",
    "external_desc": "We are experiencing an issue with Cloud Memorystore in us-central1 starting at 12:13 US/Pacific.",
    "updates": [
      {
        "created": "2021-02-18T23:59:43+00:00",
        "modified": "2021-02-18T23:59:43+00:00",
        "when": "2021-02-18T23:59:43+00:00",
        "text": "Our engineers have determined this issue was mitigated at 15:28 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-18T23:17:02+00:00",
        "modified": "2021-02-18T23:17:02+00:00",
        "when": "2021-02-18T23:17:02+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-18T23:59:43+00:00",
      "modified": "2021-02-18T23:59:43+00:00",
      "when": "2021-02-18T23:59:43+00:00",
      "text": "Our engineers have determined this issue was mitigated at 15:28 PST. Please visit https://status.cloud.google.com/incident/compute/21002 for further details.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LGPLu3M5pcUAKU1z6eP3",
    "service_name": "Cloud Memorystore",
    "affected_products": [
      {
        "title": "Cloud Memorystore",
        "id": "LGPLu3M5pcUAKU1z6eP3"
      }
    ],
    "uri": "incidents/bWW1KUmjBhZWnE9cHWfV"
  },
  {
    "id": "UK3LcXtsL7sW9g8TZkJM",
    "number": "8078011420978358670",
    "begin": "2021-02-18T20:13:00+00:00",
    "created": "2021-02-18T23:05:15+00:00",
    "end": "2021-02-19T00:48:39+00:00",
    "modified": "2021-02-19T01:32:47+00:00",
    "external_desc": "We are experiencing an issue with Cloud AI in us-central1 starting at 12:13 US/Pacific.",
    "updates": [
      {
        "created": "2021-02-18T23:05:15+00:00",
        "modified": "2021-02-18T23:05:15+00:00",
        "when": "2021-02-18T23:05:15+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-18T23:05:15+00:00",
      "modified": "2021-02-18T23:05:15+00:00",
      "when": "2021-02-18T23:05:15+00:00",
      "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/compute/21002. No further updates will be made through this incident.",
      "status": "SERVICE_DISRUPTION"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "z9PfKanGZYvYNUbnKzRJ",
    "service_name": "Cloud Machine Learning",
    "affected_products": [
      {
        "title": "Cloud Machine Learning",
        "id": "z9PfKanGZYvYNUbnKzRJ"
      }
    ],
    "uri": "incidents/UK3LcXtsL7sW9g8TZkJM"
  },
  {
    "id": "tqwPWZHj8thosqR5MJkp",
    "number": "1051829891270894049",
    "begin": "2021-02-12T22:51:10+00:00",
    "created": "2021-02-13T00:10:58+00:00",
    "end": "2021-02-13T02:55:46+00:00",
    "modified": "2021-02-19T17:05:12+00:00",
    "external_desc": "The issue with network configuration propagating for Cloud Networking VPN, Network Load Balancer VIPs, and VM Instances in multiple regions is resolved.",
    "updates": [
      {
        "created": "2021-02-19T17:03:00+00:00",
        "modified": "2021-02-19T17:05:12+00:00",
        "when": "2021-02-19T17:03:00+00:00",
        "text": "# ISSUE SUMMARY\nOn Friday, 12 February 2021, Google Cloud Networking experienced elevated packet loss for newly created, updated, deleted or migrated virtual machines (VMs) and network endpoints for a duration of 4 hours, 4 minutes. Network programming for VMs and network endpoints was also affected for the duration. To our customers whose businesses were impacted during this service disruption, we sincerely apologize – this is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability.\n# ROOT CAUSE\nGoogle Cloud's networking control plane has global components that are responsible for fanning-out network configurations that can affect an entire Virtual Private Cloud (VPC) network to downstream (regional/zonal) networking controllers. Work has been ongoing to better isolate global networking control plane components to limit scope of impact for issues that affect these global components. Cloud Networking also relies on a suite of automation tools to manage and enforce the quota of resources allocated to VPC networks. Some quotas are enforced with logic that will automatically remove resources when the quota is decreased, and reprocess previous resource operations when quota is increased.\nThe circumstances that led to this was a latent issue in the control plane quota enforcement logic. During routine handling of peering quota change requests, previous operations that were rejected due to a lack of available quota were being re-evaluated and re-processed by the networking control plane. While doing this re-evaluation, the networking control plane encountered the latent issue and could not process other incoming network programming operations, triggering timeouts for those requests. As VPC resources are multi-regional in nature, this also meant that newly created, updated, deleted or migrated VM resources in regions that required programming on the network control plane were not able to establish connectivity, resulting in elevated packet loss.\n# REMEDIATION AND PREVENTION\nOnce the nature and scope of the issue became clear, Google engineers paused VM migrations globally to prevent existing instances from being impacted. Networking quota changes were also paused to prevent a recurrence until a fix had been rolled out. The issue trigger was isolated to update operations, not initial load operations, so a rolling restart of the networking control plane was triggered to mitigate the issue. Teams worked through the weekend to ensure that recurrence was not possible by rolling out a fix globally.\nIn addition to fixing the underlying cause, we will be implementing changes to prevent and reduce the impact of this type of failure in several ways:\n1\\. Add health checks and automated restarts when the networking control plane responsible for peering operations becomes unresponsive\n2\\. Continue work to regionalize network control plane components to reduce scope of impact for future issues of this type\n3\\. Automatically pause VM migrations when high numbers of VMs are exhibiting networking issues\n4\\. Improve monitoring of network control plane operations to decrease time to mitigation for issues of this type\n5\\. Improve networking data plane resilience when the networking control plane is unresponsive\n# DETAILED DESCRIPTION OF IMPACT\nOn Friday 12 February, 2021 from 14:51 to 18:55 US/Pacific, Cloud Networking control plane operations experienced increased error rates, and experienced elevated packet loss for both inter- and intra-region traffic.\n#### Cloud Networking\nElevated control plane operation error rates of up to 15% in most regions except for us-central1. Region us-central1 experienced elevated control plane error rates of up to 50% between 15:00 and 16:15, dropping to values similar to other regions by 16:45. VM to VM traffic experienced up to 2.5% packet loss for intra-region traffic, and up to 3.5% loss for inter-region traffic.\n#### Cloud VPN\n1.4% of Cloud VPN tunnels in us-central1 lost connectivity from 15:12 to 17:00.\n#### Cloud Interconnect\nChanges to Cloud Interconnect resources experienced delayed propagation or failures during the incident.\n#### Compute Engine (GCE)\nNewly created, updated, deleted or migrated VMs failed to have networking set up during the incident. Existing instances that were not migrated or updated during the incident were not impacted.\n#### Kubernetes Engine (GKE)\nApproximately 1000 clusters were affected by the inability to provision new clusters or nodes. Node availability was impacted due to the impact to Cloud Networking and GCE instances for the duration of the incident.\n#### Cloud Dataproc\nCluster creation and update operations that created new nodes experienced failures during the incident due to the impact to GCE VM networking.\n#### Cloud Shell\nCloud Shell users assigned to us-central1 were unable to connect to Cloud Shell. Existing sessions were unaffected.\n#### Cloud SQL\n6.3% of instance creation operations failed globally between 14:55 and 17:52. Maintenance operations failed or timed out during the incident, but did not impact data plane availability on existing instances. Replica creation during the incident resulted in instances in a failed state, and were automatically recovered within 24 hours.\n#### Cloud Memorystore\nUp to 100% of instance creations failed between 15:15 and 18:20. Instances that were being live-migrated came up on new hosts without networking and faced connectivity issues until they recovered automatically.\n#### Cloud Data Fusion\nCloud Data Fusion instance creations failed during the incident due to failure to create GKE and Cloud SQL instances.\n#### Filestore\nA small number of Filestore instances were live-migrated during the incident. These newly migrated instances lost networking after the live migration before recovering on their own.\n#### Cloud Load Balancing\nCreate and update requests for global L7 external load balancers experienced up to 98% error rate between 15:17 and 18:15, and error rates up to 50% between 18:15 and 18:33. Create and update requests for regional L7 internal load balancers experienced up to 10% error rates, with us-central1 experiencing up to 70% error rates between 15:10 and 17:02.\n#### App Engine Flex\nUp to 80% of new deployments to App Engine Flex failed during the incident.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T03:55:46+00:00",
        "modified": "2021-02-13T03:55:46+00:00",
        "when": "2021-02-13T03:55:46+00:00",
        "text": "The issue with network configuration propagating for Cloud Networking VPN, Network Load Balancer VIPs, and VM Instances in multiple regions has been resolved for all affected projects as of Friday, 2021-02-12 18:55 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T03:10:34+00:00",
        "modified": "2021-02-13T03:10:34+00:00",
        "when": "2021-02-13T03:10:34+00:00",
        "text": "Description: The mitigation has rolled out to all regions. We will continue to monitor the situation to ensure the issue does not recur before declaring full resolution.\nAll affected products should be recovered.\nWe will provide an update by Friday, 2021-02-12 20:00 US/Pacific\nDiagnosis: None at this time.\nWorkaround: Customers should now be able to continue using products as normal.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T02:26:41+00:00",
        "modified": "2021-02-13T02:26:41+00:00",
        "when": "2021-02-13T02:26:41+00:00",
        "text": "Description: Mitigation work is progressing as expected and we are continuing to see recovery. Mitigation is continuing to roll out in other regions. Mitigation is still expected to complete by 19:00 US/Pacific.\nNetwork connectivity within us-central1 should be fully recovered, however, some connectivity issues to other regions may persist while the mitigation completes roll out.\nCurrent known impacted products:\nCompute Engine\nCloud SQL\nDataproc\nMemorystore\nApp Engine Flex\nCloud Composer\nKubernetes Engine\nCloud Data Fusion\nWe will provide an update by Friday, 2021-02-12 19:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using Cloud VPN, creating new Network Load Balancer VIPs, and new VM Instances may not be able to achieve external connectivity. Existing configurations should be unaffected. Instances that have live-migrated within the impact period may experience connectivity loss. Cloud VPN tunnels may have been impacted between 14:50 and 15:31\nThis issue would impact services that rely on instances to function, dataproc cluster creation, new dataflow jobs, and App Engine Flex deployments may also be impacted.\nWorkaround: No workaround at this time. However, to reduce the likelihood of impact customers should pause autoscalers and other systems which may cause changes such as upgrades or deployments.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-13T01:50:09+00:00",
        "modified": "2021-02-13T02:29:39+00:00",
        "when": "2021-02-13T01:50:09+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team and we are continuing to see recovery. We believe that mitigation has fully completed rolling out in the us-central1 region, and we are monitoring for recovery. Mitigation is continuing to roll out in other regions. We estimate mitigation to be fully complete by 19:00 US/Pacific.\nNetwork connectivity within us-central1 should be fully recovered, however, some connectivity issues to other regions may persist while the mitigation completes roll out.\nCurrent known impacted products:\nCompute Engine\nCloud SQL\nDataproc\nMemorystore\nApp Engine Flex\nCloud Composer\nKubernetes Engine\nCloud Data Fusion\nWe will provide an update by Friday, 2021-02-12 18:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using Cloud VPN, creating new Network Load Balancer VIPs, and new VM Instances with external IPs may not be able to achieve external connectivity. Existing configurations should be unaffected. Instances that have live-migrated within the impact period may experience connectivity loss. Cloud VPN tunnels may have been impacted between 14:50 and 15:31\nThis issue would impact services that rely on instances to function, dataproc cluster creation, new dataflow jobs, and App Engine Flex deployments may also be impacted.\nWorkaround: No workaround at this time. However, to reduce the likelihood of impact customers should pause autoscalers and other systems which may cause changes such as upgrades or deployments.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-13T01:06:04+00:00",
        "modified": "2021-02-13T02:30:39+00:00",
        "when": "2021-02-13T01:06:04+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team and we are starting to see recovery.\nWe do not have an ETA for mitigation at this point.\nCurrent known impacted products:\nCompute Engine\nCloud SQL\nDataproc\nMemorystore\nApp Engine Flex\nCloud Composer\nKubernetes Engine\nWe will provide more information by Friday, 2021-02-12 17:45 US/Pacific.\nDiagnosis: Customers using Cloud VPN, creating new Network Load Balancer VIPs, and new VM Instances with external IPs may not be able to achieve external connectivity. Existing configurations should be unaffected.\nThis issue would impact services that rely on instances to function, dataproc cluster creation, new dataflow jobs, and App Engine Flex deployments may also be impacted.\nWorkaround: No workaround at this time. However, to reduce the likelihood of impact customers should pause autoscalers and other systems which may cause changes such as upgrades or deployments.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-13T00:45:03+00:00",
        "modified": "2021-02-13T02:31:01+00:00",
        "when": "2021-02-13T00:45:03+00:00",
        "text": "Description: We are experiencing an issue with network configuration propagation for Cloud Networking VPN, Network Load Balancer VIPs, and VM Instance Public IPs in us-central1 with some impact in: us-east1, europe-west4, europe-west1, asia-east1, asia-northeast1, beginning at Friday, 2021-02-12 14:50 US/Pacific.\nConnectivity for existing configurations should not be impacted.\nCurrent known impacted products:\nCompute Engine\nCloud SQL\nDataproc\nMemorystore\nApp Engine Flex\nCloud Composer\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-02-12 17:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using Cloud VPN, creating new Network Load Balancer VIPs, and new VM Instances with external IPs may not be able to achieve external connectivity. Existing configurations should be unaffected.\nThis issue would impact services that rely on instances to function, dataproc cluster creation, new dataflow jobs, and App Engine Flex deployments may also be impacted.\nWorkaround: No workaround at this time. However, to reduce the likelihood of impact customers should pause autoscalers and other systems which may cause changes such as upgrades or deployments.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-13T00:10:59+00:00",
        "modified": "2021-02-13T00:10:59+00:00",
        "when": "2021-02-13T00:10:59+00:00",
        "text": "Description: We are experiencing an issue with Cloud Networking VPN, Network Load Balancer VIPs, and VM Instance Public IPs in us-east1, us-central1, europe-west4, europe-west1, asia-east1, asia-northeast1, beginning at Friday, 2021-02-12 14:50 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-02-12 17:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using Cloud VPN, creating new Network Load Balancer VIPs, and new VM Instances with external IPs may not be able to achieve external connectivity. Existing configurations should be unaffected.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-19T17:03:00+00:00",
      "modified": "2021-02-19T17:05:12+00:00",
      "when": "2021-02-19T17:03:00+00:00",
      "text": "# ISSUE SUMMARY\nOn Friday, 12 February 2021, Google Cloud Networking experienced elevated packet loss for newly created, updated, deleted or migrated virtual machines (VMs) and network endpoints for a duration of 4 hours, 4 minutes. Network programming for VMs and network endpoints was also affected for the duration. To our customers whose businesses were impacted during this service disruption, we sincerely apologize – this is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability.\n# ROOT CAUSE\nGoogle Cloud's networking control plane has global components that are responsible for fanning-out network configurations that can affect an entire Virtual Private Cloud (VPC) network to downstream (regional/zonal) networking controllers. Work has been ongoing to better isolate global networking control plane components to limit scope of impact for issues that affect these global components. Cloud Networking also relies on a suite of automation tools to manage and enforce the quota of resources allocated to VPC networks. Some quotas are enforced with logic that will automatically remove resources when the quota is decreased, and reprocess previous resource operations when quota is increased.\nThe circumstances that led to this was a latent issue in the control plane quota enforcement logic. During routine handling of peering quota change requests, previous operations that were rejected due to a lack of available quota were being re-evaluated and re-processed by the networking control plane. While doing this re-evaluation, the networking control plane encountered the latent issue and could not process other incoming network programming operations, triggering timeouts for those requests. As VPC resources are multi-regional in nature, this also meant that newly created, updated, deleted or migrated VM resources in regions that required programming on the network control plane were not able to establish connectivity, resulting in elevated packet loss.\n# REMEDIATION AND PREVENTION\nOnce the nature and scope of the issue became clear, Google engineers paused VM migrations globally to prevent existing instances from being impacted. Networking quota changes were also paused to prevent a recurrence until a fix had been rolled out. The issue trigger was isolated to update operations, not initial load operations, so a rolling restart of the networking control plane was triggered to mitigate the issue. Teams worked through the weekend to ensure that recurrence was not possible by rolling out a fix globally.\nIn addition to fixing the underlying cause, we will be implementing changes to prevent and reduce the impact of this type of failure in several ways:\n1\\. Add health checks and automated restarts when the networking control plane responsible for peering operations becomes unresponsive\n2\\. Continue work to regionalize network control plane components to reduce scope of impact for future issues of this type\n3\\. Automatically pause VM migrations when high numbers of VMs are exhibiting networking issues\n4\\. Improve monitoring of network control plane operations to decrease time to mitigation for issues of this type\n5\\. Improve networking data plane resilience when the networking control plane is unresponsive\n# DETAILED DESCRIPTION OF IMPACT\nOn Friday 12 February, 2021 from 14:51 to 18:55 US/Pacific, Cloud Networking control plane operations experienced increased error rates, and experienced elevated packet loss for both inter- and intra-region traffic.\n#### Cloud Networking\nElevated control plane operation error rates of up to 15% in most regions except for us-central1. Region us-central1 experienced elevated control plane error rates of up to 50% between 15:00 and 16:15, dropping to values similar to other regions by 16:45. VM to VM traffic experienced up to 2.5% packet loss for intra-region traffic, and up to 3.5% loss for inter-region traffic.\n#### Cloud VPN\n1.4% of Cloud VPN tunnels in us-central1 lost connectivity from 15:12 to 17:00.\n#### Cloud Interconnect\nChanges to Cloud Interconnect resources experienced delayed propagation or failures during the incident.\n#### Compute Engine (GCE)\nNewly created, updated, deleted or migrated VMs failed to have networking set up during the incident. Existing instances that were not migrated or updated during the incident were not impacted.\n#### Kubernetes Engine (GKE)\nApproximately 1000 clusters were affected by the inability to provision new clusters or nodes. Node availability was impacted due to the impact to Cloud Networking and GCE instances for the duration of the incident.\n#### Cloud Dataproc\nCluster creation and update operations that created new nodes experienced failures during the incident due to the impact to GCE VM networking.\n#### Cloud Shell\nCloud Shell users assigned to us-central1 were unable to connect to Cloud Shell. Existing sessions were unaffected.\n#### Cloud SQL\n6.3% of instance creation operations failed globally between 14:55 and 17:52. Maintenance operations failed or timed out during the incident, but did not impact data plane availability on existing instances. Replica creation during the incident resulted in instances in a failed state, and were automatically recovered within 24 hours.\n#### Cloud Memorystore\nUp to 100% of instance creations failed between 15:15 and 18:20. Instances that were being live-migrated came up on new hosts without networking and faced connectivity issues until they recovered automatically.\n#### Cloud Data Fusion\nCloud Data Fusion instance creations failed during the incident due to failure to create GKE and Cloud SQL instances.\n#### Filestore\nA small number of Filestore instances were live-migrated during the incident. These newly migrated instances lost networking after the live migration before recovering on their own.\n#### Cloud Load Balancing\nCreate and update requests for global L7 external load balancers experienced up to 98% error rate between 15:17 and 18:15, and error rates up to 50% between 18:15 and 18:33. Create and update requests for regional L7 internal load balancers experienced up to 10% error rates, with us-central1 experiencing up to 70% error rates between 15:10 and 17:02.\n#### App Engine Flex\nUp to 80% of new deployments to App Engine Flex failed during the incident.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/tqwPWZHj8thosqR5MJkp"
  },
  {
    "id": "vUyXMVpQyAe9ibYnYcCG",
    "number": "11701989872452202521",
    "begin": "2021-02-12T22:50:18+00:00",
    "created": "2021-02-13T00:24:19+00:00",
    "end": "2021-02-13T03:16:01+00:00",
    "modified": "2021-02-13T03:16:01+00:00",
    "external_desc": "We are experiencing an issue with Google Cloud infrastructure components, beginning at Friday, 2021-02-12 14:50 US/Pacific.",
    "updates": [
      {
        "created": "2021-02-13T03:16:01+00:00",
        "modified": "2021-02-13T03:16:01+00:00",
        "when": "2021-02-13T03:16:01+00:00",
        "text": "For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T00:24:19+00:00",
        "modified": "2021-02-13T00:24:19+00:00",
        "when": "2021-02-13T00:24:19+00:00",
        "text": "Description: We are experiencing an issue with Google Cloud infrastructure components, beginning at Friday, 2021-02-12 14:50 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-02-12 17:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-13T03:16:01+00:00",
      "modified": "2021-02-13T03:16:01+00:00",
      "when": "2021-02-13T03:16:01+00:00",
      "text": "For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "uoypgc4GWUyzAKRHPjEv",
    "service_name": "Google Cloud Infrastructure Components",
    "affected_products": [
      {
        "title": "Google Cloud Infrastructure Components",
        "id": "uoypgc4GWUyzAKRHPjEv"
      }
    ],
    "uri": "incidents/vUyXMVpQyAe9ibYnYcCG"
  },
  {
    "id": "b3FNY44ruufUfCNBPvKQ",
    "number": "10924997862408222651",
    "begin": "2021-02-12T22:50:00+00:00",
    "created": "2021-02-13T01:16:51+00:00",
    "end": "2021-02-13T02:55:00+00:00",
    "modified": "2021-02-13T03:28:12+00:00",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.goog",
    "updates": [
      {
        "created": "2021-02-13T03:28:11+00:00",
        "modified": "2021-02-13T03:28:11+00:00",
        "when": "2021-02-13T03:28:11+00:00",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T01:16:51+00:00",
        "modified": "2021-02-13T01:16:51+00:00",
        "when": "2021-02-13T01:16:51+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-13T03:28:11+00:00",
      "modified": "2021-02-13T03:28:11+00:00",
      "when": "2021-02-13T03:28:11+00:00",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/b3FNY44ruufUfCNBPvKQ"
  },
  {
    "id": "baKKdbZ1M1We5j6y2G9k",
    "number": "17642517881793704043",
    "begin": "2021-02-12T22:50:00+00:00",
    "created": "2021-02-13T00:55:29+00:00",
    "end": "2021-02-13T02:55:00+00:00",
    "modified": "2021-02-13T03:28:02+00:00",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.goog",
    "updates": [
      {
        "created": "2021-02-13T03:28:01+00:00",
        "modified": "2021-02-13T03:28:01+00:00",
        "when": "2021-02-13T03:28:01+00:00",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T00:55:29+00:00",
        "modified": "2021-02-13T00:55:29+00:00",
        "when": "2021-02-13T00:55:29+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-13T03:28:01+00:00",
      "modified": "2021-02-13T03:28:01+00:00",
      "when": "2021-02-13T03:28:01+00:00",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LGPLu3M5pcUAKU1z6eP3",
    "service_name": "Cloud Memorystore",
    "affected_products": [
      {
        "title": "Cloud Memorystore",
        "id": "LGPLu3M5pcUAKU1z6eP3"
      }
    ],
    "uri": "incidents/baKKdbZ1M1We5j6y2G9k"
  },
  {
    "id": "aVUuw5cr7iMM6UbuwyYb",
    "number": "9724640967198945251",
    "begin": "2021-02-12T22:50:00+00:00",
    "created": "2021-02-13T01:43:04+00:00",
    "end": "2021-02-13T02:55:00+00:00",
    "modified": "2021-02-13T03:28:07+00:00",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.goog",
    "updates": [
      {
        "created": "2021-02-13T03:28:07+00:00",
        "modified": "2021-02-13T03:28:07+00:00",
        "when": "2021-02-13T03:28:07+00:00",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T01:43:04+00:00",
        "modified": "2021-02-13T01:43:04+00:00",
        "when": "2021-02-13T01:43:04+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-13T03:28:07+00:00",
      "modified": "2021-02-13T03:28:07+00:00",
      "when": "2021-02-13T03:28:07+00:00",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "rLKDHeeaBiXTeutF1air",
    "service_name": "Cloud Data Fusion",
    "affected_products": [
      {
        "title": "Cloud Data Fusion",
        "id": "rLKDHeeaBiXTeutF1air"
      }
    ],
    "uri": "incidents/aVUuw5cr7iMM6UbuwyYb"
  },
  {
    "id": "jmQo7Yt8Rhb7Bvb7itmF",
    "number": "8783736191556432956",
    "begin": "2021-02-12T22:50:00+00:00",
    "created": "2021-02-13T01:06:56+00:00",
    "end": "2021-02-13T02:55:00+00:00",
    "modified": "2021-02-13T03:28:26+00:00",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.goog",
    "updates": [
      {
        "created": "2021-02-13T03:28:26+00:00",
        "modified": "2021-02-13T03:28:26+00:00",
        "when": "2021-02-13T03:28:26+00:00",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T01:06:56+00:00",
        "modified": "2021-02-13T01:06:56+00:00",
        "when": "2021-02-13T01:06:56+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-13T03:28:26+00:00",
      "modified": "2021-02-13T03:28:26+00:00",
      "when": "2021-02-13T03:28:26+00:00",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "hV87iK5DcEXKgWU2kDri",
    "service_name": "Google Cloud SQL",
    "affected_products": [
      {
        "title": "Google Cloud SQL",
        "id": "hV87iK5DcEXKgWU2kDri"
      }
    ],
    "uri": "incidents/jmQo7Yt8Rhb7Bvb7itmF"
  },
  {
    "id": "QjGHpZrwAdM9i91v1QUy",
    "number": "18283974493806301833",
    "begin": "2021-02-12T22:50:00+00:00",
    "created": "2021-02-13T01:15:31+00:00",
    "end": "2021-02-13T02:55:00+00:00",
    "modified": "2021-02-13T03:28:07+00:00",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.goog",
    "updates": [
      {
        "created": "2021-02-13T03:28:07+00:00",
        "modified": "2021-02-13T03:28:07+00:00",
        "when": "2021-02-13T03:28:07+00:00",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T01:15:32+00:00",
        "modified": "2021-02-13T01:15:32+00:00",
        "when": "2021-02-13T01:15:32+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-13T03:28:07+00:00",
      "modified": "2021-02-13T03:28:07+00:00",
      "when": "2021-02-13T03:28:07+00:00",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/QjGHpZrwAdM9i91v1QUy"
  },
  {
    "id": "PQE98n5aGQZ2gVWJqwi3",
    "number": "10579273867044882431",
    "begin": "2021-02-12T22:50:00+00:00",
    "created": "2021-02-13T01:14:15+00:00",
    "end": "2021-02-13T02:55:00+00:00",
    "modified": "2021-02-13T03:28:20+00:00",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.goog",
    "updates": [
      {
        "created": "2021-02-13T03:28:20+00:00",
        "modified": "2021-02-13T03:28:20+00:00",
        "when": "2021-02-13T03:28:20+00:00",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T01:14:15+00:00",
        "modified": "2021-02-13T01:14:15+00:00",
        "when": "2021-02-13T01:14:15+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-13T03:28:20+00:00",
      "modified": "2021-02-13T03:28:20+00:00",
      "when": "2021-02-13T03:28:20+00:00",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "YxkG5FfcC42cQmvBCk4j",
    "service_name": "Google Cloud Composer",
    "affected_products": [
      {
        "title": "Google Cloud Composer",
        "id": "YxkG5FfcC42cQmvBCk4j"
      }
    ],
    "uri": "incidents/PQE98n5aGQZ2gVWJqwi3"
  },
  {
    "id": "PdFyr6FwVot63cx6Pcrs",
    "number": "6679570468017856979",
    "begin": "2021-02-12T22:50:00+00:00",
    "created": "2021-02-13T00:56:34+00:00",
    "end": "2021-02-13T02:55:00+00:00",
    "modified": "2021-02-13T03:28:03+00:00",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.goog",
    "updates": [
      {
        "created": "2021-02-13T03:28:03+00:00",
        "modified": "2021-02-13T03:28:03+00:00",
        "when": "2021-02-13T03:28:03+00:00",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T00:56:34+00:00",
        "modified": "2021-02-13T00:56:34+00:00",
        "when": "2021-02-13T00:56:34+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-13T03:28:03+00:00",
      "modified": "2021-02-13T03:28:03+00:00",
      "when": "2021-02-13T03:28:03+00:00",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "kchyUtnkMHJWaAva8aYc",
    "service_name": "Google App Engine",
    "affected_products": [
      {
        "title": "Google App Engine",
        "id": "kchyUtnkMHJWaAva8aYc"
      }
    ],
    "uri": "incidents/PdFyr6FwVot63cx6Pcrs"
  },
  {
    "id": "exT9bwgm4CvWu7MzydD3",
    "number": "11566717885938357240",
    "begin": "2021-02-12T22:50:00+00:00",
    "created": "2021-02-13T01:11:09+00:00",
    "end": "2021-02-13T02:55:00+00:00",
    "modified": "2021-02-13T03:27:32+00:00",
    "external_desc": "Our engineers have determined this issue to be linked to a single Google incident. For regular status updates, please visit https://status.cloud.goog",
    "updates": [
      {
        "created": "2021-02-13T03:27:32+00:00",
        "modified": "2021-02-13T03:27:32+00:00",
        "when": "2021-02-13T03:27:32+00:00",
        "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-13T01:11:09+00:00",
        "modified": "2021-02-13T01:11:09+00:00",
        "when": "2021-02-13T01:11:09+00:00",
        "text": "Our engineers have determined this issue to be linked to a single Google\nincident. For regular status updates, please visit https://status.cloud.google.com/incident/cloud-networking/21002. No further updates will be made through this incident.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-13T03:27:32+00:00",
      "modified": "2021-02-13T03:27:32+00:00",
      "when": "2021-02-13T03:27:32+00:00",
      "text": "Our engineers have determined this issue was mitigated at 18:55 PST. Please visit https://status.cloud.google.com/incident/cloud-networking/21002 for further details. No further updates will be made through this incident.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "yjXrEg3Yvy26BauMwr69",
    "service_name": "Google Cloud Dataproc",
    "affected_products": [
      {
        "title": "Google Cloud Dataproc",
        "id": "yjXrEg3Yvy26BauMwr69"
      }
    ],
    "uri": "incidents/exT9bwgm4CvWu7MzydD3"
  },
  {
    "id": "zpowCsUWo6sthoEFHA7n",
    "number": "12134677436007681555",
    "begin": "2021-02-11T19:50:44+00:00",
    "created": "2021-02-11T19:50:45+00:00",
    "end": "2021-02-11T20:05:20+00:00",
    "modified": "2021-02-11T20:05:20+00:00",
    "external_desc": "Cloud Datastore experiencing increased error rates and latencies for operations for data in the US multi-region",
    "updates": [
      {
        "created": "2021-02-11T20:05:20+00:00",
        "modified": "2021-02-11T20:05:20+00:00",
        "when": "2021-02-11T20:05:20+00:00",
        "text": "The issue with Cloud Datastore has been resolved for all affected users as of Thursday, 2021-02-11 12:05 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-11T19:57:03+00:00",
        "modified": "2021-02-11T19:57:03+00:00",
        "when": "2021-02-11T19:57:03+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team and we are noticing error rates and latencies return to normal levels.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2021-02-11 12:30 US/Pacific.\nDiagnosis: Elevated latencies and error rates for requests for data in the US multi-region.\nWorkaround: Retry requests/queries.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-11T19:50:46+00:00",
        "modified": "2021-02-11T19:50:46+00:00",
        "when": "2021-02-11T19:50:46+00:00",
        "text": "Description: We are experiencing an issue with Cloud Datastore where requests affecting data in the US multi-region are experiencing elevated latencies and error rates beginning at Thursday, 2021-02-11 11:09:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nIf you are affected by this issue, please retry requests.\nWe will provide an update by Thursday, 2021-02-11 12:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Elevated latencies and error rates for requests for data in the US multi-region.\nWorkaround: Retry requests/queries.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-11T20:05:20+00:00",
      "modified": "2021-02-11T20:05:20+00:00",
      "when": "2021-02-11T20:05:20+00:00",
      "text": "The issue with Cloud Datastore has been resolved for all affected users as of Thursday, 2021-02-11 12:05 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "MaS3dKoqp1oqkea4qB9U",
    "service_name": "Google Cloud Datastore",
    "affected_products": [
      {
        "title": "Google Cloud Datastore",
        "id": "MaS3dKoqp1oqkea4qB9U"
      }
    ],
    "uri": "incidents/zpowCsUWo6sthoEFHA7n"
  },
  {
    "id": "9K8w3ZFKk26vNrQ8xE9v",
    "number": "13295000902823729006",
    "begin": "2021-02-11T19:30:47+00:00",
    "created": "2021-02-11T19:43:18+00:00",
    "end": "2021-02-11T20:04:40+00:00",
    "modified": "2021-02-11T20:04:40+00:00",
    "external_desc": "Cloud Firestore experiencing increased error rates and latencies for operations for data in the US multi-region",
    "updates": [
      {
        "created": "2021-02-11T20:04:40+00:00",
        "modified": "2021-02-11T20:04:40+00:00",
        "when": "2021-02-11T20:04:40+00:00",
        "text": "The issue with Cloud Firestore has been resolved for all affected users as of Thursday, 2021-02-11 12:04 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-11T19:56:10+00:00",
        "modified": "2021-02-11T19:56:10+00:00",
        "when": "2021-02-11T19:56:10+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team and we are noticing error rates and latencies return to normal levels.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2021-02-11 12:30 US/Pacific.\nDiagnosis: Elevated latencies and error rates for operations on data in the US multi-region. These include, queries, commits, listen API requests, and reads.\nWorkaround: Retry requests/queries.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-11T19:47:41+00:00",
        "modified": "2021-02-11T19:47:41+00:00",
        "when": "2021-02-11T19:47:41+00:00",
        "text": "Description: We are experiencing an issue with Cloud Firestore where operations (commits, listen API, reads, query) in the US multi-region are experiencing elevated latencies and error rates beginning at Thursday, 2021-02-11 11:09:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nIf you are affected by this issue, please retry requests.\nWe will provide an update by Thursday, 2021-02-11 12:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Elevated latencies and error rates for operations on data in the US multi-region. These include, queries, commits, listen API requests, and reads.\nWorkaround: Retry requests/queries.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-11T19:43:18+00:00",
        "modified": "2021-02-11T19:43:18+00:00",
        "when": "2021-02-11T19:43:18+00:00",
        "text": "Description: We are experiencing an issue with Cloud Firestore where operations (commits, listen API, reads, query) in the US multi-region are experiencing elevated latencies and error rates beginning at Thursday, 2021-02-11 11:09:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nIf you are affected by this issue, please retry requests.\nWe will provide an update by Thursday, 2021-02-11 12:18 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Elevated latencies and error rates for operations on data in the US multi-region. These include, queries, commits, listen API requests, and reads.\nWorkaround: Retry requests/queries.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-11T20:04:40+00:00",
      "modified": "2021-02-11T20:04:40+00:00",
      "when": "2021-02-11T20:04:40+00:00",
      "text": "The issue with Cloud Firestore has been resolved for all affected users as of Thursday, 2021-02-11 12:04 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "CETSkT92V21G6A1x28me",
    "service_name": "Cloud Firestore",
    "affected_products": [
      {
        "title": "Cloud Firestore",
        "id": "CETSkT92V21G6A1x28me"
      }
    ],
    "uri": "incidents/9K8w3ZFKk26vNrQ8xE9v"
  },
  {
    "id": "p1HfB8trCBdxqeJbw65U",
    "number": "2030156099454549671",
    "begin": "2021-02-11T19:15:44+00:00",
    "created": "2021-02-11T19:27:53+00:00",
    "end": "2021-02-11T20:11:18+00:00",
    "modified": "2021-02-11T20:11:19+00:00",
    "external_desc": "Google BigQuery experiencing increased error rates and latencies for queries for data in the US multi-region",
    "updates": [
      {
        "created": "2021-02-11T20:11:18+00:00",
        "modified": "2021-02-11T20:11:18+00:00",
        "when": "2021-02-11T20:11:18+00:00",
        "text": "The issue with Google BigQuery has been resolved for all affected users as of Thursday, 2021-02-11 12:05 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-11T19:54:40+00:00",
        "modified": "2021-02-11T19:54:40+00:00",
        "when": "2021-02-11T19:54:40+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team and we are noticing error rates and latencies return to normal levels.\nWe expect mitigation to be complete by Thursday, 2021-02-11 13:00 US/Pacific.\nWe will provide more information by Thursday, 2021-02-11 12:30 US/Pacific.\nDiagnosis: Elevated latencies and error rates for queries for data in the US multi-region.\nWorkaround: Retry requests/queries.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-11T19:46:52+00:00",
        "modified": "2021-02-11T19:46:52+00:00",
        "when": "2021-02-11T19:46:52+00:00",
        "text": "Description: We are experiencing an issue with Google BigQuery where queries for data in the US multi-region are experiencing elevated latencies and error rates beginning at Thursday, 2021-02-11 11:09:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nIf you are affected by this issue, please retry requests.\nWe will provide an update by Thursday, 2021-02-11 12:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Elevated latencies and error rates for queries for data in the US multi-region.\nWorkaround: Retry requests/queries.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-11T19:27:53+00:00",
        "modified": "2021-02-11T19:27:53+00:00",
        "when": "2021-02-11T19:27:53+00:00",
        "text": "Description: We are experiencing an issue with Google BigQuery where queries for data in the US multi-region are experiencing elevated latencies and error rates beginning at Thursday, 2021-02-11 11:09:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nIf you are affected by this issue, please retry requests.\nWe will provide an update by Thursday, 2021-02-11 12:18 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Elevated latencies and error rates for queries for data in the US multi-region.\nWorkaround: Retry requests/queries.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-11T20:11:18+00:00",
      "modified": "2021-02-11T20:11:18+00:00",
      "when": "2021-02-11T20:11:18+00:00",
      "text": "The issue with Google BigQuery has been resolved for all affected users as of Thursday, 2021-02-11 12:05 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "9CcrhHUcFevXPSVaSxkf",
    "service_name": "Google BigQuery",
    "affected_products": [
      {
        "title": "Google BigQuery",
        "id": "9CcrhHUcFevXPSVaSxkf"
      }
    ],
    "uri": "incidents/p1HfB8trCBdxqeJbw65U"
  },
  {
    "id": "sJhprF3We9rWuxTKw5vK",
    "number": "2764523066536573644",
    "begin": "2021-02-11T18:58:00+00:00",
    "created": "2021-02-11T22:07:35+00:00",
    "end": "2021-02-11T19:35:04+00:00",
    "modified": "2021-02-11T22:11:02+00:00",
    "external_desc": "Cloud BigTable is experiencing increased error rates and latencies for operations on data in us-central1-c.",
    "updates": [
      {
        "created": "2021-02-11T22:09:04+00:00",
        "modified": "2021-02-11T22:09:04+00:00",
        "when": "2021-02-11T22:09:04+00:00",
        "text": "The issue with Cloud Bigtable has been resolved for all affected projects as of Thursday, 2021-02-11 11:35 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-11T22:07:35+00:00",
        "modified": "2021-02-11T22:07:35+00:00",
        "when": "2021-02-11T22:07:35+00:00",
        "text": "Cloud BigTable is experiencing increased error rates and latencies for operations on data in us-central1-c starting at Thursday, 2021-02-11 11:58 US/Pacific.\nThe issue with Cloud Bigtable has been resolved for all affected projects as of Thursday, 2021-02-11 11:35 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-11T22:09:04+00:00",
      "modified": "2021-02-11T22:09:04+00:00",
      "when": "2021-02-11T22:09:04+00:00",
      "text": "The issue with Cloud Bigtable has been resolved for all affected projects as of Thursday, 2021-02-11 11:35 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LfZSuE3xdQU46YMFV5fy",
    "service_name": "Google Cloud Bigtable",
    "affected_products": [
      {
        "title": "Google Cloud Bigtable",
        "id": "LfZSuE3xdQU46YMFV5fy"
      }
    ],
    "uri": "incidents/sJhprF3We9rWuxTKw5vK"
  },
  {
    "id": "v8QDroZPzjQyHy7RZrJS",
    "number": "13806485436214200242",
    "begin": "2021-02-06T06:57:02+00:00",
    "created": "2021-02-06T07:24:24+00:00",
    "end": "2021-02-06T08:32:03+00:00",
    "modified": "2021-02-06T08:32:03+00:00",
    "external_desc": "Google App Engine services in multiple regions may experience errors",
    "updates": [
      {
        "created": "2021-02-06T08:32:03+00:00",
        "modified": "2021-02-06T08:32:03+00:00",
        "when": "2021-02-06T08:32:03+00:00",
        "text": "The issue with Google App Engine has been resolved for all affected projects as of Saturday, 2021-02-06 00:25 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-06T07:55:37+00:00",
        "modified": "2021-02-06T07:55:37+00:00",
        "when": "2021-02-06T07:55:37+00:00",
        "text": "Description: We believe the issue with Google App Engine is partially resolved.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Saturday, 2021-02-06 01:20 US/Pacific with current details.\nDiagnosis: Increased errors and elevated latency.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-06T07:27:43+00:00",
        "modified": "2021-02-06T07:27:43+00:00",
        "when": "2021-02-06T07:27:43+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Saturday, 2021-02-06 00:00 US/Pacific.\nWe will provide more information by Saturday, 2021-02-06 00:21 US/Pacific.\nDiagnosis: Increased errors and elevated latency.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-02-06T07:24:25+00:00",
        "modified": "2021-02-06T07:24:25+00:00",
        "when": "2021-02-06T07:24:25+00:00",
        "text": "Description: We are experiencing an issue with Google App Engine, beginning at Friday, 2021-02-05 22:15 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-02-05 23:53 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Increased errors and elevated latency.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-06T08:32:03+00:00",
      "modified": "2021-02-06T08:32:03+00:00",
      "when": "2021-02-06T08:32:03+00:00",
      "text": "The issue with Google App Engine has been resolved for all affected projects as of Saturday, 2021-02-06 00:25 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "kchyUtnkMHJWaAva8aYc",
    "service_name": "Google App Engine",
    "affected_products": [
      {
        "title": "Google App Engine",
        "id": "kchyUtnkMHJWaAva8aYc"
      }
    ],
    "uri": "incidents/v8QDroZPzjQyHy7RZrJS"
  },
  {
    "id": "B3eZWtirMMLwJRYsozyG",
    "number": "10473973404607883893",
    "begin": "2021-02-02T01:17:39+00:00",
    "created": "2021-02-02T01:48:13+00:00",
    "end": "2021-02-02T02:20:10+00:00",
    "modified": "2021-02-02T02:20:10+00:00",
    "external_desc": "GKE cluster operations may fail in various regions.",
    "updates": [
      {
        "created": "2021-02-02T02:20:10+00:00",
        "modified": "2021-02-02T02:20:10+00:00",
        "when": "2021-02-02T02:20:10+00:00",
        "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Monday, 2021-02-01 18:19 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-02-02T01:48:13+00:00",
        "modified": "2021-02-02T01:48:13+00:00",
        "when": "2021-02-02T01:48:13+00:00",
        "text": "Description: We are experiencing an intermittent issue with Google Kubernetes Engine.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-02-01 18:32 US/Pacific with current details.\nLocations:\n* asia-east2\n* asia-northeast2\n* asia-northeast3\n* asia-southeast2\n* europe-north1\n* us-central1\nWe apologize to all who are affected by the disruption.\nDiagnosis: Clusters and node-pool creation operation may ended up with an error.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-02-02T02:20:10+00:00",
      "modified": "2021-02-02T02:20:10+00:00",
      "when": "2021-02-02T02:20:10+00:00",
      "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Monday, 2021-02-01 18:19 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/B3eZWtirMMLwJRYsozyG"
  },
  {
    "id": "mq2rNnCsyYif8ywgtwpb",
    "number": "5895670521423148944",
    "begin": "2021-01-29T17:39:24+00:00",
    "created": "2021-01-29T20:52:13+00:00",
    "end": "2021-01-30T03:45:31+00:00",
    "modified": "2021-01-30T03:45:32+00:00",
    "external_desc": "The issue with Cloud SQL API instance mutations and SQL Proxy operations in us-central1 has partially recovered",
    "updates": [
      {
        "created": "2021-01-30T03:45:32+00:00",
        "modified": "2021-01-30T03:45:32+00:00",
        "when": "2021-01-30T03:45:32+00:00",
        "text": "The issue with Cloud SQL API instance mutations and SQL Proxy operations has been resolved for all affected users as of Friday, 2021-01-29 18:45 US/Pacific.\nAll operations including instance restart and delete are healthy.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-01-30T02:59:39+00:00",
        "modified": "2021-01-30T02:59:39+00:00",
        "when": "2021-01-30T02:59:39+00:00",
        "text": "Description: The issue with Cloud SQL API instance mutations and SQL Proxy operations in us-central1 has partially recovered. We believe impact began at 08:50 US/Pacific with the error rate increasing starting at 09:25 US/Pacific. Partial recovery occurred at 14:54 US/Pacific\nOur engineering team has rolled out a mitigation and partially resolved the issue. We believe most of the service has recovered. At this time we believe only instances.delete and instances.restart continue to be impacted. Some operations such as instances.patch which require an instance.restart may also be impacted. The product team has identified the root cause of the issue and has begun implementing a fix.\nThe product team has started rolling out the potential fix. We are monitoring the effects of this rollout to determine if the fix has solved the issue.\nWe will provide an update by Friday, 2021-01-29 20:00 US/Pacific with current details.\nDiagnosis: Customers impacted by this issue may see increased latency or errors when performing Instance mutation requests, such as create, delete and update. Connection to Cloud SQL instances may be disrupted if a new ephemeral cert is required by the Cloud SQL Proxy. Errors returned may be 502 or 503.\nWorkaround: None at this time. We believe other regions are not impacted at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-30T00:28:50+00:00",
        "modified": "2021-01-30T00:28:50+00:00",
        "when": "2021-01-30T00:28:50+00:00",
        "text": "Description: The issue with Cloud SQL API instance mutations and SQL Proxy operations in us-central1 has partially recovered. We believe impact began at 08:50 US/Pacific with the error rate increasing starting at 09:25 US/Pacific. Partial recovery occurred at 14:54 US/Pacific\nOur engineering team has rolled out a mitigation and partially resolved the issue. We believe most of the service has recovered. At this time we believe only instances.delete and instances.restart continue to be impacted. Some operations such as instances.patch which require an instance.restart may also be impacted. The product team has identified the root cause of the issue and has begun implementing a fix. We expect that the Cloud SQL API will remain in the current partially resolved state for several hours until the fix is fully verified and rolled out.\nWe will provide an update by Friday, 2021-01-29 19:00 US/Pacific with current details.\nDiagnosis: Customers impacted by this issue may see increased latency or errors when performing Instance mutation requests, such as create, delete and update. Connection to Cloud SQL instances may be disrupted if a new ephemeral cert is required by the Cloud SQL Proxy. Errors returned may be 502 or 503.\nWorkaround: None at this time. We believe other regions are not impacted at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-29T23:31:04+00:00",
        "modified": "2021-01-29T23:31:04+00:00",
        "when": "2021-01-29T23:31:04+00:00",
        "text": "Description: The issue with Cloud SQL API instance mutations and SQL Proxy operations in us-central1 has partially recovered. We believe impact began at 08:50 US/Pacific with the error rate increasing starting at 09:25 US/Pacific. Partial recovery occurred at 14:54 US/Pacific\nOur engineering team has rolled out a mitigation and partially resolved the issue. We believe most of the service has recovered. At this time we believe only instances.delete and instances.restart continue to be impacted. Some operations such as instances.patch which require an instance.restart may also be impacted. We are working on further mitigation to bring the service back to a nominal operating state.\nWe will provide an update by Friday, 2021-01-29 16:30 US/Pacific with current details.\nDiagnosis: Customers impacted by this issue may see increased latency or errors when performing Instance mutation requests, such as create, delete and update. Connection to Cloud SQL instances may be disrupted if a new ephemeral cert is required by the Cloud SQL Proxy. Errors returned may be 502 or 503.\nWorkaround: None at this time. We believe other regions are not impacted at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-29T22:38:04+00:00",
        "modified": "2021-01-29T22:38:04+00:00",
        "when": "2021-01-29T22:38:04+00:00",
        "text": "Description: We are experiencing an issue with Cloud SQL API instance mutations and SQL Proxy operations in us-central1. We believe impact began at 08:50 US/Pacific with the error rate increasing starting at 09:25 US/Pacific.\nOur engineering team continues to investigate the issue. Instance mutation operations (such as instances.create or instances.delete) as well as requests for certificates (sslCerts.createEphemeral) when using Cloud SQL Proxy are impacted. Existing connections to Cloud SQL instances should be unaffected. New connections without Cloud SQL Proxy are also unaffected.\nThe product team has identified a potential mitigation and is working to implement it. We believe the change will be finished rolling out by 15:00 US/Pacific, we will be continuously monitoring the service to evaluate the effectiveness of the mitigation.\nWe will provide an update by Friday, 2021-01-29 15:30 US/Pacific with current details.\nDiagnosis: Customers impacted by this issue may see increased latency or errors when performing Instance mutation requests, such as create, delete and update. Connection to Cloud SQL instances may be disrupted if a new ephemeral cert is required by the Cloud SQL Proxy. Errors returned may be 502 or 503.\nWorkaround: None at this time. We believe other regions are not impacted at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-29T21:59:53+00:00",
        "modified": "2021-01-29T21:59:53+00:00",
        "when": "2021-01-29T21:59:53+00:00",
        "text": "Description: We are experiencing an issue with Cloud SQL API instance mutations in us-central1. We believe impact began at 08:50 US/Pacific with the error rate increasing starting at 09:25 US/Pacific.\nOur engineering team continues to investigate the issue. Instance mutation operations (such as instances.create or instances.delete) as well as requests for certificates (sslCerts.createEphemeral) when using Cloud SQL Proxy are impacted. Existing connections to Cloud SQL instances should be unaffected.\nThe product team has identified a potential mitigation and is working to implement it. As part of the mitigation, all requests to instances delete and instances restart will receive an error.\nWe will provide an update by Friday, 2021-01-29 15:00 US/Pacific with current details.\nDiagnosis: Customers impacted by this issue may see increased latency or errors when performing Instance mutation requests, such as create, delete and update. Connection to Cloud SQL instances may be disrupted if a new ephemeral cert is required by the Cloud SQL Proxy. Errors returned may be 502 or 503.\nWorkaround: None at this time. We believe other regions are not impacted at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-29T21:41:52+00:00",
        "modified": "2021-01-29T21:41:52+00:00",
        "when": "2021-01-29T21:41:52+00:00",
        "text": "Description: We are experiencing an issue with Cloud SQL.\nOur engineering team continues to investigate the issue. New instance creation, other instance operations, and SQL queries to already existing instances may be failing. We are troubleshooting the error at this time.\nWe will provide an update by Friday, 2021-01-29 16:00 US/Pacific with current details.\nDiagnosis: Instance creation, operations, and queries in us-central1 region may result in 502 (backend timeout) or 503 (service unavailable) errors.\nCustomers may also experience Cloud SQL Proxy connectivity related issues, due in part to this incident.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-29T21:01:31+00:00",
        "modified": "2021-01-29T21:01:31+00:00",
        "when": "2021-01-29T21:01:31+00:00",
        "text": "Description: We are experiencing an issue with Cloud SQL.\nOur engineering team continues to investigate the issue. New instance creation, other instance operations, and SQL queries to already existing instances may be failing.\nWe will provide an update by Friday, 2021-01-29 13:00 US/Pacific with current details.\nDiagnosis: Instance creation, operations, and queries in us-central1 region may result in 502 (backend timeout) or 503 (service unavailable) errors.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-29T20:52:14+00:00",
        "modified": "2021-01-29T20:52:14+00:00",
        "when": "2021-01-29T20:52:14+00:00",
        "text": "Description: We are experiencing an issue with Cloud SQL.\nOur engineering team continues to investigate the issue. New instance creation, other instance operations, and SQL queries to already existing instances may be failing. We are troubleshooting the error at this time.\nWe will provide an update by Friday, 2021-01-29 16:00 US/Pacific with current details.\nDiagnosis: Instance creation, operations, and queries in us-central1 region may result in 502 (backend timeout) or 503 (service unavailable) errors.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-01-30T03:45:32+00:00",
      "modified": "2021-01-30T03:45:32+00:00",
      "when": "2021-01-30T03:45:32+00:00",
      "text": "The issue with Cloud SQL API instance mutations and SQL Proxy operations has been resolved for all affected users as of Friday, 2021-01-29 18:45 US/Pacific.\nAll operations including instance restart and delete are healthy.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "hV87iK5DcEXKgWU2kDri",
    "service_name": "Google Cloud SQL",
    "affected_products": [
      {
        "title": "Google Cloud SQL",
        "id": "hV87iK5DcEXKgWU2kDri"
      }
    ],
    "uri": "incidents/mq2rNnCsyYif8ywgtwpb"
  },
  {
    "id": "PjPBzVQtSNRu5eRMZfn7",
    "number": "15110493858506382411",
    "begin": "2021-01-21T23:55:40+00:00",
    "created": "2021-01-22T00:26:46+00:00",
    "end": "2021-01-22T03:17:48+00:00",
    "modified": "2021-01-22T03:17:49+00:00",
    "external_desc": "We are experiencing an issue with Cloud DNS CNAME chasing in multiple zones.",
    "updates": [
      {
        "created": "2021-01-22T03:17:49+00:00",
        "modified": "2021-01-22T03:17:49+00:00",
        "when": "2021-01-22T03:17:49+00:00",
        "text": "The issue with Cloud DNS has been resolved for all affected projects as of Thursday, 2021-01-21 19:17 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-01-22T02:48:04+00:00",
        "modified": "2021-01-22T02:48:04+00:00",
        "when": "2021-01-22T02:48:04+00:00",
        "text": "Description: Customers using CNAME chasing may experience an issue with Cloud DNS. Querying for a record defined in one private zone that points to a record in another private zone does not return the final answer. See https://cloud.google.com/dns/docs/cnamechasing for more details about CNAME chasing.\nThe following zones are known to be impacted currently: us-east1-d\nMitigation work is currently underway by our engineering team. The mitigation is expected to complete by Thursday, 2021-01-21 19:15 US/Pacific.\nWe will provide more information by Thursday, 2021-01-21 19:15 US/Pacific.\nDiagnosis: CNAME chasing between private zone to private zone is not working.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-22T02:16:10+00:00",
        "modified": "2021-01-22T02:16:10+00:00",
        "when": "2021-01-22T02:16:10+00:00",
        "text": "Description: Customers using CNAME chasing may experience an issue with Cloud DNS. Querying for a record defined in one private zone that points to a record in another private zone does not return the final answer. See https://cloud.google.com/dns/docs/cnamechasing for more details about CNAME chasing.\nThe following zones are known to be impacted currently:\neurope-west1-c\nus-east1-d\nus-west1-a\nMitigation work is currently underway by our engineering team. The mitigation is expected to complete by Thursday, 2021-01-21 18:45 US/Pacific.\nWe will provide more information by Thursday, 2021-01-21 18:45 US/Pacific.\nDiagnosis: CNAME chasing between private zone to private zone is not working.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-22T01:39:18+00:00",
        "modified": "2021-01-22T01:43:10+00:00",
        "when": "2021-01-22T01:39:18+00:00",
        "text": "Description: Customers using CNAME chasing may experience an issue with Cloud DNS. Querying for a record defined in one private zone that points to a record in another private zone does not return the final answer. See https://cloud.google.com/dns/docs/cnamechasing for more details about CNAME chasing.\nThe following zones are known to be impacted currently:\nasia-east1-a\naustralia-southeast1-a\neurope-west1-c\neurope-west2-a\nus-east1-d\nus-west1-a\nMitigation work is currently underway by our engineering team. The mitigation is expected to complete by Thursday, 2021-01-21 18:30 US/Pacific.\nWe will provide more information by Thursday, 2021-01-21 18:15 US/Pacific.\nDiagnosis: CNAME chasing between private zone to private zone is not working.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-22T01:31:59+00:00",
        "modified": "2021-01-22T02:17:49+00:00",
        "when": "2021-01-22T01:31:59+00:00",
        "text": "Description: Customers using CNAME chasing may experience an issue with Cloud DNS. Querying for a record defined in one private zone that points to a record in another private zone does not return the final answer. See https://cloud.google.com/dns/docs/cnamechasing for more details about CNAME chasing.\nMitigation work is currently underway by our engineering team.\nThe following zones are known to be impacted:\nasia-east1-a\nasia-east2-c\nasia-northeast1-a\nasia-northeast2-c\nasia-northeast3-c\nasia-south1-a\nasia-southeast1-a\nasia-southeast2-c\naustralia-southeast1-a\neurope-west1-c\neurope-west2-a\neurope-west3-a\neurope-west6-c\nsouthamerica-east1-a\nus-central1-d\nus-east1-d\nus-west1-a\nus-west2-c\nus-west3-c\nus-west4-c\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2021-01-21 18:00 US/Pacific.\nDiagnosis: CNAME chasing between private zone to private zone is not working.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-22T00:26:46+00:00",
        "modified": "2021-01-22T02:18:23+00:00",
        "when": "2021-01-22T00:26:46+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team.\nThe following zones are known to be impacted:\nasia-east1-a\nasia-east2-c\nasia-northeast1-a\nasia-northeast2-c\nasia-northeast3-c\nasia-south1-a\nasia-southeast1-a\nasia-southeast2-c\naustralia-southeast1-a\neurope-west1-c\neurope-west2-a\neurope-west3-a\neurope-west6-c\nsouthamerica-east1-a\nus-central1-d\nus-east1-d\nus-west1-a\nus-west2-c\nus-west3-c\nus-west4-c\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2021-01-21 17:30 US/Pacific.\nDiagnosis: CNAME chasing between private zone to private zone is not working.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-01-22T03:17:49+00:00",
      "modified": "2021-01-22T03:17:49+00:00",
      "when": "2021-01-22T03:17:49+00:00",
      "text": "The issue with Cloud DNS has been resolved for all affected projects as of Thursday, 2021-01-21 19:17 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "TUZUsWSJUVJGW97Jq2sH",
    "service_name": "Google Cloud DNS",
    "affected_products": [
      {
        "title": "Google Cloud DNS",
        "id": "TUZUsWSJUVJGW97Jq2sH"
      }
    ],
    "uri": "incidents/PjPBzVQtSNRu5eRMZfn7"
  },
  {
    "id": "dHFNjgMMggHELFKKkmBN",
    "number": "11801387977050056114",
    "begin": "2021-01-19T19:12:54+00:00",
    "created": "2021-01-19T20:06:01+00:00",
    "end": "2021-01-19T21:57:23+00:00",
    "modified": "2021-01-19T22:12:58+00:00",
    "external_desc": "We are experiencing network latency in us-central1 and us-east1",
    "updates": [
      {
        "created": "2021-01-19T21:57:23+00:00",
        "modified": "2021-01-19T21:57:23+00:00",
        "when": "2021-01-19T21:57:23+00:00",
        "text": "The issue with Google Cloud infrastructure components is believed to be currently affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-01-19T21:40:17+00:00",
        "modified": "2021-01-19T22:12:58+00:00",
        "when": "2021-01-19T21:40:17+00:00",
        "text": "Description: We believe the issue with Google Cloud infrastructure components is partially resolved and risk of reoccurrence is low. The last event with this issue happened at 11:39 AM US/Pacific\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Tuesday, 2021-01-19 15:00 US/Pacific with current details.\nDiagnosis: Cloud Networking traffic going through us-central1 and us-east1 shows increased latency.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-19T21:25:19+00:00",
        "modified": "2021-01-19T22:12:42+00:00",
        "when": "2021-01-19T21:25:19+00:00",
        "text": "Description: Our engineering team has determined that further investigation is required to mitigate the issue. The issue remains intermittent.\nWe will provide an update by Tuesday, 2021-01-19 14:00 US/Pacific with current details.\nDiagnosis: Cloud Networking traffic going through us-central1 and us-east1 shows increased latency.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-19T20:06:02+00:00",
        "modified": "2021-01-19T22:12:23+00:00",
        "when": "2021-01-19T20:06:02+00:00",
        "text": "Description: We are experiencing an intermittent issue with Google Cloud infrastructure components, the issue manifests itself as periods of increased latency every 30 minutes, beginning at Tuesday, 2021-01-19 07:50:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-01-19 13:30 US/Pacific with current details.\nDiagnosis: Cloud Networking traffic going through us-central1 and us-east1 shows increased latency.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-01-19T21:57:23+00:00",
      "modified": "2021-01-19T21:57:23+00:00",
      "when": "2021-01-19T21:57:23+00:00",
      "text": "The issue with Google Cloud infrastructure components is believed to be currently affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "uoypgc4GWUyzAKRHPjEv",
    "service_name": "Google Cloud Infrastructure Components",
    "affected_products": [
      {
        "title": "Google Cloud Infrastructure Components",
        "id": "uoypgc4GWUyzAKRHPjEv"
      }
    ],
    "uri": "incidents/dHFNjgMMggHELFKKkmBN"
  },
  {
    "id": "qnbPenZy16YDykptsWFG",
    "number": "15704485881660584513",
    "begin": "2021-01-15T13:29:29+00:00",
    "created": "2021-01-15T13:34:25+00:00",
    "end": "2021-01-15T15:05:47+00:00",
    "modified": "2021-01-15T15:05:48+00:00",
    "external_desc": "We are experiencing an issue with Cloud Interconnect",
    "updates": [
      {
        "created": "2021-01-15T15:05:48+00:00",
        "modified": "2021-01-15T15:05:48+00:00",
        "when": "2021-01-15T15:05:48+00:00",
        "text": "The issue with Cloud Interconnect has been resolved for all affected projects as of Friday, 2021-01-15 06:53 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-01-15T14:14:09+00:00",
        "modified": "2021-01-15T14:14:09+00:00",
        "when": "2021-01-15T14:14:09+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-01-15 07:25 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-15T13:34:26+00:00",
        "modified": "2021-01-15T13:34:26+00:00",
        "when": "2021-01-15T13:34:26+00:00",
        "text": "Description: We are experiencing an issue with Cloud Interconnect beginning at Friday, 2021-01-15 04:36:30 PST.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-01-15 06:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-01-15T15:05:48+00:00",
      "modified": "2021-01-15T15:05:48+00:00",
      "when": "2021-01-15T15:05:48+00:00",
      "text": "The issue with Cloud Interconnect has been resolved for all affected projects as of Friday, 2021-01-15 06:53 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/qnbPenZy16YDykptsWFG"
  },
  {
    "id": "YPWAM5jUMNAsEdt8hp8Z",
    "number": "5747346264348366471",
    "begin": "2021-01-14T01:05:22+00:00",
    "created": "2021-01-14T20:15:47+00:00",
    "end": "2021-01-19T21:03:12+00:00",
    "modified": "2021-01-19T21:03:13+00:00",
    "external_desc": "We are experiencing an issue with Cloud SDK Versions 321, 322 and 323 Installed on Windows.",
    "updates": [
      {
        "created": "2021-01-19T21:03:12+00:00",
        "modified": "2021-01-19T21:03:12+00:00",
        "when": "2021-01-19T21:03:12+00:00",
        "text": "The issue with Cloud Developer Tools has been resolved for all affected users as of Tuesday, 2021-01-19 12:58 US/Pacific.\nPlease see workaround for detailed instructions\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-01-19T21:02:48+00:00",
        "modified": "2021-01-19T21:02:48+00:00",
        "when": "2021-01-19T21:02:48+00:00",
        "text": "Description: Mitigation work has been completed by our engineering team.\nFor mitigation steps please see workaround.\nWe will provide an update by Tuesday, 2021-01-19 13:10 US/Pacific with current details.\nDiagnosis: The command \"gcloud components update\" fails for Cloud SDK versions 321, 322 and 323 installed on Windows.\nWorkaround: Please run the following commands in a PowerShell window:\n```\n$gcloudDir = Get-Command gcloud | Select -ExpandProperty \"Source\" | Split-Path | Split-Path\nattrib -r \"$gcloudDir\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\lib\\kuberun\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\lib\\kuberun\\*.*\" /s\nRemove-Item \"$gcloudDir\\..\\google-cloud-sdk.staging\" -Recurse\nIf any of the commands fail, proceed with running the remaining commands. After running the PowerShell script, run the following in a regular Command Prompt (not PowerShell):\n```\ngcloud components update\n```\nAfter running this command, ensure that your gcloud installation is at version 324.0.0 or higher.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-19T20:57:49+00:00",
        "modified": "2021-01-19T20:57:49+00:00",
        "when": "2021-01-19T20:57:49+00:00",
        "text": "Description: Mitigation work has been completed by our engineering team.\nFor mitigation steps please see workaround.\nWe will provide an update by Tuesday, 2021-01-19 13:10 US/Pacific with current details.\nDiagnosis: The command \"gcloud components update\" fails for Cloud SDK versions 321, 322 and 323 installed on Windows.\nWorkaround: Please run the following commands in a PowerShell window:\n```\n$gcloudDir = Get-Command gcloud | Select -ExpandProperty \"Source\" | Split-Path | Split-Path\nattrib -r \"$gcloudDir\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\lib\\kuberun\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\lib\\kuberun\\*.*\" /s\nRemove-Item \"$gcloudDir\\..\\google-cloud-sdk.staging\" -Recurse\nIf any of the commands fail, proceed with running the remaining commands. After running the PowerShell script, run the following in a regular Command Prompt (not PowerShell):\n```\ngcloud components update --version 324.0.0\n```",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2021-01-14T20:15:48+00:00",
        "modified": "2021-01-14T20:15:48+00:00",
        "when": "2021-01-14T20:15:48+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Tuesday, 2021-01-19 12:00 US/Pacific.\nPlease see the workaround section below for more details.\nDiagnosis: The command \"gcloud components update\" fails for Cloud SDK versions 321, 322 and 323 installed on Windows.\nWorkaround: Please run the following commands in a PowerShell window:\n$gcloudDir = Get-Command gcloud | Select -ExpandProperty \"Source\" | Split-Path | Split-Path\nattrib -r \"$gcloudDir\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\lib\\kuberun\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\platform\\kuberun_licenses\\*.*\" /s\nattrib -r \"$gcloudDir\\..\\google-cloud-sdk.staging\\lib\\kuberun\\*.*\" /s\nRemove-Item \"$gcloudDir\\..\\google-cloud-sdk.staging\" -Recurse\nIf any of the commands fail, proceed with running the remaining commands.\nAfter running the PowerShell script, run the following in a regular Command Prompt (not PowerShell):\ngcloud components update --version 320.0.0\nPlease note, after applying this workaround, do not run 'gcloud components update' as this will re-trigger the issue. Please wait until the fix is released before updating components.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2021-01-19T21:03:12+00:00",
      "modified": "2021-01-19T21:03:12+00:00",
      "when": "2021-01-19T21:03:12+00:00",
      "text": "The issue with Cloud Developer Tools has been resolved for all affected users as of Tuesday, 2021-01-19 12:58 US/Pacific.\nPlease see workaround for detailed instructions\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "bGThzF7oEGP5jcuDdMuk",
    "service_name": "Google Cloud Support",
    "affected_products": [
      {
        "title": "Google Cloud Support",
        "id": "bGThzF7oEGP5jcuDdMuk"
      }
    ],
    "uri": "incidents/YPWAM5jUMNAsEdt8hp8Z"
  },
  {
    "id": "eT1dA2td4ma8nqwBbAoT",
    "number": "7873533702493731882",
    "begin": "2021-01-08T20:27:14+00:00",
    "created": "2021-01-08T20:27:16+00:00",
    "end": "2021-01-08T21:20:56+00:00",
    "modified": "2021-01-08T21:20:56+00:00",
    "external_desc": "Cloud L7 (HTTP) External LB configuration changes propagating with high latency",
    "updates": [
      {
        "created": "2021-01-08T21:20:56+00:00",
        "modified": "2021-01-08T21:20:56+00:00",
        "when": "2021-01-08T21:20:56+00:00",
        "text": "The issue with Cloud L7 (HTTP) External Load Balancer components has been resolved for all affected users as of Friday, 2021-01-08 12:21 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2021-01-08T20:31:46+00:00",
        "modified": "2021-01-08T20:31:46+00:00",
        "when": "2021-01-08T20:31:46+00:00",
        "text": "Description: We are experiencing an intermittent issue with Cloud L7 (HTTP) External Load Balancer components beginning at Friday, 2021-01-08 11:39 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-01-08 14:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Cloud L7 (HTTP) External LB updates appear stalled - customers will likely see delays to updating their projects.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2021-01-08T20:27:17+00:00",
        "modified": "2021-01-08T20:27:17+00:00",
        "when": "2021-01-08T20:27:17+00:00",
        "text": "Description: We are experiencing an intermittent issue with Google Cloud configuration infrastructure components beginning at Friday, 2021-01-08 11:39 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2021-01-08 14:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Cloud customer updates appear stalled - customers will likely see delays to updating their projects.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      }
    ],
    "most_recent_update": {
      "created": "2021-01-08T21:20:56+00:00",
      "modified": "2021-01-08T21:20:56+00:00",
      "when": "2021-01-08T21:20:56+00:00",
      "text": "The issue with Cloud L7 (HTTP) External Load Balancer components has been resolved for all affected users as of Friday, 2021-01-08 12:21 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_OUTAGE",
    "severity": "high",
    "service_key": "uoypgc4GWUyzAKRHPjEv",
    "service_name": "Google Cloud Infrastructure Components",
    "affected_products": [
      {
        "title": "Google Cloud Infrastructure Components",
        "id": "uoypgc4GWUyzAKRHPjEv"
      }
    ],
    "uri": "incidents/eT1dA2td4ma8nqwBbAoT"
  },
  {
    "id": "nGFv79FDfTbWfKU2aHRK",
    "number": "16970567168892120596",
    "begin": "2020-12-15T10:01:01+00:00",
    "created": "2020-12-15T10:20:28+00:00",
    "end": "2020-12-15T12:13:00+00:00",
    "modified": "2020-12-15T12:13:01+00:00",
    "external_desc": "Cloud Router: metrics missing",
    "updates": [
      {
        "created": "2020-12-15T12:13:00+00:00",
        "modified": "2020-12-15T12:13:00+00:00",
        "when": "2020-12-15T12:13:00+00:00",
        "text": "The issue with Cloud Router metrics has been resolved for all affected projects as of Tuesday, 2020-12-15 04:00 US/Pacific and metrics from Cloud Router should now be flowing to Metrics Explorer.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-15T10:20:29+00:00",
        "modified": "2020-12-15T10:20:29+00:00",
        "when": "2020-12-15T10:20:29+00:00",
        "text": "Description: We are experiencing an issue with Cloud Router monitoring data (metrics) missing beginning at Monday, 2020-12-14 12:00 US/Pacific. Routers themselves are not impacted and should be working with no issues.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2020-12-15 04:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Visible decrease in Cloud Router data in Metrics Explorer.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-12-15T12:13:00+00:00",
      "modified": "2020-12-15T12:13:00+00:00",
      "when": "2020-12-15T12:13:00+00:00",
      "text": "The issue with Cloud Router metrics has been resolved for all affected projects as of Tuesday, 2020-12-15 04:00 US/Pacific and metrics from Cloud Router should now be flowing to Metrics Explorer.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/nGFv79FDfTbWfKU2aHRK"
  },
  {
    "id": "cFXPsFUnUELR8U2bQeGz",
    "number": "8166874104611817413",
    "begin": "2020-12-14T12:07:00+00:00",
    "created": "2020-12-14T13:34:13+00:00",
    "end": "2020-12-14T14:23:42+00:00",
    "modified": "2020-12-23T00:49:44+00:00",
    "external_desc": "Google Cloud services are experiencing issues and we have an other update at 5:30 PDT",
    "updates": [
      {
        "created": "2020-12-23T00:49:44+00:00",
        "modified": "2020-12-23T00:49:44+00:00",
        "when": "2020-12-23T00:49:44+00:00",
        "text": "The following is a correction to the previously posted ISSUE SUMMARY, which after further research we determined needed an amendment. All services that require sign-in via a Google Account were affected with varying impact. Some operations with Cloud service accounts experienced elevated error rates on requests to the following endpoints: www.googleapis.com or oauth2.googleapis.com. Impact varied based on the Cloud Service and service account. Please open a support case if you were impacted and have further questions.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-18T19:37:01+00:00",
        "modified": "2020-12-18T19:38:53+00:00",
        "when": "2020-12-18T19:37:01+00:00",
        "text": "# ISSUE SUMMARY\nOn Monday 14 December, 2020, for a duration of 47 minutes, customer-facing Google services that required Google OAuth access were unavailable. Cloud Service accounts used by GCP workloads were not impacted and continued to function. We apologize to our customers whose services or businesses were impacted during this incident, and we are taking immediate steps to improve the platform’s performance and availability.\n# ROOT CAUSE\nThe Google User ID Service maintains a unique identifier for every account and handles authentication credentials for OAuth tokens and cookies. It stores account data in a distributed database, which uses Paxos protocols to coordinate updates. For security reasons, this service will reject requests when it detects outdated data.\nGoogle uses an evolving suite of automation tools to manage the quota of various resources allocated for services. As part of an ongoing migration of the User ID Service to a new quota system, a change was made in October to register the User ID Service with the new quota system, but parts of the previous quota system were left in place which incorrectly reported the usage for the User ID Service as 0. An existing grace period on enforcing quota restrictions delayed the impact, which eventually expired, triggering automated quota systems to decrease the quota allowed for the User ID service and triggering this incident. Existing safety checks exist to prevent many unintended quota changes, but at the time they did not cover the scenario of zero reported load for a single service:\n• Quota changes to large number of users, since only a single group was the target of the change,\n• Lowering quota below usage, since the reported usage was inaccurately being reported as zero,\n• Excessive quota reduction to storage systems, since no alert fired during the grace period,\n• Low quota, since the difference between usage and quota exceeded the protection limit.\nAs a result, the quota for the account database was reduced, which prevented the Paxos leader from writing. Shortly after, the majority of read operations became outdated which resulted in errors on authentication lookups.\n# REMEDIATION AND PREVENTION\nThe scope of the problem was immediately clear as the new quotas took effect. This was detected by automated alerts for capacity at 2020-12-14 03:43 US/Pacific, and for errors with the User ID Service starting at 03:46, which paged Google Engineers at 03:48 within one minute of customer impact. At 04:08 the root cause and a potential fix were identified, which led to disabling the quota enforcement in one datacenter at 04:22. This quickly improved the situation, and at 04:27 the same mitigation was applied to all datacenters, which returned error rates to normal levels by 04:33. As outlined below, some user services took longer to fully recover.\nIn addition to fixing the underlying cause, we will be implementing changes to prevent, reduce the impact of, and better communicate about this type of failure in several ways:\n1\\. Review our quota management automation to prevent fast implementation of global changes\n2\\. Improve monitoring and alerting to catch incorrect configurations sooner\n3\\. Improve reliability of tools and procedures for posting external communications during outages that affect internal tools\n4\\. Evaluate and implement improved write failure resilience into our User ID service database\n5\\. Improve resilience of GCP Services to more strictly limit the impact to the data plane during User ID Service failures\nWe would like to apologize for the scope of impact that this incident had on our customers and their businesses. We take any incident that affects the availability and reliability of our customers extremely seriously, particularly incidents which span multiple regions. We are conducting a thorough investigation of the incident and will be making the changes which result from that investigation our top priority in Google Engineering.\n# DETAILED DESCRIPTION OF IMPACT\nOn Monday 14 December, 2020 from 03:46 to 04:33 US/Pacific, credential issuance and account metadata lookups for all Google user accounts failed. As a result, we could not verify that user requests were authenticated and served 5xx errors on virtually all authenticated traffic. The majority of authenticated services experienced similar control plane impact: elevated error rates across all Google Cloud Platform and Google Workspace APIs and Consoles. Products continued to deliver service normally during the incident except where specifically called out below. Most services recovered automatically within a short period of time after the main issue ended at 04:33. Some services had unique or lingering impact, which is detailed below.\n#### Cloud Console\nAny users who hadn't already previously authenticated to Cloud Console were unable to login. Users who had already authenticated may have been able to use Cloud Console but may have seen some features degraded.\n#### Google BigQuery\nDuring the incident, streaming requests returned ~75% errors, while BigQuery jobs returned ~10% errors on average globally.\n#### Google Cloud Storage\nApproximately 15% of requests to Google Cloud Storage (GCS) were impacted during the outage, specifically those using OAuth, HMAC or email authentication. After 2020-12-14 04:31 US/Pacific, the majority of impact was resolved, however, there was lingering impact, for <1% of clients that attempted to finalize resumable uploads that started during the window. These uploads were left in a non-resumable state; the error code GCS returned was retryable, but subsequent retries were unable to make progress, leaving these objects unfinalized.\n#### Google Cloud Networking\nThe networking control plane continued to see elevated error rates on operations until it fully recovered at 2020-12-14 05:21 US/Pacific. Only operations that made modifications to the data plane VPC network were impacted. All existing configurations in the data plane remained operational.\n#### Google Kubernetes Engine\nDuring the incident, ~4% of requests to the GKE control plane API failed, and nearly all Google-managed and customer workloads could not report metrics to Cloud Monitoring.\nWe believe ~5% of requests to Kubernetes control planes failed but do not have accurate measures due to unreported Cloud Monitoring metrics.\nFor up to an hour after the outage, ~1.9% nodes reported conditions such as StartGracePeriod or NetworkUnavailable which may have had an impact on user workloads.\n#### Google Workspace\nAll Google Workspace services rely on Google's account infrastructure for login, authentication, and enforcement of access control on resources (e.g. documents, Calendar events, Gmail messages). As a consequence, all authenticated Google Workspace apps were down for the duration of the incident. After the issue was mitigated at 2020-12-14 04:32 US/Pacific, Google Workspace apps recovered, and most services were fully recovered by 05:00. Some services, including Google Calendar and Google Workspace Admin Console, served errors up to 05:21 due to a traffic spike following initial recovery. Some Gmail users experienced errors for up to an hour after recovery due to caching of errors from identity services.\n#### Cloud Support\nCloud Support's internal tools were impacted, which delayed our ability to share outage communications with customers on the Google Cloud Platform and Google Workspace Status Dashboards. Customers were unable to create or view cases in the Cloud Console. We were able to update customers at 2020-12-14 05:34 US/Pacific after the impact had ended.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-14T20:17:52+00:00",
        "modified": "2020-12-14T20:26:36+00:00",
        "when": "2020-12-14T20:17:52+00:00",
        "text": "Preliminary Incident Statement while full Incident Report is prepared.\n(All Times US/Pacific)\nIncident Start: 2020-12-14 03:45\nIncident End: 2020-12-14 04:35\nDuration: 50 minutes;\n### Affected:\n- Services: Google Cloud Platform, Google Workspace\n- Features: Account login and authentication to all Cloud services\n- Regions/Zones: Global\n### Description:\nGoogle Cloud Platform and Google Workspace experienced a global outage affecting all services which require Google account authentication for a duration of 50 minutes. The root cause was an issue in our automated quota management system which reduced capacity for Google's central identity management system, causing it to return errors globally. As a result, we couldn’t verify that user requests were authenticated and served errors to our users.\n### Customer Impact:\n- GCP services (including Cloud Console, Cloud Storage, BigQuery, Google Kubernetes Engine) requiring authentication would have returned an error for all users.\n- Google Workspace services (including Gmail, Calendar, Meet, Docs and Drive) requiring authentication would have returned an error for all users.\n### Additional Details:\n- Many of our internal users and tools experienced similar errors, which added delays to our outage external communication.\n- We will publish an analysis of this incident once we have completed our internal investigation.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-14T14:23:42+00:00",
        "modified": "2020-12-14T14:23:42+00:00",
        "when": "2020-12-14T14:23:42+00:00",
        "text": "As of 4:32 PST the system affected was restored and all services recovered shortly afterwards.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-14T13:34:14+00:00",
        "modified": "2020-12-14T14:45:23+00:00",
        "when": "2020-12-14T13:34:14+00:00",
        "text": "Google Cloud services are experiencing issues and we have an other update at 5:30 PST",
        "status": "SERVICE_OUTAGE"
      }
    ],
    "most_recent_update": {
      "created": "2020-12-23T00:49:44+00:00",
      "modified": "2020-12-23T00:49:44+00:00",
      "when": "2020-12-23T00:49:44+00:00",
      "text": "The following is a correction to the previously posted ISSUE SUMMARY, which after further research we determined needed an amendment. All services that require sign-in via a Google Account were affected with varying impact. Some operations with Cloud service accounts experienced elevated error rates on requests to the following endpoints: www.googleapis.com or oauth2.googleapis.com. Impact varied based on the Cloud Service and service account. Please open a support case if you were impacted and have further questions.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_OUTAGE",
    "severity": "high",
    "service_key": "uoypgc4GWUyzAKRHPjEv",
    "service_name": "Google Cloud Infrastructure Components",
    "affected_products": [
      {
        "title": "Google Cloud Infrastructure Components",
        "id": "uoypgc4GWUyzAKRHPjEv"
      }
    ],
    "uri": "incidents/cFXPsFUnUELR8U2bQeGz"
  },
  {
    "id": "Ndnndvsprwu1dmRpbx2d",
    "number": "8484089340023804825",
    "begin": "2020-12-10T03:38:29+00:00",
    "created": "2020-12-10T03:41:20+00:00",
    "end": "2020-12-10T04:42:15+00:00",
    "modified": "2020-12-10T04:42:15+00:00",
    "external_desc": "Cloud Dataflow resources in europe-west2-a may be unreachable",
    "updates": [
      {
        "created": "2020-12-10T04:42:15+00:00",
        "modified": "2020-12-10T04:42:15+00:00",
        "when": "2020-12-10T04:42:15+00:00",
        "text": "The issue with Cloud Dataflow in europe-west2-a has been resolved for all affected projects as of Wednesday, 2020-12-09 20:41 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-10T03:41:21+00:00",
        "modified": "2020-12-10T03:41:21+00:00",
        "when": "2020-12-10T03:41:21+00:00",
        "text": "Description: Our engineering team continues to investigate the issue.\nFor regular status updates, please follow: status.cloud.google.com/incident/zall/20011, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-12-10T04:42:15+00:00",
      "modified": "2020-12-10T04:42:15+00:00",
      "when": "2020-12-10T04:42:15+00:00",
      "text": "The issue with Cloud Dataflow in europe-west2-a has been resolved for all affected projects as of Wednesday, 2020-12-09 20:41 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "T9bFoXPqG8w8g1YbWTKY",
    "service_name": "Google Cloud Dataflow",
    "affected_products": [
      {
        "title": "Google Cloud Dataflow",
        "id": "T9bFoXPqG8w8g1YbWTKY"
      }
    ],
    "uri": "incidents/Ndnndvsprwu1dmRpbx2d"
  },
  {
    "id": "jM6nNd971RMAcuufDBee",
    "number": "1493461324682532733",
    "begin": "2020-12-10T03:06:07+00:00",
    "created": "2020-12-10T03:36:54+00:00",
    "end": "2020-12-10T04:40:48+00:00",
    "modified": "2020-12-10T04:40:49+00:00",
    "external_desc": "Cloud SQL instances in europe-west2-a may be unreachable",
    "updates": [
      {
        "created": "2020-12-10T04:40:48+00:00",
        "modified": "2020-12-10T04:40:48+00:00",
        "when": "2020-12-10T04:40:48+00:00",
        "text": "The issue with Cloud SQL in europe-west2-a has been resolved for all affected projects as of Wednesday, 2020-12-09 20:19 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-10T03:36:54+00:00",
        "modified": "2020-12-10T03:36:54+00:00",
        "when": "2020-12-10T03:36:54+00:00",
        "text": "Description: Our engineering team continues to investigate the issue.\nFor regular status updates, please follow: status.cloud.google.com/incident/zall/20011, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-12-10T04:40:48+00:00",
      "modified": "2020-12-10T04:40:48+00:00",
      "when": "2020-12-10T04:40:48+00:00",
      "text": "The issue with Cloud SQL in europe-west2-a has been resolved for all affected projects as of Wednesday, 2020-12-09 20:19 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "hV87iK5DcEXKgWU2kDri",
    "service_name": "Google Cloud SQL",
    "affected_products": [
      {
        "title": "Google Cloud SQL",
        "id": "hV87iK5DcEXKgWU2kDri"
      }
    ],
    "uri": "incidents/jM6nNd971RMAcuufDBee"
  },
  {
    "id": "zvkLF2ESXcD13Xd9VD4f",
    "number": "4997996330665119394",
    "begin": "2020-12-10T03:00:08+00:00",
    "created": "2020-12-10T03:32:16+00:00",
    "end": "2020-12-10T04:39:17+00:00",
    "modified": "2020-12-10T04:39:17+00:00",
    "external_desc": "Cloud GCE resources may be unreachable in europe-west2-a",
    "updates": [
      {
        "created": "2020-12-10T04:39:17+00:00",
        "modified": "2020-12-10T04:39:17+00:00",
        "when": "2020-12-10T04:39:17+00:00",
        "text": "The issue with Google Compute Engine has been resolved for all affected users as of Wednesday, 2020-12-09 20:39 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-10T03:32:17+00:00",
        "modified": "2020-12-10T03:32:17+00:00",
        "when": "2020-12-10T03:32:17+00:00",
        "text": "Description: We are experiencing an issue with Google Compute Engine.\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: status.cloud.google.com/incident/zall/20011, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-12-10T04:39:17+00:00",
      "modified": "2020-12-10T04:39:17+00:00",
      "when": "2020-12-10T04:39:17+00:00",
      "text": "The issue with Google Compute Engine has been resolved for all affected users as of Wednesday, 2020-12-09 20:39 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/zvkLF2ESXcD13Xd9VD4f"
  },
  {
    "id": "WEvPzYGLJV1ddhYzwSqz",
    "number": "18399943488613864780",
    "begin": "2020-12-10T02:46:22+00:00",
    "created": "2020-12-10T03:34:44+00:00",
    "end": "2020-12-10T05:04:26+00:00",
    "modified": "2020-12-10T05:04:26+00:00",
    "external_desc": "Cloud Memorystore resources may be unreachable in europe-west2-a",
    "updates": [
      {
        "created": "2020-12-10T05:04:26+00:00",
        "modified": "2020-12-10T05:04:26+00:00",
        "when": "2020-12-10T05:04:26+00:00",
        "text": "The issue with Cloud Memorystore has been resolved for all affected projects as of Wednesday, 2020-12-09 21:00 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-10T04:59:27+00:00",
        "modified": "2020-12-10T04:59:27+00:00",
        "when": "2020-12-10T04:59:27+00:00",
        "text": "Description: The underlying infrastructure issue in europe-west2-a has been mitigated, and we are seeing recoveries in most Cloud Memorystore instances.\nWe will continue to monitor for full recovery, and provide more information by Wednesday, 2020-12-09 22:30 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-12-10T03:34:45+00:00",
        "modified": "2020-12-10T03:34:45+00:00",
        "when": "2020-12-10T03:34:45+00:00",
        "text": "Description: We are experiencing an issue with Cloud Memorystore.\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: status.cloud.google.com/incident/zall/20011, no further updates will be provided here.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-12-10T05:04:26+00:00",
      "modified": "2020-12-10T05:04:26+00:00",
      "when": "2020-12-10T05:04:26+00:00",
      "text": "The issue with Cloud Memorystore has been resolved for all affected projects as of Wednesday, 2020-12-09 21:00 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LGPLu3M5pcUAKU1z6eP3",
    "service_name": "Cloud Memorystore",
    "affected_products": [
      {
        "title": "Cloud Memorystore",
        "id": "LGPLu3M5pcUAKU1z6eP3"
      }
    ],
    "uri": "incidents/WEvPzYGLJV1ddhYzwSqz"
  },
  {
    "id": "qRpmq9arsrCV7xWdfftF",
    "number": "2176039009975666311",
    "begin": "2020-12-10T02:31:38+00:00",
    "created": "2020-12-10T03:17:41+00:00",
    "end": "2020-12-10T03:55:02+00:00",
    "modified": "2020-12-15T19:56:41+00:00",
    "external_desc": "All Cloud Platform resources in europe-west2-a may be unreachable as of 2020-12-09 18:32 US/Pacific.",
    "updates": [
      {
        "created": "2020-12-15T19:03:12+00:00",
        "modified": "2020-12-15T19:56:41+00:00",
        "when": "2020-12-15T19:03:12+00:00",
        "text": "# ISSUE SUMMARY\nOn Wednesday 9 December, 2020, Google Cloud Platform experienced networking unavailability in zone europe-west2-a, resulting in some customers being unable to access their resources, for a duration of 1 hour 24 minutes. The following Google services had degraded service that extended beyond the initial 1 hour 24 minute network disruption:\n- 1.5% of Cloud Memorystore Redis instances were unhealthy for a total duration of 2 hours 24 minutes\n- 4.5% of Classic Cloud VPN tunnels in the europe-west2 region experienced unavailability after the main disruption had recovered and these tunnels remained down for a duration of 8 hours and 10 minutes\n- App Engine Flex experienced increased deployment error rates for a total duration of 1 hour 45 minutes\nWe apologize to our Cloud customers who were impacted during this disruption. We have conducted a thorough internal investigation and are taking immediate action to improve the resiliency and availability of our service.\n# ROOT CAUSE\nGoogle’s underlying networking control plane consists of multiple distributed components that make up the Software Defined Networking (SDN) stack. These components run on multiple machines so that failure of a machine or even multiple machines does not impact network capacity. To achieve this, the control plane elects a leader from a pool of machines to provide configuration to the various infrastructure components. The leader election process depends on a local instance of Google’s internal lock service to read various configurations and files for determining the leader. The control plane is responsible for Border Gateway Protocol (BGP) peering sessions between physical routers connecting a cloud zone to the Google backbone.\nGoogle’s internal lock service provides Access Control List (ACLs) mechanisms to control reading and writing of various files stored in the service. A change to the ACLs used by the network control plane caused the tasks responsible for leader election to no longer have access to the files required for the process. The production environment contained ACLs not present in the staging or canary environments due to those environments being rebuilt using updated processes during previous maintenance events. This meant that some of the ACLs removed in the change were in use in europe-west2-a, and the validation of the configuration change in testing and canary environments did not surface the issue.\nGoogle's resilience strategy relies on the principle of defense in depth. Specifically, despite the network control infrastructure being designed to be highly resilient, the network is designed to 'fail static' and run for a period of time without the control plane being present as an additional line of defense against failure. The network ran normally for a short period - several minutes - after the control plane had been unable to elect a leader task. After this period, BGP routing between europe-west2-a and the rest of the Google backbone network was withdrawn, resulting in isolation of the zone and inaccessibility of resources in the zone.\n# REMEDIATION AND PREVENTION\nGoogle engineers were automatically alerted to elevated error rates in europe-west2-a at 2020-12-09 18:29 US/Pacific and immediately started an investigation. The configuration change rollout was automatically halted as soon as the issue was detected, preventing it from reaching any other zones. At 19:30, mitigation was applied to rollback the configuration change in europe-west2-a. This completed at 19:55, mitigating the immediate issue. Some services such as Cloud MemoryStore and Cloud VPN took additional time to recover due to complications arising from the initial disruption. Services with extended recovery timelines are described in the “detailed description of impact” section below.\nWe are committed to preventing this situation from happening again and are implementing the following actions:\nIn addition to rolling back the configuration change responsible for this disruption, we are auditing all network ACLs to ensure they are consistent across environments. While the network continued to operate for a short time after the change was rolled out, we are improving the operating mode of the data plane when the control plane is unavailable for extended periods. Improvements in visibility to recent changes will be made to reduce the time to mitigation. Additional observability will be added to lock service ACLs allowing for additional validation when making changes to ACLs. We are also improving the canary and release process for future changes of this type to ensure these changes are made safely.\n# DETAILED DESCRIPTION OF IMPACT\nOn Wednesday 9 December, 2020 from 18:31 to 19:55 US/Pacific Google Cloud experienced unavailability for some Google services hosted in zone europe-west2-a as described in detail below. If impact time differs significantly, it will be mentioned specifically.\n## Compute Engine\n~60% of VMs in europe-west2-a were unreachable from outside the zone. Projects affected by this incident would have observed 100% of VMs in the zone being unreachable. Communication within the zone had minor issues, but largely worked normally. VM creation and deletion operations were stalled during the outage. VMs on hosts that had hardware or other faults during the outage were not repaired and restarted onto healthy hosts during the outage.\n## Persistent Disk\nVMs in europe-west2-a experienced stuck I/O operations for 59% of standard persistent disks located in that zone. 27% of regional persistent disks in europe-west2 briefly experienced high I/O latency at the start and end of the incident. Persistent Disk snapshot creation and restore for 59% of disks located in europe-west2-a failed during the incident. Additionally, snapshot creation for Regional Persistent Disks with one replica located in zone europe-west2-a was unavailable.\n## Cloud SQL\n~79% of HA Cloud SQL instances experienced <5 minutes of downtime due to autofailover with an additional ~5% experiencing <25m of downtime after manual recovery. ~13% of HA Cloud SQL instances with legacy HA configuration did not failover because the replicas were out of sync, and were unreachable for the full duration of the incident. The remaining HA Cloud SQL instances did not failover due to stuck operations. Overall, 97.5% of Regional PD based HA instances and 23% of legacy MySQL HA instances had <25m downtime with the remaining instances being unconnectable during the outage. Google engineering is committed to improving the successful failover rate for Cloud SQL HA instances for zonal outages like this.\n## Google App Engine\nApp Engine Flex apps in europe-west2 experienced increased deployment error rates between 10% and 100% from 18:44 to 20:29.\nApp Engine Standard apps running in the europe-west2 region experienced increased deployment error rates of up to 9.6% that lasted from 18:38 to 18:47. ~34.7% of App Engine Standard apps in the region experienced increased serving error rates between 18:32 and 18:38.\n## Cloud Functions\n34.8% of Cloud Functions served from europe-west2 experienced increased serving error rates between 18:32 and 18:38.\n## Cloud Run\n54.8% of Cloud Run apps served from europe-west2 experienced increased serving error rates between 18:32 and 18:38.\n## Cloud MemoryStore\n~10% of Redis instances in europe-west2, were unreachable during the outage. Both standard tier and basic tier instances were affected. After the main outage was mitigated, most instances recovered, but ~1.5% of instances remained unhealthy for 60 minutes before recovering on their own.\n## Cloud Filestore\n~16% of Filestore instances in europe-west2 were unhealthy. Instances in the zone were unreachable from outside the zone, but access within the zone was largely unaffected.\n## Cloud Bigtable\n100% of single-homed Cloud Bigtable instances in europe-west2-a were unavailable during the outage, translating into 100% error rate for customer instances located in this zone.\n## Kubernetes Engine\n~67% of cluster control planes in europe-west2-a and 10% of regional clusters in europe-west2 were unavailable for the duration of the incident. Investigation into the regional cluster control plane unavailability is still ongoing. Node creation and deletion operations were stalled due to the impact to Compute Engine operations.\n## Cloud Interconnect\nElevated packet loss for zones in europe-west2. Starting at 18:31 packets destined for resources in europe-west2-a experienced loss for the duration of the incident. Additionally, interconnect attachments in europe-west2 experienced regional loss for 7 minutes at 18:31 and 8 minutes at 19:53.\n## Cloud Dataflow\n~10% of jobs in europe-west2 failed or got stuck in cancellation during the outage. ~40% of Dataflow Streaming Engine jobs in the region were degraded over the course of the incident.\n## Cloud VPN\nA number of Cloud VPN tunnels were reset during the disruption and were automatically relocated to other zones in the region. This is within the design of the product, as the loss of one zone is planned. However once zone europe-west2-a reconnected to the network, a combination of bugs in the VPN control plane were triggered by some of the now stale VPN gateways in the zone. This caused an outage to 4.5% of Classic Cloud VPN tunnels in europe-west2 for a duration of 8 hours and 10 minutes after the main disruption had recovered.\n## Cloud Dataproc\n~0.01% of Dataproc API requests to europe-west2 returned UNAVAILABLE during the incident. The majority of these requests were read-only requests (ListClusters, ListJobs, etc.)\n# SLA CREDITS\nIf you believe your paid application experienced an SLA violation as a result of this incident, please submit the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-10T04:43:02+00:00",
        "modified": "2020-12-10T04:43:02+00:00",
        "when": "2020-12-10T04:43:02+00:00",
        "text": "The issue with Google Cloud infrastructure components is believed to be resolved for all services, however a small number of Compute resources may still be affected and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-10T04:30:03+00:00",
        "modified": "2020-12-10T04:30:03+00:00",
        "when": "2020-12-10T04:30:03+00:00",
        "text": "Description: We believe the issue with Google Cloud infrastructure components is resolved for most services as of approximately 2020-12-09 20:21.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Wednesday, 2020-12-09 22:07 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: Moving resources to another zone temporarily.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-10T04:11:39+00:00",
        "modified": "2020-12-10T04:11:39+00:00",
        "when": "2020-12-10T04:11:39+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team. We are starting to see recovery for some Google Cloud infrastructure components.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Wednesday, 2020-12-09 21:40 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: Moving resources to another zone temporarily.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-10T03:51:18+00:00",
        "modified": "2020-12-10T03:51:18+00:00",
        "when": "2020-12-10T03:51:18+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2020-12-09 21:32 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-12-10T03:17:42+00:00",
        "modified": "2020-12-10T03:17:42+00:00",
        "when": "2020-12-10T03:17:42+00:00",
        "text": "Description: We are experiencing an issue with Google Cloud infrastructure components affecting resources located in europe-west2-a.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2020-12-09 20:46 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-12-15T19:03:12+00:00",
      "modified": "2020-12-15T19:56:41+00:00",
      "when": "2020-12-15T19:03:12+00:00",
      "text": "# ISSUE SUMMARY\nOn Wednesday 9 December, 2020, Google Cloud Platform experienced networking unavailability in zone europe-west2-a, resulting in some customers being unable to access their resources, for a duration of 1 hour 24 minutes. The following Google services had degraded service that extended beyond the initial 1 hour 24 minute network disruption:\n- 1.5% of Cloud Memorystore Redis instances were unhealthy for a total duration of 2 hours 24 minutes\n- 4.5% of Classic Cloud VPN tunnels in the europe-west2 region experienced unavailability after the main disruption had recovered and these tunnels remained down for a duration of 8 hours and 10 minutes\n- App Engine Flex experienced increased deployment error rates for a total duration of 1 hour 45 minutes\nWe apologize to our Cloud customers who were impacted during this disruption. We have conducted a thorough internal investigation and are taking immediate action to improve the resiliency and availability of our service.\n# ROOT CAUSE\nGoogle’s underlying networking control plane consists of multiple distributed components that make up the Software Defined Networking (SDN) stack. These components run on multiple machines so that failure of a machine or even multiple machines does not impact network capacity. To achieve this, the control plane elects a leader from a pool of machines to provide configuration to the various infrastructure components. The leader election process depends on a local instance of Google’s internal lock service to read various configurations and files for determining the leader. The control plane is responsible for Border Gateway Protocol (BGP) peering sessions between physical routers connecting a cloud zone to the Google backbone.\nGoogle’s internal lock service provides Access Control List (ACLs) mechanisms to control reading and writing of various files stored in the service. A change to the ACLs used by the network control plane caused the tasks responsible for leader election to no longer have access to the files required for the process. The production environment contained ACLs not present in the staging or canary environments due to those environments being rebuilt using updated processes during previous maintenance events. This meant that some of the ACLs removed in the change were in use in europe-west2-a, and the validation of the configuration change in testing and canary environments did not surface the issue.\nGoogle's resilience strategy relies on the principle of defense in depth. Specifically, despite the network control infrastructure being designed to be highly resilient, the network is designed to 'fail static' and run for a period of time without the control plane being present as an additional line of defense against failure. The network ran normally for a short period - several minutes - after the control plane had been unable to elect a leader task. After this period, BGP routing between europe-west2-a and the rest of the Google backbone network was withdrawn, resulting in isolation of the zone and inaccessibility of resources in the zone.\n# REMEDIATION AND PREVENTION\nGoogle engineers were automatically alerted to elevated error rates in europe-west2-a at 2020-12-09 18:29 US/Pacific and immediately started an investigation. The configuration change rollout was automatically halted as soon as the issue was detected, preventing it from reaching any other zones. At 19:30, mitigation was applied to rollback the configuration change in europe-west2-a. This completed at 19:55, mitigating the immediate issue. Some services such as Cloud MemoryStore and Cloud VPN took additional time to recover due to complications arising from the initial disruption. Services with extended recovery timelines are described in the “detailed description of impact” section below.\nWe are committed to preventing this situation from happening again and are implementing the following actions:\nIn addition to rolling back the configuration change responsible for this disruption, we are auditing all network ACLs to ensure they are consistent across environments. While the network continued to operate for a short time after the change was rolled out, we are improving the operating mode of the data plane when the control plane is unavailable for extended periods. Improvements in visibility to recent changes will be made to reduce the time to mitigation. Additional observability will be added to lock service ACLs allowing for additional validation when making changes to ACLs. We are also improving the canary and release process for future changes of this type to ensure these changes are made safely.\n# DETAILED DESCRIPTION OF IMPACT\nOn Wednesday 9 December, 2020 from 18:31 to 19:55 US/Pacific Google Cloud experienced unavailability for some Google services hosted in zone europe-west2-a as described in detail below. If impact time differs significantly, it will be mentioned specifically.\n## Compute Engine\n~60% of VMs in europe-west2-a were unreachable from outside the zone. Projects affected by this incident would have observed 100% of VMs in the zone being unreachable. Communication within the zone had minor issues, but largely worked normally. VM creation and deletion operations were stalled during the outage. VMs on hosts that had hardware or other faults during the outage were not repaired and restarted onto healthy hosts during the outage.\n## Persistent Disk\nVMs in europe-west2-a experienced stuck I/O operations for 59% of standard persistent disks located in that zone. 27% of regional persistent disks in europe-west2 briefly experienced high I/O latency at the start and end of the incident. Persistent Disk snapshot creation and restore for 59% of disks located in europe-west2-a failed during the incident. Additionally, snapshot creation for Regional Persistent Disks with one replica located in zone europe-west2-a was unavailable.\n## Cloud SQL\n~79% of HA Cloud SQL instances experienced <5 minutes of downtime due to autofailover with an additional ~5% experiencing <25m of downtime after manual recovery. ~13% of HA Cloud SQL instances with legacy HA configuration did not failover because the replicas were out of sync, and were unreachable for the full duration of the incident. The remaining HA Cloud SQL instances did not failover due to stuck operations. Overall, 97.5% of Regional PD based HA instances and 23% of legacy MySQL HA instances had <25m downtime with the remaining instances being unconnectable during the outage. Google engineering is committed to improving the successful failover rate for Cloud SQL HA instances for zonal outages like this.\n## Google App Engine\nApp Engine Flex apps in europe-west2 experienced increased deployment error rates between 10% and 100% from 18:44 to 20:29.\nApp Engine Standard apps running in the europe-west2 region experienced increased deployment error rates of up to 9.6% that lasted from 18:38 to 18:47. ~34.7% of App Engine Standard apps in the region experienced increased serving error rates between 18:32 and 18:38.\n## Cloud Functions\n34.8% of Cloud Functions served from europe-west2 experienced increased serving error rates between 18:32 and 18:38.\n## Cloud Run\n54.8% of Cloud Run apps served from europe-west2 experienced increased serving error rates between 18:32 and 18:38.\n## Cloud MemoryStore\n~10% of Redis instances in europe-west2, were unreachable during the outage. Both standard tier and basic tier instances were affected. After the main outage was mitigated, most instances recovered, but ~1.5% of instances remained unhealthy for 60 minutes before recovering on their own.\n## Cloud Filestore\n~16% of Filestore instances in europe-west2 were unhealthy. Instances in the zone were unreachable from outside the zone, but access within the zone was largely unaffected.\n## Cloud Bigtable\n100% of single-homed Cloud Bigtable instances in europe-west2-a were unavailable during the outage, translating into 100% error rate for customer instances located in this zone.\n## Kubernetes Engine\n~67% of cluster control planes in europe-west2-a and 10% of regional clusters in europe-west2 were unavailable for the duration of the incident. Investigation into the regional cluster control plane unavailability is still ongoing. Node creation and deletion operations were stalled due to the impact to Compute Engine operations.\n## Cloud Interconnect\nElevated packet loss for zones in europe-west2. Starting at 18:31 packets destined for resources in europe-west2-a experienced loss for the duration of the incident. Additionally, interconnect attachments in europe-west2 experienced regional loss for 7 minutes at 18:31 and 8 minutes at 19:53.\n## Cloud Dataflow\n~10% of jobs in europe-west2 failed or got stuck in cancellation during the outage. ~40% of Dataflow Streaming Engine jobs in the region were degraded over the course of the incident.\n## Cloud VPN\nA number of Cloud VPN tunnels were reset during the disruption and were automatically relocated to other zones in the region. This is within the design of the product, as the loss of one zone is planned. However once zone europe-west2-a reconnected to the network, a combination of bugs in the VPN control plane were triggered by some of the now stale VPN gateways in the zone. This caused an outage to 4.5% of Classic Cloud VPN tunnels in europe-west2 for a duration of 8 hours and 10 minutes after the main disruption had recovered.\n## Cloud Dataproc\n~0.01% of Dataproc API requests to europe-west2 returned UNAVAILABLE during the incident. The majority of these requests were read-only requests (ListClusters, ListJobs, etc.)\n# SLA CREDITS\nIf you believe your paid application experienced an SLA violation as a result of this incident, please submit the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "uoypgc4GWUyzAKRHPjEv",
    "service_name": "Google Cloud Infrastructure Components",
    "affected_products": [
      {
        "title": "Google Cloud Infrastructure Components",
        "id": "uoypgc4GWUyzAKRHPjEv"
      }
    ],
    "uri": "incidents/qRpmq9arsrCV7xWdfftF"
  },
  {
    "id": "3K3wmdKmCy6rrZP17WkR",
    "number": "11618083252853721247",
    "begin": "2020-12-04T23:57:00+00:00",
    "created": "2020-12-04T23:57:14+00:00",
    "end": "2020-12-05T03:08:37+00:00",
    "modified": "2020-12-05T03:08:38+00:00",
    "external_desc": "We are experiencing an intermittent issue with Cloud Firestore beginning at Friday, 2020-12-04 12:09:08 US/Pacific.",
    "updates": [
      {
        "created": "2020-12-05T03:08:37+00:00",
        "modified": "2020-12-05T03:08:37+00:00",
        "when": "2020-12-05T03:08:37+00:00",
        "text": "The issue with Cloud Firestore has been resolved for all affected users as of Friday, 2020-12-04 19:00 US/Pacific. We thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-05T01:58:51+00:00",
        "modified": "2020-12-05T01:58:51+00:00",
        "when": "2020-12-05T01:58:51+00:00",
        "text": "Mitigation work is currently underway by our engineering team.\nImpact in us-east1 has been mitigated.\nWe will provide more information by Friday, 2020-12-04 19:00 US/Pacific.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2020-12-04T23:57:14+00:00",
        "modified": "2020-12-04T23:57:14+00:00",
        "when": "2020-12-04T23:57:14+00:00",
        "text": "Mitigation work is currently underway by our engineering team.\nWe expect mitigation to be complete by 17:45 US/Pacific.\nWe will provide more information by Friday, 2020-12-04 17:30 US/Pacific.",
        "status": "SERVICE_OUTAGE"
      }
    ],
    "most_recent_update": {
      "created": "2020-12-05T03:08:37+00:00",
      "modified": "2020-12-05T03:08:37+00:00",
      "when": "2020-12-05T03:08:37+00:00",
      "text": "The issue with Cloud Firestore has been resolved for all affected users as of Friday, 2020-12-04 19:00 US/Pacific. We thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_OUTAGE",
    "severity": "high",
    "service_key": "CETSkT92V21G6A1x28me",
    "service_name": "Cloud Firestore",
    "affected_products": [
      {
        "title": "Cloud Firestore",
        "id": "CETSkT92V21G6A1x28me"
      }
    ],
    "uri": "incidents/3K3wmdKmCy6rrZP17WkR"
  },
  {
    "id": "66MjQZfhHT5g9DQaAsU5",
    "number": "8182693355904097017",
    "begin": "2020-12-04T00:36:42+00:00",
    "created": "2020-12-04T00:57:08+00:00",
    "end": "2020-12-04T05:41:56+00:00",
    "modified": "2020-12-04T05:41:56+00:00",
    "external_desc": "Increased error rate seen for Queries to Cloud Logging.",
    "updates": [
      {
        "created": "2020-12-04T05:41:56+00:00",
        "modified": "2020-12-04T05:41:56+00:00",
        "when": "2020-12-04T05:41:56+00:00",
        "text": "The issue with Cloud Logging has been resolved for all affected users as of Thursday, 2020-12-03 21:36 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-12-04T04:54:55+00:00",
        "modified": "2020-12-04T04:54:55+00:00",
        "when": "2020-12-04T04:54:55+00:00",
        "text": "Description: Our engineering team has determined that further investigation is required to mitigate the issue.\nWe will provide an update by Thursday, 2020-12-03 22:00 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-12-04T04:02:01+00:00",
        "modified": "2020-12-04T04:02:01+00:00",
        "when": "2020-12-04T04:02:01+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2020-12-03 21:00 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-12-04T03:01:59+00:00",
        "modified": "2020-12-04T03:01:59+00:00",
        "when": "2020-12-04T03:01:59+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2020-12-03 20:00 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-12-04T01:56:57+00:00",
        "modified": "2020-12-04T01:56:57+00:00",
        "when": "2020-12-04T01:56:57+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2020-12-03 19:00 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-12-04T00:57:10+00:00",
        "modified": "2020-12-04T00:57:10+00:00",
        "when": "2020-12-04T00:57:10+00:00",
        "text": "Description: We are experiencing errors with queries to Cloud Logging beginning at Thursday, 2020-12-03 16:25 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2020-12-03 18:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-12-04T05:41:56+00:00",
      "modified": "2020-12-04T05:41:56+00:00",
      "when": "2020-12-04T05:41:56+00:00",
      "text": "The issue with Cloud Logging has been resolved for all affected users as of Thursday, 2020-12-03 21:36 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/66MjQZfhHT5g9DQaAsU5"
  },
  {
    "id": "Y2KZfZgry3aKPWdpu8PN",
    "number": "17329550064699032885",
    "begin": "2020-11-19T16:49:41+00:00",
    "created": "2020-11-19T18:18:03+00:00",
    "end": "2020-11-20T05:16:13+00:00",
    "modified": "2020-11-20T05:16:13+00:00",
    "external_desc": "Cloud Logging delays on log ingestion affecting 25% of projects.",
    "updates": [
      {
        "created": "2020-11-20T05:16:13+00:00",
        "modified": "2020-11-20T05:16:13+00:00",
        "when": "2020-11-20T05:16:13+00:00",
        "text": "The issue with Cloud Logging has been resolved for all affected projects as of Thursday, 2020-11-19 21:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-11-20T03:31:01+00:00",
        "modified": "2020-11-20T03:31:01+00:00",
        "when": "2020-11-20T03:31:01+00:00",
        "text": "Description: We believe the issue with Cloud Logging is partially resolved. Additional cleanup is ongoing. Some users may experience slow queries.\nWe expect a full resolution within 3 hours.\nWe will provide an update by Thursday, 2020-11-19 22:30 US/Pacific with current details.\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-20T02:26:52+00:00",
        "modified": "2020-11-20T02:26:52+00:00",
        "when": "2020-11-20T02:26:52+00:00",
        "text": "Description: We believe the issue with Cloud Logging is partially resolved. Additional cleanup and prevention efforts are ongoing. Some users may experience slow queries.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Thursday, 2020-11-19 19:30 US/Pacific with current details.\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-20T00:38:53+00:00",
        "modified": "2020-11-20T00:38:53+00:00",
        "when": "2020-11-20T00:38:53+00:00",
        "text": "Description: We believe the issue with Cloud Logging is partially resolved. Additional cleanup and prevention efforts are ongoing, but the majority of users should see their log data available and queries succeeding.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Thursday, 2020-11-19 18:30 US/Pacific with current details.\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-19T23:14:03+00:00",
        "modified": "2020-11-19T23:14:03+00:00",
        "when": "2020-11-19T23:14:03+00:00",
        "text": "Description: The backlog has been fully processed, but we are still seeing elevated error rates on queries with new data. Mitigation efforts are still ongoing.\nWe will provide more information by Thursday, 2020-11-19 16:45 US/Pacific.\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-19T22:04:25+00:00",
        "modified": "2020-11-19T22:04:25+00:00",
        "when": "2020-11-19T22:04:25+00:00",
        "text": "Description: Current ETA is ~2 hours to finish processing the backlog.\nWe will provide more information by Thursday, 2020-11-19 16:45 US/Pacific.\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-19T21:40:13+00:00",
        "modified": "2020-11-19T21:40:13+00:00",
        "when": "2020-11-19T21:40:13+00:00",
        "text": "Description: Log ingestion has been resumed, and now the backlog of recent data (about 4.5 hours) is being processed.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2020-11-19 16:45 US/Pacific.\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-19T20:21:11+00:00",
        "modified": "2020-11-19T20:21:11+00:00",
        "when": "2020-11-19T20:21:11+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team. Ingestion is temporarily paused for a couple hours to speedup the recovery efforts.\nWe will provide more information by Thursday, 2020-11-19 15:00 US/Pacific.\nDiagnosis: Log writes and reads experiencing latency on logs ingested after 2020-11-19 08:41 US/Pacific. 25% of customers are affected and may see incomplete queries.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-19T19:18:26+00:00",
        "modified": "2020-11-19T19:18:26+00:00",
        "when": "2020-11-19T19:18:26+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team, the current focus is on stabilizing new requests, then proceeding to process backlog.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2020-11-19 12:30 US/Pacific.\nDiagnosis: Log writes and reads experiencing latency. 25% of customers may see symptoms.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-19T18:47:43+00:00",
        "modified": "2020-11-19T18:47:43+00:00",
        "when": "2020-11-19T18:47:43+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team, the current focus is on stabilizing new requests, then proceeding to process backlog.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2020-11-19 11:50 US/Pacific.\nDiagnosis: Log writes and reads experiencing latency. 25% of customers may see symptoms.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-19T18:18:04+00:00",
        "modified": "2020-11-19T18:18:04+00:00",
        "when": "2020-11-19T18:18:04+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team, the current focus is on stabilizing new requests, then proceeding to process backlog.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2020-11-19 11:45 US/Pacific.\nDiagnosis: Log writes and reads in us-central1 experiencing latency. 25% of customers may also see similar symptoms in other locations when using the global logging region.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-11-20T05:16:13+00:00",
      "modified": "2020-11-20T05:16:13+00:00",
      "when": "2020-11-20T05:16:13+00:00",
      "text": "The issue with Cloud Logging has been resolved for all affected projects as of Thursday, 2020-11-19 21:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/Y2KZfZgry3aKPWdpu8PN"
  },
  {
    "id": "F3ynGAM65bztYcpXm47U",
    "number": "5277528808744564477",
    "begin": "2020-11-17T20:02:42+00:00",
    "created": "2020-11-17T20:19:31+00:00",
    "end": "2020-11-17T20:36:58+00:00",
    "modified": "2020-11-17T20:36:58+00:00",
    "external_desc": "Storage Transfer Service unable to edit job configurations",
    "updates": [
      {
        "created": "2020-11-17T20:36:58+00:00",
        "modified": "2020-11-17T20:36:58+00:00",
        "when": "2020-11-17T20:36:58+00:00",
        "text": "The issue with Google Cloud Storage transfer service is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-11-17T20:19:33+00:00",
        "modified": "2020-11-17T20:19:33+00:00",
        "when": "2020-11-17T20:19:33+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2020-11-17 14:00 US/Pacific.\nDiagnosis: Affected customers will see invalid input errors when attempting to modify some fields within a transfer job's configuration.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-11-17T20:36:58+00:00",
      "modified": "2020-11-17T20:36:58+00:00",
      "when": "2020-11-17T20:36:58+00:00",
      "text": "The issue with Google Cloud Storage transfer service is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "UwaYoXQ5bHYHG6EdiPB8",
    "service_name": "Google Cloud Storage",
    "affected_products": [
      {
        "title": "Google Cloud Storage",
        "id": "UwaYoXQ5bHYHG6EdiPB8"
      }
    ],
    "uri": "incidents/F3ynGAM65bztYcpXm47U"
  },
  {
    "id": "u1KnEuW3YbVThbYSS6NZ",
    "number": "8507828116521640934",
    "begin": "2020-11-12T23:37:41+00:00",
    "created": "2020-11-13T19:27:29+00:00",
    "end": "2020-11-13T22:23:20+00:00",
    "modified": "2020-11-13T22:23:21+00:00",
    "external_desc": "We are experiencing an issue with loading several pages in the Cloud Console, including modifying External HTTP(S) Load Balancer configurations.",
    "updates": [
      {
        "created": "2020-11-13T22:23:20+00:00",
        "modified": "2020-11-13T22:23:20+00:00",
        "when": "2020-11-13T22:23:20+00:00",
        "text": "The issue with Cloud Console pages not loading has been resolved for all affected projects. as of Friday, 2020-11-13 13:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-11-13T20:58:54+00:00",
        "modified": "2020-11-13T20:58:54+00:00",
        "when": "2020-11-13T20:58:54+00:00",
        "text": "Description: Customers trying to modify External HTTP(S) Load Balancer configurations in Cloud Console may see their custom cache key settings inadvertently cleared.\nAdditionally, customers might be having issues loading other pages in the Cloud Console.\nThe rollout for the mitigation is currently underway and about halfway complete.\nWe will provide an update by Friday, 2020-11-13 14:30 US/Pacific with current details.\nDiagnosis: Customers trying to modify External HTTP(S) Load Balancer configurations in Cloud Console may see their custom cache key settings inadvertently cleared.\nWorkaround: Use gcloud commands to make changes for load balancers.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-13T19:30:08+00:00",
        "modified": "2020-11-13T19:30:08+00:00",
        "when": "2020-11-13T19:30:08+00:00",
        "text": "Description: Customers trying to modify External HTTP(S) Load Balancer configurations in Cloud Console may see their custom cache key settings inadvertently cleared.\nAdditionally, customers might be having issues loading other pages in the Cloud Console.\nOur engineering team has determined that further investigation is required to mitigate the issue.\nWe will provide an update by Friday, 2020-11-13 13:00 US/Pacific with current details.\nDiagnosis: Customers trying to modify External HTTP(S) Load Balancer configurations in Cloud Console may see their custom cache key settings inadvertently cleared.\nWorkaround: Use gcloud commands to make changes for load balancers.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-13T19:27:30+00:00",
        "modified": "2020-11-13T19:27:30+00:00",
        "when": "2020-11-13T19:27:30+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Friday, 2020-11-13 15:00 US/Pacific.\nWe will provide more information by Friday, 2020-11-13 11:30 US/Pacific.\nDiagnosis: Customers trying to modify External HTTP(S) Load Balancer configurations in Cloud Console may see their custom cache key settings inadvertently cleared.\nWorkaround: Use gcloud commands to make changes for load balancers.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-11-13T22:23:20+00:00",
      "modified": "2020-11-13T22:23:20+00:00",
      "when": "2020-11-13T22:23:20+00:00",
      "text": "The issue with Cloud Console pages not loading has been resolved for all affected projects. as of Friday, 2020-11-13 13:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "Wdsr1n5vyDvCt78qEifm",
    "service_name": "Google Cloud Console",
    "affected_products": [
      {
        "title": "Google Cloud Console",
        "id": "Wdsr1n5vyDvCt78qEifm"
      }
    ],
    "uri": "incidents/u1KnEuW3YbVThbYSS6NZ"
  },
  {
    "id": "XEVideuyoH5ey3k1Ea6D",
    "number": "3470571992247963341",
    "begin": "2020-11-10T21:41:00+00:00",
    "created": "2020-11-10T22:33:26+00:00",
    "end": "2020-11-11T19:01:10+00:00",
    "modified": "2020-11-11T19:01:10+00:00",
    "external_desc": "Elevated frequency of Host Maintenance events on GCE instances with an attached GPU(s) and SSD(s)",
    "updates": [
      {
        "created": "2020-11-11T19:01:10+00:00",
        "modified": "2020-11-11T19:01:10+00:00",
        "when": "2020-11-11T19:01:10+00:00",
        "text": "The issue with Google Compute Engine instances with an attached GPU(s) and SSD(s) is believed to be affecting a very small number of projects and our Engineering Team continues to work on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-11-11T00:04:29+00:00",
        "modified": "2020-11-11T00:04:29+00:00",
        "when": "2020-11-11T00:04:29+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team. Further investigation of current impact and mitigation timeline is ongoing.\nWe will provide more information by Wednesday, 2020-11-11 13:00 US/Pacific.\nDiagnosis: Affected customers will experience elevated frequency of Host Maintenance events on GCE instances with an attached GPU(s) and SSD(s).\nWorkaround: Temporarily switch to use V100 GPU's which are unaffected by this issue.\nhttps://cloud.google.com/compute/docs/gpus",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-11-10T22:33:27+00:00",
        "modified": "2020-11-10T22:33:27+00:00",
        "when": "2020-11-10T22:33:27+00:00",
        "text": "Description: We are experiencing an issue with Google Compute Engine beginning in 2020-08. A firmware rollout is being created that should address the issue.\nThe rollout is currently expected to complete next week, but mitigation efforts are still ongoing.\nWe will provide more information by Tuesday, 2020-11-10 16:30 US/Pacific.\nDiagnosis: Affected customers will experience elevated frequency of Host Maintenance events on GCE instances with an attached GPU(s) and SSD(s).\nWorkaround: Temporarily switch to use V100 GPU's which are unaffected by this issue.\nhttps://cloud.google.com/compute/docs/gpus",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-11-11T19:01:10+00:00",
      "modified": "2020-11-11T19:01:10+00:00",
      "when": "2020-11-11T19:01:10+00:00",
      "text": "The issue with Google Compute Engine instances with an attached GPU(s) and SSD(s) is believed to be affecting a very small number of projects and our Engineering Team continues to work on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/XEVideuyoH5ey3k1Ea6D"
  },
  {
    "id": "CYJJtJjLoKE24P3cY5Sj",
    "number": "9895981887663985833",
    "begin": "2020-11-05T20:22:48+00:00",
    "created": "2020-11-05T20:41:54+00:00",
    "end": "2020-11-05T21:43:49+00:00",
    "modified": "2020-11-05T21:43:50+00:00",
    "external_desc": "GAE Cloud Monitoring Metrics are not being ingested.",
    "updates": [
      {
        "created": "2020-11-05T21:43:49+00:00",
        "modified": "2020-11-05T21:43:49+00:00",
        "when": "2020-11-05T21:43:49+00:00",
        "text": "The issue with Google App Engine has been resolved for all affected projects as of Thursday, 2020-11-05 13:11 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-11-05T20:57:17+00:00",
        "modified": "2020-11-05T20:57:17+00:00",
        "when": "2020-11-05T20:57:17+00:00",
        "text": "Description: We have rolled back an update and believe the issue with Google App Engine is partially resolved. Our engineering teams are working to confirm full resolution.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Thursday, 2020-11-05 13:45 US/Pacific with current details.\nDiagnosis: Metric dashboards for GAE services no longer update.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      },
      {
        "created": "2020-11-05T20:41:55+00:00",
        "modified": "2020-11-05T20:41:55+00:00",
        "when": "2020-11-05T20:41:55+00:00",
        "text": "Description: We are experiencing an issue with Google App Engine beginning at Thursday, 2020-11-05 09:55 US/Pacific. Cloud Monitoring Metrics are no longer being ingested causing telemetry data to be unavailable.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2020-11-05 13:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Metric dashboards for GAE services no longer update.\nWorkaround: None at this time.",
        "status": "SERVICE_OUTAGE"
      }
    ],
    "most_recent_update": {
      "created": "2020-11-05T21:43:49+00:00",
      "modified": "2020-11-05T21:43:49+00:00",
      "when": "2020-11-05T21:43:49+00:00",
      "text": "The issue with Google App Engine has been resolved for all affected projects as of Thursday, 2020-11-05 13:11 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_OUTAGE",
    "severity": "high",
    "service_key": "kchyUtnkMHJWaAva8aYc",
    "service_name": "Google App Engine",
    "affected_products": [
      {
        "title": "Google App Engine",
        "id": "kchyUtnkMHJWaAva8aYc"
      }
    ],
    "uri": "incidents/CYJJtJjLoKE24P3cY5Sj"
  },
  {
    "id": "w9cZh4SAJwJkJFEFoU8K",
    "number": "7934219454829159134",
    "begin": "2020-10-30T15:33:55+00:00",
    "created": "2020-10-30T23:30:54+00:00",
    "end": "2020-10-31T00:02:25+00:00",
    "modified": "2020-10-31T00:02:26+00:00",
    "external_desc": "GCE instance creation/start/stop operations failing in us-central1-f",
    "updates": [
      {
        "created": "2020-10-31T00:02:25+00:00",
        "modified": "2020-10-31T00:02:25+00:00",
        "when": "2020-10-31T00:02:25+00:00",
        "text": "The issue with Google Compute Engine has been resolved for all affected users as of Friday, 2020-10-30 16:35 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-30T23:56:13+00:00",
        "modified": "2020-10-30T23:56:13+00:00",
        "when": "2020-10-30T23:56:13+00:00",
        "text": "Description: We believe the issue with Google Compute Engine operations is partially resolved. All previous operations should have completed, and customers should experience normal latency on new operations.\nWe will provide an update by Friday, 2020-10-30 17:45 US/Pacific with current details.\nDiagnosis: Affected customers may see delays performing instance operations, but they should eventually complete. Other Cloud Services that create instances on demand may also experience impact such as: Google Kubernetes Engine, Composer, Dataproc, and Dataflow.\nWorkaround: When possible try instance operations in other zones.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-30T23:37:45+00:00",
        "modified": "2020-10-30T23:37:45+00:00",
        "when": "2020-10-30T23:37:45+00:00",
        "text": "Description: Other Cloud Services that create instances on demand may be impacted such as: Google Kubernetes Engine, Composer, Dataproc, and Dataflow\nWe will provide an update by Friday, 2020-10-30 17:00 US/Pacific with current details.\nDiagnosis: Affected customers may see delays performing instance operations, but they should eventually complete. Other Cloud Services that create instances on demand may also experience impact such as: Google Kubernetes Engine, Composer, Dataproc, and Dataflow.\nWorkaround: When possible try instance operations in other zones.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-30T23:30:55+00:00",
        "modified": "2020-10-30T23:30:55+00:00",
        "when": "2020-10-30T23:30:55+00:00",
        "text": "Description: We are experiencing an issue with Google Compute Engine starting on Friday, 2020-10-30 07:30 US/Pacific. The backlog is continuing to decrease, and delays on new instance creation have significantly decreased from the peak with an average of 1 minute. We are anticipating the backlog to clear in approximately 40 minutes.\nWe will provide an update by Friday, 2020-10-30 17:00 US/Pacific with current details.\nDiagnosis: Affected customers may see delays performing instance operations, but they should eventually complete.\nWorkaround: When possible try instance operations in other zones.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-31T00:02:25+00:00",
      "modified": "2020-10-31T00:02:25+00:00",
      "when": "2020-10-31T00:02:25+00:00",
      "text": "The issue with Google Compute Engine has been resolved for all affected users as of Friday, 2020-10-30 16:35 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/w9cZh4SAJwJkJFEFoU8K"
  },
  {
    "id": "5NBzNV3qbEcok9mxQzTt",
    "number": "8318904122087609064",
    "begin": "2020-10-29T20:09:28+00:00",
    "created": "2020-10-29T20:12:14+00:00",
    "end": "2020-10-29T21:16:52+00:00",
    "modified": "2020-10-29T21:16:53+00:00",
    "external_desc": "We believe the issue with Cloud Run deployments failing is fully resolved as of Thursday, 2020-10-29 14:07.",
    "updates": [
      {
        "created": "2020-10-29T21:16:53+00:00",
        "modified": "2020-10-29T21:16:53+00:00",
        "when": "2020-10-29T21:16:53+00:00",
        "text": "The issue with Cloud Run deployments failing globally has been resolved for all affected projects as of Thursday, 2020-10-29 14:07 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-29T21:11:24+00:00",
        "modified": "2020-10-29T21:11:24+00:00",
        "when": "2020-10-29T21:11:24+00:00",
        "text": "Description: We believe the issue with Cloud Run deployments failing is fully resolved as of Thursday, 2020-10-29 14:07.\nWe are currently monitoring the situation to ensure there is no recurrence.\nWe will provide an update by Thursday, 2020-10-29 14:45 US/Pacific with current details.\nDiagnosis: New deployments to Cloud Run will fail globally.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-29T20:40:23+00:00",
        "modified": "2020-10-29T20:40:23+00:00",
        "when": "2020-10-29T20:40:23+00:00",
        "text": "Description: Our engineering team is currently rolling back a configuration change to mitigate the issue. We do not yet have an ETA for full resolution.\nExisting Cloud Run deployments are unaffected.\nWe will provide more information by Thursday, 2020-10-29 14:30 US/Pacific.\nDiagnosis: New deployments to Cloud Run will fail globally.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-29T20:12:17+00:00",
        "modified": "2020-10-29T20:12:17+00:00",
        "when": "2020-10-29T20:12:17+00:00",
        "text": "Description: We are investigating an issue with Cloud Run deployments failing globally starting at Thursday, 2020-10-29 12:45 US/Pacific.\nWe will provide more information by Thursday, 2020-10-29 14:00 US/Pacific.\nDiagnosis: New deployments to Cloud Run may fail.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-29T21:16:53+00:00",
      "modified": "2020-10-29T21:16:53+00:00",
      "when": "2020-10-29T21:16:53+00:00",
      "text": "The issue with Cloud Run deployments failing globally has been resolved for all affected projects as of Thursday, 2020-10-29 14:07 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "9D7d2iNBQWN24zc1VamE",
    "service_name": "Cloud Run",
    "affected_products": [
      {
        "title": "Cloud Run",
        "id": "9D7d2iNBQWN24zc1VamE"
      }
    ],
    "uri": "incidents/5NBzNV3qbEcok9mxQzTt"
  },
  {
    "id": "7rMydYAN8YKtsxyzF2wj",
    "number": "14785656458316182180",
    "begin": "2020-10-27T20:21:53+00:00",
    "created": "2020-10-27T20:24:38+00:00",
    "end": "2020-10-27T21:09:41+00:00",
    "modified": "2020-10-27T21:09:41+00:00",
    "external_desc": "We've received a report of an issue with Google Cloud Storage as of Tuesday, 2020-10-27 11:00 US/Pacific.",
    "updates": [
      {
        "created": "2020-10-27T21:09:41+00:00",
        "modified": "2020-10-27T21:09:41+00:00",
        "when": "2020-10-27T21:09:41+00:00",
        "text": "The issue with Google Cloud Storage buckets in us-central1 seeing higher latency and timeout errors has been resolved for all affected projects as of Tuesday, 2020-10-27 13:30 US/Pacific.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-27T20:53:24+00:00",
        "modified": "2020-10-27T20:53:24+00:00",
        "when": "2020-10-27T20:53:24+00:00",
        "text": "Description: We've received a report of an issue with Google Cloud Storage as of Tuesday, 2020-10-27 11:00 US/Pacific.\nMitigation has been effective and we believe the issue should be resolved as of Tuesday, 2020-10-27 13:30 US/Pacific. We are continuing to monitor the situation for any changes.\nWe will provide more information by Tuesday, 2020-10-27 14:15 US/Pacific.\nDiagnosis: Affected customers may experience request timeout errors. Downstream services may include Google Container Registry with images being stored in us-central1. This may cause GKE workloads to have trouble pulling new images in us-central1.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-27T20:38:23+00:00",
        "modified": "2020-10-27T20:38:23+00:00",
        "when": "2020-10-27T20:38:23+00:00",
        "text": "Description: We are experiencing an issue with Google Cloud Storage requests timing out as of Tuesday, 2020-10-27 11:00 US/Pacific.\nGoogle Container Registry is also experiencing timeout errors as a result of the Google Cloud Storage issues.\nOur engineers are currently investigating the root cause and working to mitigate the issue.\nWe will provide more information by Tuesday, 2020-10-27 14:15 US/Pacific.\nLocation: us-central1\nDiagnosis: Affected customers may experience request timeout errors.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-27T20:24:40+00:00",
        "modified": "2020-10-27T20:24:40+00:00",
        "when": "2020-10-27T20:24:40+00:00",
        "text": "Description: We've received a report of an issue with Google Cloud Storage as of Tuesday, 2020-10-27 11:00 US/Pacific.\nOur engineers are currently investigating the root cause.\nWe will provide more information by Tuesday, 2020-10-27 14:00 US/Pacific.\nLocation: us-central1\nDiagnosis: Affected customers may experience request timeout errors.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-27T21:09:41+00:00",
      "modified": "2020-10-27T21:09:41+00:00",
      "when": "2020-10-27T21:09:41+00:00",
      "text": "The issue with Google Cloud Storage buckets in us-central1 seeing higher latency and timeout errors has been resolved for all affected projects as of Tuesday, 2020-10-27 13:30 US/Pacific.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "UwaYoXQ5bHYHG6EdiPB8",
    "service_name": "Google Cloud Storage",
    "affected_products": [
      {
        "title": "Google Cloud Storage",
        "id": "UwaYoXQ5bHYHG6EdiPB8"
      }
    ],
    "uri": "incidents/7rMydYAN8YKtsxyzF2wj"
  },
  {
    "id": "GuPZryLqT4zkmR8kKm4Z",
    "number": "5929880961445049648",
    "begin": "2020-10-24T16:56:39+00:00",
    "created": "2020-10-24T17:18:47+00:00",
    "end": "2020-10-24T19:02:57+00:00",
    "modified": "2020-10-27T05:18:07+00:00",
    "external_desc": "We are investigating an elevated error rate in us-east1 for Cloud Storage Customers.",
    "updates": [
      {
        "created": "2020-10-24T19:02:57+00:00",
        "modified": "2020-10-27T05:10:48+00:00",
        "when": "2020-10-24T19:02:57+00:00",
        "text": "Mitigations are complete, and we are seeing service restored for all customers.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-24T18:06:37+00:00",
        "modified": "2020-10-24T18:06:37+00:00",
        "when": "2020-10-24T18:06:37+00:00",
        "text": "Description: We are experiencing an issue with Google Cloud Storage beginning at Saturday, 2020-10-24 07:40 PDT.\nCurrently, we have begun mitigations, and customers should begin to experience regular service within the hour.\nWe will provide an update by Saturday, 2020-10-24 12:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: This may appear as timeouts, 5XX errors and potential authorization errors being returned from the service.\nWorkaround: There is no workaround at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-24T17:18:48+00:00",
        "modified": "2020-10-24T17:18:48+00:00",
        "when": "2020-10-24T17:18:48+00:00",
        "text": "Description: We are experiencing an issue with Google Cloud Storage beginning at Saturday, 2020-10-24 07:40 PDT.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2020-10-24 11:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: This may appear as timeouts, 5XX errors and potential authorization errors being returned from the service.\nWorkaround: There is no workaround at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-24T19:02:57+00:00",
      "modified": "2020-10-27T05:10:48+00:00",
      "when": "2020-10-24T19:02:57+00:00",
      "text": "Mitigations are complete, and we are seeing service restored for all customers.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "UwaYoXQ5bHYHG6EdiPB8",
    "service_name": "Google Cloud Storage",
    "affected_products": [
      {
        "title": "Google Cloud Storage",
        "id": "UwaYoXQ5bHYHG6EdiPB8"
      }
    ],
    "uri": "incidents/GuPZryLqT4zkmR8kKm4Z"
  },
  {
    "id": "o7iZ5G548ApGXoyeimGu",
    "number": "7403841714541921274",
    "begin": "2020-10-23T13:22:29+00:00",
    "created": "2020-10-23T13:47:22+00:00",
    "end": "2020-10-23T15:00:41+00:00",
    "modified": "2020-10-23T15:00:42+00:00",
    "external_desc": "Some deployments to Google Cloud Functions using go113 runtime are failing",
    "updates": [
      {
        "created": "2020-10-23T15:00:41+00:00",
        "modified": "2020-10-23T15:00:41+00:00",
        "when": "2020-10-23T15:00:41+00:00",
        "text": "The issue with deployments of Google Cloud Functions using go113 runtime has been resolved for all affected users as of Friday, 2020-10-23 07:51 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-23T14:54:17+00:00",
        "modified": "2020-10-23T14:54:17+00:00",
        "when": "2020-10-23T14:54:17+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2020-10-23 08:15 US/Pacific.\nDiagnosis: Customers affected by this issue may see an error similar to the following:\nERROR: (gcloud.functions.deploy) OperationError: code=3, message=Build failed: # github.com/cloudevents/sdk-go/v2/extensions\nsrc/github.com/cloudevents/sdk-go/v2/extensions/distributed_tracing_extension.go:161:3: cannot use span (type trace.Span) as type *trace.Span in return argument:\n*trace.Span is pointer to interface, not interface; Error ID: 1093f764\nWorkaround: Customers can avoid this issue by making sure to include a \"go.mod\" file in their project. For more information see this blog post:\nhttps://blog.golang.org/using-go-modules",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-23T14:13:11+00:00",
        "modified": "2020-10-23T14:13:11+00:00",
        "when": "2020-10-23T14:13:11+00:00",
        "text": "Description: We are experiencing an issue with Google Cloud Functions, affecting deployments using the \"go113\" runtime, beginning at Thursday, 2020-10-22 15:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2020-10-23 08:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers affected by this issue may see an error similar to the following:\nERROR: (gcloud.functions.deploy) OperationError: code=3, message=Build failed: # github.com/cloudevents/sdk-go/v2/extensions\nsrc/github.com/cloudevents/sdk-go/v2/extensions/distributed_tracing_extension.go:161:3: cannot use span (type trace.Span) as type *trace.Span in return argument:\n*trace.Span is pointer to interface, not interface; Error ID: 1093f764\nWorkaround: Customers can avoid this issue by making sure to include a \"go.mod\" file in their project. For more information see this blog post:\nhttps://blog.golang.org/using-go-modules",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-23T13:47:24+00:00",
        "modified": "2020-10-23T13:47:24+00:00",
        "when": "2020-10-23T13:47:24+00:00",
        "text": "Description: We are experiencing an issue with Google Cloud Functions, affecting deployments using the \"go113\" runtime, beginning at Thursday, 2020-10-22 15:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2020-10-23 08:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers affected by this issue may see an error similar to the following:\nERROR: (gcloud.functions.deploy) OperationError: code=3, message=Build failed: # github.com/cloudevents/sdk-go/v2/extensions\nsrc/github.com/cloudevents/sdk-go/v2/extensions/distributed_tracing_extension.go:161:3: cannot use span (type trace.Span) as type *trace.Span in return argument:\n*trace.Span is pointer to interface, not interface; Error ID: 1093f764\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-23T15:00:41+00:00",
      "modified": "2020-10-23T15:00:41+00:00",
      "when": "2020-10-23T15:00:41+00:00",
      "text": "The issue with deployments of Google Cloud Functions using go113 runtime has been resolved for all affected users as of Friday, 2020-10-23 07:51 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "oW4vJ7VNqyxTWNzSHopX",
    "service_name": "Google Cloud Functions",
    "affected_products": [
      {
        "title": "Google Cloud Functions",
        "id": "oW4vJ7VNqyxTWNzSHopX"
      }
    ],
    "uri": "incidents/o7iZ5G548ApGXoyeimGu"
  },
  {
    "id": "3gQTXFNuxBfN4GBr2RAY",
    "number": "8854402229900326638",
    "begin": "2020-10-23T01:08:25+00:00",
    "created": "2020-10-23T01:26:41+00:00",
    "end": "2020-10-23T03:11:51+00:00",
    "modified": "2020-10-23T03:11:51+00:00",
    "external_desc": "We're experiencing an issue with gcloud auth application-default login.",
    "updates": [
      {
        "created": "2020-10-23T03:11:51+00:00",
        "modified": "2020-10-23T03:11:51+00:00",
        "when": "2020-10-23T03:11:51+00:00",
        "text": "The issue with gcloud is believed to be affecting a very small number of users and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-23T01:56:12+00:00",
        "modified": "2020-10-23T01:56:12+00:00",
        "when": "2020-10-23T01:56:12+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2020-10-22 21:00 US/Pacific.\nDiagnosis: Customers may receive 'Sign in with Google temporarily disabled for this app' when running 'gcloud auth application-default login'.\nWorkaround: 1. Get in touch with your Google Workspace (formerly GSuite) administrator\n2. Visit [https://support.google.com/a/answer/7281227](https://support.google.com/a/answer/7281227)\n3. Follow the \"Manage access to apps: Trusted, Limited, or Blocked\" method\n4. Add '764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com' as a trusted Client ID.\n5. Retry your 'gcloud auth application-default login' operation within a few minutes.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-23T01:45:32+00:00",
        "modified": "2020-10-23T01:54:27+00:00",
        "when": "2020-10-23T01:45:32+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2020-10-22 20:00 US/Pacific.\nDiagnosis: Customers may receive 'Sign in with Google temporarily disabled for this app' when running 'gcloud auth application-default login'.\nWorkaround:\n1. Get in touch with your Google Workspace (formerly GSuite) administrator\n2. Visit [https://support.google.com/a/answer/7281227](https://support.google.com/a/answer/7281227)\n3. Follow the \"Manage access to apps: Trusted, Limited, or Blocked\" method\n4. Add '764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com' as a trusted Client ID.\n5. Retry your 'gcloud auth application-default login' operation within a few minutes.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-23T01:26:43+00:00",
        "modified": "2020-10-23T01:57:16+00:00",
        "when": "2020-10-23T01:26:43+00:00",
        "text": "Description: We are experiencing an issue with gcloud auth application-default login.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2020-10-22 19:00 US/Pacific with current details.\nDiagnosis: Customers may receive 'Sign in with Google temporarily disabled for this app' when running 'gcloud auth application-default login'.\nWorkaround: 1. Get in touch with your Google Workspace (formerly GSuite) administrator\n2. Visit [https://support.google.com/a/answer/7281227](https://support.google.com/a/answer/7281227)\n3. Follow the \"Manage access to apps: Trusted, Limited, or Blocked\" method\n4. Add '764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com' as a trusted Client ID.\n5. Retry your 'gcloud auth application-default login' operation within a few minutes.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-23T03:11:51+00:00",
      "modified": "2020-10-23T03:11:51+00:00",
      "when": "2020-10-23T03:11:51+00:00",
      "text": "The issue with gcloud is believed to be affecting a very small number of users and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "bGThzF7oEGP5jcuDdMuk",
    "service_name": "Google Cloud Support",
    "affected_products": [
      {
        "title": "Google Cloud Support",
        "id": "bGThzF7oEGP5jcuDdMuk"
      }
    ],
    "uri": "incidents/3gQTXFNuxBfN4GBr2RAY"
  },
  {
    "id": "dheHaUyFjoLWXD5Wp4hD",
    "number": "14449373835609281099",
    "begin": "2020-10-20T00:42:01+00:00",
    "created": "2020-10-20T00:44:54+00:00",
    "end": "2020-10-20T03:56:22+00:00",
    "modified": "2020-10-20T03:56:23+00:00",
    "external_desc": "We are experiencing an issue with Google Kubernetes Engine in us-central1.",
    "updates": [
      {
        "created": "2020-10-20T03:56:22+00:00",
        "modified": "2020-10-20T03:56:22+00:00",
        "when": "2020-10-20T03:56:22+00:00",
        "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Monday, 2020-10-19 20:00 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-20T02:59:25+00:00",
        "modified": "2020-10-20T02:59:25+00:00",
        "when": "2020-10-20T02:59:25+00:00",
        "text": "Description: Our engineering team continues to work on mitigating the underlying networking issue.\nWe will provide an update by Monday, 2020-10-19 21:15 US/Pacific with current details.\nDiagnosis: Cluster mutation operations may result errors for affected clusters. The operations include creations and deletions of clusters, nodepools, and nodes.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-20T02:06:55+00:00",
        "modified": "2020-10-20T02:06:55+00:00",
        "when": "2020-10-20T02:06:55+00:00",
        "text": "Description: Our engineering team has determined that further investigation is required to mitigate the underlying networking issue.\nWe will provide an update by Monday, 2020-10-19 20:05 US/Pacific with current details.\nDiagnosis: Affected clusters may fail during cluster mutation operations, including creations and deletions of clusters, nodepools, and nodes.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-20T01:38:07+00:00",
        "modified": "2020-10-20T01:38:07+00:00",
        "when": "2020-10-20T01:38:07+00:00",
        "text": "Description: Mitigation work is still underway in the underlying networking incident. We believe that cluster mutation operations will be recovered shortly after the underlying incident is mitigated.\nWe will provide more information by Monday, 2020-10-19 19:15 US/Pacific.\nDiagnosis: Affected clusters may fail during cluster mutation operations, including creations and deletions of clusters, nodepools, and nodes.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-20T01:05:18+00:00",
        "modified": "2020-10-20T01:05:18+00:00",
        "when": "2020-10-20T01:05:18+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team. We believe that the mitigation of the underlying networking incident will resolve its affect to cluster mutation operations. We do not yet have a ETA of full mitigation at this point.\nWe will provide more information by Monday, 2020-10-19 18:45 US/Pacific.\nDiagnosis: Affected clusters may fail during cluster mutation operations, including creations and deletions of clusters, nodepools, and nodes.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-20T00:44:55+00:00",
        "modified": "2020-10-20T00:44:55+00:00",
        "when": "2020-10-20T00:44:55+00:00",
        "text": "Description: We are experiencing an issue with Google Kubernetes Engine in the us-central1 region. We believe the cause is related to the currently ongoing networking incident in the region. Our engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2020-10-19 18:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected clusters may fail during cluster mutation operations, including creations and deletions of clusters, nodepools, and nodes.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-20T03:56:22+00:00",
      "modified": "2020-10-20T03:56:22+00:00",
      "when": "2020-10-20T03:56:22+00:00",
      "text": "The issue with Google Kubernetes Engine has been resolved for all affected projects as of Monday, 2020-10-19 20:00 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/dheHaUyFjoLWXD5Wp4hD"
  },
  {
    "id": "VoJNub6ejZ5iFurC73G6",
    "number": "12825795447649237417",
    "begin": "2020-10-19T21:19:11+00:00",
    "created": "2020-10-19T21:20:53+00:00",
    "end": "2020-10-19T21:49:44+00:00",
    "modified": "2020-10-19T21:49:45+00:00",
    "external_desc": "We are currently experiencing an issue with Google Kubernetes Engine customers experiencing elevated rates of packet loss in southamerica-east1-[a, b, c] due to the ongoing Cloud Networking issue beginning at Monday, 2020-10-19 13:05 US/Pacific.",
    "updates": [
      {
        "created": "2020-10-19T21:49:44+00:00",
        "modified": "2020-10-19T21:49:44+00:00",
        "when": "2020-10-19T21:49:44+00:00",
        "text": "The issue with Google Kubernetes Engine has been resolved for all affected users as of Monday, 2020-10-19 14:12 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-19T21:20:54+00:00",
        "modified": "2020-10-19T21:20:54+00:00",
        "when": "2020-10-19T21:20:54+00:00",
        "text": "Description: We are currently experiencing an issue with Google Kubernetes Engine customers experiencing elevated rates of packet loss in southamerica-east1-[a, b, c] due to the ongoing Cloud Networking issue beginning at Monday, 2020-10-19 13:05 US/Pacific.\nPlease follow (https://status.cloud.google.com/incident/cloud-networking/20010) for current details and future updates.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-19T21:49:44+00:00",
      "modified": "2020-10-19T21:49:44+00:00",
      "when": "2020-10-19T21:49:44+00:00",
      "text": "The issue with Google Kubernetes Engine has been resolved for all affected users as of Monday, 2020-10-19 14:12 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/VoJNub6ejZ5iFurC73G6"
  },
  {
    "id": "rJd67S2k8JaG8FPKg3u7",
    "number": "17819765702780175038",
    "begin": "2020-10-19T20:58:47+00:00",
    "created": "2020-10-19T21:04:13+00:00",
    "end": "2020-10-19T21:37:18+00:00",
    "modified": "2020-10-19T21:37:19+00:00",
    "external_desc": "We are currently experiencing an issue with Google Compute Engine customers experiencing elevated rates of packet loss in southamerica-east1-{a, b, c} due to the ongoing Cloud Networking issue beginning at Monday, 2020-10-19 13:05 US/Pacific.",
    "updates": [
      {
        "created": "2020-10-19T21:37:18+00:00",
        "modified": "2020-10-19T21:37:18+00:00",
        "when": "2020-10-19T21:37:18+00:00",
        "text": "The issue with Google Compute Engine in southamerica-east1 has been resolved for all affected projects as of Monday, 2020-10-19 14:12 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-19T21:04:14+00:00",
        "modified": "2020-10-19T21:04:14+00:00",
        "when": "2020-10-19T21:04:14+00:00",
        "text": "Description: We are currently experiencing an issue with Google Compute Engine customers experiencing elevated rates of packet loss in southamerica-east1-[a, b, c] due to the ongoing Cloud Networking issue beginning at Monday, 2020-10-19 13:05 US/Pacific.\nPlease follow (https://status.cloud.google.com/incident/cloud-networking/20010) for current details and future updates.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-19T21:37:18+00:00",
      "modified": "2020-10-19T21:37:18+00:00",
      "when": "2020-10-19T21:37:18+00:00",
      "text": "The issue with Google Compute Engine in southamerica-east1 has been resolved for all affected projects as of Monday, 2020-10-19 14:12 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "L3ggmi3Jy4xJmgodFA9K",
    "service_name": "Google Compute Engine",
    "affected_products": [
      {
        "title": "Google Compute Engine",
        "id": "L3ggmi3Jy4xJmgodFA9K"
      }
    ],
    "uri": "incidents/rJd67S2k8JaG8FPKg3u7"
  },
  {
    "id": "EzN2YDriBp8LFTwqL2kY",
    "number": "1992977149047935837",
    "begin": "2020-10-19T20:40:43+00:00",
    "created": "2020-10-19T21:13:16+00:00",
    "end": "2020-10-19T21:44:23+00:00",
    "modified": "2020-10-19T21:44:24+00:00",
    "external_desc": "We've received a report of an issue with Cloud Bigtable as of Monday, 2020-10-19 13:18:57 PDT",
    "updates": [
      {
        "created": "2020-10-19T21:44:23+00:00",
        "modified": "2020-10-19T21:44:23+00:00",
        "when": "2020-10-19T21:44:23+00:00",
        "text": "The issue with Cloud Bigtable has been resolved for all affected projects as of Monday, 2020-10-19 14:05 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-19T21:17:52+00:00",
        "modified": "2020-10-19T21:17:52+00:00",
        "when": "2020-10-19T21:17:52+00:00",
        "text": "Description: We are experiencing an issue with Cloud Bigtable.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2020-10-19 15:50 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-19T21:13:17+00:00",
        "modified": "2020-10-19T21:13:17+00:00",
        "when": "2020-10-19T21:13:17+00:00",
        "text": "Description: We are currently experiencing an issue with Cloud Bigtable customers experiencing elevated error rates in southamerica-east1-[a, b, c] due to the ongoing Cloud Networking issue beginning at Monday, 2020-10-19 13:05 US/Pacific.\nPlease follow (https://status.cloud.google.com/incident/cloud-networking/20010) for current details and future updates.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-19T21:44:23+00:00",
      "modified": "2020-10-19T21:44:23+00:00",
      "when": "2020-10-19T21:44:23+00:00",
      "text": "The issue with Cloud Bigtable has been resolved for all affected projects as of Monday, 2020-10-19 14:05 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LfZSuE3xdQU46YMFV5fy",
    "service_name": "Google Cloud Bigtable",
    "affected_products": [
      {
        "title": "Google Cloud Bigtable",
        "id": "LfZSuE3xdQU46YMFV5fy"
      }
    ],
    "uri": "incidents/EzN2YDriBp8LFTwqL2kY"
  },
  {
    "id": "6ikDZn3BFFXjkDERZiWV",
    "number": "16031502602257712913",
    "begin": "2020-10-19T20:20:49+00:00",
    "created": "2020-10-19T21:09:16+00:00",
    "end": "2020-10-19T21:23:45+00:00",
    "modified": "2020-10-19T21:23:46+00:00",
    "external_desc": "Google Cloud Storage customers making requests to southamerica-east1 will experience elevated error rates due to the ongoing Cloud Networking issue as of Monday, 2020-10-19 13:05 US/Pacific.",
    "updates": [
      {
        "created": "2020-10-19T21:23:45+00:00",
        "modified": "2020-10-19T21:23:45+00:00",
        "when": "2020-10-19T21:23:45+00:00",
        "text": "The issue with Google Cloud Storage in southamerica-east1 has been resolved for all affected users as of Monday, 2020-10-19 14:12 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-19T21:09:17+00:00",
        "modified": "2020-10-19T21:09:17+00:00",
        "when": "2020-10-19T21:09:17+00:00",
        "text": "Description: Google Cloud Storage customers making requests to southamerica-east1 will experience elevated error rates due to the ongoing Cloud Networking issue as of Monday, 2020-10-19 13:05 US/Pacific.\nPlease follow (https://status.cloud.google.com/incident/cloud-networking/20010) for current details and future updates.\nDiagnosis: None at this time.\nWorkaround: Other GCS regions are unaffected.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-19T21:23:45+00:00",
      "modified": "2020-10-19T21:23:45+00:00",
      "when": "2020-10-19T21:23:45+00:00",
      "text": "The issue with Google Cloud Storage in southamerica-east1 has been resolved for all affected users as of Monday, 2020-10-19 14:12 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "UwaYoXQ5bHYHG6EdiPB8",
    "service_name": "Google Cloud Storage",
    "affected_products": [
      {
        "title": "Google Cloud Storage",
        "id": "UwaYoXQ5bHYHG6EdiPB8"
      }
    ],
    "uri": "incidents/6ikDZn3BFFXjkDERZiWV"
  },
  {
    "id": "yW4fTce2iKW8XkG6Q4Ln",
    "number": "346823224043991594",
    "begin": "2020-10-19T20:19:06+00:00",
    "created": "2020-10-19T20:45:41+00:00",
    "end": "2020-10-19T21:34:43+00:00",
    "modified": "2020-10-20T01:25:46+00:00",
    "external_desc": "We are experiencing an issue with Cloud Networking beginning in the southamerica-east1 region starting at Monday, 2020-10-19 13:03 US/Pacific.",
    "updates": [
      {
        "created": "2020-10-19T21:34:43+00:00",
        "modified": "2020-10-19T21:34:43+00:00",
        "when": "2020-10-19T21:34:43+00:00",
        "text": "The issue with Google Cloud Networking has been resolved for all affected users as of Monday, 2020-10-19 14:11 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-19T21:14:20+00:00",
        "modified": "2020-10-20T01:25:45+00:00",
        "when": "2020-10-19T21:14:20+00:00",
        "text": "Description: We are experiencing an issue with Cloud Networking beginning in the southamerica-east1 region starting at Monday, 2020-10-19 13:03 PDT. This issue is impacting Google Coud Storage, Compute Engine, Kubernetes Engine and Cloud Bigtable.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2020-10-19 15:30 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-19T20:57:21+00:00",
        "modified": "2020-10-20T01:21:50+00:00",
        "when": "2020-10-19T20:57:21+00:00",
        "text": "Description: We are experiencing an issue with Cloud Networking beginning in the southamerica-east1 region starting at Monday, 2020-10-19 13:03 US/Pacific. This issue is impacting Google Coud Storage, Compute Engine, Kubernetes Engine and Cloud Bigtable.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2020-10-19 14:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-19T20:55:52+00:00",
        "modified": "2020-10-20T01:21:32+00:00",
        "when": "2020-10-19T20:55:52+00:00",
        "text": "Description: We are experiencing an issue with Cloud Networking beginning in the southamerica-east1 region starting at Monday, 2020-10-19 13:03 US/Pacific. This issue is impacting GCS, GCE, and GKE.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2020-10-19 14:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-19T20:45:43+00:00",
        "modified": "2020-10-20T01:10:58+00:00",
        "when": "2020-10-19T20:45:43+00:00",
        "text": "Description: We are experiencing an issue with Cloud Networking beginning at Monday, 2020-10-19 13:03 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2020-10-19 14:25 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-19T21:34:43+00:00",
      "modified": "2020-10-19T21:34:43+00:00",
      "when": "2020-10-19T21:34:43+00:00",
      "text": "The issue with Google Cloud Networking has been resolved for all affected users as of Monday, 2020-10-19 14:11 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/yW4fTce2iKW8XkG6Q4Ln"
  },
  {
    "id": "BVe3XidYYNAR5z1bAw6u",
    "number": "15037487531745376957",
    "begin": "2020-10-07T21:27:06+00:00",
    "created": "2020-10-07T21:58:39+00:00",
    "end": "2020-10-08T13:54:35+00:00",
    "modified": "2020-10-08T13:54:35+00:00",
    "external_desc": "We are currently working to mitigate the issue of Cloud Composer create/update environment requests failing in asia-northeast1, asia-northeast2, asia-northeast3, asia-southeast1, europe-west1, europe-west3, europe-west6, europe-west4, northamerica-northeast1, southamerica-east1,us-central1, us-east1, us-west1, us-west2, and us-west4.",
    "updates": [
      {
        "created": "2020-10-08T13:54:35+00:00",
        "modified": "2020-10-08T13:54:35+00:00",
        "when": "2020-10-08T13:54:35+00:00",
        "text": "The issue with Cloud Composer has been resolved for all affected projects as of Thursday, 2020-10-08 06:54 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-08T06:07:10+00:00",
        "modified": "2020-10-08T06:07:10+00:00",
        "when": "2020-10-08T06:07:10+00:00",
        "text": "Description: We are currently working to mitigate the issue of Cloud Composer create/update environment requests failing in asia-northeast1, asia-northeast2, asia-northeast3, asia-southeast1, europe-west1, europe-west3, europe-west6, europe-west4, northamerica-northeast1,southamerica-east1,us-central1, us-east1, us-west1, us-west2, and us-west4. .\nOur engineers are currently rolling back a configuration change to mitigate.\nWe will provide more information by Thursday, 2020-10-08 07:00 US/Pacific.\nDiagnosis: Create/update environment requests are failing. Existing workloads are unaffected.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-07T22:50:01+00:00",
        "modified": "2020-10-07T22:50:01+00:00",
        "when": "2020-10-07T22:50:01+00:00",
        "text": "Description: We are currently working to mitigate the issue of Cloud Composer create/update environment requests failing in asia-northeast1, asia-northeast2, asia-northeast3, europe-west3, europe-west6, northamerica-northeast1, southamerica-east1, and us-west4.\nOur engineers are currently rolling back a configuration change to mitigate. We expect the rollback to complete within the next 7 hours.\nWe will provide more information by Wednesday, 2020-10-07 23:00 US/Pacific.\nDiagnosis: Create/update environment requests are failing in asia-northeast1, asia-northeast2, asia-northeast3, europe-west3, europe-west6, northamerica-northeast1, southamerica-east1, and us-west4. Existing workloads are unaffected.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-07T21:58:40+00:00",
        "modified": "2020-10-07T21:58:40+00:00",
        "when": "2020-10-07T21:58:40+00:00",
        "text": "Description: We are investigating an issue of Cloud Composer create/update requests failing in asia-northeast1, asia-northeast2, asia-northeast3, europe-west3, europe-west6, northamerica-northeast1, southamerica-east1, and us-west4. Existing workloads are unaffected.\nWe will provide more information by Wednesday, 2020-10-07 16:00 US/Pacific.\nDiagnosis: Create/update environment requests are failing in asia-northeast1, asia-northeast2, asia-northeast3, europe-west3, europe-west6, northamerica-northeast1, southamerica-east1, and us-west4. Existing workloads are unaffected.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-08T13:54:35+00:00",
      "modified": "2020-10-08T13:54:35+00:00",
      "when": "2020-10-08T13:54:35+00:00",
      "text": "The issue with Cloud Composer has been resolved for all affected projects as of Thursday, 2020-10-08 06:54 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "YxkG5FfcC42cQmvBCk4j",
    "service_name": "Google Cloud Composer",
    "affected_products": [
      {
        "title": "Google Cloud Composer",
        "id": "YxkG5FfcC42cQmvBCk4j"
      }
    ],
    "uri": "incidents/BVe3XidYYNAR5z1bAw6u"
  },
  {
    "id": "UkaG5TY2UnYu2nu3QJHE",
    "number": "17164830441377413415",
    "begin": "2020-10-06T14:41:56+00:00",
    "created": "2020-10-06T15:16:26+00:00",
    "end": "2020-10-06T16:17:08+00:00",
    "modified": "2020-10-06T16:17:08+00:00",
    "external_desc": "App Engine Standard returning elevated HTTP 500 errors in us-central1",
    "updates": [
      {
        "created": "2020-10-06T16:17:08+00:00",
        "modified": "2020-10-06T16:17:08+00:00",
        "when": "2020-10-06T16:17:08+00:00",
        "text": "The issue with Google App Engine has been resolved for all affected users as of Tuesday, 2020-10-06 09:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-06T15:56:23+00:00",
        "modified": "2020-10-06T15:56:23+00:00",
        "when": "2020-10-06T15:56:23+00:00",
        "text": "Description: We are experiencing an issue with Google App Engine in us-central1 beginning at Tuesday, 2020-10-06 06:45 US/Pacific.\nSymptoms: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard deployments in us-central1. These failures are viewable in Cloud Logging.\nMitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Tuesday, 2020-10-06 09:15 US/Pacific.\nWe will provide more information by Tuesday, 2020-10-06 09:15 US/Pacific.\nDiagnosis: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard instance in us-central1.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-06T15:38:55+00:00",
        "modified": "2020-10-06T15:38:55+00:00",
        "when": "2020-10-06T15:38:55+00:00",
        "text": "Description: We are experiencing an issue with Google App Engine in us-central1 beginning at Tuesday, 2020-10-06 06:45 US/Pacific.\nSymptoms: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard deployments in us-central1. These failures are viewable in Cloud Logging.\nMitigation work is currently underway by our engineering team.\nWe will provide more information by Tuesday, 2020-10-06 09:00 US/Pacific.\nDiagnosis: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard instance in us-central1.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-06T15:36:33+00:00",
        "modified": "2020-10-06T15:36:33+00:00",
        "when": "2020-10-06T15:36:33+00:00",
        "text": "Description: We are experiencing an issue with Google App Engine beginning at Tuesday, 2020-10-06 06:45 US/Pacific.\nSymptoms: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard deployments. These failures are viewable in Cloud Logging.\nMitigation work is currently underway by our engineering team.\nWe will provide more information by Tuesday, 2020-10-06 09:00 US/Pacific.\nDiagnosis: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-06T15:16:27+00:00",
        "modified": "2020-10-06T15:16:27+00:00",
        "when": "2020-10-06T15:16:27+00:00",
        "text": "Description: We are experiencing an issue with Google App Engine beginning at Tuesday, 2020-10-06 06:45 US/Pacific.\nSymptoms: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard deployments. These failures are viewable in Cloud Logging.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2020-10-06 08:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Elevated HTTP 5XX errors from containers and/or increased latency from Google App Engine Standard.\nWorkaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-06T16:17:08+00:00",
      "modified": "2020-10-06T16:17:08+00:00",
      "when": "2020-10-06T16:17:08+00:00",
      "text": "The issue with Google App Engine has been resolved for all affected users as of Tuesday, 2020-10-06 09:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "kchyUtnkMHJWaAva8aYc",
    "service_name": "Google App Engine",
    "affected_products": [
      {
        "title": "Google App Engine",
        "id": "kchyUtnkMHJWaAva8aYc"
      }
    ],
    "uri": "incidents/UkaG5TY2UnYu2nu3QJHE"
  },
  {
    "id": "67gYtuFkhRTh1pLtJGLp",
    "number": "15588388061178560235",
    "begin": "2020-10-06T13:45:00+00:00",
    "created": "2020-10-06T15:31:14+00:00",
    "end": "2020-10-06T16:23:05+00:00",
    "modified": "2020-10-06T16:23:05+00:00",
    "external_desc": "Cases failing to load in Cloud Console or Google Support Center",
    "updates": [
      {
        "created": "2020-10-06T16:23:05+00:00",
        "modified": "2020-10-06T16:23:05+00:00",
        "when": "2020-10-06T16:23:05+00:00",
        "text": "The issue with Google Cloud Support Center has been resolved for all affected users as of Tuesday, 2020-10-06 09:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-10-06T15:57:04+00:00",
        "modified": "2020-10-06T15:57:04+00:00",
        "when": "2020-10-06T15:57:04+00:00",
        "text": "DESCRIPTION: We believe the issue with Google Cloud Support Center is partially resolved. Mitigation actions have been performed and we're currently monitoring for any lingering issues. We will provide an update by Tuesday, 2020-10-06 10:52 US/Pacific with current details.\nSymptoms: Cases failing to load in Cloud Console or Google Support Center\nOur engineering team is currently investigating the issue.\nWe will provide an update by Tuesday, 2020-10-06 09:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption\nSELF-DIAGNOSIS: Cases failing to load in Cloud Console or Google Support Center WORKAROUND: If you need to open a new case please reach out via the following form: https://support.google.com/cloud/contact/prod_issue",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-10-06T15:31:14+00:00",
        "modified": "2020-10-06T15:31:14+00:00",
        "when": "2020-10-06T15:31:14+00:00",
        "text": "DESCRIPTION: We are experiencing an issue with Google Cloud Support Center beginning at Tuesday, 2020-10-06 06:45 US/Pacific.\nSymptoms: Cases failing to load in Cloud Console or Google Support Center\nOur engineering team is currently investigating the issue.\nWe will provide an update by Tuesday, 2020-10-06 09:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption\nSELF-DIAGNOSIS: Cases failing to load in Cloud Console or Google Support Center\nWORKAROUND: If you need to open a new case please reach out via the following form: https://support.google.com/cloud/contact/prod_issue",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-06T16:23:05+00:00",
      "modified": "2020-10-06T16:23:05+00:00",
      "when": "2020-10-06T16:23:05+00:00",
      "text": "The issue with Google Cloud Support Center has been resolved for all affected users as of Tuesday, 2020-10-06 09:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "bGThzF7oEGP5jcuDdMuk",
    "service_name": "Google Cloud Support",
    "affected_products": [
      {
        "title": "Google Cloud Support",
        "id": "bGThzF7oEGP5jcuDdMuk"
      }
    ],
    "uri": "incidents/67gYtuFkhRTh1pLtJGLp"
  },
  {
    "id": "yGJ84NxvpdTvCLCQ1eUu",
    "number": "1210107505050595722",
    "begin": "2020-10-06T13:45:00+00:00",
    "created": "2020-10-06T18:07:16+00:00",
    "end": "2020-10-06T16:13:00+00:00",
    "modified": "2020-10-06T18:07:16+00:00",
    "external_desc": "Cloud ML was experiencing elevated errors",
    "updates": [
      {
        "created": "2020-10-06T18:07:16+00:00",
        "modified": "2020-10-06T18:07:16+00:00",
        "when": "2020-10-06T18:07:16+00:00",
        "text": "We were experiencing an issue with Cloud Machine Learning where deployments may fail and prediction operations were failing at elevated rates in us-central1 beginning on Tuesday, 2020-10-06 06:45 US/Pacific.\nThe issue with Cloud Machine Learning has been resolved for all affected users as of Tuesday, 2020-10-06 09:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-06T18:07:16+00:00",
      "modified": "2020-10-06T18:07:16+00:00",
      "when": "2020-10-06T18:07:16+00:00",
      "text": "We were experiencing an issue with Cloud Machine Learning where deployments may fail and prediction operations were failing at elevated rates in us-central1 beginning on Tuesday, 2020-10-06 06:45 US/Pacific.\nThe issue with Cloud Machine Learning has been resolved for all affected users as of Tuesday, 2020-10-06 09:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "SERVICE_DISRUPTION"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "z9PfKanGZYvYNUbnKzRJ",
    "service_name": "Cloud Machine Learning",
    "affected_products": [
      {
        "title": "Cloud Machine Learning",
        "id": "z9PfKanGZYvYNUbnKzRJ"
      }
    ],
    "uri": "incidents/yGJ84NxvpdTvCLCQ1eUu"
  },
  {
    "id": "tjzyw7WyEhtMfSy52GyF",
    "number": "5962274566910332592",
    "begin": "2020-09-25T14:08:29+00:00",
    "created": "2020-09-25T16:27:06+00:00",
    "end": "2020-09-25T17:36:02+00:00",
    "modified": "2020-09-25T17:36:02+00:00",
    "external_desc": "We are experiencing an issue with Cloud Logging beginning at Friday, 2020-09-25 06:50 US/Pacific. Symptoms are increased error rates and potentially latency upon reading, filtering or querying logs. Writing logs are not affected. Mitigation work is already underway by our engineering team. The mitigation is expected to complete by Friday, 2020-09-25 11:00 US/Pacific. We will provide more information by Friday, 2020-09-25 11:30 US/Pacific at the latest.",
    "updates": [
      {
        "created": "2020-09-25T17:36:02+00:00",
        "modified": "2020-09-25T17:36:02+00:00",
        "when": "2020-09-25T17:36:02+00:00",
        "text": "The issue with Cloud Logging has been resolved for all affected projects as of Friday, 2020-09-25 10:30 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T17:20:56+00:00",
        "modified": "2020-09-25T17:20:56+00:00",
        "when": "2020-09-25T17:20:56+00:00",
        "text": "Description: Mitigation work is already underway by our engineering team.\nCurrent data indicates that error rates decreased approximately by half from 25% to 11% in projects affected by this issue.\nThe mitigation is expected to complete by Friday, 2020-09-25 11:00 US/Pacific.\nWe will provide more information by Friday, 2020-09-25 11:30 US/Pacific at the latest.\nDiagnosis: Listing or reading logs return an error message such as: \"An unknown error has occurred. No additional information was provided.\".\nWorkaround: None at the moment.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-25T16:30:02+00:00",
        "modified": "2020-09-25T16:30:02+00:00",
        "when": "2020-09-25T16:30:02+00:00",
        "text": "Description: We are experiencing an intermittent issue with Cloud Logging beginning at Friday, 2020-09-25 06:50 US/Pacific.\nSymptoms: increased error rates and potentially latency upon filtering or querying logs.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2020-09-25 10:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Listing or reading logs return an error message such as: \"An unknown error has occurred. No additional information was provided.\".\nWorkaround: None at the moment.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-25T16:27:07+00:00",
        "modified": "2020-09-25T16:27:07+00:00",
        "when": "2020-09-25T16:27:07+00:00",
        "text": "Description: We are experiencing an intermittent issue with Cloud Logging beginning at Friday, 2020-09-25 06:50 US/Pacific.\nSymptoms: increased error rates and potentially latency upon filtering or querying logs.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2020-09-25 09:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Listing or reading logs return an error message such as: \"An unknown error has occurred. No additional information was provided.\".\nWorkaround: None at the moment.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-09-25T17:36:02+00:00",
      "modified": "2020-09-25T17:36:02+00:00",
      "when": "2020-09-25T17:36:02+00:00",
      "text": "The issue with Cloud Logging has been resolved for all affected projects as of Friday, 2020-09-25 10:30 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/tjzyw7WyEhtMfSy52GyF"
  },
  {
    "id": "gumoYCjdcDXv8xxmLBaW",
    "number": "285465446177527200",
    "begin": "2020-09-25T01:00:50+00:00",
    "created": "2020-09-25T01:28:57+00:00",
    "end": "2020-09-25T01:33:43+00:00",
    "modified": "2020-10-08T15:12:37+00:00",
    "external_desc": "We are experiencing an issue with multiple GCP products.",
    "updates": [
      {
        "created": "2020-10-01T04:55:05+00:00",
        "modified": "2020-10-08T15:12:37+00:00",
        "when": "2020-10-01T04:55:05+00:00",
        "text": "# BACKGROUND\nGoogle’s Global Service Load Balancer (GSLB) is a collection of software and services that load balance traffic across Google properties. There are two main components, a control plane, and a data plane. The control plane provides programming to the data plane on how to handle requests. A key component of the data plane is the Google Front End (GFE). The GFE is an HTTP/TCP reverse proxy which is used to serve requests to many Google properties including: Search, Ads, G Suite (Gmail, Chat, Meet, Docs, Drive, etc.), Cloud External HTTP(S) Load Balancing, Proxy/SSL Load Balancing, and many Cloud APIs.\nGoogle’s Global Load Balancers are implemented using a GFE architecture that has two tiers in some cases. The first tier of GFEs are situated as close to the user as possible to minimize latency during connection setup. First tier GFEs route requests either directly to applications, or in some cases to a second tier of GFEs providing additional functionality, before routing to applications. This architecture allows clients to have low latency connections anywhere in the world, while taking advantage of Google’s global network to serve requests to backends, regardless of region.\nThe pool of GFE instances which were impacted in this incident are part of the second tier, handling a subset of Google services. Therefore, this incident only impacted services routed through this specific pool.\n# ISSUE SUMMARY\nOn Thursday 24 September, 2020 at 18:00 US/Pacific, one of Google’s several second-tier GFE pools experienced intermittent failures resulting in impact to several downstream services. Almost all services recovered within the initial 33 minutes of the incident; exceptions are outlined in the detailed impact section below. Affected customers experienced elevated error rates and latency when connecting to Google APIs. Existing workloads (i.e. running instances on GCE, or containers on GKE) were not impacted unless they needed to invoke impacted APIs.\nService impact can be divided into two categories, direct and indirect. Services which have a request path that flows through the impacted GFE pool would have been directly impacted. Calls to these services would have experienced higher latency or elevated errors in the form of HTTP 502 response codes. Alternatively, services which did not directly rely on this pool of impacted GFEs may invoke other services, such as authentication, that depend on this shared pool of GFEs. This indirect impact would have varied between customers. One example of this, which we expect to be one of the most common forms of indirect impact, would be use of an oauth token that needed to be refreshed or retrieved. While a service such as Cloud Spanner may not have been serving errors, customers using the Cloud Spanner Client may have seen errors when the client attempted to refresh credentials, depending on the API used to refresh/obtain the credential. A detailed description of impact can be found below.\nTo our Cloud customers whose businesses were impacted during this disruption, we sincerely apologize – we have conducted a thorough internal investigation and are taking immediate action to improve the resiliency, performance, and availability of our services.\n# ROOT CAUSE\nFor any given pool of tasks, the GFE control plane has a global view of capacity, service configurations, and network conditions, which are all combined and sent to GFEs to create efficient request serving paths. This global view allows requests to be routed seamlessly to other regions, which is useful in scenarios like failover or for load balancing between regions. GFEs are grouped into pools for a variety of traffic profiles, health checking requirements, and other factors; the impacted second-layer GFE pool was used by multiple services.\nThe GFE control plane picks up service configuration changes and distributes them to GFEs. For this incident, two service changes contained an error that resulted in a significant increase in the number of backends accessed by GFEs in this pool. The particular nature of these changes additionally meant that they would be distributed to all GFEs in this pool globally, instead of being limited to a particular region. While the global aspect was intended, the magnitude of backend increases was not. The greatly increased number of programmed backends caused GFEs to exceed their memory allocation in many locations.\nGFE has many internal protections which are activated when there is memory pressure, such as closing idle connections or refusing to accept new connections, allowing them to keep running despite a memory shortage. Tasks which exceeded memory limits were terminated. The combination of a reduced number of available GFEs and a reduction in accepted connections meant that traffic to services behind the impacted GFE pool dropped by 50%.\n# REMEDIATION AND PREVENTION\nGoogle engineers were alerted to the outage three minutes after impact began at 2020-09-24 18:03, and immediately began an investigation. At 18:15 the first service change, which significantly increased the number of programmed backends, was rolled back. At 18:18 the second service configuration change was rolled back. Google engineers started seeing recovery at 18:20 and at 18:33 the issue was fully mitigated.\nGFE is one of the most critical pieces of infrastructure at Google and has multiple lines of defense in depth, both in software and operating procedure. As the result of this outage, we are adding additional protections to both in order to eliminate this class of failure. As an immediate step we have limited the type of configuration changes that can be made until additional safeguards are in place. Those additional safeguards will include stricter validation of configuration changes; specifically, rejecting changes that cause a large increase in backend count across multiple services. In addition to a check in the control plane, we will be augmenting existing protections in the GFE against unbounded growth in any resource dimension, such as backend counts. We will also be performing an audit of existing configurations and converting risky configurations to alternative setups. A restriction will be placed on certain configuration options, only allowing use with additional review and allow lists. Finally, an audit will be performed of services in shared GFE pools, with additional pools being created to reduce impact radius, should an issue in this part of the infrastructure surface again.\n# DETAILED DESCRIPTION OF IMPACT\nOn 2020-09-24 from 18:00 to 18:33 US/Pacific (unless otherwise noted) the following services were impacted globally:\n### OAuth\nThe following OAuth paths were impacted and returned errors for 50% of requests during the impact period. Impact perceived by customers may have been less as many client libraries make requests to these paths asynchronous to refresh tokens before they expire and retry their requests upon failure, potentially receiving successful responses: - oauth2.googleapis.com/token - accounts.google.com/o/oauth2/token - www.youtube.com/o/oauth2/token - www.googleapis.com/o/oauth2/token - www.googleapis.com/oauth2/{v3,v4}/token - accounts.{google,youtube}.com/o/oauth2/{revoke,device/code,tokeninfo} - www.googleapis.com/oauth2/v3/authadvice - www.googleapis.com/oauth2/v2/IssueToken - oauthaccountmanager.googleapis.com\n_\nThe following APIs were NOT affected: - www.googleapis.com/oauth2/{v1,v2,v3}/certs - contents.googleapis.com/oauth2/{v1,v2,v3}/certs - contents6.googleapis.com/oauth2/{v1,v2,v3}/certs - iamcredentials.googleapis.com and accounts.google.com (other than specific URLs mentioned above) were not affected.\n_\n### Chat\nGoogle Chat experienced an elevated rate of HTTP 500 & 502 errors (averaging 34%) between 18:00 and 18:04, decreasing to a 7% error rate from 18:04 to 18:14, with a mean latency of 500ms. This resulted in affected users being unable to load the Chat page or to send Chat messages.\n### Classic Hangouts\nClassic Hangouts experienced an elevated error rate of HTTP 500 errors (reducing Hangouts traffic by 44%) between 18:00 and 18:25. The service error rate was below 1% for Hangouts requests within the product, including sending messages.\n### Meet\nGoogle Meet experienced error rates up to 23% of requests between 18:02 and 18:23. Affected users observed call startup failures which affected 85% of session attempts. Existing Meet sessions were not affected.\n### Voice\nGoogle Voice experienced a 66% drop in traffic between 18:00 and 18:24. Additionally, the service had an elevated error rate below 1% between 18:01 and 18:14, and an average of 100% increase in mean latency between 18:03 and 18:12.\n### Calendar\nGoogle Calendar web traffic observed up to a 60% reduction in traffic, and an elevated HTTP 500 error rate of 4.8% between 18:01 and 18:06, which decreased to and remained below 1% for the remainder of the outage. Calendar API traffic observed up to a 53% reduction in traffic, with an average error rate of 2% for the same period. The traffic reduction corresponded with HTTP 500 errors being served to users.\n### Groups\nGoogle Groups web traffic dropped roughly 50% for the classic UI, and 30% for the new UI. Users experienced an average elevated HTTP 500 error rate between 0.12 and 3%.\n### Gmail\nGmail observed a 35% drop in traffic due to the GFE responding with HTTP 500 errors. The service error rate remained below 1% for the duration of the incident. This affected Gmail page loading and web interactions with the product.\n### Docs\nGoogle Docs witnessed a 33% drop in traffic between 18:00 and 18:23, corresponding with the GFE returning HTTP 500 errors to user interactions. Additionally, between 18:01 and 18:06 the service error rate rose to 1.4%, before decreasing and remaining at approximately 0.3% until 18:23.\n### Drive\nGoogle Drive observed a 60% traffic drop between 18:00 and 18:23, corresponding with the GFE returning HTTP 500 errors to user interactions. The Drive API experienced a peak error rate of 7% between 18:02 to 18:04, and then between 1% and 2% until 18:25. Google Drive web saw up to a 4% error rate between 18:01 and 18:06. 50th percentile latency was unaffected, but 95th percentile rose up to 1.3s between 18:02 and 18:06.\n### Cloud Bigtable\nSome clients using the impacted OAuth authentication methods described above were unable to refresh their credentials and thus unable to access Cloud Bigtable. Clients using alternative authentication methods were not impacted. Impacted clients experienced elevated error rates and latency. The main impact was to clients accessing Cloud Bigtable from outside of GCP, there was a 38% drop in this traffic during the impact period.\n### Cloud Build API\nCloud Build API experienced elevated error rates due to a 50% loss of incoming traffic over 26 minutes before reaching the service front end. Additionally, 4% of Cloud Builds failed due receiving errors from other Google services\n### Cloud Key Management Service (KMS)\nCloud KMS was unable to receive API requests from GFE for ~33 minutes starting at 18:00 impacting non-Customer Managed Encryption Key (CMEK) customers. CMEK customers were not impacted.\n### Cloud Logging\nCloud Logging experienced increased error rates (25% average, up to 40% at peak) from 18:05 to 18:50. Customers would have experienced errors when viewing logs in the Cloud Console. Data ingestion was not impacted.\n### Cloud Monitoring\nCloud Monitoring API experienced elevated error rates (50% average, up to 80% at peak) of uptime checks and requests from 18:00 - 18:26. This affected cloud uptime workers running uptime checks.\n### Cloud Networking API\nCloud Networking API experienced up to 50% error rate for Network Load Balancer Creation from 18:00 to 18:20 due to downstream service errors. Additionally up to 35% of HTTP(S) Load Balancer or TCP/SSL Proxy Load Balancer creation requests failed from 18:00 - 18:28 due to downstream service errors. Traffic for existing load balancers was unaffected.\n### Google Compute Engine API\nThe Google Compute Engine (GCE) API experienced an error rate of up to 50% from 18:00 - 18:25 with affected users experiencing HTTP 502 error response codes. This would have prevented loading the GCE portion of the Cloud Console as well listing, modifying, and creating GCE resources via other API clients. This applies only to the GCE API. GCE instance connectivity and availability was not impacted. Please note that some GCP services were served by the impacted GFE pool, so customer workloads running inside compute instances may have seen impact if they depend on other GCP services that experienced impact. Autoscaler continued to function nominally during the outage window.\n### Cloud Profiler\nCloud Profiler API experienced an elevated rate of HTTP 502 errors due to an up to 50% reduction in global traffic for all requests.\n### Cloud Run API\nCloud Run API experienced an elevated rate of HTTP 502 errors up to 70% from 18:00 to 18:30. Existing Cloud Run deployments were unaffected.\n### Cloud Spanner\nCloud Spanner clients experienced elevated error rates due to authentication issues which caused a 20% drop in traffic. Impacted customers saw increased latency and errors accessing Cloud Spanner. Clients using alternative authentication methods, such as GKE Workload Identity, were not impacted.\n### Game Servers\nGame Servers experienced elevated request latencies of up to 4x normal levels during the incident window, resulting in some clients experiencing connection timeouts and increased retry attempts. The service did not experience elevated error rates.\n### Google Cloud Console\n4.18% of customers experienced \"The attempted action failed\" error messages when attempting to load pages in the Cloud Console during the incident window. This prevented some customers from viewing the UI of networking, compute, billing, monitoring, and other products and services within the Cloud Console platform.\n### Google Cloud SQL\n0.08% of Cloud SQL's fleet experienced instance metrics and logging delays from 18:07 - 18:37 for a duration of 30 minutes. The Cloud SQL API did not serve errors during the outage, but incoming traffic dropped by ~30%. No spurious auto-failovers or auto-repairs were executed as a result of the incident. There were no actual instance failures.\n### Google Kubernetes Engine\nRequests to the Google Kubernetes Engine (GKE) control plane experienced increased timeouts and HTTP 502 error. Up to 6.6% of cluster masters reported errors during the time of the incident. Up to 5.5% of newly added nodes to clusters may have experienced errors due to issues communicating with impacted cluster masters.\n### Firebase Crashlytics\n66% of Crashlytics imports from AWS were impacted from 18:01 - 19:01 US/Pacific for a duration of 60 minutes. This created an import backlog which was quickly worked through 10 minutes after the incident ended.\n### Dialogflow and Speech-to-text API\nRequests to Dialogflow returned up to 72% errors in the form of HTTP 502 response codes. Requests to Google Speech API may have seen up to 68% errors in the form of HTTP 502 response codes.\n### Cloud Firestore and Datastore\nCloud Firestore saw 80% of listen streams become disconnected and up to 50% error rates for query/get requests across all regions except nam5 and eur3.\n# SLA CREDITS\nIf you believe your paid application experienced an SLA violation as a result of this incident, please populate the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/.\nFor G Suite, please request an SLA credit through one of the Support channels: https://support.google.com/a/answer/104721\nG Suite Service Level Agreement can be found at https://gsuite.google.com/intl/en/terms/sla.html",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T21:48:54+00:00",
        "modified": "2020-09-25T21:49:40+00:00",
        "when": "2020-09-25T21:48:54+00:00",
        "text": "With all services restored to normal operation, Google’s engineering teams are now conducting a thorough post-mortem to ensure we understand all the contributing factors and downstream impact to GCP and G Suite from this incident. The root cause of this disruption is well understood and safeguards have been put in place to prevent any possible recurrence of the issue.\nAt this time we have determined that the following products were affected:\n### Cloud Build API\nGoogle Front End (GFE) prevented API requests from reaching the service. CreateBuild requests that did make it to the servers were more likely to fail due to user code calling other GCP services.\n### Cloud Firestore and Datastore\nCloud Firestore saw 80% of listen streams become disconnected and a 50% drop in query/get requests across all regions except nam5 and eur3.\n### Cloud Key Management Service (KMS)\nGoogle Front End (GFE) prevented API requests from reaching the service.\n### Cloud Logging\nUnavailable for viewing in the Cloud Console, but data ingestion was not impacted.\n### Cloud Monitoring\nElevated error rates of uptime checks and requests to the Cloud Monitoring API\n### Cloud Compute Engine\nRequests to compute.googleapis.com would have seen an increase in 502 errors. Existing instances were not impacted.\n### Cloud Spanner\nCloud Spanner experienced elevated latency spikes which may have resulted in connection timeouts.\n### Game Servers\nMinor impact to cluster availability due to dependencies on other services.\n### Google Cloud Console\nMultiple pages and some core functionality of the Cloud Console impacted.\n### Google Cloud SQL\nMinor connectivity problems. Instance log reporting to stackdriver was delayed. There was a ~50% drop in SqlInstancesService.List API requests.\n### Google Kubernetes Engine\nMinor impact to cluster availability due to dependencies on other services.\n### Firebase Crashlytics\nFrom 18:00 - 18:24, Crashlytics imports from AWS were impacted. This created an import backlog which was quickly worked through 10 minutes after the incident ended.\nWe are conducting an internal investigation of this issue and will make appropriate improvements to our systems to help prevent or minimize future recurrence. We will provide a detailed report of this incident, including both GCP and G Suite impact, once we have completed our internal investigation. This detailed report will also contain information regarding SLA credits.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T02:31:43+00:00",
        "modified": "2020-09-25T02:31:43+00:00",
        "when": "2020-09-25T02:31:43+00:00",
        "text": "We believe the issue with multiple GCP products has been resolved for most traffic at 2020-09-24 18:33 US/Pacific.\nAffected products include: Cloud Run, Firestore Watch, Cloud SQL, Cloud Spanner, GKE, Cloud Logging, Cloud Monitoring, Cloud Console, Cloud KMS, Game Server\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T02:19:04+00:00",
        "modified": "2020-09-25T02:19:04+00:00",
        "when": "2020-09-25T02:19:04+00:00",
        "text": "Description: We are experiencing an issue with multiple GCP products, beginning at Thursday, 2020-09-24 17:58 US/Pacific.\nSymptoms: Increased error rate\nAffected products include: Cloud Run, Firestore Watch, Cloud SQL, Cloud Spanner, GKE, Cloud Logging, Cloud Monitoring, Cloud Console, Cloud KMS, Game Server\nMitigation work is currently underway by our engineering team.\nWe will provide an update by Thursday, 2020-09-24 20:00 US/Pacific with current details.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T02:05:57+00:00",
        "modified": "2020-09-25T02:05:57+00:00",
        "when": "2020-09-25T02:05:57+00:00",
        "text": "Description: We are experiencing an issue with multiple GCP products, beginning at Thursday, 2020-09-24 17:58 US/Pacific.\nSymptoms: Increased error rate.\nAffected products include: Cloud Run, Firestore Watch, Cloud SQL, Cloud Spanner, GKE, Cloud Logging, Cloud Monitoring, Cloud Console, Cloud KMS, Game Server\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2020-09-24 20:00 US/Pacific with current details.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T01:46:10+00:00",
        "modified": "2020-09-25T01:46:10+00:00",
        "when": "2020-09-25T01:46:10+00:00",
        "text": "Description: We are experiencing an issue with multiple GCP products, beginning at Thursday, 2020-09-24 17:58 US/Pacific.\nSymptoms: Increased error rate.\nAffected products include: Cloud Run, Firestore Watch, Cloud SQL, Cloud Spanner, GKE, Cloud Logging, Cloud Monitoring, Cloud Console\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2020-09-24 19:30 US/Pacific with current details.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T01:28:58+00:00",
        "modified": "2020-09-25T01:28:58+00:00",
        "when": "2020-09-25T01:28:58+00:00",
        "text": "Description: We are experiencing an issue with multiple GCP products.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2020-09-24 19:00 US/Pacific with current details.",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-10-01T04:55:05+00:00",
      "modified": "2020-10-08T15:12:37+00:00",
      "when": "2020-10-01T04:55:05+00:00",
      "text": "# BACKGROUND\nGoogle’s Global Service Load Balancer (GSLB) is a collection of software and services that load balance traffic across Google properties. There are two main components, a control plane, and a data plane. The control plane provides programming to the data plane on how to handle requests. A key component of the data plane is the Google Front End (GFE). The GFE is an HTTP/TCP reverse proxy which is used to serve requests to many Google properties including: Search, Ads, G Suite (Gmail, Chat, Meet, Docs, Drive, etc.), Cloud External HTTP(S) Load Balancing, Proxy/SSL Load Balancing, and many Cloud APIs.\nGoogle’s Global Load Balancers are implemented using a GFE architecture that has two tiers in some cases. The first tier of GFEs are situated as close to the user as possible to minimize latency during connection setup. First tier GFEs route requests either directly to applications, or in some cases to a second tier of GFEs providing additional functionality, before routing to applications. This architecture allows clients to have low latency connections anywhere in the world, while taking advantage of Google’s global network to serve requests to backends, regardless of region.\nThe pool of GFE instances which were impacted in this incident are part of the second tier, handling a subset of Google services. Therefore, this incident only impacted services routed through this specific pool.\n# ISSUE SUMMARY\nOn Thursday 24 September, 2020 at 18:00 US/Pacific, one of Google’s several second-tier GFE pools experienced intermittent failures resulting in impact to several downstream services. Almost all services recovered within the initial 33 minutes of the incident; exceptions are outlined in the detailed impact section below. Affected customers experienced elevated error rates and latency when connecting to Google APIs. Existing workloads (i.e. running instances on GCE, or containers on GKE) were not impacted unless they needed to invoke impacted APIs.\nService impact can be divided into two categories, direct and indirect. Services which have a request path that flows through the impacted GFE pool would have been directly impacted. Calls to these services would have experienced higher latency or elevated errors in the form of HTTP 502 response codes. Alternatively, services which did not directly rely on this pool of impacted GFEs may invoke other services, such as authentication, that depend on this shared pool of GFEs. This indirect impact would have varied between customers. One example of this, which we expect to be one of the most common forms of indirect impact, would be use of an oauth token that needed to be refreshed or retrieved. While a service such as Cloud Spanner may not have been serving errors, customers using the Cloud Spanner Client may have seen errors when the client attempted to refresh credentials, depending on the API used to refresh/obtain the credential. A detailed description of impact can be found below.\nTo our Cloud customers whose businesses were impacted during this disruption, we sincerely apologize – we have conducted a thorough internal investigation and are taking immediate action to improve the resiliency, performance, and availability of our services.\n# ROOT CAUSE\nFor any given pool of tasks, the GFE control plane has a global view of capacity, service configurations, and network conditions, which are all combined and sent to GFEs to create efficient request serving paths. This global view allows requests to be routed seamlessly to other regions, which is useful in scenarios like failover or for load balancing between regions. GFEs are grouped into pools for a variety of traffic profiles, health checking requirements, and other factors; the impacted second-layer GFE pool was used by multiple services.\nThe GFE control plane picks up service configuration changes and distributes them to GFEs. For this incident, two service changes contained an error that resulted in a significant increase in the number of backends accessed by GFEs in this pool. The particular nature of these changes additionally meant that they would be distributed to all GFEs in this pool globally, instead of being limited to a particular region. While the global aspect was intended, the magnitude of backend increases was not. The greatly increased number of programmed backends caused GFEs to exceed their memory allocation in many locations.\nGFE has many internal protections which are activated when there is memory pressure, such as closing idle connections or refusing to accept new connections, allowing them to keep running despite a memory shortage. Tasks which exceeded memory limits were terminated. The combination of a reduced number of available GFEs and a reduction in accepted connections meant that traffic to services behind the impacted GFE pool dropped by 50%.\n# REMEDIATION AND PREVENTION\nGoogle engineers were alerted to the outage three minutes after impact began at 2020-09-24 18:03, and immediately began an investigation. At 18:15 the first service change, which significantly increased the number of programmed backends, was rolled back. At 18:18 the second service configuration change was rolled back. Google engineers started seeing recovery at 18:20 and at 18:33 the issue was fully mitigated.\nGFE is one of the most critical pieces of infrastructure at Google and has multiple lines of defense in depth, both in software and operating procedure. As the result of this outage, we are adding additional protections to both in order to eliminate this class of failure. As an immediate step we have limited the type of configuration changes that can be made until additional safeguards are in place. Those additional safeguards will include stricter validation of configuration changes; specifically, rejecting changes that cause a large increase in backend count across multiple services. In addition to a check in the control plane, we will be augmenting existing protections in the GFE against unbounded growth in any resource dimension, such as backend counts. We will also be performing an audit of existing configurations and converting risky configurations to alternative setups. A restriction will be placed on certain configuration options, only allowing use with additional review and allow lists. Finally, an audit will be performed of services in shared GFE pools, with additional pools being created to reduce impact radius, should an issue in this part of the infrastructure surface again.\n# DETAILED DESCRIPTION OF IMPACT\nOn 2020-09-24 from 18:00 to 18:33 US/Pacific (unless otherwise noted) the following services were impacted globally:\n### OAuth\nThe following OAuth paths were impacted and returned errors for 50% of requests during the impact period. Impact perceived by customers may have been less as many client libraries make requests to these paths asynchronous to refresh tokens before they expire and retry their requests upon failure, potentially receiving successful responses: - oauth2.googleapis.com/token - accounts.google.com/o/oauth2/token - www.youtube.com/o/oauth2/token - www.googleapis.com/o/oauth2/token - www.googleapis.com/oauth2/{v3,v4}/token - accounts.{google,youtube}.com/o/oauth2/{revoke,device/code,tokeninfo} - www.googleapis.com/oauth2/v3/authadvice - www.googleapis.com/oauth2/v2/IssueToken - oauthaccountmanager.googleapis.com\n_\nThe following APIs were NOT affected: - www.googleapis.com/oauth2/{v1,v2,v3}/certs - contents.googleapis.com/oauth2/{v1,v2,v3}/certs - contents6.googleapis.com/oauth2/{v1,v2,v3}/certs - iamcredentials.googleapis.com and accounts.google.com (other than specific URLs mentioned above) were not affected.\n_\n### Chat\nGoogle Chat experienced an elevated rate of HTTP 500 & 502 errors (averaging 34%) between 18:00 and 18:04, decreasing to a 7% error rate from 18:04 to 18:14, with a mean latency of 500ms. This resulted in affected users being unable to load the Chat page or to send Chat messages.\n### Classic Hangouts\nClassic Hangouts experienced an elevated error rate of HTTP 500 errors (reducing Hangouts traffic by 44%) between 18:00 and 18:25. The service error rate was below 1% for Hangouts requests within the product, including sending messages.\n### Meet\nGoogle Meet experienced error rates up to 23% of requests between 18:02 and 18:23. Affected users observed call startup failures which affected 85% of session attempts. Existing Meet sessions were not affected.\n### Voice\nGoogle Voice experienced a 66% drop in traffic between 18:00 and 18:24. Additionally, the service had an elevated error rate below 1% between 18:01 and 18:14, and an average of 100% increase in mean latency between 18:03 and 18:12.\n### Calendar\nGoogle Calendar web traffic observed up to a 60% reduction in traffic, and an elevated HTTP 500 error rate of 4.8% between 18:01 and 18:06, which decreased to and remained below 1% for the remainder of the outage. Calendar API traffic observed up to a 53% reduction in traffic, with an average error rate of 2% for the same period. The traffic reduction corresponded with HTTP 500 errors being served to users.\n### Groups\nGoogle Groups web traffic dropped roughly 50% for the classic UI, and 30% for the new UI. Users experienced an average elevated HTTP 500 error rate between 0.12 and 3%.\n### Gmail\nGmail observed a 35% drop in traffic due to the GFE responding with HTTP 500 errors. The service error rate remained below 1% for the duration of the incident. This affected Gmail page loading and web interactions with the product.\n### Docs\nGoogle Docs witnessed a 33% drop in traffic between 18:00 and 18:23, corresponding with the GFE returning HTTP 500 errors to user interactions. Additionally, between 18:01 and 18:06 the service error rate rose to 1.4%, before decreasing and remaining at approximately 0.3% until 18:23.\n### Drive\nGoogle Drive observed a 60% traffic drop between 18:00 and 18:23, corresponding with the GFE returning HTTP 500 errors to user interactions. The Drive API experienced a peak error rate of 7% between 18:02 to 18:04, and then between 1% and 2% until 18:25. Google Drive web saw up to a 4% error rate between 18:01 and 18:06. 50th percentile latency was unaffected, but 95th percentile rose up to 1.3s between 18:02 and 18:06.\n### Cloud Bigtable\nSome clients using the impacted OAuth authentication methods described above were unable to refresh their credentials and thus unable to access Cloud Bigtable. Clients using alternative authentication methods were not impacted. Impacted clients experienced elevated error rates and latency. The main impact was to clients accessing Cloud Bigtable from outside of GCP, there was a 38% drop in this traffic during the impact period.\n### Cloud Build API\nCloud Build API experienced elevated error rates due to a 50% loss of incoming traffic over 26 minutes before reaching the service front end. Additionally, 4% of Cloud Builds failed due receiving errors from other Google services\n### Cloud Key Management Service (KMS)\nCloud KMS was unable to receive API requests from GFE for ~33 minutes starting at 18:00 impacting non-Customer Managed Encryption Key (CMEK) customers. CMEK customers were not impacted.\n### Cloud Logging\nCloud Logging experienced increased error rates (25% average, up to 40% at peak) from 18:05 to 18:50. Customers would have experienced errors when viewing logs in the Cloud Console. Data ingestion was not impacted.\n### Cloud Monitoring\nCloud Monitoring API experienced elevated error rates (50% average, up to 80% at peak) of uptime checks and requests from 18:00 - 18:26. This affected cloud uptime workers running uptime checks.\n### Cloud Networking API\nCloud Networking API experienced up to 50% error rate for Network Load Balancer Creation from 18:00 to 18:20 due to downstream service errors. Additionally up to 35% of HTTP(S) Load Balancer or TCP/SSL Proxy Load Balancer creation requests failed from 18:00 - 18:28 due to downstream service errors. Traffic for existing load balancers was unaffected.\n### Google Compute Engine API\nThe Google Compute Engine (GCE) API experienced an error rate of up to 50% from 18:00 - 18:25 with affected users experiencing HTTP 502 error response codes. This would have prevented loading the GCE portion of the Cloud Console as well listing, modifying, and creating GCE resources via other API clients. This applies only to the GCE API. GCE instance connectivity and availability was not impacted. Please note that some GCP services were served by the impacted GFE pool, so customer workloads running inside compute instances may have seen impact if they depend on other GCP services that experienced impact. Autoscaler continued to function nominally during the outage window.\n### Cloud Profiler\nCloud Profiler API experienced an elevated rate of HTTP 502 errors due to an up to 50% reduction in global traffic for all requests.\n### Cloud Run API\nCloud Run API experienced an elevated rate of HTTP 502 errors up to 70% from 18:00 to 18:30. Existing Cloud Run deployments were unaffected.\n### Cloud Spanner\nCloud Spanner clients experienced elevated error rates due to authentication issues which caused a 20% drop in traffic. Impacted customers saw increased latency and errors accessing Cloud Spanner. Clients using alternative authentication methods, such as GKE Workload Identity, were not impacted.\n### Game Servers\nGame Servers experienced elevated request latencies of up to 4x normal levels during the incident window, resulting in some clients experiencing connection timeouts and increased retry attempts. The service did not experience elevated error rates.\n### Google Cloud Console\n4.18% of customers experienced \"The attempted action failed\" error messages when attempting to load pages in the Cloud Console during the incident window. This prevented some customers from viewing the UI of networking, compute, billing, monitoring, and other products and services within the Cloud Console platform.\n### Google Cloud SQL\n0.08% of Cloud SQL's fleet experienced instance metrics and logging delays from 18:07 - 18:37 for a duration of 30 minutes. The Cloud SQL API did not serve errors during the outage, but incoming traffic dropped by ~30%. No spurious auto-failovers or auto-repairs were executed as a result of the incident. There were no actual instance failures.\n### Google Kubernetes Engine\nRequests to the Google Kubernetes Engine (GKE) control plane experienced increased timeouts and HTTP 502 error. Up to 6.6% of cluster masters reported errors during the time of the incident. Up to 5.5% of newly added nodes to clusters may have experienced errors due to issues communicating with impacted cluster masters.\n### Firebase Crashlytics\n66% of Crashlytics imports from AWS were impacted from 18:01 - 19:01 US/Pacific for a duration of 60 minutes. This created an import backlog which was quickly worked through 10 minutes after the incident ended.\n### Dialogflow and Speech-to-text API\nRequests to Dialogflow returned up to 72% errors in the form of HTTP 502 response codes. Requests to Google Speech API may have seen up to 68% errors in the form of HTTP 502 response codes.\n### Cloud Firestore and Datastore\nCloud Firestore saw 80% of listen streams become disconnected and up to 50% error rates for query/get requests across all regions except nam5 and eur3.\n# SLA CREDITS\nIf you believe your paid application experienced an SLA violation as a result of this incident, please populate the SLA credit request: https://support.google.com/cloud/contact/cloud_platform_sla\nA full list of all Google Cloud Platform Service Level Agreements can be found at https://cloud.google.com/terms/sla/.\nFor G Suite, please request an SLA credit through one of the Support channels: https://support.google.com/a/answer/104721\nG Suite Service Level Agreement can be found at https://gsuite.google.com/intl/en/terms/sla.html",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "uoypgc4GWUyzAKRHPjEv",
    "service_name": "Google Cloud Infrastructure Components",
    "affected_products": [
      {
        "title": "Google Cloud Infrastructure Components",
        "id": "uoypgc4GWUyzAKRHPjEv"
      }
    ],
    "uri": "incidents/gumoYCjdcDXv8xxmLBaW"
  },
  {
    "id": "vyu9LMTy4r87GehRH7B4",
    "number": "906177592348249136",
    "begin": "2020-09-25T00:58:00+00:00",
    "created": "2020-09-25T02:11:53+00:00",
    "end": "2020-09-25T01:33:00+00:00",
    "modified": "2020-09-25T02:35:20+00:00",
    "external_desc": "We are experiencing an issue with Cloud Networking.",
    "updates": [
      {
        "created": "2020-09-25T02:35:20+00:00",
        "modified": "2020-09-25T02:35:20+00:00",
        "when": "2020-09-25T02:35:20+00:00",
        "text": "Cloud Networking has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T02:11:53+00:00",
        "modified": "2020-09-25T02:11:53+00:00",
        "when": "2020-09-25T02:11:53+00:00",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-09-25T02:35:20+00:00",
      "modified": "2020-09-25T02:35:20+00:00",
      "when": "2020-09-25T02:35:20+00:00",
      "text": "Cloud Networking has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "VNJxzcH58QmTt5H6pnT6",
    "service_name": "Google Cloud Networking",
    "affected_products": [
      {
        "title": "Google Cloud Networking",
        "id": "VNJxzcH58QmTt5H6pnT6"
      }
    ],
    "uri": "incidents/vyu9LMTy4r87GehRH7B4"
  },
  {
    "id": "PKhasmT8Rn1hevQUoCTv",
    "number": "11997880250569502756",
    "begin": "2020-09-25T00:58:00+00:00",
    "created": "2020-09-25T01:56:49+00:00",
    "end": "2020-09-25T01:33:00+00:00",
    "modified": "2020-09-25T02:36:34+00:00",
    "external_desc": "We are experiencing an issue with Cloud Run.",
    "updates": [
      {
        "created": "2020-09-25T02:36:34+00:00",
        "modified": "2020-09-25T02:36:34+00:00",
        "when": "2020-09-25T02:36:34+00:00",
        "text": "Cloud Run has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T01:56:49+00:00",
        "modified": "2020-09-25T01:56:49+00:00",
        "when": "2020-09-25T01:56:49+00:00",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-09-25T02:36:34+00:00",
      "modified": "2020-09-25T02:36:34+00:00",
      "when": "2020-09-25T02:36:34+00:00",
      "text": "Cloud Run has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "9D7d2iNBQWN24zc1VamE",
    "service_name": "Cloud Run",
    "affected_products": [
      {
        "title": "Cloud Run",
        "id": "9D7d2iNBQWN24zc1VamE"
      }
    ],
    "uri": "incidents/PKhasmT8Rn1hevQUoCTv"
  },
  {
    "id": "tEA5oT681iGwzNTT1yXa",
    "number": "1861461441100758490",
    "begin": "2020-09-25T00:58:00+00:00",
    "created": "2020-09-25T01:58:18+00:00",
    "end": "2020-09-25T01:33:00+00:00",
    "modified": "2020-09-25T02:38:44+00:00",
    "external_desc": "We are experiencing an issue with Cloud SQL.",
    "updates": [
      {
        "created": "2020-09-25T02:38:44+00:00",
        "modified": "2020-09-25T02:38:44+00:00",
        "when": "2020-09-25T02:38:44+00:00",
        "text": "Cloud SQL has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T01:58:18+00:00",
        "modified": "2020-09-25T01:58:18+00:00",
        "when": "2020-09-25T01:58:18+00:00",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-09-25T02:38:44+00:00",
      "modified": "2020-09-25T02:38:44+00:00",
      "when": "2020-09-25T02:38:44+00:00",
      "text": "Cloud SQL has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "hV87iK5DcEXKgWU2kDri",
    "service_name": "Google Cloud SQL",
    "affected_products": [
      {
        "title": "Google Cloud SQL",
        "id": "hV87iK5DcEXKgWU2kDri"
      }
    ],
    "uri": "incidents/tEA5oT681iGwzNTT1yXa"
  },
  {
    "id": "TNAJyPwGkJYgSiqxcqsR",
    "number": "3425808731282158750",
    "begin": "2020-09-25T00:58:00+00:00",
    "created": "2020-09-25T01:59:12+00:00",
    "end": "2020-09-25T01:33:00+00:00",
    "modified": "2020-09-25T02:38:06+00:00",
    "external_desc": "We are experiencing an issue with Cloud Spanner.",
    "updates": [
      {
        "created": "2020-09-25T02:38:05+00:00",
        "modified": "2020-09-25T02:38:05+00:00",
        "when": "2020-09-25T02:38:05+00:00",
        "text": "Cloud Spanner has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T01:59:13+00:00",
        "modified": "2020-09-25T01:59:13+00:00",
        "when": "2020-09-25T01:59:13+00:00",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-09-25T02:38:05+00:00",
      "modified": "2020-09-25T02:38:05+00:00",
      "when": "2020-09-25T02:38:05+00:00",
      "text": "Cloud Spanner has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "EcNGGUgBtBLrtm4mWvqC",
    "service_name": "Cloud Spanner",
    "affected_products": [
      {
        "title": "Cloud Spanner",
        "id": "EcNGGUgBtBLrtm4mWvqC"
      }
    ],
    "uri": "incidents/TNAJyPwGkJYgSiqxcqsR"
  },
  {
    "id": "PXr1pcud4NBAN6wnTyAz",
    "number": "4060610444830342362",
    "begin": "2020-09-25T00:58:00+00:00",
    "created": "2020-09-25T02:02:34+00:00",
    "end": "2020-09-25T01:33:00+00:00",
    "modified": "2020-09-25T02:34:26+00:00",
    "external_desc": "We are experiencing an issue with Cloud KMS.",
    "updates": [
      {
        "created": "2020-09-25T02:25:37+00:00",
        "modified": "2020-09-25T02:32:28+00:00",
        "when": "2020-09-25T02:25:37+00:00",
        "text": "Cloud KMS has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T02:02:34+00:00",
        "modified": "2020-09-25T02:02:34+00:00",
        "when": "2020-09-25T02:02:34+00:00",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-09-25T02:25:37+00:00",
      "modified": "2020-09-25T02:32:28+00:00",
      "when": "2020-09-25T02:25:37+00:00",
      "text": "Cloud KMS has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "67cSySTL7dwJZo9JWUGU",
    "service_name": "Cloud Key Management Service",
    "affected_products": [
      {
        "title": "Cloud Key Management Service",
        "id": "67cSySTL7dwJZo9JWUGU"
      }
    ],
    "uri": "incidents/PXr1pcud4NBAN6wnTyAz"
  },
  {
    "id": "a3SJ5ueGVTX552VkN8oF",
    "number": "4769978148556814659",
    "begin": "2020-09-25T00:58:00+00:00",
    "created": "2020-09-25T02:00:49+00:00",
    "end": "2020-09-25T01:33:00+00:00",
    "modified": "2020-09-25T02:39:52+00:00",
    "external_desc": "We are experiencing an issue with Google Kubernetes Engine",
    "updates": [
      {
        "created": "2020-09-25T02:39:52+00:00",
        "modified": "2020-09-25T02:39:52+00:00",
        "when": "2020-09-25T02:39:52+00:00",
        "text": "Google Kubernetes Engine has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T02:00:49+00:00",
        "modified": "2020-09-25T02:00:49+00:00",
        "when": "2020-09-25T02:00:49+00:00",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-09-25T02:39:52+00:00",
      "modified": "2020-09-25T02:39:52+00:00",
      "when": "2020-09-25T02:39:52+00:00",
      "text": "Google Kubernetes Engine has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "LCSbT57h59oR4W98NHuz",
    "service_name": "Google Kubernetes Engine",
    "affected_products": [
      {
        "title": "Google Kubernetes Engine",
        "id": "LCSbT57h59oR4W98NHuz"
      }
    ],
    "uri": "incidents/a3SJ5ueGVTX552VkN8oF"
  },
  {
    "id": "hyfBtk7CBH2zLcJLcSXz",
    "number": "4140621108509172194",
    "begin": "2020-09-25T00:58:00+00:00",
    "created": "2020-09-25T02:04:44+00:00",
    "end": "2020-09-25T01:33:00+00:00",
    "modified": "2020-09-25T02:34:30+00:00",
    "external_desc": "We are experiencing an issue with Firestore.",
    "updates": [
      {
        "created": "2020-09-25T02:22:36+00:00",
        "modified": "2020-09-25T02:31:38+00:00",
        "when": "2020-09-25T02:22:36+00:00",
        "text": "Cloud FIrestore has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T02:04:44+00:00",
        "modified": "2020-09-25T02:04:44+00:00",
        "when": "2020-09-25T02:04:44+00:00",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-09-25T02:22:36+00:00",
      "modified": "2020-09-25T02:31:38+00:00",
      "when": "2020-09-25T02:22:36+00:00",
      "text": "Cloud FIrestore has been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "CETSkT92V21G6A1x28me",
    "service_name": "Cloud Firestore",
    "affected_products": [
      {
        "title": "Cloud Firestore",
        "id": "CETSkT92V21G6A1x28me"
      }
    ],
    "uri": "incidents/hyfBtk7CBH2zLcJLcSXz"
  },
  {
    "id": "YHqxsYdVr8A4hZTBBQu7",
    "number": "12508635328468412716",
    "begin": "2020-09-25T00:58:00+00:00",
    "created": "2020-09-25T02:08:06+00:00",
    "end": "2020-09-25T01:33:00+00:00",
    "modified": "2020-09-25T02:41:12+00:00",
    "external_desc": "We are experiencing an issue with Cloud Logging and Cloud Monitoring.",
    "updates": [
      {
        "created": "2020-09-25T02:41:12+00:00",
        "modified": "2020-09-25T02:41:12+00:00",
        "when": "2020-09-25T02:41:12+00:00",
        "text": "Cloud Monitoring and Cloud Logging have been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T02:08:06+00:00",
        "modified": "2020-09-25T02:08:06+00:00",
        "when": "2020-09-25T02:08:06+00:00",
        "text": "We are currently investigating an issue affecting multiple Cloud services.\nPlease view all status updates in https://status.cloud.google.com/incident/zall/20010",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-09-25T02:41:12+00:00",
      "modified": "2020-09-25T02:41:12+00:00",
      "when": "2020-09-25T02:41:12+00:00",
      "text": "Cloud Monitoring and Cloud Logging have been affected by the Google incident https://status.cloud.google.com/incident/zall/20010 since 2020-09-24 17:58 US/Pacific. The issue was resolved for most traffic at 2020-09-24 18:33 US/Pacific.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "DixAowEQm45KgqXKP5tR",
    "service_name": "Operations",
    "affected_products": [
      {
        "title": "Operations",
        "id": "DixAowEQm45KgqXKP5tR"
      }
    ],
    "uri": "incidents/YHqxsYdVr8A4hZTBBQu7"
  },
  {
    "id": "CPaCHnswG1BiQUNjXDXk",
    "number": "7553999531258965690",
    "begin": "2020-09-24T08:40:38+00:00",
    "created": "2020-09-24T08:50:11+00:00",
    "end": "2020-09-25T03:03:00+00:00",
    "modified": "2020-09-25T03:03:00+00:00",
    "external_desc": "Cloud Shell Connectivity Issues in asia-southeast1 and an issue with the Pricing UI not loading for some billing accounts with a custom price model has been resolved.",
    "updates": [
      {
        "created": "2020-09-25T03:03:00+00:00",
        "modified": "2020-09-25T03:03:00+00:00",
        "when": "2020-09-25T03:03:00+00:00",
        "text": "The issue with Cloud Shell has been resolved for all affected users as of Thursday, 2020-09-24 18:30 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
        "status": "AVAILABLE"
      },
      {
        "created": "2020-09-25T02:17:36+00:00",
        "modified": "2020-09-25T02:17:36+00:00",
        "when": "2020-09-25T02:17:36+00:00",
        "text": "Description: Cloud Shell Issue Description:\nWe are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. The investigation will take a few hours. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\nWe will provide an update by Thursday, 2020-09-24 23:30 US/Pacific with current details.\nDiagnosis: Cloud Shell Diagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\nWorkaround: Cloud Shell Workaround: As a workaround you can use gcloud sdk on your local command line.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-24T21:42:19+00:00",
        "modified": "2020-09-24T21:42:19+00:00",
        "when": "2020-09-24T21:42:19+00:00",
        "text": "Description: Cloud Shell Issue Description:\nWe are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. The investigation will take a few hours. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\nWe will provide an update by Thursday, 2020-09-24 18:30 US/Pacific with current details.\nDiagnosis: Cloud Shell Diagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\nWorkaround: Cloud Shell Workaround: As a workaround you can use gcloud sdk on your local command line.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-24T20:51:03+00:00",
        "modified": "2020-09-24T20:51:03+00:00",
        "when": "2020-09-24T20:51:03+00:00",
        "text": "Description: Cloud Shell Issue Description:\nWe are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\nCloud Console Billing UI Issue Description:\nCloud Console is experiencing an issue with Pricing UI page not loading for some billing accounts associated with a custom price model globally.\nWe are currently rolling back the code change that is responsible for this issue. We expect to complete this in the next hour.\nWe will provide an update by Thursday, 2020-09-24 15:00 US/Pacific with current details.\nDiagnosis: Cloud Shell Diagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\nCloud Console Billing UI Diagnosis:\nAffected customers' Billing UI page may not load properly.\nWorkaround: Cloud Shell Workaround: As a workaround you can use gcloud sdk on your local command line.\nCloud Billing UI Workaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-24T20:15:37+00:00",
        "modified": "2020-09-24T20:15:37+00:00",
        "when": "2020-09-24T20:15:37+00:00",
        "text": "Description: Cloud Shell Issue Description:\nWe are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\nCloud Console Billing UI Issue Description:\nAdditionally, Cloud Console is experiencing an issue with Pricing UI page not loading for some billing accounts associated with a custom price model globally.\nWe will provide an update by Thursday, 2020-09-24 14:00 US/Pacific with current details.\nDiagnosis: Cloud Shell Diagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\nCloud Console Billing UI Diagnosis:\nAffected customers' Billing UI page may not load properly.\nWorkaround: Cloud Shell Workaround: As a workaround you can use gcloud sdk on your local command line.\nCloud Billing UI Workaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-24T19:46:39+00:00",
        "modified": "2020-09-24T19:46:39+00:00",
        "when": "2020-09-24T19:46:39+00:00",
        "text": "Cloud Shell Issue Description:\nWe are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\nCloud Console Billing UI Issue Description:\nAdditionally, Cloud Console is experiencing an issue with Pricing UI page not loading for some billing accounts associated with a custom price model globally.\nWe will provide an update by Thursday, 2020-09-24 14:00 US/Pacific with current details.\nCloud Shell Diagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\nCloud Console Billing UI Diagnosis:\nAffected customers' Billing UI page may not load properly.\nCloud Shell Workaround: As a workaround you can use command line on your local machine.\nCloud Billing UI Workaround: None at this time.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-24T19:24:24+00:00",
        "modified": "2020-09-24T19:24:24+00:00",
        "when": "2020-09-24T19:24:24+00:00",
        "text": "Description: We are experiencing an issue with Cloud Shell in asia-southeast1. It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\nWe will provide an update by Thursday, 2020-09-24 13:30 US/Pacific with current details.\nDiagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\nWorkaround: As a workaround you can use command line on your local machine.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-24T17:28:24+00:00",
        "modified": "2020-09-24T17:28:24+00:00",
        "when": "2020-09-24T17:28:24+00:00",
        "text": "Description: It has been partially mitigated, but our engineering team has determined that further investigation is required to fully resolve the issue. Users might still encounter connectivity issues when starting new Cloud Shell sessions.\nWe will provide an update by Thursday, 2020-09-24 12:30 US/Pacific with current details.\nDiagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or connectivity errors when attempting to create a new Cloud Shell instance.\nWorkaround: As a workaround you can use command line on your local machine.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-24T16:22:44+00:00",
        "modified": "2020-09-24T16:22:44+00:00",
        "when": "2020-09-24T16:22:44+00:00",
        "text": "Description: A potential root cause has been identified, and we are working to have a mitigation rolled out.\nWe will provide more information by Thursday, 2020-09-24 10:30 US/Pacific.\nDiagnosis: Error message \"Cloud Shell is temporarily not available please try after some time\", or errors when attempting to create a new Cloud Shell instance.\nWorkaround: As a workaround you can use command line on your local machine.",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-24T13:51:42+00:00",
        "modified": "2020-09-24T13:51:42+00:00",
        "when": "2020-09-24T13:51:42+00:00",
        "text": "Description: Mitigation work is still underway by our engineering team.\nWe will provide more information by Thursday, 2020-09-24 09:26 US/Pacific.\nDiagnosis: Error message Cloud Shell is temporarily not available please try after some time\nWorkaround: As a workaround you can use command line on your local machine",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-24T12:35:26+00:00",
        "modified": "2020-09-24T12:35:26+00:00",
        "when": "2020-09-24T12:35:26+00:00",
        "text": "Description: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2020-09-24 07:01 US/Pacific.\nDiagnosis: Error message Cloud Shell is temporarily not available please try after some time\nWorkaround: As a workaround you can use command line on your local machine",
        "status": "SERVICE_DISRUPTION"
      },
      {
        "created": "2020-09-24T08:50:12+00:00",
        "modified": "2020-09-24T08:50:12+00:00",
        "when": "2020-09-24T08:50:12+00:00",
        "text": "Description: We are experiencing an issue with Cloud Shell in asia-southeast1 beginning at Wednesday, 2020-09-24 22:00:00 US/Pacific.\nSymptoms: error message Cloud Shell is temporarily not available please try after some time.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2020-09-24 06:00 US/Pacific with current details.\nDiagnosis: Error message Cloud Shell is temporarily not available please try after some time\nWorkaround: As a workaround you can use command line on your local machine",
        "status": "SERVICE_DISRUPTION"
      }
    ],
    "most_recent_update": {
      "created": "2020-09-25T03:03:00+00:00",
      "modified": "2020-09-25T03:03:00+00:00",
      "when": "2020-09-25T03:03:00+00:00",
      "text": "The issue with Cloud Shell has been resolved for all affected users as of Thursday, 2020-09-24 18:30 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.",
      "status": "AVAILABLE"
    },
    "status_impact": "SERVICE_DISRUPTION",
    "severity": "medium",
    "service_key": "Wdsr1n5vyDvCt78qEifm",
    "service_name": "Google Cloud Console",
    "affected_products": [
      {
        "title": "Google Cloud Console",
        "id": "Wdsr1n5vyDvCt78qEifm"
      }
    ],
    "uri": "incidents/CPaCHnswG1BiQUNjXDXk"
  }
]
